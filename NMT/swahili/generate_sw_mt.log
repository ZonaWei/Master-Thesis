nohup: ignoring input
/home/mwei/NMT_projects/MAenv/lib/python3.13/site-packages/peft/tuners/lora/bnb.py:93: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.
  warnings.warn(
--- 1. Loading base model and LoRA adapter ---
Loading LoRA adapter from: ./sw-25k-finetune/checkpoint-7815
--- Merging LoRA adapter into the base model ---
--- 2. Loading source test file: ./test_data/flores200_en.txt ---
--- 3. Generating translations ---
  0%|          | 0/64 [00:00<?, ?it/s]/home/mwei/NMT_projects/MAenv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
  2%|▏         | 1/64 [00:04<04:56,  4.70s/it]  3%|▎         | 2/64 [00:08<04:20,  4.20s/it]  5%|▍         | 3/64 [00:11<03:30,  3.45s/it]  6%|▋         | 4/64 [00:14<03:24,  3.41s/it]  8%|▊         | 5/64 [00:18<03:25,  3.48s/it]  9%|▉         | 6/64 [00:24<04:24,  4.57s/it] 11%|█         | 7/64 [00:28<03:59,  4.20s/it] 12%|█▎        | 8/64 [00:30<03:27,  3.71s/it] 14%|█▍        | 9/64 [00:33<03:04,  3.36s/it] 16%|█▌        | 10/64 [00:35<02:44,  3.05s/it] 17%|█▋        | 11/64 [00:42<03:41,  4.17s/it] 19%|█▉        | 12/64 [00:45<03:14,  3.74s/it] 20%|██        | 13/64 [00:49<03:18,  3.89s/it] 22%|██▏       | 14/64 [00:51<02:48,  3.38s/it] 23%|██▎       | 15/64 [00:54<02:33,  3.13s/it] 25%|██▌       | 16/64 [00:58<02:40,  3.35s/it] 27%|██▋       | 17/64 [01:00<02:30,  3.21s/it] 28%|██▊       | 18/64 [01:04<02:37,  3.42s/it] 30%|██▉       | 19/64 [01:08<02:32,  3.38s/it] 31%|███▏      | 20/64 [01:10<02:12,  3.02s/it] 33%|███▎      | 21/64 [01:13<02:10,  3.03s/it] 34%|███▍      | 22/64 [01:18<02:28,  3.54s/it] 36%|███▌      | 23/64 [01:20<02:09,  3.15s/it] 38%|███▊      | 24/64 [01:24<02:13,  3.35s/it] 39%|███▉      | 25/64 [01:27<02:04,  3.20s/it] 41%|████      | 26/64 [01:30<02:02,  3.23s/it] 42%|████▏     | 27/64 [01:33<02:00,  3.26s/it] 44%|████▍     | 28/64 [01:36<01:53,  3.15s/it] 45%|████▌     | 29/64 [01:43<02:27,  4.20s/it] 47%|████▋     | 30/64 [01:46<02:12,  3.91s/it] 48%|████▊     | 31/64 [01:50<02:08,  3.90s/it] 50%|█████     | 32/64 [01:53<01:57,  3.66s/it] 52%|█████▏    | 33/64 [01:55<01:43,  3.33s/it] 53%|█████▎    | 34/64 [01:58<01:34,  3.16s/it] 55%|█████▍    | 35/64 [02:03<01:47,  3.71s/it] 56%|█████▋    | 36/64 [02:06<01:35,  3.42s/it] 58%|█████▊    | 37/64 [02:08<01:23,  3.11s/it] 59%|█████▉    | 38/64 [02:11<01:16,  2.93s/it] 61%|██████    | 39/64 [02:13<01:10,  2.82s/it] 62%|██████▎   | 40/64 [02:16<01:05,  2.74s/it] 64%|██████▍   | 41/64 [02:18<00:56,  2.45s/it] 66%|██████▌   | 42/64 [02:20<00:54,  2.48s/it] 67%|██████▋   | 43/64 [02:23<00:56,  2.68s/it] 69%|██████▉   | 44/64 [02:27<01:00,  3.00s/it] 70%|███████   | 45/64 [02:30<00:56,  2.99s/it] 72%|███████▏  | 46/64 [02:33<00:51,  2.89s/it] 73%|███████▎  | 47/64 [02:36<00:50,  2.95s/it] 75%|███████▌  | 48/64 [02:39<00:45,  2.84s/it] 77%|███████▋  | 49/64 [02:45<00:59,  3.98s/it] 78%|███████▊  | 50/64 [02:48<00:49,  3.51s/it] 80%|███████▉  | 51/64 [02:50<00:40,  3.15s/it] 81%|████████▏ | 52/64 [02:52<00:35,  2.95s/it] 83%|████████▎ | 53/64 [02:56<00:33,  3.04s/it] 84%|████████▍ | 54/64 [02:58<00:29,  2.98s/it] 86%|████████▌ | 55/64 [03:01<00:25,  2.86s/it] 88%|████████▊ | 56/64 [03:03<00:21,  2.71s/it] 89%|████████▉ | 57/64 [03:06<00:18,  2.63s/it] 91%|█████████ | 58/64 [03:08<00:15,  2.52s/it] 92%|█████████▏| 59/64 [03:11<00:13,  2.68s/it] 94%|█████████▍| 60/64 [03:15<00:11,  2.93s/it] 95%|█████████▌| 61/64 [03:18<00:08,  2.92s/it] 97%|█████████▋| 62/64 [03:20<00:05,  2.80s/it] 98%|█████████▊| 63/64 [03:23<00:02,  2.83s/it]100%|██████████| 64/64 [03:25<00:00,  2.57s/it]100%|██████████| 64/64 [03:25<00:00,  3.21s/it]

--- 4. Calculating metrics ---
BLEU Score: 29.74
chrF++ Score: 58.00

--- 5. Machine Translation (MT) predictions successfully saved to: ./inflection/swahili_large_MT.txt ---

COMET not installed. Skipping. Install with: pip install unbabel-comet
