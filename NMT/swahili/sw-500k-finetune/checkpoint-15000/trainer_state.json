{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.839424,
  "eval_steps": 5000,
  "global_step": 15000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0128,
      "grad_norm": 0.12776857614517212,
      "learning_rate": 0.00019949833631942667,
      "loss": 2.4047,
      "step": 50
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.08772023022174835,
      "learning_rate": 0.00019898643460455594,
      "loss": 2.0865,
      "step": 100
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.09280034899711609,
      "learning_rate": 0.00019847453288968518,
      "loss": 2.0407,
      "step": 150
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.09427858144044876,
      "learning_rate": 0.00019796263117481444,
      "loss": 2.0435,
      "step": 200
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.0932098850607872,
      "learning_rate": 0.0001974507294599437,
      "loss": 2.0066,
      "step": 250
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.09434956312179565,
      "learning_rate": 0.00019693882774507294,
      "loss": 2.0016,
      "step": 300
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.10069625079631805,
      "learning_rate": 0.0001964269260302022,
      "loss": 2.0119,
      "step": 350
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.09423355013132095,
      "learning_rate": 0.00019591502431533147,
      "loss": 2.005,
      "step": 400
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.10349138081073761,
      "learning_rate": 0.0001954031226004607,
      "loss": 1.9808,
      "step": 450
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.0994051992893219,
      "learning_rate": 0.00019489122088558997,
      "loss": 2.01,
      "step": 500
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.09976089745759964,
      "learning_rate": 0.00019437931917071924,
      "loss": 1.9956,
      "step": 550
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.10117699950933456,
      "learning_rate": 0.0001938674174558485,
      "loss": 1.993,
      "step": 600
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.10844603925943375,
      "learning_rate": 0.00019335551574097774,
      "loss": 1.9915,
      "step": 650
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.10043200105428696,
      "learning_rate": 0.000192843614026107,
      "loss": 1.9882,
      "step": 700
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.10582122951745987,
      "learning_rate": 0.00019233171231123627,
      "loss": 1.9751,
      "step": 750
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.10351689904928207,
      "learning_rate": 0.0001918198105963655,
      "loss": 1.9975,
      "step": 800
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.10623613744974136,
      "learning_rate": 0.00019130790888149477,
      "loss": 2.0036,
      "step": 850
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.09992825984954834,
      "learning_rate": 0.00019079600716662403,
      "loss": 1.9761,
      "step": 900
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.10775794088840485,
      "learning_rate": 0.00019028410545175327,
      "loss": 2.02,
      "step": 950
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.09962191432714462,
      "learning_rate": 0.00018977220373688253,
      "loss": 1.9834,
      "step": 1000
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.10640667378902435,
      "learning_rate": 0.0001892603020220118,
      "loss": 1.9772,
      "step": 1050
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.09994716197252274,
      "learning_rate": 0.00018874840030714106,
      "loss": 2.0017,
      "step": 1100
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.10144593566656113,
      "learning_rate": 0.00018823649859227027,
      "loss": 1.9999,
      "step": 1150
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.10666812211275101,
      "learning_rate": 0.00018772459687739954,
      "loss": 1.9854,
      "step": 1200
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10702092200517654,
      "learning_rate": 0.0001872126951625288,
      "loss": 1.9671,
      "step": 1250
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.10654759407043457,
      "learning_rate": 0.00018670079344765804,
      "loss": 1.9894,
      "step": 1300
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.10723783075809479,
      "learning_rate": 0.0001861888917327873,
      "loss": 1.9921,
      "step": 1350
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.11013513803482056,
      "learning_rate": 0.00018567699001791657,
      "loss": 1.9966,
      "step": 1400
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.10324951261281967,
      "learning_rate": 0.00018516508830304583,
      "loss": 2.0116,
      "step": 1450
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.11099766194820404,
      "learning_rate": 0.00018465318658817507,
      "loss": 1.988,
      "step": 1500
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.10512222349643707,
      "learning_rate": 0.00018414128487330433,
      "loss": 1.9838,
      "step": 1550
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.11113092303276062,
      "learning_rate": 0.0001836293831584336,
      "loss": 1.9963,
      "step": 1600
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.11195182800292969,
      "learning_rate": 0.00018311748144356283,
      "loss": 1.9845,
      "step": 1650
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.1027967557311058,
      "learning_rate": 0.0001826055797286921,
      "loss": 1.995,
      "step": 1700
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.11006203293800354,
      "learning_rate": 0.00018209367801382136,
      "loss": 1.9863,
      "step": 1750
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.11143249273300171,
      "learning_rate": 0.0001815817762989506,
      "loss": 2.0032,
      "step": 1800
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.10810015350580215,
      "learning_rate": 0.00018106987458407986,
      "loss": 1.9561,
      "step": 1850
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.10382017493247986,
      "learning_rate": 0.00018055797286920913,
      "loss": 1.9727,
      "step": 1900
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.10749742388725281,
      "learning_rate": 0.0001800460711543384,
      "loss": 1.9631,
      "step": 1950
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.1188570037484169,
      "learning_rate": 0.00017953416943946763,
      "loss": 1.9616,
      "step": 2000
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.11087021976709366,
      "learning_rate": 0.0001790222677245969,
      "loss": 1.9937,
      "step": 2050
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.11312833428382874,
      "learning_rate": 0.00017851036600972616,
      "loss": 1.9642,
      "step": 2100
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.10643121600151062,
      "learning_rate": 0.0001779984642948554,
      "loss": 1.9885,
      "step": 2150
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.11331538110971451,
      "learning_rate": 0.00017748656257998466,
      "loss": 1.9869,
      "step": 2200
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.10669917613267899,
      "learning_rate": 0.00017697466086511392,
      "loss": 1.961,
      "step": 2250
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.11270427703857422,
      "learning_rate": 0.00017646275915024316,
      "loss": 1.9917,
      "step": 2300
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.1100756898522377,
      "learning_rate": 0.0001759508574353724,
      "loss": 1.9794,
      "step": 2350
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.11589960008859634,
      "learning_rate": 0.00017543895572050166,
      "loss": 1.9937,
      "step": 2400
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.10489202290773392,
      "learning_rate": 0.00017492705400563093,
      "loss": 1.9718,
      "step": 2450
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.10739452391862869,
      "learning_rate": 0.00017441515229076017,
      "loss": 1.9951,
      "step": 2500
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.10846120864152908,
      "learning_rate": 0.00017390325057588943,
      "loss": 2.0056,
      "step": 2550
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.10627059638500214,
      "learning_rate": 0.0001733913488610187,
      "loss": 1.9886,
      "step": 2600
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.13372443616390228,
      "learning_rate": 0.00017287944714614793,
      "loss": 1.9975,
      "step": 2650
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.11040057986974716,
      "learning_rate": 0.0001723675454312772,
      "loss": 1.9735,
      "step": 2700
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.10613962262868881,
      "learning_rate": 0.00017185564371640646,
      "loss": 1.9916,
      "step": 2750
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.11907161772251129,
      "learning_rate": 0.00017134374200153572,
      "loss": 1.991,
      "step": 2800
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.11326760798692703,
      "learning_rate": 0.00017083184028666496,
      "loss": 1.9639,
      "step": 2850
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.11766059696674347,
      "learning_rate": 0.00017031993857179423,
      "loss": 1.994,
      "step": 2900
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.11238425970077515,
      "learning_rate": 0.0001698080368569235,
      "loss": 1.9682,
      "step": 2950
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.11319658905267715,
      "learning_rate": 0.00016929613514205273,
      "loss": 1.9984,
      "step": 3000
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.11187569051980972,
      "learning_rate": 0.000168784233427182,
      "loss": 1.9949,
      "step": 3050
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.10565675050020218,
      "learning_rate": 0.00016827233171231126,
      "loss": 1.9832,
      "step": 3100
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.11098507046699524,
      "learning_rate": 0.0001677604299974405,
      "loss": 1.9836,
      "step": 3150
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.10627549141645432,
      "learning_rate": 0.00016724852828256976,
      "loss": 1.9831,
      "step": 3200
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.10792720317840576,
      "learning_rate": 0.00016673662656769902,
      "loss": 1.9951,
      "step": 3250
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.11007720232009888,
      "learning_rate": 0.00016622472485282829,
      "loss": 1.9809,
      "step": 3300
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.11001308262348175,
      "learning_rate": 0.00016571282313795752,
      "loss": 1.9782,
      "step": 3350
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.10890128463506699,
      "learning_rate": 0.0001652009214230868,
      "loss": 1.9822,
      "step": 3400
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.1092546209692955,
      "learning_rate": 0.00016468901970821605,
      "loss": 1.9796,
      "step": 3450
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.11691822856664658,
      "learning_rate": 0.00016417711799334526,
      "loss": 1.9682,
      "step": 3500
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.10545719414949417,
      "learning_rate": 0.00016366521627847453,
      "loss": 1.9854,
      "step": 3550
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.11316832900047302,
      "learning_rate": 0.0001631533145636038,
      "loss": 2.0079,
      "step": 3600
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.10748758167028427,
      "learning_rate": 0.00016264141284873305,
      "loss": 1.9683,
      "step": 3650
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.10955619812011719,
      "learning_rate": 0.0001621295111338623,
      "loss": 1.9814,
      "step": 3700
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.10625164210796356,
      "learning_rate": 0.00016161760941899156,
      "loss": 1.9972,
      "step": 3750
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.11160173267126083,
      "learning_rate": 0.00016110570770412082,
      "loss": 1.9582,
      "step": 3800
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.1093694418668747,
      "learning_rate": 0.00016059380598925006,
      "loss": 1.9975,
      "step": 3850
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.11405433714389801,
      "learning_rate": 0.00016008190427437932,
      "loss": 1.9523,
      "step": 3900
    },
    {
      "epoch": 1.011008,
      "grad_norm": 0.11508573591709137,
      "learning_rate": 0.00015957000255950859,
      "loss": 2.0014,
      "step": 3950
    },
    {
      "epoch": 1.023808,
      "grad_norm": 0.11170428991317749,
      "learning_rate": 0.00015905810084463782,
      "loss": 1.9857,
      "step": 4000
    },
    {
      "epoch": 1.036608,
      "grad_norm": 0.1128789559006691,
      "learning_rate": 0.0001585461991297671,
      "loss": 1.9974,
      "step": 4050
    },
    {
      "epoch": 1.049408,
      "grad_norm": 0.11463138461112976,
      "learning_rate": 0.00015803429741489635,
      "loss": 2.0006,
      "step": 4100
    },
    {
      "epoch": 1.062208,
      "grad_norm": 0.11575431376695633,
      "learning_rate": 0.00015752239570002562,
      "loss": 1.9597,
      "step": 4150
    },
    {
      "epoch": 1.075008,
      "grad_norm": 0.12202995270490646,
      "learning_rate": 0.00015701049398515485,
      "loss": 1.9778,
      "step": 4200
    },
    {
      "epoch": 1.0878079999999999,
      "grad_norm": 0.12262052297592163,
      "learning_rate": 0.00015649859227028412,
      "loss": 1.9837,
      "step": 4250
    },
    {
      "epoch": 1.100608,
      "grad_norm": 0.12188620865345001,
      "learning_rate": 0.00015598669055541338,
      "loss": 1.9827,
      "step": 4300
    },
    {
      "epoch": 1.113408,
      "grad_norm": 0.11083568632602692,
      "learning_rate": 0.00015547478884054262,
      "loss": 1.9734,
      "step": 4350
    },
    {
      "epoch": 1.126208,
      "grad_norm": 0.11644476652145386,
      "learning_rate": 0.00015496288712567188,
      "loss": 1.9607,
      "step": 4400
    },
    {
      "epoch": 1.139008,
      "grad_norm": 0.11367405951023102,
      "learning_rate": 0.00015445098541080115,
      "loss": 1.9883,
      "step": 4450
    },
    {
      "epoch": 1.151808,
      "grad_norm": 0.12092164903879166,
      "learning_rate": 0.00015393908369593039,
      "loss": 1.9726,
      "step": 4500
    },
    {
      "epoch": 1.164608,
      "grad_norm": 0.1195952519774437,
      "learning_rate": 0.00015342718198105965,
      "loss": 1.9798,
      "step": 4550
    },
    {
      "epoch": 1.177408,
      "grad_norm": 0.11427929997444153,
      "learning_rate": 0.00015291528026618891,
      "loss": 1.9796,
      "step": 4600
    },
    {
      "epoch": 1.190208,
      "grad_norm": 0.11159844696521759,
      "learning_rate": 0.00015240337855131815,
      "loss": 1.9656,
      "step": 4650
    },
    {
      "epoch": 1.203008,
      "grad_norm": 0.1179608553647995,
      "learning_rate": 0.0001518914768364474,
      "loss": 1.978,
      "step": 4700
    },
    {
      "epoch": 1.215808,
      "grad_norm": 0.12131062150001526,
      "learning_rate": 0.00015137957512157665,
      "loss": 1.9615,
      "step": 4750
    },
    {
      "epoch": 1.228608,
      "grad_norm": 0.12305980175733566,
      "learning_rate": 0.00015086767340670592,
      "loss": 1.973,
      "step": 4800
    },
    {
      "epoch": 1.241408,
      "grad_norm": 0.11026506870985031,
      "learning_rate": 0.00015035577169183515,
      "loss": 1.9988,
      "step": 4850
    },
    {
      "epoch": 1.254208,
      "grad_norm": 0.1335020363330841,
      "learning_rate": 0.00014984386997696442,
      "loss": 1.9977,
      "step": 4900
    },
    {
      "epoch": 1.2670080000000001,
      "grad_norm": 0.1245853379368782,
      "learning_rate": 0.00014933196826209368,
      "loss": 1.991,
      "step": 4950
    },
    {
      "epoch": 1.279808,
      "grad_norm": 0.11845096200704575,
      "learning_rate": 0.00014882006654722295,
      "loss": 1.9653,
      "step": 5000
    },
    {
      "epoch": 1.292608,
      "grad_norm": 0.11150467395782471,
      "learning_rate": 0.00014830816483235218,
      "loss": 1.9664,
      "step": 5050
    },
    {
      "epoch": 1.305408,
      "grad_norm": 0.11975403130054474,
      "learning_rate": 0.00014779626311748145,
      "loss": 1.977,
      "step": 5100
    },
    {
      "epoch": 1.318208,
      "grad_norm": 0.1216936707496643,
      "learning_rate": 0.0001472843614026107,
      "loss": 1.9832,
      "step": 5150
    },
    {
      "epoch": 1.331008,
      "grad_norm": 0.11903740465641022,
      "learning_rate": 0.00014677245968773995,
      "loss": 1.9893,
      "step": 5200
    },
    {
      "epoch": 1.3438080000000001,
      "grad_norm": 0.1104232594370842,
      "learning_rate": 0.00014626055797286921,
      "loss": 1.9763,
      "step": 5250
    },
    {
      "epoch": 1.356608,
      "grad_norm": 0.11086247116327286,
      "learning_rate": 0.00014574865625799848,
      "loss": 1.9661,
      "step": 5300
    },
    {
      "epoch": 1.369408,
      "grad_norm": 0.12139515578746796,
      "learning_rate": 0.00014523675454312772,
      "loss": 1.991,
      "step": 5350
    },
    {
      "epoch": 1.3822079999999999,
      "grad_norm": 0.10253070294857025,
      "learning_rate": 0.00014472485282825698,
      "loss": 1.9643,
      "step": 5400
    },
    {
      "epoch": 1.395008,
      "grad_norm": 0.1219511479139328,
      "learning_rate": 0.00014421295111338625,
      "loss": 1.9875,
      "step": 5450
    },
    {
      "epoch": 1.407808,
      "grad_norm": 0.11694992333650589,
      "learning_rate": 0.0001437010493985155,
      "loss": 1.9584,
      "step": 5500
    },
    {
      "epoch": 1.420608,
      "grad_norm": 0.11698873341083527,
      "learning_rate": 0.00014318914768364475,
      "loss": 1.9581,
      "step": 5550
    },
    {
      "epoch": 1.433408,
      "grad_norm": 0.10934054106473923,
      "learning_rate": 0.000142677245968774,
      "loss": 1.9605,
      "step": 5600
    },
    {
      "epoch": 1.446208,
      "grad_norm": 0.1317596733570099,
      "learning_rate": 0.00014216534425390328,
      "loss": 1.9644,
      "step": 5650
    },
    {
      "epoch": 1.459008,
      "grad_norm": 0.11666382849216461,
      "learning_rate": 0.0001416534425390325,
      "loss": 1.9616,
      "step": 5700
    },
    {
      "epoch": 1.471808,
      "grad_norm": 0.11072203516960144,
      "learning_rate": 0.00014114154082416178,
      "loss": 1.9816,
      "step": 5750
    },
    {
      "epoch": 1.484608,
      "grad_norm": 0.11933266371488571,
      "learning_rate": 0.00014062963910929104,
      "loss": 1.9743,
      "step": 5800
    },
    {
      "epoch": 1.497408,
      "grad_norm": 0.11711461842060089,
      "learning_rate": 0.00014011773739442028,
      "loss": 1.9609,
      "step": 5850
    },
    {
      "epoch": 1.510208,
      "grad_norm": 0.12179394066333771,
      "learning_rate": 0.00013960583567954952,
      "loss": 1.9812,
      "step": 5900
    },
    {
      "epoch": 1.523008,
      "grad_norm": 0.13119111955165863,
      "learning_rate": 0.00013909393396467878,
      "loss": 1.9765,
      "step": 5950
    },
    {
      "epoch": 1.5358079999999998,
      "grad_norm": 0.12273302674293518,
      "learning_rate": 0.00013858203224980804,
      "loss": 1.9606,
      "step": 6000
    },
    {
      "epoch": 1.548608,
      "grad_norm": 0.13117796182632446,
      "learning_rate": 0.00013807013053493728,
      "loss": 1.9812,
      "step": 6050
    },
    {
      "epoch": 1.5614080000000001,
      "grad_norm": 0.12052684277296066,
      "learning_rate": 0.00013755822882006655,
      "loss": 1.9717,
      "step": 6100
    },
    {
      "epoch": 1.574208,
      "grad_norm": 0.1164250299334526,
      "learning_rate": 0.0001370463271051958,
      "loss": 1.9798,
      "step": 6150
    },
    {
      "epoch": 1.587008,
      "grad_norm": 0.1229502409696579,
      "learning_rate": 0.00013653442539032505,
      "loss": 1.9715,
      "step": 6200
    },
    {
      "epoch": 1.599808,
      "grad_norm": 0.12110541015863419,
      "learning_rate": 0.0001360225236754543,
      "loss": 1.9685,
      "step": 6250
    },
    {
      "epoch": 1.612608,
      "grad_norm": 0.10656557232141495,
      "learning_rate": 0.00013551062196058358,
      "loss": 1.9824,
      "step": 6300
    },
    {
      "epoch": 1.625408,
      "grad_norm": 0.12254111468791962,
      "learning_rate": 0.00013499872024571284,
      "loss": 1.9653,
      "step": 6350
    },
    {
      "epoch": 1.638208,
      "grad_norm": 0.11488639563322067,
      "learning_rate": 0.00013448681853084208,
      "loss": 1.9882,
      "step": 6400
    },
    {
      "epoch": 1.651008,
      "grad_norm": 0.11615224182605743,
      "learning_rate": 0.00013397491681597134,
      "loss": 1.9865,
      "step": 6450
    },
    {
      "epoch": 1.663808,
      "grad_norm": 0.11727690696716309,
      "learning_rate": 0.0001334630151011006,
      "loss": 1.9581,
      "step": 6500
    },
    {
      "epoch": 1.6766079999999999,
      "grad_norm": 0.13231153786182404,
      "learning_rate": 0.00013295111338622984,
      "loss": 1.984,
      "step": 6550
    },
    {
      "epoch": 1.689408,
      "grad_norm": 0.11528357863426208,
      "learning_rate": 0.0001324392116713591,
      "loss": 1.9819,
      "step": 6600
    },
    {
      "epoch": 1.7022080000000002,
      "grad_norm": 0.13374540209770203,
      "learning_rate": 0.00013192730995648837,
      "loss": 1.9781,
      "step": 6650
    },
    {
      "epoch": 1.715008,
      "grad_norm": 0.11330275982618332,
      "learning_rate": 0.0001314154082416176,
      "loss": 1.9537,
      "step": 6700
    },
    {
      "epoch": 1.727808,
      "grad_norm": 0.12152128666639328,
      "learning_rate": 0.00013090350652674687,
      "loss": 2.0008,
      "step": 6750
    },
    {
      "epoch": 1.740608,
      "grad_norm": 0.11891337484121323,
      "learning_rate": 0.00013039160481187614,
      "loss": 1.9897,
      "step": 6800
    },
    {
      "epoch": 1.7534079999999999,
      "grad_norm": 0.12387853860855103,
      "learning_rate": 0.0001298797030970054,
      "loss": 1.9722,
      "step": 6850
    },
    {
      "epoch": 1.766208,
      "grad_norm": 0.12455694377422333,
      "learning_rate": 0.00012936780138213464,
      "loss": 1.9982,
      "step": 6900
    },
    {
      "epoch": 1.7790080000000001,
      "grad_norm": 0.10987143963575363,
      "learning_rate": 0.0001288558996672639,
      "loss": 1.9429,
      "step": 6950
    },
    {
      "epoch": 1.791808,
      "grad_norm": 0.11001572757959366,
      "learning_rate": 0.00012834399795239314,
      "loss": 1.9519,
      "step": 7000
    },
    {
      "epoch": 1.804608,
      "grad_norm": 0.12427855283021927,
      "learning_rate": 0.0001278320962375224,
      "loss": 1.9572,
      "step": 7050
    },
    {
      "epoch": 1.817408,
      "grad_norm": 0.11856727302074432,
      "learning_rate": 0.00012732019452265164,
      "loss": 1.9814,
      "step": 7100
    },
    {
      "epoch": 1.8302079999999998,
      "grad_norm": 0.11061318963766098,
      "learning_rate": 0.0001268082928077809,
      "loss": 1.9679,
      "step": 7150
    },
    {
      "epoch": 1.843008,
      "grad_norm": 0.12266626209020615,
      "learning_rate": 0.00012629639109291017,
      "loss": 1.9821,
      "step": 7200
    },
    {
      "epoch": 1.8558080000000001,
      "grad_norm": 0.12359634041786194,
      "learning_rate": 0.0001257844893780394,
      "loss": 1.9482,
      "step": 7250
    },
    {
      "epoch": 1.868608,
      "grad_norm": 0.12651902437210083,
      "learning_rate": 0.00012527258766316867,
      "loss": 1.9503,
      "step": 7300
    },
    {
      "epoch": 1.881408,
      "grad_norm": 0.1175343468785286,
      "learning_rate": 0.00012476068594829794,
      "loss": 1.9622,
      "step": 7350
    },
    {
      "epoch": 1.894208,
      "grad_norm": 0.1252260059118271,
      "learning_rate": 0.00012424878423342717,
      "loss": 1.9575,
      "step": 7400
    },
    {
      "epoch": 1.907008,
      "grad_norm": 0.12183551490306854,
      "learning_rate": 0.00012373688251855644,
      "loss": 1.9651,
      "step": 7450
    },
    {
      "epoch": 1.919808,
      "grad_norm": 0.12256187200546265,
      "learning_rate": 0.0001232249808036857,
      "loss": 1.9578,
      "step": 7500
    },
    {
      "epoch": 1.932608,
      "grad_norm": 0.10919918119907379,
      "learning_rate": 0.00012271307908881494,
      "loss": 1.9648,
      "step": 7550
    },
    {
      "epoch": 1.945408,
      "grad_norm": 0.1094730794429779,
      "learning_rate": 0.0001222011773739442,
      "loss": 2.0018,
      "step": 7600
    },
    {
      "epoch": 1.958208,
      "grad_norm": 0.129462331533432,
      "learning_rate": 0.00012168927565907347,
      "loss": 1.9609,
      "step": 7650
    },
    {
      "epoch": 1.9710079999999999,
      "grad_norm": 0.1146572157740593,
      "learning_rate": 0.00012117737394420272,
      "loss": 1.9606,
      "step": 7700
    },
    {
      "epoch": 1.983808,
      "grad_norm": 0.11175089329481125,
      "learning_rate": 0.00012066547222933198,
      "loss": 1.969,
      "step": 7750
    },
    {
      "epoch": 1.9966080000000002,
      "grad_norm": 0.11695479601621628,
      "learning_rate": 0.00012015357051446123,
      "loss": 1.9647,
      "step": 7800
    },
    {
      "epoch": 2.009216,
      "grad_norm": 0.11883815377950668,
      "learning_rate": 0.00011964166879959049,
      "loss": 1.9792,
      "step": 7850
    },
    {
      "epoch": 2.022016,
      "grad_norm": 0.12307341396808624,
      "learning_rate": 0.00011912976708471975,
      "loss": 1.9684,
      "step": 7900
    },
    {
      "epoch": 2.034816,
      "grad_norm": 0.11995202302932739,
      "learning_rate": 0.000118617865369849,
      "loss": 1.9619,
      "step": 7950
    },
    {
      "epoch": 2.047616,
      "grad_norm": 0.11728060990571976,
      "learning_rate": 0.00011810596365497825,
      "loss": 1.9779,
      "step": 8000
    },
    {
      "epoch": 2.060416,
      "grad_norm": 0.1249001994729042,
      "learning_rate": 0.00011759406194010752,
      "loss": 1.9814,
      "step": 8050
    },
    {
      "epoch": 2.073216,
      "grad_norm": 0.11749758571386337,
      "learning_rate": 0.00011708216022523677,
      "loss": 1.9491,
      "step": 8100
    },
    {
      "epoch": 2.086016,
      "grad_norm": 0.12871544063091278,
      "learning_rate": 0.00011657025851036603,
      "loss": 1.9672,
      "step": 8150
    },
    {
      "epoch": 2.098816,
      "grad_norm": 0.11934535950422287,
      "learning_rate": 0.00011605835679549525,
      "loss": 1.9827,
      "step": 8200
    },
    {
      "epoch": 2.111616,
      "grad_norm": 0.13377122581005096,
      "learning_rate": 0.00011554645508062452,
      "loss": 1.9732,
      "step": 8250
    },
    {
      "epoch": 2.124416,
      "grad_norm": 0.12323366105556488,
      "learning_rate": 0.00011503455336575377,
      "loss": 1.9534,
      "step": 8300
    },
    {
      "epoch": 2.137216,
      "grad_norm": 0.11973417550325394,
      "learning_rate": 0.00011452265165088303,
      "loss": 1.99,
      "step": 8350
    },
    {
      "epoch": 2.150016,
      "grad_norm": 0.117780901491642,
      "learning_rate": 0.00011401074993601228,
      "loss": 1.9641,
      "step": 8400
    },
    {
      "epoch": 2.162816,
      "grad_norm": 0.13030120730400085,
      "learning_rate": 0.00011349884822114154,
      "loss": 1.959,
      "step": 8450
    },
    {
      "epoch": 2.1756159999999998,
      "grad_norm": 0.1230497881770134,
      "learning_rate": 0.0001129869465062708,
      "loss": 1.9569,
      "step": 8500
    },
    {
      "epoch": 2.188416,
      "grad_norm": 0.12635983526706696,
      "learning_rate": 0.00011247504479140005,
      "loss": 1.9427,
      "step": 8550
    },
    {
      "epoch": 2.201216,
      "grad_norm": 0.12621361017227173,
      "learning_rate": 0.00011196314307652931,
      "loss": 1.9638,
      "step": 8600
    },
    {
      "epoch": 2.214016,
      "grad_norm": 0.11878605931997299,
      "learning_rate": 0.00011145124136165857,
      "loss": 1.9588,
      "step": 8650
    },
    {
      "epoch": 2.226816,
      "grad_norm": 0.12738628685474396,
      "learning_rate": 0.00011093933964678782,
      "loss": 1.946,
      "step": 8700
    },
    {
      "epoch": 2.239616,
      "grad_norm": 0.12281110137701035,
      "learning_rate": 0.00011042743793191708,
      "loss": 1.9694,
      "step": 8750
    },
    {
      "epoch": 2.252416,
      "grad_norm": 0.1259886622428894,
      "learning_rate": 0.00010991553621704633,
      "loss": 1.9839,
      "step": 8800
    },
    {
      "epoch": 2.265216,
      "grad_norm": 0.1321735382080078,
      "learning_rate": 0.0001094036345021756,
      "loss": 1.9732,
      "step": 8850
    },
    {
      "epoch": 2.278016,
      "grad_norm": 0.13270998001098633,
      "learning_rate": 0.00010889173278730485,
      "loss": 1.9484,
      "step": 8900
    },
    {
      "epoch": 2.290816,
      "grad_norm": 0.1195446327328682,
      "learning_rate": 0.0001083798310724341,
      "loss": 1.9711,
      "step": 8950
    },
    {
      "epoch": 2.303616,
      "grad_norm": 0.14041823148727417,
      "learning_rate": 0.00010786792935756336,
      "loss": 1.9556,
      "step": 9000
    },
    {
      "epoch": 2.316416,
      "grad_norm": 0.12844502925872803,
      "learning_rate": 0.00010735602764269261,
      "loss": 1.9587,
      "step": 9050
    },
    {
      "epoch": 2.329216,
      "grad_norm": 0.12904828786849976,
      "learning_rate": 0.00010684412592782186,
      "loss": 1.9619,
      "step": 9100
    },
    {
      "epoch": 2.342016,
      "grad_norm": 0.12149620801210403,
      "learning_rate": 0.00010633222421295113,
      "loss": 1.9602,
      "step": 9150
    },
    {
      "epoch": 2.354816,
      "grad_norm": 0.11608989536762238,
      "learning_rate": 0.00010582032249808038,
      "loss": 1.9692,
      "step": 9200
    },
    {
      "epoch": 2.367616,
      "grad_norm": 0.13492897152900696,
      "learning_rate": 0.00010530842078320964,
      "loss": 1.9617,
      "step": 9250
    },
    {
      "epoch": 2.380416,
      "grad_norm": 0.12785787880420685,
      "learning_rate": 0.0001047965190683389,
      "loss": 1.9918,
      "step": 9300
    },
    {
      "epoch": 2.393216,
      "grad_norm": 0.12791907787322998,
      "learning_rate": 0.00010428461735346813,
      "loss": 1.9803,
      "step": 9350
    },
    {
      "epoch": 2.406016,
      "grad_norm": 0.12563934922218323,
      "learning_rate": 0.00010377271563859738,
      "loss": 1.9933,
      "step": 9400
    },
    {
      "epoch": 2.418816,
      "grad_norm": 0.12134047597646713,
      "learning_rate": 0.00010326081392372665,
      "loss": 1.9699,
      "step": 9450
    },
    {
      "epoch": 2.431616,
      "grad_norm": 0.1297237128019333,
      "learning_rate": 0.0001027489122088559,
      "loss": 1.9654,
      "step": 9500
    },
    {
      "epoch": 2.444416,
      "grad_norm": 0.13229180872440338,
      "learning_rate": 0.00010223701049398515,
      "loss": 1.9495,
      "step": 9550
    },
    {
      "epoch": 2.457216,
      "grad_norm": 0.1300443559885025,
      "learning_rate": 0.00010172510877911441,
      "loss": 1.9595,
      "step": 9600
    },
    {
      "epoch": 2.470016,
      "grad_norm": 0.12721030414104462,
      "learning_rate": 0.00010121320706424366,
      "loss": 1.9685,
      "step": 9650
    },
    {
      "epoch": 2.482816,
      "grad_norm": 0.1284370869398117,
      "learning_rate": 0.00010070130534937293,
      "loss": 1.9614,
      "step": 9700
    },
    {
      "epoch": 2.495616,
      "grad_norm": 0.12413085252046585,
      "learning_rate": 0.00010018940363450218,
      "loss": 1.9656,
      "step": 9750
    },
    {
      "epoch": 2.508416,
      "grad_norm": 0.12754443287849426,
      "learning_rate": 9.967750191963143e-05,
      "loss": 1.9638,
      "step": 9800
    },
    {
      "epoch": 2.521216,
      "grad_norm": 0.12485195696353912,
      "learning_rate": 9.916560020476069e-05,
      "loss": 1.9676,
      "step": 9850
    },
    {
      "epoch": 2.5340160000000003,
      "grad_norm": 0.12280993908643723,
      "learning_rate": 9.865369848988994e-05,
      "loss": 1.9728,
      "step": 9900
    },
    {
      "epoch": 2.5468159999999997,
      "grad_norm": 0.1457461714744568,
      "learning_rate": 9.814179677501921e-05,
      "loss": 1.9774,
      "step": 9950
    },
    {
      "epoch": 2.559616,
      "grad_norm": 0.14032740890979767,
      "learning_rate": 9.762989506014846e-05,
      "loss": 1.9668,
      "step": 10000
    },
    {
      "epoch": 2.572416,
      "grad_norm": 0.13336120545864105,
      "learning_rate": 9.711799334527771e-05,
      "loss": 1.9758,
      "step": 10050
    },
    {
      "epoch": 2.585216,
      "grad_norm": 0.1324584037065506,
      "learning_rate": 9.660609163040697e-05,
      "loss": 1.9529,
      "step": 10100
    },
    {
      "epoch": 2.598016,
      "grad_norm": 0.11677328497171402,
      "learning_rate": 9.609418991553622e-05,
      "loss": 1.9607,
      "step": 10150
    },
    {
      "epoch": 2.610816,
      "grad_norm": 0.12061172723770142,
      "learning_rate": 9.558228820066549e-05,
      "loss": 1.9526,
      "step": 10200
    },
    {
      "epoch": 2.623616,
      "grad_norm": 0.12552791833877563,
      "learning_rate": 9.507038648579473e-05,
      "loss": 1.9487,
      "step": 10250
    },
    {
      "epoch": 2.636416,
      "grad_norm": 0.12527255713939667,
      "learning_rate": 9.455848477092398e-05,
      "loss": 1.9479,
      "step": 10300
    },
    {
      "epoch": 2.649216,
      "grad_norm": 0.13633988797664642,
      "learning_rate": 9.404658305605324e-05,
      "loss": 1.9759,
      "step": 10350
    },
    {
      "epoch": 2.662016,
      "grad_norm": 0.12539666891098022,
      "learning_rate": 9.353468134118249e-05,
      "loss": 1.9556,
      "step": 10400
    },
    {
      "epoch": 2.674816,
      "grad_norm": 0.12774498760700226,
      "learning_rate": 9.302277962631176e-05,
      "loss": 1.9692,
      "step": 10450
    },
    {
      "epoch": 2.6876160000000002,
      "grad_norm": 0.12357871234416962,
      "learning_rate": 9.2510877911441e-05,
      "loss": 1.9791,
      "step": 10500
    },
    {
      "epoch": 2.700416,
      "grad_norm": 0.1207105815410614,
      "learning_rate": 9.199897619657026e-05,
      "loss": 1.9814,
      "step": 10550
    },
    {
      "epoch": 2.713216,
      "grad_norm": 0.12441639602184296,
      "learning_rate": 9.148707448169952e-05,
      "loss": 1.9657,
      "step": 10600
    },
    {
      "epoch": 2.726016,
      "grad_norm": 0.12611711025238037,
      "learning_rate": 9.097517276682877e-05,
      "loss": 1.9851,
      "step": 10650
    },
    {
      "epoch": 2.738816,
      "grad_norm": 0.1279035210609436,
      "learning_rate": 9.046327105195804e-05,
      "loss": 1.9672,
      "step": 10700
    },
    {
      "epoch": 2.751616,
      "grad_norm": 0.11566575616598129,
      "learning_rate": 8.995136933708729e-05,
      "loss": 1.9677,
      "step": 10750
    },
    {
      "epoch": 2.7644159999999998,
      "grad_norm": 0.12333325296640396,
      "learning_rate": 8.943946762221654e-05,
      "loss": 1.9726,
      "step": 10800
    },
    {
      "epoch": 2.777216,
      "grad_norm": 0.12015390396118164,
      "learning_rate": 8.892756590734579e-05,
      "loss": 1.97,
      "step": 10850
    },
    {
      "epoch": 2.790016,
      "grad_norm": 0.11369010806083679,
      "learning_rate": 8.841566419247504e-05,
      "loss": 1.9602,
      "step": 10900
    },
    {
      "epoch": 2.802816,
      "grad_norm": 0.11674965173006058,
      "learning_rate": 8.79037624776043e-05,
      "loss": 1.9833,
      "step": 10950
    },
    {
      "epoch": 2.815616,
      "grad_norm": 0.129603773355484,
      "learning_rate": 8.739186076273355e-05,
      "loss": 1.9787,
      "step": 11000
    },
    {
      "epoch": 2.828416,
      "grad_norm": 0.13007941842079163,
      "learning_rate": 8.687995904786282e-05,
      "loss": 1.9624,
      "step": 11050
    },
    {
      "epoch": 2.841216,
      "grad_norm": 0.11227510869503021,
      "learning_rate": 8.636805733299207e-05,
      "loss": 1.9737,
      "step": 11100
    },
    {
      "epoch": 2.854016,
      "grad_norm": 0.11910870671272278,
      "learning_rate": 8.585615561812132e-05,
      "loss": 1.9521,
      "step": 11150
    },
    {
      "epoch": 2.866816,
      "grad_norm": 0.13272015750408173,
      "learning_rate": 8.534425390325059e-05,
      "loss": 1.958,
      "step": 11200
    },
    {
      "epoch": 2.879616,
      "grad_norm": 0.12417547404766083,
      "learning_rate": 8.483235218837984e-05,
      "loss": 1.9759,
      "step": 11250
    },
    {
      "epoch": 2.892416,
      "grad_norm": 0.1635272353887558,
      "learning_rate": 8.43204504735091e-05,
      "loss": 1.98,
      "step": 11300
    },
    {
      "epoch": 2.9052160000000002,
      "grad_norm": 0.1234307587146759,
      "learning_rate": 8.380854875863835e-05,
      "loss": 1.9609,
      "step": 11350
    },
    {
      "epoch": 2.918016,
      "grad_norm": 0.1271170973777771,
      "learning_rate": 8.32966470437676e-05,
      "loss": 1.9666,
      "step": 11400
    },
    {
      "epoch": 2.930816,
      "grad_norm": 0.11927071213722229,
      "learning_rate": 8.278474532889685e-05,
      "loss": 1.972,
      "step": 11450
    },
    {
      "epoch": 2.943616,
      "grad_norm": 0.1200292631983757,
      "learning_rate": 8.22728436140261e-05,
      "loss": 1.9593,
      "step": 11500
    },
    {
      "epoch": 2.956416,
      "grad_norm": 0.11899605393409729,
      "learning_rate": 8.176094189915537e-05,
      "loss": 1.9594,
      "step": 11550
    },
    {
      "epoch": 2.969216,
      "grad_norm": 0.1314619928598404,
      "learning_rate": 8.124904018428462e-05,
      "loss": 1.9648,
      "step": 11600
    },
    {
      "epoch": 2.982016,
      "grad_norm": 0.12068735808134079,
      "learning_rate": 8.073713846941387e-05,
      "loss": 1.9649,
      "step": 11650
    },
    {
      "epoch": 2.994816,
      "grad_norm": 0.1291370391845703,
      "learning_rate": 8.022523675454313e-05,
      "loss": 1.9742,
      "step": 11700
    },
    {
      "epoch": 3.007424,
      "grad_norm": 0.1231311783194542,
      "learning_rate": 7.971333503967238e-05,
      "loss": 1.9652,
      "step": 11750
    },
    {
      "epoch": 3.020224,
      "grad_norm": 0.134357750415802,
      "learning_rate": 7.920143332480165e-05,
      "loss": 1.9808,
      "step": 11800
    },
    {
      "epoch": 3.033024,
      "grad_norm": 0.12963071465492249,
      "learning_rate": 7.86895316099309e-05,
      "loss": 1.9754,
      "step": 11850
    },
    {
      "epoch": 3.045824,
      "grad_norm": 0.13100038468837738,
      "learning_rate": 7.817762989506015e-05,
      "loss": 1.9621,
      "step": 11900
    },
    {
      "epoch": 3.058624,
      "grad_norm": 0.13028094172477722,
      "learning_rate": 7.766572818018941e-05,
      "loss": 1.9418,
      "step": 11950
    },
    {
      "epoch": 3.071424,
      "grad_norm": 0.1296229213476181,
      "learning_rate": 7.715382646531865e-05,
      "loss": 1.9597,
      "step": 12000
    },
    {
      "epoch": 3.084224,
      "grad_norm": 0.1238752156496048,
      "learning_rate": 7.664192475044792e-05,
      "loss": 1.9674,
      "step": 12050
    },
    {
      "epoch": 3.097024,
      "grad_norm": 0.12760356068611145,
      "learning_rate": 7.613002303557717e-05,
      "loss": 1.9513,
      "step": 12100
    },
    {
      "epoch": 3.109824,
      "grad_norm": 0.13595154881477356,
      "learning_rate": 7.561812132070643e-05,
      "loss": 1.9633,
      "step": 12150
    },
    {
      "epoch": 3.122624,
      "grad_norm": 0.13883724808692932,
      "learning_rate": 7.510621960583568e-05,
      "loss": 1.9548,
      "step": 12200
    },
    {
      "epoch": 3.135424,
      "grad_norm": 0.11349375545978546,
      "learning_rate": 7.459431789096493e-05,
      "loss": 1.9559,
      "step": 12250
    },
    {
      "epoch": 3.148224,
      "grad_norm": 0.1197819858789444,
      "learning_rate": 7.40824161760942e-05,
      "loss": 1.9708,
      "step": 12300
    },
    {
      "epoch": 3.161024,
      "grad_norm": 0.14849373698234558,
      "learning_rate": 7.357051446122345e-05,
      "loss": 1.9766,
      "step": 12350
    },
    {
      "epoch": 3.173824,
      "grad_norm": 0.12081290036439896,
      "learning_rate": 7.305861274635271e-05,
      "loss": 1.9469,
      "step": 12400
    },
    {
      "epoch": 3.186624,
      "grad_norm": 0.14037641882896423,
      "learning_rate": 7.254671103148196e-05,
      "loss": 1.9831,
      "step": 12450
    },
    {
      "epoch": 3.199424,
      "grad_norm": 0.13864083588123322,
      "learning_rate": 7.203480931661121e-05,
      "loss": 1.9782,
      "step": 12500
    },
    {
      "epoch": 3.212224,
      "grad_norm": 0.13423481583595276,
      "learning_rate": 7.152290760174048e-05,
      "loss": 1.9549,
      "step": 12550
    },
    {
      "epoch": 3.225024,
      "grad_norm": 0.1325918287038803,
      "learning_rate": 7.101100588686972e-05,
      "loss": 1.9595,
      "step": 12600
    },
    {
      "epoch": 3.237824,
      "grad_norm": 0.1439184993505478,
      "learning_rate": 7.049910417199898e-05,
      "loss": 1.9392,
      "step": 12650
    },
    {
      "epoch": 3.250624,
      "grad_norm": 0.13265389204025269,
      "learning_rate": 6.998720245712823e-05,
      "loss": 1.9813,
      "step": 12700
    },
    {
      "epoch": 3.263424,
      "grad_norm": 0.12298312038183212,
      "learning_rate": 6.947530074225748e-05,
      "loss": 1.9443,
      "step": 12750
    },
    {
      "epoch": 3.276224,
      "grad_norm": 0.12768244743347168,
      "learning_rate": 6.896339902738675e-05,
      "loss": 1.9503,
      "step": 12800
    },
    {
      "epoch": 3.289024,
      "grad_norm": 0.12347497045993805,
      "learning_rate": 6.8451497312516e-05,
      "loss": 1.9728,
      "step": 12850
    },
    {
      "epoch": 3.301824,
      "grad_norm": 0.11852968484163284,
      "learning_rate": 6.793959559764526e-05,
      "loss": 1.9685,
      "step": 12900
    },
    {
      "epoch": 3.3146240000000002,
      "grad_norm": 0.1383204162120819,
      "learning_rate": 6.742769388277451e-05,
      "loss": 1.9651,
      "step": 12950
    },
    {
      "epoch": 3.327424,
      "grad_norm": 0.14295314252376556,
      "learning_rate": 6.691579216790376e-05,
      "loss": 1.9804,
      "step": 13000
    },
    {
      "epoch": 3.340224,
      "grad_norm": 0.13114836812019348,
      "learning_rate": 6.640389045303303e-05,
      "loss": 1.9868,
      "step": 13050
    },
    {
      "epoch": 3.353024,
      "grad_norm": 0.1254286915063858,
      "learning_rate": 6.589198873816228e-05,
      "loss": 1.9684,
      "step": 13100
    },
    {
      "epoch": 3.365824,
      "grad_norm": 0.14635862410068512,
      "learning_rate": 6.538008702329154e-05,
      "loss": 1.9626,
      "step": 13150
    },
    {
      "epoch": 3.378624,
      "grad_norm": 0.12110601365566254,
      "learning_rate": 6.486818530842078e-05,
      "loss": 1.9435,
      "step": 13200
    },
    {
      "epoch": 3.3914239999999998,
      "grad_norm": 0.13311044871807098,
      "learning_rate": 6.435628359355004e-05,
      "loss": 1.959,
      "step": 13250
    },
    {
      "epoch": 3.404224,
      "grad_norm": 0.15353892743587494,
      "learning_rate": 6.38443818786793e-05,
      "loss": 1.9632,
      "step": 13300
    },
    {
      "epoch": 3.417024,
      "grad_norm": 0.12498675286769867,
      "learning_rate": 6.333248016380854e-05,
      "loss": 1.9826,
      "step": 13350
    },
    {
      "epoch": 3.429824,
      "grad_norm": 0.14439141750335693,
      "learning_rate": 6.282057844893781e-05,
      "loss": 1.9509,
      "step": 13400
    },
    {
      "epoch": 3.442624,
      "grad_norm": 0.13672758638858795,
      "learning_rate": 6.230867673406706e-05,
      "loss": 1.9693,
      "step": 13450
    },
    {
      "epoch": 3.455424,
      "grad_norm": 0.1364138126373291,
      "learning_rate": 6.179677501919632e-05,
      "loss": 1.9545,
      "step": 13500
    },
    {
      "epoch": 3.468224,
      "grad_norm": 0.13508149981498718,
      "learning_rate": 6.128487330432557e-05,
      "loss": 1.9501,
      "step": 13550
    },
    {
      "epoch": 3.481024,
      "grad_norm": 0.12761728465557098,
      "learning_rate": 6.077297158945483e-05,
      "loss": 1.9455,
      "step": 13600
    },
    {
      "epoch": 3.493824,
      "grad_norm": 0.1274581402540207,
      "learning_rate": 6.026106987458408e-05,
      "loss": 1.9592,
      "step": 13650
    },
    {
      "epoch": 3.506624,
      "grad_norm": 0.13822244107723236,
      "learning_rate": 5.974916815971334e-05,
      "loss": 1.9456,
      "step": 13700
    },
    {
      "epoch": 3.519424,
      "grad_norm": 0.12341953814029694,
      "learning_rate": 5.92372664448426e-05,
      "loss": 1.9529,
      "step": 13750
    },
    {
      "epoch": 3.5322240000000003,
      "grad_norm": 0.14223110675811768,
      "learning_rate": 5.872536472997184e-05,
      "loss": 1.9836,
      "step": 13800
    },
    {
      "epoch": 3.5450239999999997,
      "grad_norm": 0.133437842130661,
      "learning_rate": 5.82134630151011e-05,
      "loss": 1.9497,
      "step": 13850
    },
    {
      "epoch": 3.557824,
      "grad_norm": 0.11731118708848953,
      "learning_rate": 5.770156130023036e-05,
      "loss": 1.9569,
      "step": 13900
    },
    {
      "epoch": 3.570624,
      "grad_norm": 0.12970256805419922,
      "learning_rate": 5.7189659585359615e-05,
      "loss": 1.951,
      "step": 13950
    },
    {
      "epoch": 3.583424,
      "grad_norm": 0.12294124066829681,
      "learning_rate": 5.6677757870488865e-05,
      "loss": 1.9519,
      "step": 14000
    },
    {
      "epoch": 3.596224,
      "grad_norm": 0.12668372690677643,
      "learning_rate": 5.616585615561812e-05,
      "loss": 1.9593,
      "step": 14050
    },
    {
      "epoch": 3.609024,
      "grad_norm": 0.12990476191043854,
      "learning_rate": 5.565395444074738e-05,
      "loss": 1.9478,
      "step": 14100
    },
    {
      "epoch": 3.621824,
      "grad_norm": 0.1342759132385254,
      "learning_rate": 5.514205272587664e-05,
      "loss": 1.9565,
      "step": 14150
    },
    {
      "epoch": 3.634624,
      "grad_norm": 0.13025203347206116,
      "learning_rate": 5.4630151011005896e-05,
      "loss": 1.9655,
      "step": 14200
    },
    {
      "epoch": 3.647424,
      "grad_norm": 0.13414247334003448,
      "learning_rate": 5.4118249296135146e-05,
      "loss": 1.9714,
      "step": 14250
    },
    {
      "epoch": 3.660224,
      "grad_norm": 0.12586286664009094,
      "learning_rate": 5.3606347581264404e-05,
      "loss": 1.9555,
      "step": 14300
    },
    {
      "epoch": 3.673024,
      "grad_norm": 0.14158400893211365,
      "learning_rate": 5.309444586639365e-05,
      "loss": 1.9886,
      "step": 14350
    },
    {
      "epoch": 3.685824,
      "grad_norm": 0.12772135436534882,
      "learning_rate": 5.2582544151522905e-05,
      "loss": 1.9671,
      "step": 14400
    },
    {
      "epoch": 3.698624,
      "grad_norm": 0.12333209812641144,
      "learning_rate": 5.207064243665216e-05,
      "loss": 1.9858,
      "step": 14450
    },
    {
      "epoch": 3.711424,
      "grad_norm": 0.12050411105155945,
      "learning_rate": 5.155874072178142e-05,
      "loss": 1.9526,
      "step": 14500
    },
    {
      "epoch": 3.724224,
      "grad_norm": 0.12431298196315765,
      "learning_rate": 5.104683900691067e-05,
      "loss": 1.9617,
      "step": 14550
    },
    {
      "epoch": 3.737024,
      "grad_norm": 0.13974317908287048,
      "learning_rate": 5.053493729203993e-05,
      "loss": 1.9788,
      "step": 14600
    },
    {
      "epoch": 3.7498240000000003,
      "grad_norm": 0.13084863126277924,
      "learning_rate": 5.0023035577169186e-05,
      "loss": 1.9589,
      "step": 14650
    },
    {
      "epoch": 3.7626239999999997,
      "grad_norm": 0.1419890969991684,
      "learning_rate": 4.9511133862298444e-05,
      "loss": 1.9544,
      "step": 14700
    },
    {
      "epoch": 3.775424,
      "grad_norm": 0.1487315595149994,
      "learning_rate": 4.89992321474277e-05,
      "loss": 1.969,
      "step": 14750
    },
    {
      "epoch": 3.788224,
      "grad_norm": 0.14095990359783173,
      "learning_rate": 4.8487330432556946e-05,
      "loss": 1.9445,
      "step": 14800
    },
    {
      "epoch": 3.801024,
      "grad_norm": 0.13577239215373993,
      "learning_rate": 4.79754287176862e-05,
      "loss": 1.9405,
      "step": 14850
    },
    {
      "epoch": 3.813824,
      "grad_norm": 0.1357572227716446,
      "learning_rate": 4.746352700281546e-05,
      "loss": 1.9763,
      "step": 14900
    },
    {
      "epoch": 3.826624,
      "grad_norm": 0.12415075302124023,
      "learning_rate": 4.695162528794472e-05,
      "loss": 1.9517,
      "step": 14950
    },
    {
      "epoch": 3.839424,
      "grad_norm": 0.14721570909023285,
      "learning_rate": 4.6439723573073976e-05,
      "loss": 1.9877,
      "step": 15000
    }
  ],
  "logging_steps": 50,
  "max_steps": 19535,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.75941481689514e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
