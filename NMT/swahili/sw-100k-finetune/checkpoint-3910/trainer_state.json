{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 5000,
  "global_step": 3910,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.064,
      "grad_norm": 0.1144385039806366,
      "learning_rate": 0.00019749360613810743,
      "loss": 2.387,
      "step": 50
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.08432962745428085,
      "learning_rate": 0.00019493606138107418,
      "loss": 2.07,
      "step": 100
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.08865402638912201,
      "learning_rate": 0.00019237851662404093,
      "loss": 2.0385,
      "step": 150
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.09342767298221588,
      "learning_rate": 0.00018982097186700768,
      "loss": 2.0168,
      "step": 200
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0904431864619255,
      "learning_rate": 0.00018726342710997444,
      "loss": 2.026,
      "step": 250
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.09986984729766846,
      "learning_rate": 0.0001847058823529412,
      "loss": 2.0187,
      "step": 300
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.10594289749860764,
      "learning_rate": 0.00018214833759590794,
      "loss": 2.0237,
      "step": 350
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.10283902287483215,
      "learning_rate": 0.0001795907928388747,
      "loss": 2.0055,
      "step": 400
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.10290664434432983,
      "learning_rate": 0.00017703324808184142,
      "loss": 1.9984,
      "step": 450
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1030336320400238,
      "learning_rate": 0.00017447570332480817,
      "loss": 2.0108,
      "step": 500
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.10275525599718094,
      "learning_rate": 0.00017191815856777492,
      "loss": 2.0055,
      "step": 550
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.10312476009130478,
      "learning_rate": 0.00016936061381074167,
      "loss": 1.9731,
      "step": 600
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.09813260287046432,
      "learning_rate": 0.00016680306905370843,
      "loss": 2.026,
      "step": 650
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.09872998297214508,
      "learning_rate": 0.00016424552429667518,
      "loss": 1.9949,
      "step": 700
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.10679169744253159,
      "learning_rate": 0.00016168797953964193,
      "loss": 1.9957,
      "step": 750
    },
    {
      "epoch": 1.02304,
      "grad_norm": 0.11372392624616623,
      "learning_rate": 0.00015913043478260868,
      "loss": 1.9949,
      "step": 800
    },
    {
      "epoch": 1.08704,
      "grad_norm": 0.10565389692783356,
      "learning_rate": 0.00015657289002557543,
      "loss": 2.0133,
      "step": 850
    },
    {
      "epoch": 1.15104,
      "grad_norm": 0.10204342752695084,
      "learning_rate": 0.00015401534526854219,
      "loss": 1.9732,
      "step": 900
    },
    {
      "epoch": 1.2150400000000001,
      "grad_norm": 0.10755802690982819,
      "learning_rate": 0.00015145780051150894,
      "loss": 1.9882,
      "step": 950
    },
    {
      "epoch": 1.27904,
      "grad_norm": 0.09686943888664246,
      "learning_rate": 0.0001489002557544757,
      "loss": 2.001,
      "step": 1000
    },
    {
      "epoch": 1.34304,
      "grad_norm": 0.11227152496576309,
      "learning_rate": 0.00014634271099744244,
      "loss": 1.9763,
      "step": 1050
    },
    {
      "epoch": 1.40704,
      "grad_norm": 0.11746396869421005,
      "learning_rate": 0.00014378516624040922,
      "loss": 1.9934,
      "step": 1100
    },
    {
      "epoch": 1.47104,
      "grad_norm": 0.11451490968465805,
      "learning_rate": 0.00014122762148337597,
      "loss": 1.9717,
      "step": 1150
    },
    {
      "epoch": 1.53504,
      "grad_norm": 0.11043866723775864,
      "learning_rate": 0.00013867007672634273,
      "loss": 1.991,
      "step": 1200
    },
    {
      "epoch": 1.59904,
      "grad_norm": 0.10777568817138672,
      "learning_rate": 0.00013611253196930948,
      "loss": 2.0082,
      "step": 1250
    },
    {
      "epoch": 1.66304,
      "grad_norm": 0.11415136605501175,
      "learning_rate": 0.00013355498721227623,
      "loss": 2.0121,
      "step": 1300
    },
    {
      "epoch": 1.7270400000000001,
      "grad_norm": 0.11581166833639145,
      "learning_rate": 0.00013099744245524298,
      "loss": 1.9954,
      "step": 1350
    },
    {
      "epoch": 1.79104,
      "grad_norm": 0.10961873829364777,
      "learning_rate": 0.00012843989769820973,
      "loss": 1.9592,
      "step": 1400
    },
    {
      "epoch": 1.85504,
      "grad_norm": 0.11312862485647202,
      "learning_rate": 0.0001258823529411765,
      "loss": 1.9969,
      "step": 1450
    },
    {
      "epoch": 1.9190399999999999,
      "grad_norm": 0.1217251718044281,
      "learning_rate": 0.00012332480818414324,
      "loss": 1.9775,
      "step": 1500
    },
    {
      "epoch": 1.98304,
      "grad_norm": 0.11554869264364243,
      "learning_rate": 0.00012076726342710998,
      "loss": 1.9785,
      "step": 1550
    },
    {
      "epoch": 2.04608,
      "grad_norm": 0.12377709895372391,
      "learning_rate": 0.00011820971867007673,
      "loss": 1.9639,
      "step": 1600
    },
    {
      "epoch": 2.11008,
      "grad_norm": 0.11925437301397324,
      "learning_rate": 0.00011565217391304348,
      "loss": 1.9882,
      "step": 1650
    },
    {
      "epoch": 2.17408,
      "grad_norm": 0.12109269946813583,
      "learning_rate": 0.00011309462915601023,
      "loss": 1.9718,
      "step": 1700
    },
    {
      "epoch": 2.23808,
      "grad_norm": 0.1216239258646965,
      "learning_rate": 0.00011053708439897699,
      "loss": 1.9849,
      "step": 1750
    },
    {
      "epoch": 2.30208,
      "grad_norm": 0.12175723165273666,
      "learning_rate": 0.00010797953964194374,
      "loss": 1.9728,
      "step": 1800
    },
    {
      "epoch": 2.36608,
      "grad_norm": 0.11959265917539597,
      "learning_rate": 0.00010542199488491049,
      "loss": 1.9825,
      "step": 1850
    },
    {
      "epoch": 2.4300800000000002,
      "grad_norm": 0.12798672914505005,
      "learning_rate": 0.00010286445012787724,
      "loss": 2.003,
      "step": 1900
    },
    {
      "epoch": 2.49408,
      "grad_norm": 0.11426295340061188,
      "learning_rate": 0.000100306905370844,
      "loss": 1.9613,
      "step": 1950
    },
    {
      "epoch": 2.55808,
      "grad_norm": 0.11522825807332993,
      "learning_rate": 9.774936061381075e-05,
      "loss": 1.9846,
      "step": 2000
    },
    {
      "epoch": 2.62208,
      "grad_norm": 0.12819567322731018,
      "learning_rate": 9.51918158567775e-05,
      "loss": 1.9665,
      "step": 2050
    },
    {
      "epoch": 2.68608,
      "grad_norm": 0.12750646471977234,
      "learning_rate": 9.263427109974425e-05,
      "loss": 1.9768,
      "step": 2100
    },
    {
      "epoch": 2.75008,
      "grad_norm": 0.12562350928783417,
      "learning_rate": 9.0076726342711e-05,
      "loss": 1.993,
      "step": 2150
    },
    {
      "epoch": 2.81408,
      "grad_norm": 0.1318930685520172,
      "learning_rate": 8.751918158567776e-05,
      "loss": 1.9832,
      "step": 2200
    },
    {
      "epoch": 2.8780799999999997,
      "grad_norm": 0.11832817643880844,
      "learning_rate": 8.496163682864451e-05,
      "loss": 1.9679,
      "step": 2250
    },
    {
      "epoch": 2.94208,
      "grad_norm": 0.13497333228588104,
      "learning_rate": 8.240409207161126e-05,
      "loss": 1.9922,
      "step": 2300
    },
    {
      "epoch": 3.00512,
      "grad_norm": 0.12002777308225632,
      "learning_rate": 7.984654731457801e-05,
      "loss": 1.9972,
      "step": 2350
    },
    {
      "epoch": 3.06912,
      "grad_norm": 0.1257631927728653,
      "learning_rate": 7.728900255754476e-05,
      "loss": 1.9645,
      "step": 2400
    },
    {
      "epoch": 3.13312,
      "grad_norm": 0.12134335190057755,
      "learning_rate": 7.473145780051152e-05,
      "loss": 1.9657,
      "step": 2450
    },
    {
      "epoch": 3.19712,
      "grad_norm": 0.12571829557418823,
      "learning_rate": 7.217391304347827e-05,
      "loss": 1.9996,
      "step": 2500
    },
    {
      "epoch": 3.26112,
      "grad_norm": 0.14227549731731415,
      "learning_rate": 6.9616368286445e-05,
      "loss": 1.974,
      "step": 2550
    },
    {
      "epoch": 3.32512,
      "grad_norm": 0.1293974369764328,
      "learning_rate": 6.705882352941176e-05,
      "loss": 1.9703,
      "step": 2600
    },
    {
      "epoch": 3.38912,
      "grad_norm": 0.1276392787694931,
      "learning_rate": 6.450127877237851e-05,
      "loss": 1.9601,
      "step": 2650
    },
    {
      "epoch": 3.45312,
      "grad_norm": 0.13229350745677948,
      "learning_rate": 6.194373401534526e-05,
      "loss": 1.9683,
      "step": 2700
    },
    {
      "epoch": 3.5171200000000002,
      "grad_norm": 0.13048869371414185,
      "learning_rate": 5.938618925831202e-05,
      "loss": 1.9799,
      "step": 2750
    },
    {
      "epoch": 3.58112,
      "grad_norm": 0.1399778425693512,
      "learning_rate": 5.6828644501278774e-05,
      "loss": 1.9778,
      "step": 2800
    },
    {
      "epoch": 3.64512,
      "grad_norm": 0.1307513266801834,
      "learning_rate": 5.4271099744245526e-05,
      "loss": 1.9726,
      "step": 2850
    },
    {
      "epoch": 3.70912,
      "grad_norm": 0.12600257992744446,
      "learning_rate": 5.171355498721228e-05,
      "loss": 1.9743,
      "step": 2900
    },
    {
      "epoch": 3.77312,
      "grad_norm": 0.12652555108070374,
      "learning_rate": 4.915601023017903e-05,
      "loss": 1.9862,
      "step": 2950
    },
    {
      "epoch": 3.83712,
      "grad_norm": 0.12848392128944397,
      "learning_rate": 4.659846547314578e-05,
      "loss": 1.9802,
      "step": 3000
    },
    {
      "epoch": 3.90112,
      "grad_norm": 0.12741060554981232,
      "learning_rate": 4.4040920716112535e-05,
      "loss": 1.9831,
      "step": 3050
    },
    {
      "epoch": 3.9651199999999998,
      "grad_norm": 0.13330033421516418,
      "learning_rate": 4.148337595907929e-05,
      "loss": 1.9821,
      "step": 3100
    },
    {
      "epoch": 4.02816,
      "grad_norm": 0.12484509497880936,
      "learning_rate": 3.892583120204604e-05,
      "loss": 1.9492,
      "step": 3150
    },
    {
      "epoch": 4.09216,
      "grad_norm": 0.1288534700870514,
      "learning_rate": 3.636828644501279e-05,
      "loss": 1.9905,
      "step": 3200
    },
    {
      "epoch": 4.15616,
      "grad_norm": 0.14303573966026306,
      "learning_rate": 3.3810741687979543e-05,
      "loss": 1.9648,
      "step": 3250
    },
    {
      "epoch": 4.22016,
      "grad_norm": 0.13531926274299622,
      "learning_rate": 3.1253196930946296e-05,
      "loss": 1.9853,
      "step": 3300
    },
    {
      "epoch": 4.28416,
      "grad_norm": 0.1298294961452484,
      "learning_rate": 2.8695652173913044e-05,
      "loss": 1.9498,
      "step": 3350
    },
    {
      "epoch": 4.34816,
      "grad_norm": 0.1274322122335434,
      "learning_rate": 2.6138107416879796e-05,
      "loss": 1.9888,
      "step": 3400
    },
    {
      "epoch": 4.41216,
      "grad_norm": 0.13379396498203278,
      "learning_rate": 2.358056265984655e-05,
      "loss": 1.9844,
      "step": 3450
    },
    {
      "epoch": 4.47616,
      "grad_norm": 0.131545752286911,
      "learning_rate": 2.10230179028133e-05,
      "loss": 1.9548,
      "step": 3500
    },
    {
      "epoch": 4.54016,
      "grad_norm": 0.13137350976467133,
      "learning_rate": 1.8465473145780053e-05,
      "loss": 1.9941,
      "step": 3550
    },
    {
      "epoch": 4.60416,
      "grad_norm": 0.1331770420074463,
      "learning_rate": 1.5907928388746805e-05,
      "loss": 1.961,
      "step": 3600
    },
    {
      "epoch": 4.66816,
      "grad_norm": 0.13041408360004425,
      "learning_rate": 1.3350383631713556e-05,
      "loss": 1.974,
      "step": 3650
    },
    {
      "epoch": 4.73216,
      "grad_norm": 0.13536334037780762,
      "learning_rate": 1.0792838874680308e-05,
      "loss": 1.9616,
      "step": 3700
    },
    {
      "epoch": 4.79616,
      "grad_norm": 0.13251042366027832,
      "learning_rate": 8.23529411764706e-06,
      "loss": 1.9742,
      "step": 3750
    },
    {
      "epoch": 4.8601600000000005,
      "grad_norm": 0.13099518418312073,
      "learning_rate": 5.677749360613811e-06,
      "loss": 1.9724,
      "step": 3800
    },
    {
      "epoch": 4.92416,
      "grad_norm": 0.14097002148628235,
      "learning_rate": 3.120204603580563e-06,
      "loss": 1.9685,
      "step": 3850
    },
    {
      "epoch": 4.98816,
      "grad_norm": 0.13821010291576385,
      "learning_rate": 5.626598465473146e-07,
      "loss": 1.9847,
      "step": 3900
    }
  ],
  "logging_steps": 50,
  "max_steps": 3910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.586159765402419e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
