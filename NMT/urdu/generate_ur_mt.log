nohup: ignoring input
/home/mwei/NMT_projects/MAenv/lib/python3.13/site-packages/peft/tuners/lora/bnb.py:93: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.
  warnings.warn(
--- 1. Loading base model and LoRA adapter ---
Loading LoRA adapter from: ./ur-25k-finetune/checkpoint-7815
--- Merging LoRA adapter into the base model ---
--- 2. Loading source test file: ./test_data/flores200_en.txt ---
--- 3. Generating translations ---
  0%|          | 0/64 [00:00<?, ?it/s]/home/mwei/NMT_projects/MAenv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
  2%|▏         | 1/64 [00:03<03:43,  3.54s/it]  3%|▎         | 2/64 [00:05<02:56,  2.85s/it]  5%|▍         | 3/64 [00:07<02:21,  2.32s/it]  6%|▋         | 4/64 [00:09<02:09,  2.16s/it]  8%|▊         | 5/64 [00:11<02:06,  2.14s/it]  9%|▉         | 6/64 [00:13<01:55,  2.00s/it] 11%|█         | 7/64 [00:15<02:03,  2.16s/it] 12%|█▎        | 8/64 [00:17<01:53,  2.03s/it] 14%|█▍        | 9/64 [00:21<02:21,  2.57s/it] 16%|█▌        | 10/64 [00:23<02:03,  2.29s/it] 17%|█▋        | 11/64 [00:25<02:07,  2.40s/it] 19%|█▉        | 12/64 [00:27<01:55,  2.22s/it] 20%|██        | 13/64 [00:30<01:59,  2.35s/it] 22%|██▏       | 14/64 [00:31<01:41,  2.03s/it] 23%|██▎       | 15/64 [00:33<01:35,  1.95s/it] 25%|██▌       | 16/64 [00:35<01:46,  2.21s/it] 27%|██▋       | 17/64 [00:37<01:38,  2.11s/it] 28%|██▊       | 18/64 [00:40<01:47,  2.34s/it] 30%|██▉       | 19/64 [00:42<01:41,  2.25s/it] 31%|███▏      | 20/64 [00:44<01:27,  1.99s/it] 33%|███▎      | 21/64 [00:45<01:21,  1.90s/it] 34%|███▍      | 22/64 [00:48<01:30,  2.17s/it] 36%|███▌      | 23/64 [00:50<01:21,  1.99s/it] 38%|███▊      | 24/64 [00:52<01:27,  2.18s/it] 39%|███▉      | 25/64 [00:54<01:22,  2.12s/it] 41%|████      | 26/64 [00:56<01:20,  2.11s/it] 42%|████▏     | 27/64 [00:58<01:16,  2.08s/it] 44%|████▍     | 28/64 [01:00<01:10,  1.97s/it] 45%|████▌     | 29/64 [01:04<01:27,  2.49s/it] 47%|████▋     | 30/64 [01:06<01:24,  2.47s/it] 48%|████▊     | 31/64 [01:08<01:18,  2.39s/it] 50%|█████     | 32/64 [01:11<01:14,  2.33s/it] 52%|█████▏    | 33/64 [01:12<01:06,  2.14s/it] 53%|█████▎    | 34/64 [01:14<01:00,  2.02s/it] 55%|█████▍    | 35/64 [01:17<01:08,  2.35s/it] 56%|█████▋    | 36/64 [01:19<01:03,  2.27s/it] 58%|█████▊    | 37/64 [01:21<00:55,  2.04s/it] 59%|█████▉    | 38/64 [01:23<00:51,  1.97s/it] 61%|██████    | 39/64 [01:24<00:47,  1.90s/it] 62%|██████▎   | 40/64 [01:26<00:44,  1.86s/it] 64%|██████▍   | 41/64 [01:28<00:41,  1.82s/it] 66%|██████▌   | 42/64 [01:29<00:37,  1.71s/it] 67%|██████▋   | 43/64 [01:31<00:39,  1.86s/it] 69%|██████▉   | 44/64 [01:34<00:39,  1.97s/it] 70%|███████   | 45/64 [01:36<00:36,  1.95s/it] 72%|███████▏  | 46/64 [01:37<00:33,  1.85s/it] 73%|███████▎  | 47/64 [01:39<00:30,  1.81s/it] 75%|███████▌  | 48/64 [01:41<00:28,  1.77s/it] 77%|███████▋  | 49/64 [01:43<00:27,  1.82s/it] 78%|███████▊  | 50/64 [01:44<00:24,  1.77s/it] 80%|███████▉  | 51/64 [01:46<00:22,  1.73s/it] 81%|████████▏ | 52/64 [01:48<00:20,  1.73s/it] 83%|████████▎ | 53/64 [01:50<00:20,  1.87s/it] 84%|████████▍ | 54/64 [01:53<00:24,  2.43s/it] 86%|████████▌ | 55/64 [01:55<00:20,  2.24s/it] 88%|████████▊ | 56/64 [01:57<00:16,  2.02s/it] 89%|████████▉ | 57/64 [01:59<00:13,  1.96s/it] 91%|█████████ | 58/64 [02:00<00:11,  1.86s/it] 92%|█████████▏| 59/64 [02:02<00:09,  1.88s/it] 94%|█████████▍| 60/64 [02:04<00:07,  1.96s/it] 95%|█████████▌| 61/64 [02:06<00:05,  1.90s/it] 97%|█████████▋| 62/64 [02:08<00:03,  1.89s/it] 98%|█████████▊| 63/64 [02:10<00:01,  1.86s/it]100%|██████████| 64/64 [02:11<00:00,  1.71s/it]100%|██████████| 64/64 [02:11<00:00,  2.06s/it]

--- 4. Calculating metrics ---
BLEU Score: 19.08
chrF++ Score: 46.65

--- 5. Machine Translation (MT) predictions successfully saved to: ./inflection/urdu_large_MT.txt ---

COMET not installed. Skipping. Install with: pip install unbabel-comet
