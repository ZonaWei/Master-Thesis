{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.96,
  "eval_steps": 5000,
  "global_step": 155000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 0.26353925466537476,
      "learning_rate": 0.00019993728,
      "loss": 2.1972,
      "step": 50
    },
    {
      "epoch": 0.0032,
      "grad_norm": 0.3282485604286194,
      "learning_rate": 0.00019987328,
      "loss": 1.9315,
      "step": 100
    },
    {
      "epoch": 0.0048,
      "grad_norm": 0.2737760543823242,
      "learning_rate": 0.00019980928,
      "loss": 1.929,
      "step": 150
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.2880769968032837,
      "learning_rate": 0.00019974528000000003,
      "loss": 1.8639,
      "step": 200
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.30557936429977417,
      "learning_rate": 0.00019968128000000002,
      "loss": 1.9067,
      "step": 250
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.2582036554813385,
      "learning_rate": 0.00019961728000000002,
      "loss": 1.8352,
      "step": 300
    },
    {
      "epoch": 0.0112,
      "grad_norm": 0.3274189531803131,
      "learning_rate": 0.00019955328,
      "loss": 1.8551,
      "step": 350
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.3233484625816345,
      "learning_rate": 0.00019948928,
      "loss": 1.8661,
      "step": 400
    },
    {
      "epoch": 0.0144,
      "grad_norm": 0.2914128005504608,
      "learning_rate": 0.00019942528,
      "loss": 1.8172,
      "step": 450
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.35439565777778625,
      "learning_rate": 0.00019936128,
      "loss": 1.8619,
      "step": 500
    },
    {
      "epoch": 0.0176,
      "grad_norm": 0.2711907923221588,
      "learning_rate": 0.00019929728000000002,
      "loss": 1.7761,
      "step": 550
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.2807377576828003,
      "learning_rate": 0.00019923328000000001,
      "loss": 1.8048,
      "step": 600
    },
    {
      "epoch": 0.0208,
      "grad_norm": 0.3172101080417633,
      "learning_rate": 0.00019916928,
      "loss": 1.842,
      "step": 650
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.2880374789237976,
      "learning_rate": 0.00019910528,
      "loss": 1.8586,
      "step": 700
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.27228522300720215,
      "learning_rate": 0.00019904128000000003,
      "loss": 1.8729,
      "step": 750
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.2890121042728424,
      "learning_rate": 0.00019897728,
      "loss": 1.8069,
      "step": 800
    },
    {
      "epoch": 0.0272,
      "grad_norm": 0.2905806303024292,
      "learning_rate": 0.00019891328,
      "loss": 1.8295,
      "step": 850
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.29283496737480164,
      "learning_rate": 0.00019884928,
      "loss": 1.8463,
      "step": 900
    },
    {
      "epoch": 0.0304,
      "grad_norm": 0.29434120655059814,
      "learning_rate": 0.00019878528,
      "loss": 1.8103,
      "step": 950
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.28946739435195923,
      "learning_rate": 0.00019872128,
      "loss": 1.8317,
      "step": 1000
    },
    {
      "epoch": 0.0336,
      "grad_norm": 0.3153814971446991,
      "learning_rate": 0.00019865728000000003,
      "loss": 1.813,
      "step": 1050
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.3222438395023346,
      "learning_rate": 0.00019859328000000002,
      "loss": 1.8464,
      "step": 1100
    },
    {
      "epoch": 0.0368,
      "grad_norm": 0.29560357332229614,
      "learning_rate": 0.00019852928000000002,
      "loss": 1.9226,
      "step": 1150
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.29105767607688904,
      "learning_rate": 0.00019846528,
      "loss": 1.8513,
      "step": 1200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.26652443408966064,
      "learning_rate": 0.00019840128,
      "loss": 1.8431,
      "step": 1250
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.2923721373081207,
      "learning_rate": 0.00019833728,
      "loss": 1.8424,
      "step": 1300
    },
    {
      "epoch": 0.0432,
      "grad_norm": 0.26076075434684753,
      "learning_rate": 0.00019827328,
      "loss": 1.8441,
      "step": 1350
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.30182528495788574,
      "learning_rate": 0.00019820928000000002,
      "loss": 1.8486,
      "step": 1400
    },
    {
      "epoch": 0.0464,
      "grad_norm": 0.27145299315452576,
      "learning_rate": 0.00019814528000000001,
      "loss": 1.8358,
      "step": 1450
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.2791845500469208,
      "learning_rate": 0.00019808128,
      "loss": 1.8343,
      "step": 1500
    },
    {
      "epoch": 0.0496,
      "grad_norm": 0.264167457818985,
      "learning_rate": 0.00019801728,
      "loss": 1.8678,
      "step": 1550
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.2937138080596924,
      "learning_rate": 0.00019795328000000003,
      "loss": 1.8931,
      "step": 1600
    },
    {
      "epoch": 0.0528,
      "grad_norm": 0.3721153736114502,
      "learning_rate": 0.00019788928,
      "loss": 1.7997,
      "step": 1650
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.3528788089752197,
      "learning_rate": 0.00019782528,
      "loss": 1.8961,
      "step": 1700
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.29615625739097595,
      "learning_rate": 0.00019776128,
      "loss": 1.8287,
      "step": 1750
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.2906250059604645,
      "learning_rate": 0.00019769728,
      "loss": 1.8878,
      "step": 1800
    },
    {
      "epoch": 0.0592,
      "grad_norm": 0.27376803755760193,
      "learning_rate": 0.00019763328,
      "loss": 1.8504,
      "step": 1850
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.2894688546657562,
      "learning_rate": 0.00019756928000000002,
      "loss": 1.8411,
      "step": 1900
    },
    {
      "epoch": 0.0624,
      "grad_norm": 0.2780006229877472,
      "learning_rate": 0.00019750528000000002,
      "loss": 1.8051,
      "step": 1950
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.2798292934894562,
      "learning_rate": 0.00019744128000000002,
      "loss": 1.837,
      "step": 2000
    },
    {
      "epoch": 0.0656,
      "grad_norm": 0.2799360752105713,
      "learning_rate": 0.00019737728,
      "loss": 1.7831,
      "step": 2050
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.3557451367378235,
      "learning_rate": 0.00019731328,
      "loss": 1.8851,
      "step": 2100
    },
    {
      "epoch": 0.0688,
      "grad_norm": 0.2686564028263092,
      "learning_rate": 0.00019724928,
      "loss": 1.8044,
      "step": 2150
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.29626479744911194,
      "learning_rate": 0.00019718528,
      "loss": 1.7919,
      "step": 2200
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.2700492739677429,
      "learning_rate": 0.00019712128000000002,
      "loss": 1.8352,
      "step": 2250
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.3018660545349121,
      "learning_rate": 0.00019705728,
      "loss": 1.8037,
      "step": 2300
    },
    {
      "epoch": 0.0752,
      "grad_norm": 0.3473361134529114,
      "learning_rate": 0.00019699328,
      "loss": 1.851,
      "step": 2350
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.2905963659286499,
      "learning_rate": 0.00019692928,
      "loss": 1.8876,
      "step": 2400
    },
    {
      "epoch": 0.0784,
      "grad_norm": 0.3261054456233978,
      "learning_rate": 0.00019686528000000003,
      "loss": 1.8353,
      "step": 2450
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3144261837005615,
      "learning_rate": 0.00019680128,
      "loss": 1.8462,
      "step": 2500
    },
    {
      "epoch": 0.0816,
      "grad_norm": 0.3111027181148529,
      "learning_rate": 0.00019673728,
      "loss": 1.8618,
      "step": 2550
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.2557617425918579,
      "learning_rate": 0.00019667328,
      "loss": 1.7728,
      "step": 2600
    },
    {
      "epoch": 0.0848,
      "grad_norm": 0.2846235930919647,
      "learning_rate": 0.00019660928,
      "loss": 1.7897,
      "step": 2650
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.296321302652359,
      "learning_rate": 0.00019654528,
      "loss": 1.8167,
      "step": 2700
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.2953985631465912,
      "learning_rate": 0.00019648128000000002,
      "loss": 1.8409,
      "step": 2750
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.30684590339660645,
      "learning_rate": 0.00019641728000000002,
      "loss": 1.8146,
      "step": 2800
    },
    {
      "epoch": 0.0912,
      "grad_norm": 0.30625712871551514,
      "learning_rate": 0.00019635328000000001,
      "loss": 1.8547,
      "step": 2850
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.2997477650642395,
      "learning_rate": 0.00019628928,
      "loss": 1.8154,
      "step": 2900
    },
    {
      "epoch": 0.0944,
      "grad_norm": 0.2655048668384552,
      "learning_rate": 0.00019622528,
      "loss": 1.8539,
      "step": 2950
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.3144604563713074,
      "learning_rate": 0.00019616128,
      "loss": 1.8211,
      "step": 3000
    },
    {
      "epoch": 0.0976,
      "grad_norm": 0.2695593535900116,
      "learning_rate": 0.00019609728,
      "loss": 1.8715,
      "step": 3050
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.2937008738517761,
      "learning_rate": 0.00019603328000000002,
      "loss": 1.8643,
      "step": 3100
    },
    {
      "epoch": 0.1008,
      "grad_norm": 0.31919771432876587,
      "learning_rate": 0.00019596928,
      "loss": 1.8439,
      "step": 3150
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.28571683168411255,
      "learning_rate": 0.00019590528,
      "loss": 1.8334,
      "step": 3200
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.3048654794692993,
      "learning_rate": 0.00019584128,
      "loss": 1.8347,
      "step": 3250
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.31459975242614746,
      "learning_rate": 0.00019577728000000003,
      "loss": 1.7965,
      "step": 3300
    },
    {
      "epoch": 0.1072,
      "grad_norm": 0.30379730463027954,
      "learning_rate": 0.00019571328,
      "loss": 1.8035,
      "step": 3350
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.3886980712413788,
      "learning_rate": 0.00019564928,
      "loss": 1.8056,
      "step": 3400
    },
    {
      "epoch": 0.1104,
      "grad_norm": 0.25802671909332275,
      "learning_rate": 0.00019558528,
      "loss": 1.8738,
      "step": 3450
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.29603859782218933,
      "learning_rate": 0.00019552128,
      "loss": 1.8607,
      "step": 3500
    },
    {
      "epoch": 0.1136,
      "grad_norm": 0.2774094045162201,
      "learning_rate": 0.00019545728,
      "loss": 1.8495,
      "step": 3550
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.22714398801326752,
      "learning_rate": 0.00019539328000000002,
      "loss": 1.7966,
      "step": 3600
    },
    {
      "epoch": 0.1168,
      "grad_norm": 0.24708707630634308,
      "learning_rate": 0.00019532928000000002,
      "loss": 1.8225,
      "step": 3650
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.2571679353713989,
      "learning_rate": 0.00019526528000000001,
      "loss": 1.8397,
      "step": 3700
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.27246594429016113,
      "learning_rate": 0.00019520128,
      "loss": 1.8499,
      "step": 3750
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.2343565970659256,
      "learning_rate": 0.00019513728,
      "loss": 1.8665,
      "step": 3800
    },
    {
      "epoch": 0.1232,
      "grad_norm": 0.20330236852169037,
      "learning_rate": 0.00019507328,
      "loss": 1.7608,
      "step": 3850
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.26765015721321106,
      "learning_rate": 0.00019500928,
      "loss": 1.8348,
      "step": 3900
    },
    {
      "epoch": 0.1264,
      "grad_norm": 0.2724221646785736,
      "learning_rate": 0.00019494528000000002,
      "loss": 1.8983,
      "step": 3950
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.2908420264720917,
      "learning_rate": 0.00019488128,
      "loss": 1.8585,
      "step": 4000
    },
    {
      "epoch": 0.1296,
      "grad_norm": 0.2686591148376465,
      "learning_rate": 0.00019481728,
      "loss": 1.8287,
      "step": 4050
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.2782033681869507,
      "learning_rate": 0.00019475328,
      "loss": 1.7974,
      "step": 4100
    },
    {
      "epoch": 0.1328,
      "grad_norm": 0.32298025488853455,
      "learning_rate": 0.00019468928000000003,
      "loss": 1.8354,
      "step": 4150
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.26933109760284424,
      "learning_rate": 0.00019462528,
      "loss": 1.8574,
      "step": 4200
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.28707337379455566,
      "learning_rate": 0.00019456128,
      "loss": 1.7923,
      "step": 4250
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.3062324523925781,
      "learning_rate": 0.00019449728,
      "loss": 1.8198,
      "step": 4300
    },
    {
      "epoch": 0.1392,
      "grad_norm": 0.2700842618942261,
      "learning_rate": 0.00019443328,
      "loss": 1.856,
      "step": 4350
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.3072773218154907,
      "learning_rate": 0.00019436928,
      "loss": 1.8071,
      "step": 4400
    },
    {
      "epoch": 0.1424,
      "grad_norm": 0.2951633930206299,
      "learning_rate": 0.00019430528000000002,
      "loss": 1.7613,
      "step": 4450
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.2582470774650574,
      "learning_rate": 0.00019424128000000002,
      "loss": 1.7502,
      "step": 4500
    },
    {
      "epoch": 0.1456,
      "grad_norm": 0.27841177582740784,
      "learning_rate": 0.00019417728000000001,
      "loss": 1.8155,
      "step": 4550
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.3236849308013916,
      "learning_rate": 0.00019411328,
      "loss": 1.8296,
      "step": 4600
    },
    {
      "epoch": 0.1488,
      "grad_norm": 0.29919496178627014,
      "learning_rate": 0.00019404928,
      "loss": 1.852,
      "step": 4650
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.2744220495223999,
      "learning_rate": 0.00019398528,
      "loss": 1.7884,
      "step": 4700
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.27109473943710327,
      "learning_rate": 0.00019392128,
      "loss": 1.8063,
      "step": 4750
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.26823607087135315,
      "learning_rate": 0.00019385728000000002,
      "loss": 1.8272,
      "step": 4800
    },
    {
      "epoch": 0.1552,
      "grad_norm": 0.2567548155784607,
      "learning_rate": 0.00019379328,
      "loss": 1.8823,
      "step": 4850
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.31447938084602356,
      "learning_rate": 0.00019372928,
      "loss": 1.8578,
      "step": 4900
    },
    {
      "epoch": 0.1584,
      "grad_norm": 0.2945173978805542,
      "learning_rate": 0.00019366528,
      "loss": 1.8347,
      "step": 4950
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3318260610103607,
      "learning_rate": 0.00019360128000000002,
      "loss": 1.8383,
      "step": 5000
    },
    {
      "epoch": 0.1616,
      "grad_norm": 0.24622096121311188,
      "learning_rate": 0.00019353728,
      "loss": 1.8644,
      "step": 5050
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.29178377985954285,
      "learning_rate": 0.00019347328,
      "loss": 1.8321,
      "step": 5100
    },
    {
      "epoch": 0.1648,
      "grad_norm": 0.30206847190856934,
      "learning_rate": 0.00019340928,
      "loss": 1.8594,
      "step": 5150
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.27607080340385437,
      "learning_rate": 0.00019334528,
      "loss": 1.7354,
      "step": 5200
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.2561093866825104,
      "learning_rate": 0.00019328128,
      "loss": 1.8503,
      "step": 5250
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.2931654155254364,
      "learning_rate": 0.00019321728000000002,
      "loss": 1.7937,
      "step": 5300
    },
    {
      "epoch": 0.1712,
      "grad_norm": 0.24605149030685425,
      "learning_rate": 0.00019315328000000002,
      "loss": 1.8057,
      "step": 5350
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.27514883875846863,
      "learning_rate": 0.00019308928,
      "loss": 1.8469,
      "step": 5400
    },
    {
      "epoch": 0.1744,
      "grad_norm": 0.30567535758018494,
      "learning_rate": 0.00019302528,
      "loss": 1.8208,
      "step": 5450
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.2894514203071594,
      "learning_rate": 0.00019296128,
      "loss": 1.8482,
      "step": 5500
    },
    {
      "epoch": 0.1776,
      "grad_norm": 0.27939373254776,
      "learning_rate": 0.00019289728,
      "loss": 1.7932,
      "step": 5550
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.2780494689941406,
      "learning_rate": 0.00019283328,
      "loss": 1.8309,
      "step": 5600
    },
    {
      "epoch": 0.1808,
      "grad_norm": 0.2629048526287079,
      "learning_rate": 0.00019276928000000002,
      "loss": 1.7973,
      "step": 5650
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.2545778155326843,
      "learning_rate": 0.00019270528,
      "loss": 1.8033,
      "step": 5700
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.28148409724235535,
      "learning_rate": 0.00019264128,
      "loss": 1.8794,
      "step": 5750
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.3110555410385132,
      "learning_rate": 0.00019257728,
      "loss": 1.8137,
      "step": 5800
    },
    {
      "epoch": 0.1872,
      "grad_norm": 0.2659410536289215,
      "learning_rate": 0.00019251328000000002,
      "loss": 1.8134,
      "step": 5850
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.26557669043540955,
      "learning_rate": 0.00019244928,
      "loss": 1.859,
      "step": 5900
    },
    {
      "epoch": 0.1904,
      "grad_norm": 0.2510668933391571,
      "learning_rate": 0.00019238528,
      "loss": 1.807,
      "step": 5950
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.36526891589164734,
      "learning_rate": 0.00019232128,
      "loss": 1.8226,
      "step": 6000
    },
    {
      "epoch": 0.1936,
      "grad_norm": 0.34275469183921814,
      "learning_rate": 0.00019225728,
      "loss": 1.8199,
      "step": 6050
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.27654916048049927,
      "learning_rate": 0.00019219328,
      "loss": 1.8217,
      "step": 6100
    },
    {
      "epoch": 0.1968,
      "grad_norm": 0.26603445410728455,
      "learning_rate": 0.00019212928000000002,
      "loss": 1.8384,
      "step": 6150
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.3515794277191162,
      "learning_rate": 0.00019206528000000002,
      "loss": 1.8472,
      "step": 6200
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.24224157631397247,
      "learning_rate": 0.00019200128,
      "loss": 1.8406,
      "step": 6250
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.24844524264335632,
      "learning_rate": 0.00019193728,
      "loss": 1.7685,
      "step": 6300
    },
    {
      "epoch": 0.2032,
      "grad_norm": 0.25249427556991577,
      "learning_rate": 0.00019187328,
      "loss": 1.8332,
      "step": 6350
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.24773761630058289,
      "learning_rate": 0.00019180928,
      "loss": 1.7945,
      "step": 6400
    },
    {
      "epoch": 0.2064,
      "grad_norm": 0.2842981219291687,
      "learning_rate": 0.00019174528,
      "loss": 1.8343,
      "step": 6450
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.2951504588127136,
      "learning_rate": 0.00019168128000000002,
      "loss": 1.7775,
      "step": 6500
    },
    {
      "epoch": 0.2096,
      "grad_norm": 0.2447315901517868,
      "learning_rate": 0.00019161728,
      "loss": 1.8632,
      "step": 6550
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.2833811044692993,
      "learning_rate": 0.00019155328,
      "loss": 1.8278,
      "step": 6600
    },
    {
      "epoch": 0.2128,
      "grad_norm": 0.243317648768425,
      "learning_rate": 0.00019148928000000003,
      "loss": 1.8707,
      "step": 6650
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.2812912166118622,
      "learning_rate": 0.00019142528000000002,
      "loss": 1.7652,
      "step": 6700
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.2709921896457672,
      "learning_rate": 0.00019136128,
      "loss": 1.7991,
      "step": 6750
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.2677575945854187,
      "learning_rate": 0.00019129728000000001,
      "loss": 1.7993,
      "step": 6800
    },
    {
      "epoch": 0.2192,
      "grad_norm": 0.3269025385379791,
      "learning_rate": 0.00019123328,
      "loss": 1.8444,
      "step": 6850
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.4281354546546936,
      "learning_rate": 0.00019116928,
      "loss": 1.8173,
      "step": 6900
    },
    {
      "epoch": 0.2224,
      "grad_norm": 0.24317175149917603,
      "learning_rate": 0.00019110528,
      "loss": 1.7924,
      "step": 6950
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.3006584942340851,
      "learning_rate": 0.00019104128000000002,
      "loss": 1.7722,
      "step": 7000
    },
    {
      "epoch": 0.2256,
      "grad_norm": 0.27111437916755676,
      "learning_rate": 0.00019097728000000002,
      "loss": 1.7918,
      "step": 7050
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.23302794992923737,
      "learning_rate": 0.00019091328,
      "loss": 1.8125,
      "step": 7100
    },
    {
      "epoch": 0.2288,
      "grad_norm": 0.24538961052894592,
      "learning_rate": 0.00019084928,
      "loss": 1.8174,
      "step": 7150
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.2817246615886688,
      "learning_rate": 0.00019078528,
      "loss": 1.8675,
      "step": 7200
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.2593502402305603,
      "learning_rate": 0.00019072128,
      "loss": 1.8296,
      "step": 7250
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.29039379954338074,
      "learning_rate": 0.00019065728,
      "loss": 1.8005,
      "step": 7300
    },
    {
      "epoch": 0.2352,
      "grad_norm": 0.30637651681900024,
      "learning_rate": 0.00019059328000000002,
      "loss": 1.8412,
      "step": 7350
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.2598709166049957,
      "learning_rate": 0.00019052928,
      "loss": 1.8368,
      "step": 7400
    },
    {
      "epoch": 0.2384,
      "grad_norm": 0.238880455493927,
      "learning_rate": 0.00019046528,
      "loss": 1.817,
      "step": 7450
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.2934788763523102,
      "learning_rate": 0.00019040128000000003,
      "loss": 1.7893,
      "step": 7500
    },
    {
      "epoch": 0.2416,
      "grad_norm": 0.29104530811309814,
      "learning_rate": 0.00019033728000000002,
      "loss": 1.8095,
      "step": 7550
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.2590932548046112,
      "learning_rate": 0.00019027328,
      "loss": 1.8328,
      "step": 7600
    },
    {
      "epoch": 0.2448,
      "grad_norm": 0.3697185814380646,
      "learning_rate": 0.00019020928000000001,
      "loss": 1.805,
      "step": 7650
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.25102436542510986,
      "learning_rate": 0.00019014528,
      "loss": 1.809,
      "step": 7700
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.26003801822662354,
      "learning_rate": 0.00019008128,
      "loss": 1.7759,
      "step": 7750
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.2608187198638916,
      "learning_rate": 0.00019001728,
      "loss": 1.7588,
      "step": 7800
    },
    {
      "epoch": 0.2512,
      "grad_norm": 0.28321152925491333,
      "learning_rate": 0.00018995328000000002,
      "loss": 1.8142,
      "step": 7850
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.3091765344142914,
      "learning_rate": 0.00018988928000000002,
      "loss": 1.7681,
      "step": 7900
    },
    {
      "epoch": 0.2544,
      "grad_norm": 0.2828325033187866,
      "learning_rate": 0.00018982528,
      "loss": 1.7879,
      "step": 7950
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.23349395394325256,
      "learning_rate": 0.00018976128,
      "loss": 1.8374,
      "step": 8000
    },
    {
      "epoch": 0.2576,
      "grad_norm": 0.2791450619697571,
      "learning_rate": 0.00018969728,
      "loss": 1.8018,
      "step": 8050
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.2225199192762375,
      "learning_rate": 0.00018963328,
      "loss": 1.7973,
      "step": 8100
    },
    {
      "epoch": 0.2608,
      "grad_norm": 0.29007312655448914,
      "learning_rate": 0.00018956928,
      "loss": 1.798,
      "step": 8150
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.27148351073265076,
      "learning_rate": 0.00018950528000000002,
      "loss": 1.7861,
      "step": 8200
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.2746705710887909,
      "learning_rate": 0.00018944128,
      "loss": 1.8296,
      "step": 8250
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.2636783719062805,
      "learning_rate": 0.00018937728,
      "loss": 1.8121,
      "step": 8300
    },
    {
      "epoch": 0.2672,
      "grad_norm": 0.28769809007644653,
      "learning_rate": 0.00018931328000000003,
      "loss": 1.8794,
      "step": 8350
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.30135291814804077,
      "learning_rate": 0.00018924928000000002,
      "loss": 1.8349,
      "step": 8400
    },
    {
      "epoch": 0.2704,
      "grad_norm": 0.2730829119682312,
      "learning_rate": 0.00018918528,
      "loss": 1.8256,
      "step": 8450
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.2593216598033905,
      "learning_rate": 0.00018912128000000001,
      "loss": 1.8032,
      "step": 8500
    },
    {
      "epoch": 0.2736,
      "grad_norm": 0.30845096707344055,
      "learning_rate": 0.00018905728,
      "loss": 1.8108,
      "step": 8550
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.2567910850048065,
      "learning_rate": 0.00018899328,
      "loss": 1.7414,
      "step": 8600
    },
    {
      "epoch": 0.2768,
      "grad_norm": 0.2894127368927002,
      "learning_rate": 0.00018892928,
      "loss": 1.8073,
      "step": 8650
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.3009282648563385,
      "learning_rate": 0.00018886528000000002,
      "loss": 1.8144,
      "step": 8700
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.27913597226142883,
      "learning_rate": 0.00018880128000000002,
      "loss": 1.83,
      "step": 8750
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.3030778169631958,
      "learning_rate": 0.00018873728,
      "loss": 1.8612,
      "step": 8800
    },
    {
      "epoch": 0.2832,
      "grad_norm": 0.2552812099456787,
      "learning_rate": 0.00018867328,
      "loss": 1.8639,
      "step": 8850
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.26538288593292236,
      "learning_rate": 0.00018860928,
      "loss": 1.8792,
      "step": 8900
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.2576821446418762,
      "learning_rate": 0.00018854528,
      "loss": 1.7926,
      "step": 8950
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.33104532957077026,
      "learning_rate": 0.00018848128,
      "loss": 1.8044,
      "step": 9000
    },
    {
      "epoch": 0.2896,
      "grad_norm": 0.24035876989364624,
      "learning_rate": 0.00018841728000000001,
      "loss": 1.8043,
      "step": 9050
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.3090621531009674,
      "learning_rate": 0.00018835328,
      "loss": 1.8679,
      "step": 9100
    },
    {
      "epoch": 0.2928,
      "grad_norm": 0.3502543866634369,
      "learning_rate": 0.00018828928,
      "loss": 1.8342,
      "step": 9150
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.3066732883453369,
      "learning_rate": 0.00018822528000000003,
      "loss": 1.8041,
      "step": 9200
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.3280852735042572,
      "learning_rate": 0.00018816128000000002,
      "loss": 1.8507,
      "step": 9250
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.26444193720817566,
      "learning_rate": 0.00018809728,
      "loss": 1.8096,
      "step": 9300
    },
    {
      "epoch": 0.2992,
      "grad_norm": 0.284878671169281,
      "learning_rate": 0.00018803328,
      "loss": 1.8117,
      "step": 9350
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.31000882387161255,
      "learning_rate": 0.00018796928,
      "loss": 1.8267,
      "step": 9400
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.2828309237957001,
      "learning_rate": 0.00018790528,
      "loss": 1.8646,
      "step": 9450
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.2671228051185608,
      "learning_rate": 0.00018784128,
      "loss": 1.8079,
      "step": 9500
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.27058878540992737,
      "learning_rate": 0.00018777728000000002,
      "loss": 1.8427,
      "step": 9550
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.28434452414512634,
      "learning_rate": 0.00018771328000000002,
      "loss": 1.8345,
      "step": 9600
    },
    {
      "epoch": 0.3088,
      "grad_norm": 0.3066434860229492,
      "learning_rate": 0.00018764928,
      "loss": 1.7793,
      "step": 9650
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.3234556019306183,
      "learning_rate": 0.00018758528,
      "loss": 1.8955,
      "step": 9700
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.2934359014034271,
      "learning_rate": 0.00018752128,
      "loss": 1.8231,
      "step": 9750
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.28823360800743103,
      "learning_rate": 0.00018745728,
      "loss": 1.8189,
      "step": 9800
    },
    {
      "epoch": 0.3152,
      "grad_norm": 0.23675954341888428,
      "learning_rate": 0.00018739328,
      "loss": 1.7848,
      "step": 9850
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.25592854619026184,
      "learning_rate": 0.00018732928000000001,
      "loss": 1.8652,
      "step": 9900
    },
    {
      "epoch": 0.3184,
      "grad_norm": 0.26737257838249207,
      "learning_rate": 0.00018726528,
      "loss": 1.8025,
      "step": 9950
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.25680261850357056,
      "learning_rate": 0.00018720128,
      "loss": 1.805,
      "step": 10000
    },
    {
      "epoch": 0.3216,
      "grad_norm": 0.2581382095813751,
      "learning_rate": 0.00018713728000000003,
      "loss": 1.8479,
      "step": 10050
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.25624823570251465,
      "learning_rate": 0.00018707328000000002,
      "loss": 1.827,
      "step": 10100
    },
    {
      "epoch": 0.3248,
      "grad_norm": 0.30259212851524353,
      "learning_rate": 0.00018700928000000002,
      "loss": 1.875,
      "step": 10150
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.28954586386680603,
      "learning_rate": 0.00018694528,
      "loss": 1.8585,
      "step": 10200
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.2518806755542755,
      "learning_rate": 0.00018688128,
      "loss": 1.8392,
      "step": 10250
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.2976131737232208,
      "learning_rate": 0.00018681728,
      "loss": 1.7865,
      "step": 10300
    },
    {
      "epoch": 0.3312,
      "grad_norm": 0.2897414267063141,
      "learning_rate": 0.00018675328,
      "loss": 1.8762,
      "step": 10350
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.30598190426826477,
      "learning_rate": 0.00018668928000000002,
      "loss": 1.8402,
      "step": 10400
    },
    {
      "epoch": 0.3344,
      "grad_norm": 0.2531066834926605,
      "learning_rate": 0.00018662528000000002,
      "loss": 1.8524,
      "step": 10450
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.2910629212856293,
      "learning_rate": 0.00018656128,
      "loss": 1.8429,
      "step": 10500
    },
    {
      "epoch": 0.3376,
      "grad_norm": 0.26494839787483215,
      "learning_rate": 0.00018649728,
      "loss": 1.8581,
      "step": 10550
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.23867100477218628,
      "learning_rate": 0.00018643328,
      "loss": 1.8293,
      "step": 10600
    },
    {
      "epoch": 0.3408,
      "grad_norm": 0.3486093580722809,
      "learning_rate": 0.00018636928,
      "loss": 1.8684,
      "step": 10650
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.2771069407463074,
      "learning_rate": 0.00018630528,
      "loss": 1.7758,
      "step": 10700
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.26930779218673706,
      "learning_rate": 0.00018624128000000001,
      "loss": 1.8114,
      "step": 10750
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.30770376324653625,
      "learning_rate": 0.00018617728,
      "loss": 1.854,
      "step": 10800
    },
    {
      "epoch": 0.3472,
      "grad_norm": 0.25376421213150024,
      "learning_rate": 0.00018611328,
      "loss": 1.7718,
      "step": 10850
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.28540685772895813,
      "learning_rate": 0.00018604928000000003,
      "loss": 1.8653,
      "step": 10900
    },
    {
      "epoch": 0.3504,
      "grad_norm": 0.30504310131073,
      "learning_rate": 0.00018598528000000002,
      "loss": 1.77,
      "step": 10950
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.32571613788604736,
      "learning_rate": 0.00018592128000000002,
      "loss": 1.8164,
      "step": 11000
    },
    {
      "epoch": 0.3536,
      "grad_norm": 0.33462202548980713,
      "learning_rate": 0.00018585728,
      "loss": 1.8292,
      "step": 11050
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.29931190609931946,
      "learning_rate": 0.00018579328,
      "loss": 1.7884,
      "step": 11100
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.3263929784297943,
      "learning_rate": 0.00018572928,
      "loss": 1.8145,
      "step": 11150
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.28324612975120544,
      "learning_rate": 0.00018566528,
      "loss": 1.848,
      "step": 11200
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.2852793037891388,
      "learning_rate": 0.00018560128000000002,
      "loss": 1.8308,
      "step": 11250
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.2887023389339447,
      "learning_rate": 0.00018553728000000002,
      "loss": 1.8572,
      "step": 11300
    },
    {
      "epoch": 0.3632,
      "grad_norm": 0.26584628224372864,
      "learning_rate": 0.00018547328,
      "loss": 1.8061,
      "step": 11350
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.2404446005821228,
      "learning_rate": 0.00018540928,
      "loss": 1.8932,
      "step": 11400
    },
    {
      "epoch": 0.3664,
      "grad_norm": 0.241496279835701,
      "learning_rate": 0.00018534528,
      "loss": 1.8011,
      "step": 11450
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.2672518789768219,
      "learning_rate": 0.00018528128,
      "loss": 1.8431,
      "step": 11500
    },
    {
      "epoch": 0.3696,
      "grad_norm": 0.28760796785354614,
      "learning_rate": 0.00018521728,
      "loss": 1.7593,
      "step": 11550
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.25891628861427307,
      "learning_rate": 0.00018515328000000001,
      "loss": 1.8445,
      "step": 11600
    },
    {
      "epoch": 0.3728,
      "grad_norm": 0.3501523733139038,
      "learning_rate": 0.00018508928,
      "loss": 1.8272,
      "step": 11650
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.268472284078598,
      "learning_rate": 0.00018502528,
      "loss": 1.8,
      "step": 11700
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.2951456308364868,
      "learning_rate": 0.00018496128000000003,
      "loss": 1.822,
      "step": 11750
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.2640589773654938,
      "learning_rate": 0.00018489728000000002,
      "loss": 1.7934,
      "step": 11800
    },
    {
      "epoch": 0.3792,
      "grad_norm": 0.3280057907104492,
      "learning_rate": 0.00018483328000000002,
      "loss": 1.8585,
      "step": 11850
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.31454166769981384,
      "learning_rate": 0.00018476928,
      "loss": 1.8129,
      "step": 11900
    },
    {
      "epoch": 0.3824,
      "grad_norm": 0.2554568946361542,
      "learning_rate": 0.00018470528,
      "loss": 1.8953,
      "step": 11950
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.3023349344730377,
      "learning_rate": 0.00018464128,
      "loss": 1.7678,
      "step": 12000
    },
    {
      "epoch": 0.3856,
      "grad_norm": 0.2404516637325287,
      "learning_rate": 0.00018457728,
      "loss": 1.8266,
      "step": 12050
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.31070834398269653,
      "learning_rate": 0.00018451328000000002,
      "loss": 1.8295,
      "step": 12100
    },
    {
      "epoch": 0.3888,
      "grad_norm": 0.2835181653499603,
      "learning_rate": 0.00018444928000000001,
      "loss": 1.8076,
      "step": 12150
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.28006038069725037,
      "learning_rate": 0.00018438528,
      "loss": 1.8199,
      "step": 12200
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.27687570452690125,
      "learning_rate": 0.00018432128,
      "loss": 1.809,
      "step": 12250
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.2804919183254242,
      "learning_rate": 0.00018425728,
      "loss": 1.7899,
      "step": 12300
    },
    {
      "epoch": 0.3952,
      "grad_norm": 0.24651996791362762,
      "learning_rate": 0.00018419328,
      "loss": 1.8533,
      "step": 12350
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.2807004451751709,
      "learning_rate": 0.00018412928,
      "loss": 1.7758,
      "step": 12400
    },
    {
      "epoch": 0.3984,
      "grad_norm": 0.30476391315460205,
      "learning_rate": 0.00018406528,
      "loss": 1.829,
      "step": 12450
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.26827600598335266,
      "learning_rate": 0.00018400128,
      "loss": 1.8195,
      "step": 12500
    },
    {
      "epoch": 0.4016,
      "grad_norm": 0.23673757910728455,
      "learning_rate": 0.00018393728,
      "loss": 1.8598,
      "step": 12550
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.24989494681358337,
      "learning_rate": 0.00018387328000000003,
      "loss": 1.8392,
      "step": 12600
    },
    {
      "epoch": 0.4048,
      "grad_norm": 0.24075178802013397,
      "learning_rate": 0.00018380928000000002,
      "loss": 1.8445,
      "step": 12650
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.2843632400035858,
      "learning_rate": 0.00018374528000000002,
      "loss": 1.7687,
      "step": 12700
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.2981577217578888,
      "learning_rate": 0.00018368128,
      "loss": 1.8458,
      "step": 12750
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.32521650195121765,
      "learning_rate": 0.00018361728,
      "loss": 1.821,
      "step": 12800
    },
    {
      "epoch": 0.4112,
      "grad_norm": 0.27054527401924133,
      "learning_rate": 0.00018355328,
      "loss": 1.8016,
      "step": 12850
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.3462103009223938,
      "learning_rate": 0.00018348928,
      "loss": 1.8108,
      "step": 12900
    },
    {
      "epoch": 0.4144,
      "grad_norm": 0.2825751006603241,
      "learning_rate": 0.00018342528000000002,
      "loss": 1.8886,
      "step": 12950
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.3350082039833069,
      "learning_rate": 0.00018336128000000001,
      "loss": 1.7819,
      "step": 13000
    },
    {
      "epoch": 0.4176,
      "grad_norm": 0.26217812299728394,
      "learning_rate": 0.00018329728,
      "loss": 1.8152,
      "step": 13050
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.26270535588264465,
      "learning_rate": 0.00018323328,
      "loss": 1.8151,
      "step": 13100
    },
    {
      "epoch": 0.4208,
      "grad_norm": 0.2880770266056061,
      "learning_rate": 0.00018316928,
      "loss": 1.844,
      "step": 13150
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.23882441222667694,
      "learning_rate": 0.00018310528,
      "loss": 1.8497,
      "step": 13200
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.29806268215179443,
      "learning_rate": 0.00018304128,
      "loss": 1.7357,
      "step": 13250
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.30735936760902405,
      "learning_rate": 0.00018297728,
      "loss": 1.7456,
      "step": 13300
    },
    {
      "epoch": 0.4272,
      "grad_norm": 0.3167664706707001,
      "learning_rate": 0.00018291328,
      "loss": 1.83,
      "step": 13350
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.2822110056877136,
      "learning_rate": 0.00018284928,
      "loss": 1.8173,
      "step": 13400
    },
    {
      "epoch": 0.4304,
      "grad_norm": 0.34858617186546326,
      "learning_rate": 0.00018278528000000003,
      "loss": 1.8429,
      "step": 13450
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.270602285861969,
      "learning_rate": 0.00018272128000000002,
      "loss": 1.9237,
      "step": 13500
    },
    {
      "epoch": 0.4336,
      "grad_norm": 0.31649303436279297,
      "learning_rate": 0.00018265728000000002,
      "loss": 1.799,
      "step": 13550
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.2711294889450073,
      "learning_rate": 0.00018259328,
      "loss": 1.8477,
      "step": 13600
    },
    {
      "epoch": 0.4368,
      "grad_norm": 0.2948797643184662,
      "learning_rate": 0.00018252928,
      "loss": 1.8724,
      "step": 13650
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.25759878754615784,
      "learning_rate": 0.00018246528,
      "loss": 1.8299,
      "step": 13700
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.2438281625509262,
      "learning_rate": 0.00018240128,
      "loss": 1.8721,
      "step": 13750
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.2911616265773773,
      "learning_rate": 0.00018233728000000002,
      "loss": 1.8533,
      "step": 13800
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.29059576988220215,
      "learning_rate": 0.00018227328000000001,
      "loss": 1.8247,
      "step": 13850
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.2909218668937683,
      "learning_rate": 0.00018220928,
      "loss": 1.8362,
      "step": 13900
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.3404514193534851,
      "learning_rate": 0.00018214528000000003,
      "loss": 1.8729,
      "step": 13950
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.27682000398635864,
      "learning_rate": 0.00018208128,
      "loss": 1.7985,
      "step": 14000
    },
    {
      "epoch": 0.4496,
      "grad_norm": 0.3178238570690155,
      "learning_rate": 0.00018201728,
      "loss": 1.8114,
      "step": 14050
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.42206868529319763,
      "learning_rate": 0.00018195328000000002,
      "loss": 1.7701,
      "step": 14100
    },
    {
      "epoch": 0.4528,
      "grad_norm": 0.24090537428855896,
      "learning_rate": 0.00018188928,
      "loss": 1.8143,
      "step": 14150
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.2803671360015869,
      "learning_rate": 0.00018182528,
      "loss": 1.8216,
      "step": 14200
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.27414023876190186,
      "learning_rate": 0.00018176128,
      "loss": 1.8382,
      "step": 14250
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.36912089586257935,
      "learning_rate": 0.00018169728000000003,
      "loss": 1.7788,
      "step": 14300
    },
    {
      "epoch": 0.4592,
      "grad_norm": 0.35252463817596436,
      "learning_rate": 0.00018163328000000002,
      "loss": 1.8177,
      "step": 14350
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.3425712287425995,
      "learning_rate": 0.00018156928000000002,
      "loss": 1.8411,
      "step": 14400
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.2492167353630066,
      "learning_rate": 0.00018150528,
      "loss": 1.8387,
      "step": 14450
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.295208603143692,
      "learning_rate": 0.00018144128,
      "loss": 1.844,
      "step": 14500
    },
    {
      "epoch": 0.4656,
      "grad_norm": 0.259620726108551,
      "learning_rate": 0.00018137728,
      "loss": 1.8248,
      "step": 14550
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.3378571569919586,
      "learning_rate": 0.00018131328,
      "loss": 1.8149,
      "step": 14600
    },
    {
      "epoch": 0.4688,
      "grad_norm": 0.2528802156448364,
      "learning_rate": 0.00018124928000000002,
      "loss": 1.8297,
      "step": 14650
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.2848917841911316,
      "learning_rate": 0.00018118528000000001,
      "loss": 1.8699,
      "step": 14700
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.28242990374565125,
      "learning_rate": 0.00018112128,
      "loss": 1.832,
      "step": 14750
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.28231117129325867,
      "learning_rate": 0.00018105728000000003,
      "loss": 1.8156,
      "step": 14800
    },
    {
      "epoch": 0.4752,
      "grad_norm": 0.28717365860939026,
      "learning_rate": 0.00018099328,
      "loss": 1.7968,
      "step": 14850
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.30614277720451355,
      "learning_rate": 0.00018092928,
      "loss": 1.8301,
      "step": 14900
    },
    {
      "epoch": 0.4784,
      "grad_norm": 0.29737618565559387,
      "learning_rate": 0.00018086528000000002,
      "loss": 1.7565,
      "step": 14950
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2768908739089966,
      "learning_rate": 0.00018080128,
      "loss": 1.8211,
      "step": 15000
    },
    {
      "epoch": 0.4816,
      "grad_norm": 0.24430079758167267,
      "learning_rate": 0.00018073728,
      "loss": 1.7897,
      "step": 15050
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.27936068177223206,
      "learning_rate": 0.00018067328,
      "loss": 1.8683,
      "step": 15100
    },
    {
      "epoch": 0.4848,
      "grad_norm": 0.31384652853012085,
      "learning_rate": 0.00018060928000000002,
      "loss": 1.7765,
      "step": 15150
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.29399365186691284,
      "learning_rate": 0.00018054528000000002,
      "loss": 1.9054,
      "step": 15200
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.24041324853897095,
      "learning_rate": 0.00018048128000000001,
      "loss": 1.8225,
      "step": 15250
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.3501955568790436,
      "learning_rate": 0.00018041728,
      "loss": 1.7886,
      "step": 15300
    },
    {
      "epoch": 0.4912,
      "grad_norm": 0.32758280634880066,
      "learning_rate": 0.00018035328,
      "loss": 1.8002,
      "step": 15350
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.2897225618362427,
      "learning_rate": 0.00018028928,
      "loss": 1.826,
      "step": 15400
    },
    {
      "epoch": 0.4944,
      "grad_norm": 0.2789852023124695,
      "learning_rate": 0.00018022528,
      "loss": 1.8104,
      "step": 15450
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.31307461857795715,
      "learning_rate": 0.00018016128000000002,
      "loss": 1.8299,
      "step": 15500
    },
    {
      "epoch": 0.4976,
      "grad_norm": 0.25537365674972534,
      "learning_rate": 0.00018009728,
      "loss": 1.8332,
      "step": 15550
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.2874082922935486,
      "learning_rate": 0.00018003328,
      "loss": 1.7854,
      "step": 15600
    },
    {
      "epoch": 0.5008,
      "grad_norm": 0.28671327233314514,
      "learning_rate": 0.00017996928000000003,
      "loss": 1.8715,
      "step": 15650
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.21953824162483215,
      "learning_rate": 0.00017990528,
      "loss": 1.8336,
      "step": 15700
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.278529554605484,
      "learning_rate": 0.00017984128,
      "loss": 1.7423,
      "step": 15750
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.2534272074699402,
      "learning_rate": 0.00017977728000000002,
      "loss": 1.7737,
      "step": 15800
    },
    {
      "epoch": 0.5072,
      "grad_norm": 0.3038809299468994,
      "learning_rate": 0.00017971328,
      "loss": 1.7642,
      "step": 15850
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.29711923003196716,
      "learning_rate": 0.00017964928,
      "loss": 1.7866,
      "step": 15900
    },
    {
      "epoch": 0.5104,
      "grad_norm": 0.28435370326042175,
      "learning_rate": 0.00017958528,
      "loss": 1.7791,
      "step": 15950
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.27239009737968445,
      "learning_rate": 0.00017952128000000002,
      "loss": 1.8685,
      "step": 16000
    },
    {
      "epoch": 0.5136,
      "grad_norm": 0.2621746063232422,
      "learning_rate": 0.00017945728000000002,
      "loss": 1.7473,
      "step": 16050
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.27038708329200745,
      "learning_rate": 0.00017939328000000001,
      "loss": 1.7863,
      "step": 16100
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.24956947565078735,
      "learning_rate": 0.00017932928,
      "loss": 1.8116,
      "step": 16150
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.23989810049533844,
      "learning_rate": 0.00017926528,
      "loss": 1.7817,
      "step": 16200
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3233598470687866,
      "learning_rate": 0.00017920128,
      "loss": 1.7617,
      "step": 16250
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.3165173828601837,
      "learning_rate": 0.00017913728,
      "loss": 1.8157,
      "step": 16300
    },
    {
      "epoch": 0.5232,
      "grad_norm": 0.300591379404068,
      "learning_rate": 0.00017907328000000002,
      "loss": 1.8124,
      "step": 16350
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.2531335949897766,
      "learning_rate": 0.00017900928,
      "loss": 1.8635,
      "step": 16400
    },
    {
      "epoch": 0.5264,
      "grad_norm": 0.33744797110557556,
      "learning_rate": 0.00017894528,
      "loss": 1.8256,
      "step": 16450
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.2737264633178711,
      "learning_rate": 0.00017888128000000003,
      "loss": 1.7591,
      "step": 16500
    },
    {
      "epoch": 0.5296,
      "grad_norm": 0.3276205062866211,
      "learning_rate": 0.00017881728,
      "loss": 1.7782,
      "step": 16550
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.26410800218582153,
      "learning_rate": 0.00017875328,
      "loss": 1.856,
      "step": 16600
    },
    {
      "epoch": 0.5328,
      "grad_norm": 0.25706735253334045,
      "learning_rate": 0.00017868928000000002,
      "loss": 1.8344,
      "step": 16650
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.23668323457241058,
      "learning_rate": 0.00017862528,
      "loss": 1.8026,
      "step": 16700
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.3767884075641632,
      "learning_rate": 0.00017856128,
      "loss": 1.8283,
      "step": 16750
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.2861843407154083,
      "learning_rate": 0.00017849728,
      "loss": 1.831,
      "step": 16800
    },
    {
      "epoch": 0.5392,
      "grad_norm": 0.27033448219299316,
      "learning_rate": 0.00017843328000000002,
      "loss": 1.8487,
      "step": 16850
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.28848153352737427,
      "learning_rate": 0.00017836928000000002,
      "loss": 1.6862,
      "step": 16900
    },
    {
      "epoch": 0.5424,
      "grad_norm": 0.2510368227958679,
      "learning_rate": 0.00017830528000000001,
      "loss": 1.7711,
      "step": 16950
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.3418081998825073,
      "learning_rate": 0.00017824128,
      "loss": 1.789,
      "step": 17000
    },
    {
      "epoch": 0.5456,
      "grad_norm": 0.2813698649406433,
      "learning_rate": 0.00017817728,
      "loss": 1.8237,
      "step": 17050
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.3089684844017029,
      "learning_rate": 0.00017811328,
      "loss": 1.8332,
      "step": 17100
    },
    {
      "epoch": 0.5488,
      "grad_norm": 0.3010209798812866,
      "learning_rate": 0.00017804928,
      "loss": 1.8162,
      "step": 17150
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.28023454546928406,
      "learning_rate": 0.00017798528000000002,
      "loss": 1.8065,
      "step": 17200
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.23379237949848175,
      "learning_rate": 0.00017792128,
      "loss": 1.8667,
      "step": 17250
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.24917513132095337,
      "learning_rate": 0.00017785728,
      "loss": 1.7886,
      "step": 17300
    },
    {
      "epoch": 0.5552,
      "grad_norm": 0.2835725247859955,
      "learning_rate": 0.00017779328000000003,
      "loss": 1.7978,
      "step": 17350
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.3475106954574585,
      "learning_rate": 0.00017772928,
      "loss": 1.8228,
      "step": 17400
    },
    {
      "epoch": 0.5584,
      "grad_norm": 0.3374146521091461,
      "learning_rate": 0.00017766528,
      "loss": 1.7998,
      "step": 17450
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3757120668888092,
      "learning_rate": 0.00017760128000000002,
      "loss": 1.8047,
      "step": 17500
    },
    {
      "epoch": 0.5616,
      "grad_norm": 0.34928324818611145,
      "learning_rate": 0.00017753728,
      "loss": 1.8139,
      "step": 17550
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.2496098130941391,
      "learning_rate": 0.00017747328,
      "loss": 1.8502,
      "step": 17600
    },
    {
      "epoch": 0.5648,
      "grad_norm": 0.31827065348625183,
      "learning_rate": 0.00017740928,
      "loss": 1.8579,
      "step": 17650
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.3573734164237976,
      "learning_rate": 0.00017734528000000002,
      "loss": 1.7441,
      "step": 17700
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.4412509799003601,
      "learning_rate": 0.00017728128000000002,
      "loss": 1.7562,
      "step": 17750
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.2741623520851135,
      "learning_rate": 0.00017721728000000001,
      "loss": 1.8069,
      "step": 17800
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.316018283367157,
      "learning_rate": 0.00017715328,
      "loss": 1.8359,
      "step": 17850
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.2855195105075836,
      "learning_rate": 0.00017708928,
      "loss": 1.836,
      "step": 17900
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.2970883846282959,
      "learning_rate": 0.00017702528,
      "loss": 1.8096,
      "step": 17950
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.37614697217941284,
      "learning_rate": 0.00017696128,
      "loss": 1.8341,
      "step": 18000
    },
    {
      "epoch": 0.5776,
      "grad_norm": 0.3002607226371765,
      "learning_rate": 0.00017689728000000002,
      "loss": 1.818,
      "step": 18050
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.3041318356990814,
      "learning_rate": 0.00017683328,
      "loss": 1.7669,
      "step": 18100
    },
    {
      "epoch": 0.5808,
      "grad_norm": 0.3178618848323822,
      "learning_rate": 0.00017676928,
      "loss": 1.8976,
      "step": 18150
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.25364354252815247,
      "learning_rate": 0.00017670528000000003,
      "loss": 1.8089,
      "step": 18200
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.28061166405677795,
      "learning_rate": 0.00017664128,
      "loss": 1.8213,
      "step": 18250
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.3130118250846863,
      "learning_rate": 0.00017657728,
      "loss": 1.8316,
      "step": 18300
    },
    {
      "epoch": 0.5872,
      "grad_norm": 0.28097760677337646,
      "learning_rate": 0.00017651328000000002,
      "loss": 1.8187,
      "step": 18350
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.26915276050567627,
      "learning_rate": 0.00017644928,
      "loss": 1.7891,
      "step": 18400
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.2977412939071655,
      "learning_rate": 0.00017638528,
      "loss": 1.7399,
      "step": 18450
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.2793760299682617,
      "learning_rate": 0.00017632128,
      "loss": 1.8198,
      "step": 18500
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.3209170401096344,
      "learning_rate": 0.00017625728000000002,
      "loss": 1.8165,
      "step": 18550
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.27943727374076843,
      "learning_rate": 0.00017619328000000002,
      "loss": 1.801,
      "step": 18600
    },
    {
      "epoch": 0.5968,
      "grad_norm": 0.2480248510837555,
      "learning_rate": 0.00017612928,
      "loss": 1.8184,
      "step": 18650
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.3465951979160309,
      "learning_rate": 0.00017606528,
      "loss": 1.8538,
      "step": 18700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.29742661118507385,
      "learning_rate": 0.00017600128,
      "loss": 1.8263,
      "step": 18750
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.3249366283416748,
      "learning_rate": 0.00017593728,
      "loss": 1.7486,
      "step": 18800
    },
    {
      "epoch": 0.6032,
      "grad_norm": 0.2889002561569214,
      "learning_rate": 0.00017587328,
      "loss": 1.834,
      "step": 18850
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.38388705253601074,
      "learning_rate": 0.00017580928000000002,
      "loss": 1.847,
      "step": 18900
    },
    {
      "epoch": 0.6064,
      "grad_norm": 0.29765382409095764,
      "learning_rate": 0.00017574528,
      "loss": 1.7741,
      "step": 18950
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.3637697398662567,
      "learning_rate": 0.00017568128,
      "loss": 1.8299,
      "step": 19000
    },
    {
      "epoch": 0.6096,
      "grad_norm": 0.2705552279949188,
      "learning_rate": 0.00017561728000000003,
      "loss": 1.7959,
      "step": 19050
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.2823468744754791,
      "learning_rate": 0.00017555328,
      "loss": 1.8566,
      "step": 19100
    },
    {
      "epoch": 0.6128,
      "grad_norm": 0.31439274549484253,
      "learning_rate": 0.00017548928,
      "loss": 1.7579,
      "step": 19150
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.25503554940223694,
      "learning_rate": 0.00017542528000000001,
      "loss": 1.7861,
      "step": 19200
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.3225623071193695,
      "learning_rate": 0.00017536128,
      "loss": 1.793,
      "step": 19250
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.2994585931301117,
      "learning_rate": 0.00017529728,
      "loss": 1.8246,
      "step": 19300
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.30394411087036133,
      "learning_rate": 0.00017523328,
      "loss": 1.8055,
      "step": 19350
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.24842619895935059,
      "learning_rate": 0.00017516928000000002,
      "loss": 1.7521,
      "step": 19400
    },
    {
      "epoch": 0.6224,
      "grad_norm": 0.3100005090236664,
      "learning_rate": 0.00017510528000000002,
      "loss": 1.8332,
      "step": 19450
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.26565080881118774,
      "learning_rate": 0.00017504128,
      "loss": 1.8378,
      "step": 19500
    },
    {
      "epoch": 0.6256,
      "grad_norm": 0.2987622022628784,
      "learning_rate": 0.00017497728,
      "loss": 1.8601,
      "step": 19550
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.32558372616767883,
      "learning_rate": 0.00017491328,
      "loss": 1.7908,
      "step": 19600
    },
    {
      "epoch": 0.6288,
      "grad_norm": 0.25801342725753784,
      "learning_rate": 0.00017484928,
      "loss": 1.7864,
      "step": 19650
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.3445659279823303,
      "learning_rate": 0.00017478528,
      "loss": 1.8804,
      "step": 19700
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.24325628578662872,
      "learning_rate": 0.00017472128000000002,
      "loss": 1.7649,
      "step": 19750
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.3279187083244324,
      "learning_rate": 0.00017465728,
      "loss": 1.7953,
      "step": 19800
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.2928561866283417,
      "learning_rate": 0.00017459328,
      "loss": 1.847,
      "step": 19850
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.3087100386619568,
      "learning_rate": 0.00017452928000000003,
      "loss": 1.8084,
      "step": 19900
    },
    {
      "epoch": 0.6384,
      "grad_norm": 0.2763884365558624,
      "learning_rate": 0.00017446528,
      "loss": 1.8238,
      "step": 19950
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2462998330593109,
      "learning_rate": 0.00017440128,
      "loss": 1.8042,
      "step": 20000
    },
    {
      "epoch": 0.6416,
      "grad_norm": 0.34025776386260986,
      "learning_rate": 0.00017433728000000001,
      "loss": 1.8496,
      "step": 20050
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.2693028151988983,
      "learning_rate": 0.00017427328,
      "loss": 1.7482,
      "step": 20100
    },
    {
      "epoch": 0.6448,
      "grad_norm": 0.27671414613723755,
      "learning_rate": 0.00017420928,
      "loss": 1.8621,
      "step": 20150
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.24955353140830994,
      "learning_rate": 0.00017414528,
      "loss": 1.792,
      "step": 20200
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.34273818135261536,
      "learning_rate": 0.00017408128000000002,
      "loss": 1.8512,
      "step": 20250
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.29512929916381836,
      "learning_rate": 0.00017401728000000002,
      "loss": 1.8144,
      "step": 20300
    },
    {
      "epoch": 0.6512,
      "grad_norm": 0.24812676012516022,
      "learning_rate": 0.00017395328,
      "loss": 1.7972,
      "step": 20350
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.3327227830886841,
      "learning_rate": 0.00017388928,
      "loss": 1.8022,
      "step": 20400
    },
    {
      "epoch": 0.6544,
      "grad_norm": 0.32608336210250854,
      "learning_rate": 0.00017382528,
      "loss": 1.8098,
      "step": 20450
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.29553648829460144,
      "learning_rate": 0.00017376128,
      "loss": 1.8387,
      "step": 20500
    },
    {
      "epoch": 0.6576,
      "grad_norm": 0.2814905345439911,
      "learning_rate": 0.00017369728,
      "loss": 1.7999,
      "step": 20550
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.25354984402656555,
      "learning_rate": 0.00017363328000000002,
      "loss": 1.7402,
      "step": 20600
    },
    {
      "epoch": 0.6608,
      "grad_norm": 0.2719014286994934,
      "learning_rate": 0.00017356928,
      "loss": 1.8151,
      "step": 20650
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.40005263686180115,
      "learning_rate": 0.00017350528,
      "loss": 1.7877,
      "step": 20700
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.25475913286209106,
      "learning_rate": 0.00017344128000000003,
      "loss": 1.7976,
      "step": 20750
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.27176469564437866,
      "learning_rate": 0.00017337728,
      "loss": 1.8036,
      "step": 20800
    },
    {
      "epoch": 0.6672,
      "grad_norm": 0.26953378319740295,
      "learning_rate": 0.00017331328,
      "loss": 1.798,
      "step": 20850
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.31953415274620056,
      "learning_rate": 0.00017324928000000001,
      "loss": 1.8378,
      "step": 20900
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.277811735868454,
      "learning_rate": 0.00017318528,
      "loss": 1.8183,
      "step": 20950
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.2684583365917206,
      "learning_rate": 0.00017312128,
      "loss": 1.8315,
      "step": 21000
    },
    {
      "epoch": 0.6736,
      "grad_norm": 0.2813534438610077,
      "learning_rate": 0.00017305728,
      "loss": 1.8793,
      "step": 21050
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.36891990900039673,
      "learning_rate": 0.00017299328000000002,
      "loss": 1.8357,
      "step": 21100
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.3916417360305786,
      "learning_rate": 0.00017292928000000002,
      "loss": 1.7945,
      "step": 21150
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.29983264207839966,
      "learning_rate": 0.00017286528,
      "loss": 1.8116,
      "step": 21200
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.24407242238521576,
      "learning_rate": 0.00017280128,
      "loss": 1.8674,
      "step": 21250
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.3153112232685089,
      "learning_rate": 0.00017273728,
      "loss": 1.7937,
      "step": 21300
    },
    {
      "epoch": 0.6832,
      "grad_norm": 0.2655923366546631,
      "learning_rate": 0.00017267328,
      "loss": 1.7878,
      "step": 21350
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.3064958453178406,
      "learning_rate": 0.00017260928000000002,
      "loss": 1.7364,
      "step": 21400
    },
    {
      "epoch": 0.6864,
      "grad_norm": 0.3148074150085449,
      "learning_rate": 0.00017254528000000002,
      "loss": 1.7855,
      "step": 21450
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.2844890356063843,
      "learning_rate": 0.00017248128,
      "loss": 1.8359,
      "step": 21500
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.2509949505329132,
      "learning_rate": 0.00017241728,
      "loss": 1.8197,
      "step": 21550
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.28207719326019287,
      "learning_rate": 0.00017235328000000003,
      "loss": 1.8161,
      "step": 21600
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.2687058448791504,
      "learning_rate": 0.00017228928,
      "loss": 1.8441,
      "step": 21650
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.3291037976741791,
      "learning_rate": 0.00017222528,
      "loss": 1.8317,
      "step": 21700
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.36067137122154236,
      "learning_rate": 0.00017216128,
      "loss": 1.8121,
      "step": 21750
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.29320740699768066,
      "learning_rate": 0.00017209728,
      "loss": 1.7432,
      "step": 21800
    },
    {
      "epoch": 0.6992,
      "grad_norm": 0.33211949467658997,
      "learning_rate": 0.00017203328,
      "loss": 1.7383,
      "step": 21850
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.37026309967041016,
      "learning_rate": 0.00017196928,
      "loss": 1.8308,
      "step": 21900
    },
    {
      "epoch": 0.7024,
      "grad_norm": 0.34383878111839294,
      "learning_rate": 0.00017190528000000002,
      "loss": 1.8398,
      "step": 21950
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.30669158697128296,
      "learning_rate": 0.00017184128000000002,
      "loss": 1.7583,
      "step": 22000
    },
    {
      "epoch": 0.7056,
      "grad_norm": 0.26830053329467773,
      "learning_rate": 0.00017177728,
      "loss": 1.8457,
      "step": 22050
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.309889018535614,
      "learning_rate": 0.00017171328,
      "loss": 1.8516,
      "step": 22100
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.3807556927204132,
      "learning_rate": 0.00017164928,
      "loss": 1.8363,
      "step": 22150
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.28944677114486694,
      "learning_rate": 0.00017158528,
      "loss": 1.8354,
      "step": 22200
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.2924533188343048,
      "learning_rate": 0.00017152128000000002,
      "loss": 1.7968,
      "step": 22250
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.24564535915851593,
      "learning_rate": 0.00017145728000000001,
      "loss": 1.8003,
      "step": 22300
    },
    {
      "epoch": 0.7152,
      "grad_norm": 0.30225563049316406,
      "learning_rate": 0.00017139328,
      "loss": 1.8286,
      "step": 22350
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.2645580768585205,
      "learning_rate": 0.00017132928,
      "loss": 1.8395,
      "step": 22400
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.33691784739494324,
      "learning_rate": 0.00017126528000000003,
      "loss": 1.8129,
      "step": 22450
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.27986273169517517,
      "learning_rate": 0.00017120128,
      "loss": 1.8095,
      "step": 22500
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.27375492453575134,
      "learning_rate": 0.00017113728,
      "loss": 1.8058,
      "step": 22550
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.27321889996528625,
      "learning_rate": 0.00017107328,
      "loss": 1.8556,
      "step": 22600
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.31352734565734863,
      "learning_rate": 0.00017100928,
      "loss": 1.8283,
      "step": 22650
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.2761245667934418,
      "learning_rate": 0.00017094528,
      "loss": 1.7723,
      "step": 22700
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.3665589392185211,
      "learning_rate": 0.00017088128,
      "loss": 1.796,
      "step": 22750
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.2642481029033661,
      "learning_rate": 0.00017081728000000002,
      "loss": 1.7666,
      "step": 22800
    },
    {
      "epoch": 0.7312,
      "grad_norm": 0.27702438831329346,
      "learning_rate": 0.00017075328000000002,
      "loss": 1.824,
      "step": 22850
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.2719050645828247,
      "learning_rate": 0.00017068928,
      "loss": 1.843,
      "step": 22900
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.25972849130630493,
      "learning_rate": 0.00017062528,
      "loss": 1.8231,
      "step": 22950
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.2952682375907898,
      "learning_rate": 0.00017056128,
      "loss": 1.7899,
      "step": 23000
    },
    {
      "epoch": 0.7376,
      "grad_norm": 0.2934182584285736,
      "learning_rate": 0.00017049728,
      "loss": 1.8516,
      "step": 23050
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.2967308461666107,
      "learning_rate": 0.00017043328000000002,
      "loss": 1.7949,
      "step": 23100
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.2434602528810501,
      "learning_rate": 0.00017036928000000001,
      "loss": 1.8634,
      "step": 23150
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.3228636384010315,
      "learning_rate": 0.00017030528,
      "loss": 1.8374,
      "step": 23200
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.26639169454574585,
      "learning_rate": 0.00017024128,
      "loss": 1.7974,
      "step": 23250
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.2638288736343384,
      "learning_rate": 0.00017017728000000003,
      "loss": 1.8062,
      "step": 23300
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.3144901990890503,
      "learning_rate": 0.00017011328,
      "loss": 1.8119,
      "step": 23350
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.31986042857170105,
      "learning_rate": 0.00017004928,
      "loss": 1.798,
      "step": 23400
    },
    {
      "epoch": 0.7504,
      "grad_norm": 0.3523099720478058,
      "learning_rate": 0.00016998528,
      "loss": 1.7681,
      "step": 23450
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.21911121904850006,
      "learning_rate": 0.00016992128,
      "loss": 1.6934,
      "step": 23500
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.34556472301483154,
      "learning_rate": 0.00016985728,
      "loss": 1.7826,
      "step": 23550
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.30230674147605896,
      "learning_rate": 0.00016979328,
      "loss": 1.8793,
      "step": 23600
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.2975812554359436,
      "learning_rate": 0.00016972928000000002,
      "loss": 1.7993,
      "step": 23650
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.26770108938217163,
      "learning_rate": 0.00016966528000000002,
      "loss": 1.8339,
      "step": 23700
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3197295665740967,
      "learning_rate": 0.00016960128,
      "loss": 1.765,
      "step": 23750
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.27934393286705017,
      "learning_rate": 0.00016953728,
      "loss": 1.8487,
      "step": 23800
    },
    {
      "epoch": 0.7632,
      "grad_norm": 0.2719819247722626,
      "learning_rate": 0.00016947328,
      "loss": 1.8049,
      "step": 23850
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.24705322086811066,
      "learning_rate": 0.00016940928,
      "loss": 1.8594,
      "step": 23900
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.31887543201446533,
      "learning_rate": 0.00016934528000000002,
      "loss": 1.8182,
      "step": 23950
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.27013924717903137,
      "learning_rate": 0.00016928128000000001,
      "loss": 1.7789,
      "step": 24000
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.2609173059463501,
      "learning_rate": 0.00016921728,
      "loss": 1.8145,
      "step": 24050
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.2566821873188019,
      "learning_rate": 0.00016915328,
      "loss": 1.8292,
      "step": 24100
    },
    {
      "epoch": 0.7728,
      "grad_norm": 0.29237884283065796,
      "learning_rate": 0.00016908928000000003,
      "loss": 1.8413,
      "step": 24150
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.3252819776535034,
      "learning_rate": 0.00016902528000000002,
      "loss": 1.8248,
      "step": 24200
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.38117000460624695,
      "learning_rate": 0.00016896128,
      "loss": 1.8139,
      "step": 24250
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.27501216530799866,
      "learning_rate": 0.00016889728,
      "loss": 1.8393,
      "step": 24300
    },
    {
      "epoch": 0.7792,
      "grad_norm": 0.3093540072441101,
      "learning_rate": 0.00016883328,
      "loss": 1.7817,
      "step": 24350
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.27095329761505127,
      "learning_rate": 0.00016876928,
      "loss": 1.8525,
      "step": 24400
    },
    {
      "epoch": 0.7824,
      "grad_norm": 0.2654114365577698,
      "learning_rate": 0.00016870528,
      "loss": 1.8051,
      "step": 24450
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.28412920236587524,
      "learning_rate": 0.00016864128000000002,
      "loss": 1.8139,
      "step": 24500
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.3227715492248535,
      "learning_rate": 0.00016857728000000002,
      "loss": 1.8092,
      "step": 24550
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.296394407749176,
      "learning_rate": 0.00016851328,
      "loss": 1.8157,
      "step": 24600
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.2815989553928375,
      "learning_rate": 0.00016844928,
      "loss": 1.8515,
      "step": 24650
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.4077520966529846,
      "learning_rate": 0.00016838528,
      "loss": 1.8156,
      "step": 24700
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.2629818916320801,
      "learning_rate": 0.00016832128,
      "loss": 1.7816,
      "step": 24750
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.2751695215702057,
      "learning_rate": 0.00016825728000000002,
      "loss": 1.7619,
      "step": 24800
    },
    {
      "epoch": 0.7952,
      "grad_norm": 0.3148442208766937,
      "learning_rate": 0.00016819328,
      "loss": 1.8226,
      "step": 24850
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.26227718591690063,
      "learning_rate": 0.00016812928,
      "loss": 1.8195,
      "step": 24900
    },
    {
      "epoch": 0.7984,
      "grad_norm": 0.27707019448280334,
      "learning_rate": 0.00016806528,
      "loss": 1.7863,
      "step": 24950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.29423680901527405,
      "learning_rate": 0.00016800128000000003,
      "loss": 1.7887,
      "step": 25000
    },
    {
      "epoch": 0.8016,
      "grad_norm": 0.24285493791103363,
      "learning_rate": 0.00016793728000000002,
      "loss": 1.7813,
      "step": 25050
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.2577679455280304,
      "learning_rate": 0.00016787328,
      "loss": 1.8143,
      "step": 25100
    },
    {
      "epoch": 0.8048,
      "grad_norm": 0.3224930465221405,
      "learning_rate": 0.00016780928,
      "loss": 1.8746,
      "step": 25150
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.3035898506641388,
      "learning_rate": 0.00016774528,
      "loss": 1.8173,
      "step": 25200
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.44122636318206787,
      "learning_rate": 0.00016768128,
      "loss": 1.8063,
      "step": 25250
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.3532845079898834,
      "learning_rate": 0.00016761728,
      "loss": 1.8492,
      "step": 25300
    },
    {
      "epoch": 0.8112,
      "grad_norm": 0.2857036590576172,
      "learning_rate": 0.00016755328000000002,
      "loss": 1.7727,
      "step": 25350
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.2945828437805176,
      "learning_rate": 0.00016748928000000001,
      "loss": 1.797,
      "step": 25400
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.2892215847969055,
      "learning_rate": 0.00016742528,
      "loss": 1.8643,
      "step": 25450
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.2497263103723526,
      "learning_rate": 0.00016736128,
      "loss": 1.7931,
      "step": 25500
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.2906442880630493,
      "learning_rate": 0.00016729728,
      "loss": 1.82,
      "step": 25550
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.28666555881500244,
      "learning_rate": 0.00016723328,
      "loss": 1.7787,
      "step": 25600
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.3235645592212677,
      "learning_rate": 0.00016716928000000002,
      "loss": 1.8671,
      "step": 25650
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.3449171781539917,
      "learning_rate": 0.00016710528,
      "loss": 1.8089,
      "step": 25700
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.2684071362018585,
      "learning_rate": 0.00016704128,
      "loss": 1.7966,
      "step": 25750
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.3123616874217987,
      "learning_rate": 0.00016697728,
      "loss": 1.8229,
      "step": 25800
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.2661760449409485,
      "learning_rate": 0.00016691328000000003,
      "loss": 1.8066,
      "step": 25850
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.32757827639579773,
      "learning_rate": 0.00016684928000000002,
      "loss": 1.7685,
      "step": 25900
    },
    {
      "epoch": 0.8304,
      "grad_norm": 0.2511202394962311,
      "learning_rate": 0.00016678528,
      "loss": 1.7805,
      "step": 25950
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.3449340760707855,
      "learning_rate": 0.00016672128,
      "loss": 1.7842,
      "step": 26000
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.270500510931015,
      "learning_rate": 0.00016665728,
      "loss": 1.7894,
      "step": 26050
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.3174208998680115,
      "learning_rate": 0.00016659328,
      "loss": 1.826,
      "step": 26100
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.3229687511920929,
      "learning_rate": 0.00016652928,
      "loss": 1.7744,
      "step": 26150
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.27487248182296753,
      "learning_rate": 0.00016646528000000002,
      "loss": 1.8147,
      "step": 26200
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.2890715003013611,
      "learning_rate": 0.00016640128000000001,
      "loss": 1.822,
      "step": 26250
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.30853885412216187,
      "learning_rate": 0.00016633728,
      "loss": 1.8315,
      "step": 26300
    },
    {
      "epoch": 0.8432,
      "grad_norm": 0.30350780487060547,
      "learning_rate": 0.00016627328,
      "loss": 1.808,
      "step": 26350
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.3385002613067627,
      "learning_rate": 0.00016620928,
      "loss": 1.8031,
      "step": 26400
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.32040590047836304,
      "learning_rate": 0.00016614528,
      "loss": 1.8416,
      "step": 26450
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.3104245066642761,
      "learning_rate": 0.00016608128000000002,
      "loss": 1.8389,
      "step": 26500
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.3207157254219055,
      "learning_rate": 0.00016601728,
      "loss": 1.8108,
      "step": 26550
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.25787878036499023,
      "learning_rate": 0.00016595328,
      "loss": 1.8632,
      "step": 26600
    },
    {
      "epoch": 0.8528,
      "grad_norm": 0.32787764072418213,
      "learning_rate": 0.00016588928,
      "loss": 1.7682,
      "step": 26650
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.2802887260913849,
      "learning_rate": 0.00016582528000000003,
      "loss": 1.7787,
      "step": 26700
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.33354368805885315,
      "learning_rate": 0.00016576128000000002,
      "loss": 1.7658,
      "step": 26750
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.33044928312301636,
      "learning_rate": 0.00016569728,
      "loss": 1.8878,
      "step": 26800
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.3689887225627899,
      "learning_rate": 0.00016563328,
      "loss": 1.8016,
      "step": 26850
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.27512046694755554,
      "learning_rate": 0.00016556928,
      "loss": 1.8432,
      "step": 26900
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.27350926399230957,
      "learning_rate": 0.00016550528,
      "loss": 1.7697,
      "step": 26950
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.3080698847770691,
      "learning_rate": 0.00016544128,
      "loss": 1.7799,
      "step": 27000
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.3651435673236847,
      "learning_rate": 0.00016537728000000002,
      "loss": 1.8371,
      "step": 27050
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.3197198510169983,
      "learning_rate": 0.00016531328000000001,
      "loss": 1.8342,
      "step": 27100
    },
    {
      "epoch": 0.8688,
      "grad_norm": 0.29202041029930115,
      "learning_rate": 0.00016524928,
      "loss": 1.7957,
      "step": 27150
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.3330199718475342,
      "learning_rate": 0.00016518528,
      "loss": 1.801,
      "step": 27200
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.28055649995803833,
      "learning_rate": 0.00016512128,
      "loss": 1.8204,
      "step": 27250
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.2888617515563965,
      "learning_rate": 0.00016505728,
      "loss": 1.763,
      "step": 27300
    },
    {
      "epoch": 0.8752,
      "grad_norm": 0.33685413002967834,
      "learning_rate": 0.00016499328000000002,
      "loss": 1.7321,
      "step": 27350
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.33966436982154846,
      "learning_rate": 0.00016492928,
      "loss": 1.7873,
      "step": 27400
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.27632245421409607,
      "learning_rate": 0.00016486528,
      "loss": 1.8002,
      "step": 27450
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2791261076927185,
      "learning_rate": 0.00016480128,
      "loss": 1.791,
      "step": 27500
    },
    {
      "epoch": 0.8816,
      "grad_norm": 0.24456509947776794,
      "learning_rate": 0.00016473728000000002,
      "loss": 1.8104,
      "step": 27550
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.27509915828704834,
      "learning_rate": 0.00016467328000000002,
      "loss": 1.7672,
      "step": 27600
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.3120898902416229,
      "learning_rate": 0.00016460928,
      "loss": 1.8277,
      "step": 27650
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.30196601152420044,
      "learning_rate": 0.00016454528,
      "loss": 1.828,
      "step": 27700
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.29778385162353516,
      "learning_rate": 0.00016448128,
      "loss": 1.8339,
      "step": 27750
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.2847273349761963,
      "learning_rate": 0.00016441728,
      "loss": 1.8068,
      "step": 27800
    },
    {
      "epoch": 0.8912,
      "grad_norm": 0.2828208804130554,
      "learning_rate": 0.00016435328000000002,
      "loss": 1.8213,
      "step": 27850
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.3050030469894409,
      "learning_rate": 0.00016428928000000002,
      "loss": 1.8062,
      "step": 27900
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.27961814403533936,
      "learning_rate": 0.00016422528,
      "loss": 1.875,
      "step": 27950
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.3048325479030609,
      "learning_rate": 0.00016416128,
      "loss": 1.8043,
      "step": 28000
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.33455923199653625,
      "learning_rate": 0.00016409728,
      "loss": 1.7764,
      "step": 28050
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.33403071761131287,
      "learning_rate": 0.00016403328,
      "loss": 1.8004,
      "step": 28100
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.2996848523616791,
      "learning_rate": 0.00016396928,
      "loss": 1.8068,
      "step": 28150
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.3293053209781647,
      "learning_rate": 0.00016390528000000002,
      "loss": 1.828,
      "step": 28200
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.28832000494003296,
      "learning_rate": 0.00016384128,
      "loss": 1.7419,
      "step": 28250
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.2944725751876831,
      "learning_rate": 0.00016377728,
      "loss": 1.7808,
      "step": 28300
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.32455775141716003,
      "learning_rate": 0.00016371328,
      "loss": 1.8068,
      "step": 28350
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.29398784041404724,
      "learning_rate": 0.00016364928000000002,
      "loss": 1.9205,
      "step": 28400
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.30220508575439453,
      "learning_rate": 0.00016358528000000002,
      "loss": 1.8537,
      "step": 28450
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.3213171660900116,
      "learning_rate": 0.00016352128,
      "loss": 1.7856,
      "step": 28500
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.28731220960617065,
      "learning_rate": 0.00016345728,
      "loss": 1.8212,
      "step": 28550
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.3313087522983551,
      "learning_rate": 0.00016339328,
      "loss": 1.8042,
      "step": 28600
    },
    {
      "epoch": 0.9168,
      "grad_norm": 0.2602091133594513,
      "learning_rate": 0.00016332928,
      "loss": 1.8076,
      "step": 28650
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.2879917323589325,
      "learning_rate": 0.00016326528000000002,
      "loss": 1.8575,
      "step": 28700
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.2879005968570709,
      "learning_rate": 0.00016320128000000002,
      "loss": 1.833,
      "step": 28750
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.2871568202972412,
      "learning_rate": 0.00016313728,
      "loss": 1.8285,
      "step": 28800
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.2793899476528168,
      "learning_rate": 0.00016307328,
      "loss": 1.8213,
      "step": 28850
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.2792058289051056,
      "learning_rate": 0.00016300928,
      "loss": 1.8233,
      "step": 28900
    },
    {
      "epoch": 0.9264,
      "grad_norm": 0.33943018317222595,
      "learning_rate": 0.00016294528,
      "loss": 1.8532,
      "step": 28950
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.27755263447761536,
      "learning_rate": 0.00016288128,
      "loss": 1.7936,
      "step": 29000
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.25337857007980347,
      "learning_rate": 0.00016281728000000002,
      "loss": 1.8086,
      "step": 29050
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.32266199588775635,
      "learning_rate": 0.00016275328,
      "loss": 1.8302,
      "step": 29100
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.28278228640556335,
      "learning_rate": 0.00016268928,
      "loss": 1.843,
      "step": 29150
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.27952712774276733,
      "learning_rate": 0.00016262528,
      "loss": 1.8678,
      "step": 29200
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.2881232798099518,
      "learning_rate": 0.00016256128000000002,
      "loss": 1.8379,
      "step": 29250
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.3701430857181549,
      "learning_rate": 0.00016249728000000002,
      "loss": 1.7875,
      "step": 29300
    },
    {
      "epoch": 0.9392,
      "grad_norm": 0.33272498846054077,
      "learning_rate": 0.00016243328,
      "loss": 1.7508,
      "step": 29350
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.24937275052070618,
      "learning_rate": 0.00016236928,
      "loss": 1.8717,
      "step": 29400
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.3316301703453064,
      "learning_rate": 0.00016230528,
      "loss": 1.7768,
      "step": 29450
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.26740020513534546,
      "learning_rate": 0.00016224128,
      "loss": 1.8403,
      "step": 29500
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.2929781973361969,
      "learning_rate": 0.00016217728000000002,
      "loss": 1.8497,
      "step": 29550
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.3386044204235077,
      "learning_rate": 0.00016211328000000002,
      "loss": 1.7728,
      "step": 29600
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.3014664947986603,
      "learning_rate": 0.00016204928,
      "loss": 1.7874,
      "step": 29650
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.29194962978363037,
      "learning_rate": 0.00016198528,
      "loss": 1.8221,
      "step": 29700
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.33200058341026306,
      "learning_rate": 0.00016192128,
      "loss": 1.7987,
      "step": 29750
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.398485004901886,
      "learning_rate": 0.00016185728,
      "loss": 1.801,
      "step": 29800
    },
    {
      "epoch": 0.9552,
      "grad_norm": 0.41863900423049927,
      "learning_rate": 0.00016179328,
      "loss": 1.7839,
      "step": 29850
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.276684433221817,
      "learning_rate": 0.00016172928000000002,
      "loss": 1.857,
      "step": 29900
    },
    {
      "epoch": 0.9584,
      "grad_norm": 0.34056177735328674,
      "learning_rate": 0.00016166528,
      "loss": 1.8299,
      "step": 29950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.33350542187690735,
      "learning_rate": 0.00016160128,
      "loss": 1.77,
      "step": 30000
    },
    {
      "epoch": 0.9616,
      "grad_norm": 0.359673410654068,
      "learning_rate": 0.00016153728,
      "loss": 1.9019,
      "step": 30050
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.31293126940727234,
      "learning_rate": 0.00016147328000000002,
      "loss": 1.842,
      "step": 30100
    },
    {
      "epoch": 0.9648,
      "grad_norm": 0.3306323289871216,
      "learning_rate": 0.00016140928000000002,
      "loss": 1.8434,
      "step": 30150
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.30820581316947937,
      "learning_rate": 0.00016134528,
      "loss": 1.8304,
      "step": 30200
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.3316570520401001,
      "learning_rate": 0.00016128128,
      "loss": 1.8265,
      "step": 30250
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.305787593126297,
      "learning_rate": 0.00016121728,
      "loss": 1.8593,
      "step": 30300
    },
    {
      "epoch": 0.9712,
      "grad_norm": 0.27650541067123413,
      "learning_rate": 0.00016115328,
      "loss": 1.7854,
      "step": 30350
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.38066500425338745,
      "learning_rate": 0.00016108928000000002,
      "loss": 1.7912,
      "step": 30400
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.2713203430175781,
      "learning_rate": 0.00016102528000000002,
      "loss": 1.7917,
      "step": 30450
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.34225383400917053,
      "learning_rate": 0.00016096128,
      "loss": 1.7988,
      "step": 30500
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.32081013917922974,
      "learning_rate": 0.00016089728,
      "loss": 1.7767,
      "step": 30550
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.3049968183040619,
      "learning_rate": 0.00016083328,
      "loss": 1.8001,
      "step": 30600
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.3199072480201721,
      "learning_rate": 0.00016076928,
      "loss": 1.8442,
      "step": 30650
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.2893892824649811,
      "learning_rate": 0.00016070528,
      "loss": 1.7692,
      "step": 30700
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.2584843635559082,
      "learning_rate": 0.00016064128000000002,
      "loss": 1.8021,
      "step": 30750
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.2609516978263855,
      "learning_rate": 0.00016057728,
      "loss": 1.788,
      "step": 30800
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.2680358588695526,
      "learning_rate": 0.00016051328,
      "loss": 1.8108,
      "step": 30850
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.3092690408229828,
      "learning_rate": 0.00016044928,
      "loss": 1.8182,
      "step": 30900
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.4666752219200134,
      "learning_rate": 0.00016038528000000002,
      "loss": 1.8516,
      "step": 30950
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.37438681721687317,
      "learning_rate": 0.00016032128000000002,
      "loss": 1.7935,
      "step": 31000
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.3360461890697479,
      "learning_rate": 0.00016025727999999999,
      "loss": 1.803,
      "step": 31050
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.38518381118774414,
      "learning_rate": 0.00016019328,
      "loss": 1.878,
      "step": 31100
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.2815493643283844,
      "learning_rate": 0.00016012928,
      "loss": 1.8446,
      "step": 31150
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.265789270401001,
      "learning_rate": 0.00016006528,
      "loss": 1.806,
      "step": 31200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3177085518836975,
      "learning_rate": 0.00016000128000000002,
      "loss": 1.7542,
      "step": 31250
    },
    {
      "epoch": 1.0016,
      "grad_norm": 0.26717400550842285,
      "learning_rate": 0.00015993728000000002,
      "loss": 1.8284,
      "step": 31300
    },
    {
      "epoch": 1.0032,
      "grad_norm": 0.24668490886688232,
      "learning_rate": 0.00015987328,
      "loss": 1.7713,
      "step": 31350
    },
    {
      "epoch": 1.0048,
      "grad_norm": 0.3256967067718506,
      "learning_rate": 0.00015980928,
      "loss": 1.7938,
      "step": 31400
    },
    {
      "epoch": 1.0064,
      "grad_norm": 0.29937753081321716,
      "learning_rate": 0.00015974528,
      "loss": 1.7698,
      "step": 31450
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.3685142397880554,
      "learning_rate": 0.00015968128,
      "loss": 1.7741,
      "step": 31500
    },
    {
      "epoch": 1.0096,
      "grad_norm": 0.3488629460334778,
      "learning_rate": 0.00015961728,
      "loss": 1.7988,
      "step": 31550
    },
    {
      "epoch": 1.0112,
      "grad_norm": 0.27539485692977905,
      "learning_rate": 0.00015955328000000001,
      "loss": 1.8062,
      "step": 31600
    },
    {
      "epoch": 1.0128,
      "grad_norm": 0.255317747592926,
      "learning_rate": 0.00015948928,
      "loss": 1.8137,
      "step": 31650
    },
    {
      "epoch": 1.0144,
      "grad_norm": 0.3480009436607361,
      "learning_rate": 0.00015942528,
      "loss": 1.7877,
      "step": 31700
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.24992406368255615,
      "learning_rate": 0.00015936128,
      "loss": 1.826,
      "step": 31750
    },
    {
      "epoch": 1.0176,
      "grad_norm": 0.2745361328125,
      "learning_rate": 0.00015929728000000002,
      "loss": 1.7848,
      "step": 31800
    },
    {
      "epoch": 1.0192,
      "grad_norm": 0.341558575630188,
      "learning_rate": 0.00015923328000000002,
      "loss": 1.817,
      "step": 31850
    },
    {
      "epoch": 1.0208,
      "grad_norm": 0.27196717262268066,
      "learning_rate": 0.00015916927999999999,
      "loss": 1.7359,
      "step": 31900
    },
    {
      "epoch": 1.0224,
      "grad_norm": 0.33006036281585693,
      "learning_rate": 0.00015910528,
      "loss": 1.7968,
      "step": 31950
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.3440926671028137,
      "learning_rate": 0.00015904128,
      "loss": 1.8606,
      "step": 32000
    },
    {
      "epoch": 1.0256,
      "grad_norm": 0.33567938208580017,
      "learning_rate": 0.00015897728,
      "loss": 1.8156,
      "step": 32050
    },
    {
      "epoch": 1.0272,
      "grad_norm": 0.28124624490737915,
      "learning_rate": 0.00015891328000000002,
      "loss": 1.7863,
      "step": 32100
    },
    {
      "epoch": 1.0288,
      "grad_norm": 0.26299458742141724,
      "learning_rate": 0.00015884928000000002,
      "loss": 1.8272,
      "step": 32150
    },
    {
      "epoch": 1.0304,
      "grad_norm": 0.2743656039237976,
      "learning_rate": 0.00015878528,
      "loss": 1.8267,
      "step": 32200
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.3233252465724945,
      "learning_rate": 0.00015872128,
      "loss": 1.8163,
      "step": 32250
    },
    {
      "epoch": 1.0336,
      "grad_norm": 0.28366464376449585,
      "learning_rate": 0.00015865728,
      "loss": 1.7863,
      "step": 32300
    },
    {
      "epoch": 1.0352,
      "grad_norm": 0.3193310499191284,
      "learning_rate": 0.00015859328,
      "loss": 1.8491,
      "step": 32350
    },
    {
      "epoch": 1.0368,
      "grad_norm": 0.3368701934814453,
      "learning_rate": 0.00015852928,
      "loss": 1.7823,
      "step": 32400
    },
    {
      "epoch": 1.0384,
      "grad_norm": 0.35319212079048157,
      "learning_rate": 0.00015846528000000001,
      "loss": 1.8253,
      "step": 32450
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.3314399719238281,
      "learning_rate": 0.00015840128,
      "loss": 1.8069,
      "step": 32500
    },
    {
      "epoch": 1.0416,
      "grad_norm": 0.324532151222229,
      "learning_rate": 0.00015833728,
      "loss": 1.794,
      "step": 32550
    },
    {
      "epoch": 1.0432,
      "grad_norm": 0.28069913387298584,
      "learning_rate": 0.00015827328,
      "loss": 1.7619,
      "step": 32600
    },
    {
      "epoch": 1.0448,
      "grad_norm": 0.26526200771331787,
      "learning_rate": 0.00015820928000000002,
      "loss": 1.7711,
      "step": 32650
    },
    {
      "epoch": 1.0464,
      "grad_norm": 0.4064723551273346,
      "learning_rate": 0.00015814528000000002,
      "loss": 1.8571,
      "step": 32700
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.2891870141029358,
      "learning_rate": 0.00015808127999999999,
      "loss": 1.7809,
      "step": 32750
    },
    {
      "epoch": 1.0496,
      "grad_norm": 0.2957039475440979,
      "learning_rate": 0.00015801728,
      "loss": 1.8019,
      "step": 32800
    },
    {
      "epoch": 1.0512,
      "grad_norm": 0.3459509313106537,
      "learning_rate": 0.00015795328,
      "loss": 1.863,
      "step": 32850
    },
    {
      "epoch": 1.0528,
      "grad_norm": 0.33211803436279297,
      "learning_rate": 0.00015788928,
      "loss": 1.7416,
      "step": 32900
    },
    {
      "epoch": 1.0544,
      "grad_norm": 0.368591845035553,
      "learning_rate": 0.00015782528000000002,
      "loss": 1.8198,
      "step": 32950
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.27592065930366516,
      "learning_rate": 0.00015776128000000002,
      "loss": 1.7957,
      "step": 33000
    },
    {
      "epoch": 1.0576,
      "grad_norm": 0.2989824414253235,
      "learning_rate": 0.00015769728,
      "loss": 1.855,
      "step": 33050
    },
    {
      "epoch": 1.0592,
      "grad_norm": 0.433463990688324,
      "learning_rate": 0.00015763328,
      "loss": 1.8611,
      "step": 33100
    },
    {
      "epoch": 1.0608,
      "grad_norm": 0.33066612482070923,
      "learning_rate": 0.00015756928,
      "loss": 1.7605,
      "step": 33150
    },
    {
      "epoch": 1.0624,
      "grad_norm": 0.2591552138328552,
      "learning_rate": 0.00015750528,
      "loss": 1.9154,
      "step": 33200
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.34322914481163025,
      "learning_rate": 0.00015744128,
      "loss": 1.8252,
      "step": 33250
    },
    {
      "epoch": 1.0656,
      "grad_norm": 0.311727911233902,
      "learning_rate": 0.00015737728000000001,
      "loss": 1.7811,
      "step": 33300
    },
    {
      "epoch": 1.0672,
      "grad_norm": 0.421575665473938,
      "learning_rate": 0.00015731328,
      "loss": 1.7762,
      "step": 33350
    },
    {
      "epoch": 1.0688,
      "grad_norm": 0.2631853222846985,
      "learning_rate": 0.00015724928,
      "loss": 1.8383,
      "step": 33400
    },
    {
      "epoch": 1.0704,
      "grad_norm": 0.3074878752231598,
      "learning_rate": 0.00015718528,
      "loss": 1.7829,
      "step": 33450
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.3355324864387512,
      "learning_rate": 0.00015712128000000002,
      "loss": 1.8317,
      "step": 33500
    },
    {
      "epoch": 1.0735999999999999,
      "grad_norm": 0.27041929960250854,
      "learning_rate": 0.00015705728000000002,
      "loss": 1.8206,
      "step": 33550
    },
    {
      "epoch": 1.0752,
      "grad_norm": 0.3223706781864166,
      "learning_rate": 0.00015699327999999999,
      "loss": 1.7873,
      "step": 33600
    },
    {
      "epoch": 1.0768,
      "grad_norm": 0.3479475975036621,
      "learning_rate": 0.00015692928,
      "loss": 1.8064,
      "step": 33650
    },
    {
      "epoch": 1.0784,
      "grad_norm": 0.3295304477214813,
      "learning_rate": 0.00015686528,
      "loss": 1.8276,
      "step": 33700
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.29153379797935486,
      "learning_rate": 0.00015680128,
      "loss": 1.8354,
      "step": 33750
    },
    {
      "epoch": 1.0816,
      "grad_norm": 0.3320961594581604,
      "learning_rate": 0.00015673728000000002,
      "loss": 1.7813,
      "step": 33800
    },
    {
      "epoch": 1.0832,
      "grad_norm": 0.28870734572410583,
      "learning_rate": 0.00015667328000000002,
      "loss": 1.7787,
      "step": 33850
    },
    {
      "epoch": 1.0848,
      "grad_norm": 0.3496930003166199,
      "learning_rate": 0.00015660928,
      "loss": 1.7701,
      "step": 33900
    },
    {
      "epoch": 1.0864,
      "grad_norm": 0.34093770384788513,
      "learning_rate": 0.00015654528,
      "loss": 1.7792,
      "step": 33950
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.37763163447380066,
      "learning_rate": 0.00015648128,
      "loss": 1.7818,
      "step": 34000
    },
    {
      "epoch": 1.0896,
      "grad_norm": 0.3034634590148926,
      "learning_rate": 0.00015641728,
      "loss": 1.8086,
      "step": 34050
    },
    {
      "epoch": 1.0912,
      "grad_norm": 0.3482048809528351,
      "learning_rate": 0.00015635328,
      "loss": 1.851,
      "step": 34100
    },
    {
      "epoch": 1.0928,
      "grad_norm": 0.3127988576889038,
      "learning_rate": 0.00015628928,
      "loss": 1.7651,
      "step": 34150
    },
    {
      "epoch": 1.0944,
      "grad_norm": 0.3618810474872589,
      "learning_rate": 0.00015622528,
      "loss": 1.8235,
      "step": 34200
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.32221728563308716,
      "learning_rate": 0.00015616128,
      "loss": 1.7345,
      "step": 34250
    },
    {
      "epoch": 1.0976,
      "grad_norm": 0.26803213357925415,
      "learning_rate": 0.00015609728,
      "loss": 1.8315,
      "step": 34300
    },
    {
      "epoch": 1.0992,
      "grad_norm": 0.31337401270866394,
      "learning_rate": 0.00015603328000000002,
      "loss": 1.7803,
      "step": 34350
    },
    {
      "epoch": 1.1008,
      "grad_norm": 0.34000110626220703,
      "learning_rate": 0.00015596928000000002,
      "loss": 1.8098,
      "step": 34400
    },
    {
      "epoch": 1.1024,
      "grad_norm": 0.28482022881507874,
      "learning_rate": 0.00015590527999999998,
      "loss": 1.8157,
      "step": 34450
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.3197460174560547,
      "learning_rate": 0.00015584128,
      "loss": 1.8229,
      "step": 34500
    },
    {
      "epoch": 1.1056,
      "grad_norm": 0.37908804416656494,
      "learning_rate": 0.00015577728,
      "loss": 1.8045,
      "step": 34550
    },
    {
      "epoch": 1.1072,
      "grad_norm": 0.3457452058792114,
      "learning_rate": 0.00015571328,
      "loss": 1.8063,
      "step": 34600
    },
    {
      "epoch": 1.1088,
      "grad_norm": 0.29493826627731323,
      "learning_rate": 0.00015564928000000002,
      "loss": 1.8184,
      "step": 34650
    },
    {
      "epoch": 1.1104,
      "grad_norm": 0.31465500593185425,
      "learning_rate": 0.00015558528000000001,
      "loss": 1.8151,
      "step": 34700
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.31782832741737366,
      "learning_rate": 0.00015552128,
      "loss": 1.7795,
      "step": 34750
    },
    {
      "epoch": 1.1136,
      "grad_norm": 0.353921502828598,
      "learning_rate": 0.00015545728,
      "loss": 1.8306,
      "step": 34800
    },
    {
      "epoch": 1.1152,
      "grad_norm": 0.372344434261322,
      "learning_rate": 0.00015539328,
      "loss": 1.7728,
      "step": 34850
    },
    {
      "epoch": 1.1168,
      "grad_norm": 0.3397030234336853,
      "learning_rate": 0.00015532928,
      "loss": 1.8093,
      "step": 34900
    },
    {
      "epoch": 1.1184,
      "grad_norm": 0.2820335030555725,
      "learning_rate": 0.00015526528,
      "loss": 1.7792,
      "step": 34950
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.31491509079933167,
      "learning_rate": 0.00015520128,
      "loss": 1.7667,
      "step": 35000
    },
    {
      "epoch": 1.1216,
      "grad_norm": 0.299378365278244,
      "learning_rate": 0.00015513728,
      "loss": 1.8073,
      "step": 35050
    },
    {
      "epoch": 1.1232,
      "grad_norm": 0.32598385214805603,
      "learning_rate": 0.00015507328,
      "loss": 1.7713,
      "step": 35100
    },
    {
      "epoch": 1.1248,
      "grad_norm": 0.28039607405662537,
      "learning_rate": 0.00015500928000000003,
      "loss": 1.8171,
      "step": 35150
    },
    {
      "epoch": 1.1264,
      "grad_norm": 0.41253066062927246,
      "learning_rate": 0.00015494528000000002,
      "loss": 1.7802,
      "step": 35200
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.27339670062065125,
      "learning_rate": 0.00015488128000000002,
      "loss": 1.8193,
      "step": 35250
    },
    {
      "epoch": 1.1296,
      "grad_norm": 0.2975656986236572,
      "learning_rate": 0.00015481728,
      "loss": 1.7778,
      "step": 35300
    },
    {
      "epoch": 1.1312,
      "grad_norm": 0.3236803412437439,
      "learning_rate": 0.00015475328,
      "loss": 1.7582,
      "step": 35350
    },
    {
      "epoch": 1.1328,
      "grad_norm": 0.440883994102478,
      "learning_rate": 0.00015468928,
      "loss": 1.7921,
      "step": 35400
    },
    {
      "epoch": 1.1344,
      "grad_norm": 0.3052278757095337,
      "learning_rate": 0.00015462528,
      "loss": 1.8246,
      "step": 35450
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.3110058605670929,
      "learning_rate": 0.00015456128000000002,
      "loss": 1.8304,
      "step": 35500
    },
    {
      "epoch": 1.1376,
      "grad_norm": 0.31396862864494324,
      "learning_rate": 0.00015449728000000001,
      "loss": 1.7622,
      "step": 35550
    },
    {
      "epoch": 1.1392,
      "grad_norm": 0.2734997570514679,
      "learning_rate": 0.00015443328,
      "loss": 1.7925,
      "step": 35600
    },
    {
      "epoch": 1.1408,
      "grad_norm": 0.3196791410446167,
      "learning_rate": 0.00015436928,
      "loss": 1.7927,
      "step": 35650
    },
    {
      "epoch": 1.1424,
      "grad_norm": 0.2641814351081848,
      "learning_rate": 0.00015430528,
      "loss": 1.7846,
      "step": 35700
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.30403661727905273,
      "learning_rate": 0.00015424128,
      "loss": 1.8281,
      "step": 35750
    },
    {
      "epoch": 1.1456,
      "grad_norm": 0.32583415508270264,
      "learning_rate": 0.00015417728,
      "loss": 1.8174,
      "step": 35800
    },
    {
      "epoch": 1.1472,
      "grad_norm": 0.33012959361076355,
      "learning_rate": 0.00015411328,
      "loss": 1.7854,
      "step": 35850
    },
    {
      "epoch": 1.1488,
      "grad_norm": 0.37429770827293396,
      "learning_rate": 0.00015404928,
      "loss": 1.7931,
      "step": 35900
    },
    {
      "epoch": 1.1504,
      "grad_norm": 0.34462815523147583,
      "learning_rate": 0.00015398528,
      "loss": 1.837,
      "step": 35950
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.2850905954837799,
      "learning_rate": 0.00015392128000000003,
      "loss": 1.7877,
      "step": 36000
    },
    {
      "epoch": 1.1536,
      "grad_norm": 0.34031912684440613,
      "learning_rate": 0.00015385728000000002,
      "loss": 1.8888,
      "step": 36050
    },
    {
      "epoch": 1.1552,
      "grad_norm": 0.32297462224960327,
      "learning_rate": 0.00015379328000000002,
      "loss": 1.7915,
      "step": 36100
    },
    {
      "epoch": 1.1568,
      "grad_norm": 0.3045384883880615,
      "learning_rate": 0.00015372928,
      "loss": 1.8502,
      "step": 36150
    },
    {
      "epoch": 1.1584,
      "grad_norm": 0.29798686504364014,
      "learning_rate": 0.00015366528,
      "loss": 1.7578,
      "step": 36200
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.33951306343078613,
      "learning_rate": 0.00015360128,
      "loss": 1.8026,
      "step": 36250
    },
    {
      "epoch": 1.1616,
      "grad_norm": 0.4101255238056183,
      "learning_rate": 0.00015353728,
      "loss": 1.8206,
      "step": 36300
    },
    {
      "epoch": 1.1632,
      "grad_norm": 0.3082432448863983,
      "learning_rate": 0.00015347328000000002,
      "loss": 1.8091,
      "step": 36350
    },
    {
      "epoch": 1.1648,
      "grad_norm": 0.2801249027252197,
      "learning_rate": 0.00015340928000000001,
      "loss": 1.9185,
      "step": 36400
    },
    {
      "epoch": 1.1663999999999999,
      "grad_norm": 0.3757953643798828,
      "learning_rate": 0.00015334528,
      "loss": 1.8604,
      "step": 36450
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.2954626977443695,
      "learning_rate": 0.00015328128,
      "loss": 1.8158,
      "step": 36500
    },
    {
      "epoch": 1.1696,
      "grad_norm": 0.3437638282775879,
      "learning_rate": 0.00015321728,
      "loss": 1.8058,
      "step": 36550
    },
    {
      "epoch": 1.1712,
      "grad_norm": 0.3517730236053467,
      "learning_rate": 0.00015315328,
      "loss": 1.831,
      "step": 36600
    },
    {
      "epoch": 1.1728,
      "grad_norm": 0.2984791696071625,
      "learning_rate": 0.00015308928,
      "loss": 1.7743,
      "step": 36650
    },
    {
      "epoch": 1.1743999999999999,
      "grad_norm": 0.3627057373523712,
      "learning_rate": 0.00015302528,
      "loss": 1.7707,
      "step": 36700
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.3559700548648834,
      "learning_rate": 0.00015296128,
      "loss": 1.7858,
      "step": 36750
    },
    {
      "epoch": 1.1776,
      "grad_norm": 0.3173324167728424,
      "learning_rate": 0.00015289728,
      "loss": 1.7932,
      "step": 36800
    },
    {
      "epoch": 1.1792,
      "grad_norm": 0.31666138768196106,
      "learning_rate": 0.00015283328000000002,
      "loss": 1.8212,
      "step": 36850
    },
    {
      "epoch": 1.1808,
      "grad_norm": 0.27523714303970337,
      "learning_rate": 0.00015276928000000002,
      "loss": 1.7585,
      "step": 36900
    },
    {
      "epoch": 1.1824,
      "grad_norm": 0.3413057327270508,
      "learning_rate": 0.00015270528000000002,
      "loss": 1.7819,
      "step": 36950
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.31366273760795593,
      "learning_rate": 0.00015264128,
      "loss": 1.8559,
      "step": 37000
    },
    {
      "epoch": 1.1856,
      "grad_norm": 0.3351357877254486,
      "learning_rate": 0.00015257728,
      "loss": 1.7828,
      "step": 37050
    },
    {
      "epoch": 1.1872,
      "grad_norm": 0.30539074540138245,
      "learning_rate": 0.00015251328,
      "loss": 1.7821,
      "step": 37100
    },
    {
      "epoch": 1.1888,
      "grad_norm": 0.26829296350479126,
      "learning_rate": 0.00015244928,
      "loss": 1.8299,
      "step": 37150
    },
    {
      "epoch": 1.1904,
      "grad_norm": 0.35140517354011536,
      "learning_rate": 0.00015238528000000002,
      "loss": 1.8242,
      "step": 37200
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.3432892858982086,
      "learning_rate": 0.00015232128,
      "loss": 1.7849,
      "step": 37250
    },
    {
      "epoch": 1.1936,
      "grad_norm": 0.3877190947532654,
      "learning_rate": 0.00015225728,
      "loss": 1.73,
      "step": 37300
    },
    {
      "epoch": 1.1952,
      "grad_norm": 0.32530057430267334,
      "learning_rate": 0.00015219328,
      "loss": 1.8432,
      "step": 37350
    },
    {
      "epoch": 1.1968,
      "grad_norm": 0.32477274537086487,
      "learning_rate": 0.00015212928,
      "loss": 1.7827,
      "step": 37400
    },
    {
      "epoch": 1.1984,
      "grad_norm": 0.27565687894821167,
      "learning_rate": 0.00015206528,
      "loss": 1.8365,
      "step": 37450
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6332089304924011,
      "learning_rate": 0.00015200128,
      "loss": 1.788,
      "step": 37500
    },
    {
      "epoch": 1.2016,
      "grad_norm": 0.32428082823753357,
      "learning_rate": 0.00015193728,
      "loss": 1.7662,
      "step": 37550
    },
    {
      "epoch": 1.2032,
      "grad_norm": 0.3099702000617981,
      "learning_rate": 0.00015187328,
      "loss": 1.8156,
      "step": 37600
    },
    {
      "epoch": 1.2048,
      "grad_norm": 0.2887175679206848,
      "learning_rate": 0.00015180928,
      "loss": 1.8168,
      "step": 37650
    },
    {
      "epoch": 1.2064,
      "grad_norm": 0.37053757905960083,
      "learning_rate": 0.00015174528000000002,
      "loss": 1.8009,
      "step": 37700
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.32706642150878906,
      "learning_rate": 0.00015168128000000002,
      "loss": 1.8218,
      "step": 37750
    },
    {
      "epoch": 1.2096,
      "grad_norm": 0.31003084778785706,
      "learning_rate": 0.00015161728000000001,
      "loss": 1.7851,
      "step": 37800
    },
    {
      "epoch": 1.2112,
      "grad_norm": 0.2788417637348175,
      "learning_rate": 0.00015155328,
      "loss": 1.8304,
      "step": 37850
    },
    {
      "epoch": 1.2128,
      "grad_norm": 0.4017048180103302,
      "learning_rate": 0.00015148928,
      "loss": 1.7992,
      "step": 37900
    },
    {
      "epoch": 1.2144,
      "grad_norm": 0.2895233929157257,
      "learning_rate": 0.00015142528,
      "loss": 1.7254,
      "step": 37950
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.3305051326751709,
      "learning_rate": 0.00015136128,
      "loss": 1.7821,
      "step": 38000
    },
    {
      "epoch": 1.2176,
      "grad_norm": 0.33789679408073425,
      "learning_rate": 0.00015129728000000002,
      "loss": 1.7373,
      "step": 38050
    },
    {
      "epoch": 1.2192,
      "grad_norm": 0.3027363121509552,
      "learning_rate": 0.00015123328,
      "loss": 1.7841,
      "step": 38100
    },
    {
      "epoch": 1.2208,
      "grad_norm": 0.2951923906803131,
      "learning_rate": 0.00015116928,
      "loss": 1.8131,
      "step": 38150
    },
    {
      "epoch": 1.2224,
      "grad_norm": 0.28957468271255493,
      "learning_rate": 0.00015110528,
      "loss": 1.8344,
      "step": 38200
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.30765658617019653,
      "learning_rate": 0.00015104128000000003,
      "loss": 1.7993,
      "step": 38250
    },
    {
      "epoch": 1.2256,
      "grad_norm": 0.3031866252422333,
      "learning_rate": 0.00015097728,
      "loss": 1.8287,
      "step": 38300
    },
    {
      "epoch": 1.2272,
      "grad_norm": 0.3143264949321747,
      "learning_rate": 0.00015091328,
      "loss": 1.7787,
      "step": 38350
    },
    {
      "epoch": 1.2288000000000001,
      "grad_norm": 0.40234971046447754,
      "learning_rate": 0.00015084928,
      "loss": 1.8152,
      "step": 38400
    },
    {
      "epoch": 1.2304,
      "grad_norm": 0.3070068359375,
      "learning_rate": 0.00015078528,
      "loss": 1.7883,
      "step": 38450
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.3090837597846985,
      "learning_rate": 0.00015072128,
      "loss": 1.7846,
      "step": 38500
    },
    {
      "epoch": 1.2336,
      "grad_norm": 0.3253558278083801,
      "learning_rate": 0.00015065728000000002,
      "loss": 1.8227,
      "step": 38550
    },
    {
      "epoch": 1.2352,
      "grad_norm": 0.3459821343421936,
      "learning_rate": 0.00015059328000000002,
      "loss": 1.7778,
      "step": 38600
    },
    {
      "epoch": 1.2368000000000001,
      "grad_norm": 0.303382009267807,
      "learning_rate": 0.00015052928000000001,
      "loss": 1.7953,
      "step": 38650
    },
    {
      "epoch": 1.2384,
      "grad_norm": 0.30121558904647827,
      "learning_rate": 0.00015046528,
      "loss": 1.7914,
      "step": 38700
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.3358129560947418,
      "learning_rate": 0.00015040128,
      "loss": 1.8355,
      "step": 38750
    },
    {
      "epoch": 1.2416,
      "grad_norm": 0.29622340202331543,
      "learning_rate": 0.00015033728,
      "loss": 1.7587,
      "step": 38800
    },
    {
      "epoch": 1.2432,
      "grad_norm": 0.29688113927841187,
      "learning_rate": 0.00015027328,
      "loss": 1.7972,
      "step": 38850
    },
    {
      "epoch": 1.2448,
      "grad_norm": 0.2806733250617981,
      "learning_rate": 0.00015020928000000002,
      "loss": 1.8304,
      "step": 38900
    },
    {
      "epoch": 1.2464,
      "grad_norm": 0.3336898684501648,
      "learning_rate": 0.00015014528,
      "loss": 1.85,
      "step": 38950
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.32632550597190857,
      "learning_rate": 0.00015008128,
      "loss": 1.7493,
      "step": 39000
    },
    {
      "epoch": 1.2496,
      "grad_norm": 0.2838543653488159,
      "learning_rate": 0.00015001728,
      "loss": 1.7878,
      "step": 39050
    },
    {
      "epoch": 1.2511999999999999,
      "grad_norm": 0.3000871539115906,
      "learning_rate": 0.00014995328000000003,
      "loss": 1.737,
      "step": 39100
    },
    {
      "epoch": 1.2528000000000001,
      "grad_norm": 0.42355743050575256,
      "learning_rate": 0.00014988928,
      "loss": 1.7841,
      "step": 39150
    },
    {
      "epoch": 1.2544,
      "grad_norm": 0.3232637345790863,
      "learning_rate": 0.00014982528,
      "loss": 1.8779,
      "step": 39200
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.3280983865261078,
      "learning_rate": 0.00014976128,
      "loss": 1.7375,
      "step": 39250
    },
    {
      "epoch": 1.2576,
      "grad_norm": 0.34571942687034607,
      "learning_rate": 0.00014969728,
      "loss": 1.8017,
      "step": 39300
    },
    {
      "epoch": 1.2591999999999999,
      "grad_norm": 0.32684412598609924,
      "learning_rate": 0.00014963328,
      "loss": 1.7576,
      "step": 39350
    },
    {
      "epoch": 1.2608,
      "grad_norm": 0.3203851580619812,
      "learning_rate": 0.00014956928000000002,
      "loss": 1.8167,
      "step": 39400
    },
    {
      "epoch": 1.2624,
      "grad_norm": 0.3456844389438629,
      "learning_rate": 0.00014950528000000002,
      "loss": 1.8553,
      "step": 39450
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.3233374357223511,
      "learning_rate": 0.00014944128000000001,
      "loss": 1.8286,
      "step": 39500
    },
    {
      "epoch": 1.2656,
      "grad_norm": 0.29563719034194946,
      "learning_rate": 0.00014937728,
      "loss": 1.8355,
      "step": 39550
    },
    {
      "epoch": 1.2671999999999999,
      "grad_norm": 0.3341997265815735,
      "learning_rate": 0.00014931328,
      "loss": 1.8233,
      "step": 39600
    },
    {
      "epoch": 1.2688,
      "grad_norm": 0.3039378821849823,
      "learning_rate": 0.00014924928,
      "loss": 1.7986,
      "step": 39650
    },
    {
      "epoch": 1.2704,
      "grad_norm": 0.2993854284286499,
      "learning_rate": 0.00014918528,
      "loss": 1.7867,
      "step": 39700
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.31874847412109375,
      "learning_rate": 0.00014912128000000002,
      "loss": 1.7845,
      "step": 39750
    },
    {
      "epoch": 1.2736,
      "grad_norm": 0.3321917951107025,
      "learning_rate": 0.00014905728,
      "loss": 1.81,
      "step": 39800
    },
    {
      "epoch": 1.2752,
      "grad_norm": 0.3547893464565277,
      "learning_rate": 0.00014899328,
      "loss": 1.7771,
      "step": 39850
    },
    {
      "epoch": 1.2768,
      "grad_norm": 0.34556958079338074,
      "learning_rate": 0.00014892928,
      "loss": 1.8319,
      "step": 39900
    },
    {
      "epoch": 1.2784,
      "grad_norm": 0.3434593677520752,
      "learning_rate": 0.00014886528000000002,
      "loss": 1.7906,
      "step": 39950
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.4165787100791931,
      "learning_rate": 0.00014880128,
      "loss": 1.803,
      "step": 40000
    },
    {
      "epoch": 1.2816,
      "grad_norm": 0.3466663360595703,
      "learning_rate": 0.00014873728,
      "loss": 1.7781,
      "step": 40050
    },
    {
      "epoch": 1.2832,
      "grad_norm": 0.2857832908630371,
      "learning_rate": 0.00014867328,
      "loss": 1.781,
      "step": 40100
    },
    {
      "epoch": 1.2848,
      "grad_norm": 0.3150106370449066,
      "learning_rate": 0.00014860928,
      "loss": 1.826,
      "step": 40150
    },
    {
      "epoch": 1.2864,
      "grad_norm": 0.2868967056274414,
      "learning_rate": 0.00014854528,
      "loss": 1.8104,
      "step": 40200
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.372823029756546,
      "learning_rate": 0.00014848128000000002,
      "loss": 1.8253,
      "step": 40250
    },
    {
      "epoch": 1.2896,
      "grad_norm": 0.33338457345962524,
      "learning_rate": 0.00014841728000000002,
      "loss": 1.7843,
      "step": 40300
    },
    {
      "epoch": 1.2912,
      "grad_norm": 0.3613193929195404,
      "learning_rate": 0.00014835328000000001,
      "loss": 1.8023,
      "step": 40350
    },
    {
      "epoch": 1.2928,
      "grad_norm": 0.29317593574523926,
      "learning_rate": 0.00014828928,
      "loss": 1.7576,
      "step": 40400
    },
    {
      "epoch": 1.2944,
      "grad_norm": 0.34706544876098633,
      "learning_rate": 0.00014822528,
      "loss": 1.7841,
      "step": 40450
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.2772780656814575,
      "learning_rate": 0.00014816128,
      "loss": 1.716,
      "step": 40500
    },
    {
      "epoch": 1.2976,
      "grad_norm": 0.3422287702560425,
      "learning_rate": 0.00014809728,
      "loss": 1.8003,
      "step": 40550
    },
    {
      "epoch": 1.2992,
      "grad_norm": 0.31978923082351685,
      "learning_rate": 0.00014803328000000002,
      "loss": 1.8656,
      "step": 40600
    },
    {
      "epoch": 1.3008,
      "grad_norm": 0.35003381967544556,
      "learning_rate": 0.00014796928,
      "loss": 1.8341,
      "step": 40650
    },
    {
      "epoch": 1.3024,
      "grad_norm": 0.37730705738067627,
      "learning_rate": 0.00014790528,
      "loss": 1.7975,
      "step": 40700
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.3073910176753998,
      "learning_rate": 0.00014784128,
      "loss": 1.8454,
      "step": 40750
    },
    {
      "epoch": 1.3056,
      "grad_norm": 0.3458861708641052,
      "learning_rate": 0.00014777728000000002,
      "loss": 1.8159,
      "step": 40800
    },
    {
      "epoch": 1.3072,
      "grad_norm": 0.3455387055873871,
      "learning_rate": 0.00014771328,
      "loss": 1.7739,
      "step": 40850
    },
    {
      "epoch": 1.3088,
      "grad_norm": 0.3526344895362854,
      "learning_rate": 0.00014764928,
      "loss": 1.7945,
      "step": 40900
    },
    {
      "epoch": 1.3104,
      "grad_norm": 0.4079650938510895,
      "learning_rate": 0.00014758528,
      "loss": 1.7561,
      "step": 40950
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.353657066822052,
      "learning_rate": 0.00014752128,
      "loss": 1.8335,
      "step": 41000
    },
    {
      "epoch": 1.3136,
      "grad_norm": 0.3740074336528778,
      "learning_rate": 0.00014745728,
      "loss": 1.7518,
      "step": 41050
    },
    {
      "epoch": 1.3152,
      "grad_norm": 0.3077223300933838,
      "learning_rate": 0.00014739328000000002,
      "loss": 1.7966,
      "step": 41100
    },
    {
      "epoch": 1.3168,
      "grad_norm": 0.4126434624195099,
      "learning_rate": 0.00014732928000000002,
      "loss": 1.8159,
      "step": 41150
    },
    {
      "epoch": 1.3184,
      "grad_norm": 0.3443746268749237,
      "learning_rate": 0.00014726528,
      "loss": 1.8004,
      "step": 41200
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.37132343649864197,
      "learning_rate": 0.00014720128,
      "loss": 1.7437,
      "step": 41250
    },
    {
      "epoch": 1.3216,
      "grad_norm": 0.3263185918331146,
      "learning_rate": 0.00014713728,
      "loss": 1.7719,
      "step": 41300
    },
    {
      "epoch": 1.3232,
      "grad_norm": 0.40090757608413696,
      "learning_rate": 0.00014707328,
      "loss": 1.762,
      "step": 41350
    },
    {
      "epoch": 1.3248,
      "grad_norm": 0.27743059396743774,
      "learning_rate": 0.00014700928,
      "loss": 1.8287,
      "step": 41400
    },
    {
      "epoch": 1.3264,
      "grad_norm": 0.3091154992580414,
      "learning_rate": 0.00014694528000000002,
      "loss": 1.7788,
      "step": 41450
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.335190087556839,
      "learning_rate": 0.00014688128,
      "loss": 1.8305,
      "step": 41500
    },
    {
      "epoch": 1.3296000000000001,
      "grad_norm": 0.38178813457489014,
      "learning_rate": 0.00014681728,
      "loss": 1.7546,
      "step": 41550
    },
    {
      "epoch": 1.3312,
      "grad_norm": 0.3165692687034607,
      "learning_rate": 0.00014675328,
      "loss": 1.7768,
      "step": 41600
    },
    {
      "epoch": 1.3328,
      "grad_norm": 0.26662909984588623,
      "learning_rate": 0.00014668928000000002,
      "loss": 1.8731,
      "step": 41650
    },
    {
      "epoch": 1.3344,
      "grad_norm": 0.2980805039405823,
      "learning_rate": 0.00014662528,
      "loss": 1.7903,
      "step": 41700
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.2575782239437103,
      "learning_rate": 0.00014656128,
      "loss": 1.763,
      "step": 41750
    },
    {
      "epoch": 1.3376000000000001,
      "grad_norm": 0.3237176835536957,
      "learning_rate": 0.00014649728,
      "loss": 1.7786,
      "step": 41800
    },
    {
      "epoch": 1.3392,
      "grad_norm": 0.3343542814254761,
      "learning_rate": 0.00014643328,
      "loss": 1.8413,
      "step": 41850
    },
    {
      "epoch": 1.3408,
      "grad_norm": 0.3350215554237366,
      "learning_rate": 0.00014636928,
      "loss": 1.8351,
      "step": 41900
    },
    {
      "epoch": 1.3424,
      "grad_norm": 0.31824707984924316,
      "learning_rate": 0.00014630528000000002,
      "loss": 1.8014,
      "step": 41950
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.3520396053791046,
      "learning_rate": 0.00014624128000000002,
      "loss": 1.8332,
      "step": 42000
    },
    {
      "epoch": 1.3456000000000001,
      "grad_norm": 0.28514134883880615,
      "learning_rate": 0.00014617728,
      "loss": 1.8449,
      "step": 42050
    },
    {
      "epoch": 1.3472,
      "grad_norm": 0.294064998626709,
      "learning_rate": 0.00014611328,
      "loss": 1.8273,
      "step": 42100
    },
    {
      "epoch": 1.3488,
      "grad_norm": 0.2852942943572998,
      "learning_rate": 0.00014604928,
      "loss": 1.7661,
      "step": 42150
    },
    {
      "epoch": 1.3504,
      "grad_norm": 0.4936048686504364,
      "learning_rate": 0.00014598528,
      "loss": 1.7497,
      "step": 42200
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.3003770411014557,
      "learning_rate": 0.00014592128,
      "loss": 1.791,
      "step": 42250
    },
    {
      "epoch": 1.3536000000000001,
      "grad_norm": 0.28336966037750244,
      "learning_rate": 0.00014585728000000002,
      "loss": 1.7604,
      "step": 42300
    },
    {
      "epoch": 1.3552,
      "grad_norm": 0.35017287731170654,
      "learning_rate": 0.00014579328,
      "loss": 1.8123,
      "step": 42350
    },
    {
      "epoch": 1.3568,
      "grad_norm": 0.38846972584724426,
      "learning_rate": 0.00014572928,
      "loss": 1.7647,
      "step": 42400
    },
    {
      "epoch": 1.3584,
      "grad_norm": 0.3396799564361572,
      "learning_rate": 0.00014566528000000003,
      "loss": 1.7916,
      "step": 42450
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.3752698004245758,
      "learning_rate": 0.00014560128000000002,
      "loss": 1.7874,
      "step": 42500
    },
    {
      "epoch": 1.3616,
      "grad_norm": 0.4169435203075409,
      "learning_rate": 0.00014553728,
      "loss": 1.7874,
      "step": 42550
    },
    {
      "epoch": 1.3632,
      "grad_norm": 0.28514042496681213,
      "learning_rate": 0.00014547328000000001,
      "loss": 1.8162,
      "step": 42600
    },
    {
      "epoch": 1.3648,
      "grad_norm": 0.3347678780555725,
      "learning_rate": 0.00014540928,
      "loss": 1.8557,
      "step": 42650
    },
    {
      "epoch": 1.3664,
      "grad_norm": 0.4134639799594879,
      "learning_rate": 0.00014534528,
      "loss": 1.8162,
      "step": 42700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.2674158811569214,
      "learning_rate": 0.00014528128,
      "loss": 1.796,
      "step": 42750
    },
    {
      "epoch": 1.3696,
      "grad_norm": 0.34035956859588623,
      "learning_rate": 0.00014521728000000002,
      "loss": 1.8463,
      "step": 42800
    },
    {
      "epoch": 1.3712,
      "grad_norm": 0.3346822261810303,
      "learning_rate": 0.00014515328000000002,
      "loss": 1.8069,
      "step": 42850
    },
    {
      "epoch": 1.3728,
      "grad_norm": 0.35592809319496155,
      "learning_rate": 0.00014508928,
      "loss": 1.7968,
      "step": 42900
    },
    {
      "epoch": 1.3744,
      "grad_norm": 0.27702903747558594,
      "learning_rate": 0.00014502528,
      "loss": 1.7221,
      "step": 42950
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.34211593866348267,
      "learning_rate": 0.00014496128,
      "loss": 1.8237,
      "step": 43000
    },
    {
      "epoch": 1.3776,
      "grad_norm": 0.34224870800971985,
      "learning_rate": 0.00014489728,
      "loss": 1.8562,
      "step": 43050
    },
    {
      "epoch": 1.3792,
      "grad_norm": 0.3255951702594757,
      "learning_rate": 0.00014483328,
      "loss": 1.7882,
      "step": 43100
    },
    {
      "epoch": 1.3808,
      "grad_norm": 0.3405020236968994,
      "learning_rate": 0.00014476928000000002,
      "loss": 1.793,
      "step": 43150
    },
    {
      "epoch": 1.3824,
      "grad_norm": 0.39779767394065857,
      "learning_rate": 0.00014470528,
      "loss": 1.7895,
      "step": 43200
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.30345460772514343,
      "learning_rate": 0.00014464128,
      "loss": 1.7943,
      "step": 43250
    },
    {
      "epoch": 1.3856,
      "grad_norm": 0.316720575094223,
      "learning_rate": 0.00014457728000000003,
      "loss": 1.8067,
      "step": 43300
    },
    {
      "epoch": 1.3872,
      "grad_norm": 0.2956230044364929,
      "learning_rate": 0.00014451328000000002,
      "loss": 1.8098,
      "step": 43350
    },
    {
      "epoch": 1.3888,
      "grad_norm": 0.3726074993610382,
      "learning_rate": 0.00014444928,
      "loss": 1.8258,
      "step": 43400
    },
    {
      "epoch": 1.3904,
      "grad_norm": 0.3203946053981781,
      "learning_rate": 0.00014438528000000001,
      "loss": 1.78,
      "step": 43450
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.5227466225624084,
      "learning_rate": 0.00014432128,
      "loss": 1.8722,
      "step": 43500
    },
    {
      "epoch": 1.3936,
      "grad_norm": 0.35883936285972595,
      "learning_rate": 0.00014425728,
      "loss": 1.7664,
      "step": 43550
    },
    {
      "epoch": 1.3952,
      "grad_norm": 0.32049357891082764,
      "learning_rate": 0.00014419328,
      "loss": 1.805,
      "step": 43600
    },
    {
      "epoch": 1.3968,
      "grad_norm": 0.2858317494392395,
      "learning_rate": 0.00014412928000000002,
      "loss": 1.7635,
      "step": 43650
    },
    {
      "epoch": 1.3984,
      "grad_norm": 0.32037436962127686,
      "learning_rate": 0.00014406528000000002,
      "loss": 1.8725,
      "step": 43700
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.4499320387840271,
      "learning_rate": 0.00014400128,
      "loss": 1.836,
      "step": 43750
    },
    {
      "epoch": 1.4016,
      "grad_norm": 0.34781306982040405,
      "learning_rate": 0.00014393728,
      "loss": 1.7635,
      "step": 43800
    },
    {
      "epoch": 1.4032,
      "grad_norm": 0.3530696630477905,
      "learning_rate": 0.00014387328,
      "loss": 1.8305,
      "step": 43850
    },
    {
      "epoch": 1.4048,
      "grad_norm": 0.34984079003334045,
      "learning_rate": 0.00014380928,
      "loss": 1.7869,
      "step": 43900
    },
    {
      "epoch": 1.4064,
      "grad_norm": 0.3199004828929901,
      "learning_rate": 0.00014374528,
      "loss": 1.7811,
      "step": 43950
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.36816656589508057,
      "learning_rate": 0.00014368128000000001,
      "loss": 1.7822,
      "step": 44000
    },
    {
      "epoch": 1.4096,
      "grad_norm": 0.3129810392856598,
      "learning_rate": 0.00014361728,
      "loss": 1.8463,
      "step": 44050
    },
    {
      "epoch": 1.4112,
      "grad_norm": 0.33324918150901794,
      "learning_rate": 0.00014355328,
      "loss": 1.7745,
      "step": 44100
    },
    {
      "epoch": 1.4128,
      "grad_norm": 0.2812459468841553,
      "learning_rate": 0.00014348928000000003,
      "loss": 1.7825,
      "step": 44150
    },
    {
      "epoch": 1.4144,
      "grad_norm": 0.29509201645851135,
      "learning_rate": 0.00014342528000000002,
      "loss": 1.7479,
      "step": 44200
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.3111228048801422,
      "learning_rate": 0.00014336128,
      "loss": 1.8218,
      "step": 44250
    },
    {
      "epoch": 1.4176,
      "grad_norm": 0.31092503666877747,
      "learning_rate": 0.00014329728,
      "loss": 1.7905,
      "step": 44300
    },
    {
      "epoch": 1.4192,
      "grad_norm": 0.31997641921043396,
      "learning_rate": 0.00014323328,
      "loss": 1.8226,
      "step": 44350
    },
    {
      "epoch": 1.4208,
      "grad_norm": 0.3316675126552582,
      "learning_rate": 0.00014316928,
      "loss": 1.8282,
      "step": 44400
    },
    {
      "epoch": 1.4224,
      "grad_norm": 0.35948219895362854,
      "learning_rate": 0.00014310528,
      "loss": 1.792,
      "step": 44450
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.3159976303577423,
      "learning_rate": 0.00014304128000000002,
      "loss": 1.7732,
      "step": 44500
    },
    {
      "epoch": 1.4256,
      "grad_norm": 0.4004642367362976,
      "learning_rate": 0.00014297728000000002,
      "loss": 1.8424,
      "step": 44550
    },
    {
      "epoch": 1.4272,
      "grad_norm": 0.32673388719558716,
      "learning_rate": 0.00014291328,
      "loss": 1.7653,
      "step": 44600
    },
    {
      "epoch": 1.4288,
      "grad_norm": 0.40853404998779297,
      "learning_rate": 0.00014284928,
      "loss": 1.8569,
      "step": 44650
    },
    {
      "epoch": 1.4304000000000001,
      "grad_norm": 0.33208397030830383,
      "learning_rate": 0.00014278528,
      "loss": 1.8365,
      "step": 44700
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.31840094923973083,
      "learning_rate": 0.00014272128,
      "loss": 1.7881,
      "step": 44750
    },
    {
      "epoch": 1.4336,
      "grad_norm": 0.3484726548194885,
      "learning_rate": 0.00014265728,
      "loss": 1.7663,
      "step": 44800
    },
    {
      "epoch": 1.4352,
      "grad_norm": 0.2811430096626282,
      "learning_rate": 0.00014259328000000001,
      "loss": 1.8286,
      "step": 44850
    },
    {
      "epoch": 1.4368,
      "grad_norm": 0.3795571029186249,
      "learning_rate": 0.00014252928,
      "loss": 1.8177,
      "step": 44900
    },
    {
      "epoch": 1.4384000000000001,
      "grad_norm": 0.39000430703163147,
      "learning_rate": 0.00014246528,
      "loss": 1.7856,
      "step": 44950
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2987789213657379,
      "learning_rate": 0.00014240128000000003,
      "loss": 1.7876,
      "step": 45000
    },
    {
      "epoch": 1.4416,
      "grad_norm": 0.37036454677581787,
      "learning_rate": 0.00014233728000000002,
      "loss": 1.7863,
      "step": 45050
    },
    {
      "epoch": 1.4432,
      "grad_norm": 0.3208499550819397,
      "learning_rate": 0.00014227328,
      "loss": 1.7799,
      "step": 45100
    },
    {
      "epoch": 1.4447999999999999,
      "grad_norm": 0.31403306126594543,
      "learning_rate": 0.00014220928,
      "loss": 1.7847,
      "step": 45150
    },
    {
      "epoch": 1.4464000000000001,
      "grad_norm": 0.37070566415786743,
      "learning_rate": 0.00014214528,
      "loss": 1.7476,
      "step": 45200
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.33278995752334595,
      "learning_rate": 0.00014208128,
      "loss": 1.8211,
      "step": 45250
    },
    {
      "epoch": 1.4496,
      "grad_norm": 0.3667762875556946,
      "learning_rate": 0.00014201728,
      "loss": 1.783,
      "step": 45300
    },
    {
      "epoch": 1.4512,
      "grad_norm": 0.3338267505168915,
      "learning_rate": 0.00014195328000000002,
      "loss": 1.7645,
      "step": 45350
    },
    {
      "epoch": 1.4527999999999999,
      "grad_norm": 0.33909153938293457,
      "learning_rate": 0.00014188928000000002,
      "loss": 1.7602,
      "step": 45400
    },
    {
      "epoch": 1.4544000000000001,
      "grad_norm": 0.3392189145088196,
      "learning_rate": 0.00014182528,
      "loss": 1.8018,
      "step": 45450
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.30267414450645447,
      "learning_rate": 0.00014176128,
      "loss": 1.7552,
      "step": 45500
    },
    {
      "epoch": 1.4576,
      "grad_norm": 0.34226635098457336,
      "learning_rate": 0.00014169728,
      "loss": 1.7785,
      "step": 45550
    },
    {
      "epoch": 1.4592,
      "grad_norm": 0.32259154319763184,
      "learning_rate": 0.00014163328,
      "loss": 1.8257,
      "step": 45600
    },
    {
      "epoch": 1.4607999999999999,
      "grad_norm": 0.3040491044521332,
      "learning_rate": 0.00014156928,
      "loss": 1.7954,
      "step": 45650
    },
    {
      "epoch": 1.4624,
      "grad_norm": 0.31883805990219116,
      "learning_rate": 0.00014150528000000001,
      "loss": 1.8409,
      "step": 45700
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.4137629270553589,
      "learning_rate": 0.00014144128,
      "loss": 1.8291,
      "step": 45750
    },
    {
      "epoch": 1.4656,
      "grad_norm": 0.28532400727272034,
      "learning_rate": 0.00014137728,
      "loss": 1.7749,
      "step": 45800
    },
    {
      "epoch": 1.4672,
      "grad_norm": 0.30976444482803345,
      "learning_rate": 0.00014131328000000003,
      "loss": 1.7749,
      "step": 45850
    },
    {
      "epoch": 1.4687999999999999,
      "grad_norm": 0.30340033769607544,
      "learning_rate": 0.00014124928000000002,
      "loss": 1.7604,
      "step": 45900
    },
    {
      "epoch": 1.4704,
      "grad_norm": 0.32595351338386536,
      "learning_rate": 0.00014118528,
      "loss": 1.8244,
      "step": 45950
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.3206924796104431,
      "learning_rate": 0.00014112128,
      "loss": 1.7957,
      "step": 46000
    },
    {
      "epoch": 1.4736,
      "grad_norm": 0.34305819869041443,
      "learning_rate": 0.00014105728,
      "loss": 1.8325,
      "step": 46050
    },
    {
      "epoch": 1.4752,
      "grad_norm": 0.3845149278640747,
      "learning_rate": 0.00014099328,
      "loss": 1.8128,
      "step": 46100
    },
    {
      "epoch": 1.4768,
      "grad_norm": 0.39862027764320374,
      "learning_rate": 0.00014092928,
      "loss": 1.8438,
      "step": 46150
    },
    {
      "epoch": 1.4784,
      "grad_norm": 0.3103168308734894,
      "learning_rate": 0.00014086528000000002,
      "loss": 1.8416,
      "step": 46200
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.3476729094982147,
      "learning_rate": 0.00014080128000000002,
      "loss": 1.794,
      "step": 46250
    },
    {
      "epoch": 1.4816,
      "grad_norm": 0.31776249408721924,
      "learning_rate": 0.00014073728,
      "loss": 1.8644,
      "step": 46300
    },
    {
      "epoch": 1.4832,
      "grad_norm": 0.33606377243995667,
      "learning_rate": 0.00014067328,
      "loss": 1.8166,
      "step": 46350
    },
    {
      "epoch": 1.4848,
      "grad_norm": 0.2685999572277069,
      "learning_rate": 0.00014060928,
      "loss": 1.7508,
      "step": 46400
    },
    {
      "epoch": 1.4864,
      "grad_norm": 0.31191036105155945,
      "learning_rate": 0.00014054528,
      "loss": 1.7549,
      "step": 46450
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.33969995379447937,
      "learning_rate": 0.00014048128,
      "loss": 1.8016,
      "step": 46500
    },
    {
      "epoch": 1.4896,
      "grad_norm": 0.44979509711265564,
      "learning_rate": 0.00014041728000000001,
      "loss": 1.7416,
      "step": 46550
    },
    {
      "epoch": 1.4912,
      "grad_norm": 0.32791203260421753,
      "learning_rate": 0.00014035328,
      "loss": 1.7905,
      "step": 46600
    },
    {
      "epoch": 1.4928,
      "grad_norm": 0.27233001589775085,
      "learning_rate": 0.00014028928,
      "loss": 1.8079,
      "step": 46650
    },
    {
      "epoch": 1.4944,
      "grad_norm": 0.3166864812374115,
      "learning_rate": 0.00014022528000000003,
      "loss": 1.7822,
      "step": 46700
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.3107931613922119,
      "learning_rate": 0.00014016128000000002,
      "loss": 1.7984,
      "step": 46750
    },
    {
      "epoch": 1.4976,
      "grad_norm": 0.34859731793403625,
      "learning_rate": 0.00014009728,
      "loss": 1.7937,
      "step": 46800
    },
    {
      "epoch": 1.4992,
      "grad_norm": 0.339667409658432,
      "learning_rate": 0.00014003328,
      "loss": 1.8131,
      "step": 46850
    },
    {
      "epoch": 1.5008,
      "grad_norm": 0.34914901852607727,
      "learning_rate": 0.00013996928,
      "loss": 1.8422,
      "step": 46900
    },
    {
      "epoch": 1.5024,
      "grad_norm": 0.3423909544944763,
      "learning_rate": 0.00013990528,
      "loss": 1.7611,
      "step": 46950
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.2741216719150543,
      "learning_rate": 0.00013984128,
      "loss": 1.8043,
      "step": 47000
    },
    {
      "epoch": 1.5056,
      "grad_norm": 0.3371882736682892,
      "learning_rate": 0.00013977728000000002,
      "loss": 1.8254,
      "step": 47050
    },
    {
      "epoch": 1.5072,
      "grad_norm": 0.3293135166168213,
      "learning_rate": 0.00013971328000000001,
      "loss": 1.7362,
      "step": 47100
    },
    {
      "epoch": 1.5088,
      "grad_norm": 0.34804025292396545,
      "learning_rate": 0.00013964928,
      "loss": 1.7854,
      "step": 47150
    },
    {
      "epoch": 1.5104,
      "grad_norm": 0.3241533637046814,
      "learning_rate": 0.00013958528,
      "loss": 1.7745,
      "step": 47200
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.2999562621116638,
      "learning_rate": 0.00013952128,
      "loss": 1.7902,
      "step": 47250
    },
    {
      "epoch": 1.5135999999999998,
      "grad_norm": 0.32197853922843933,
      "learning_rate": 0.00013945728,
      "loss": 1.7892,
      "step": 47300
    },
    {
      "epoch": 1.5152,
      "grad_norm": 0.2917451858520508,
      "learning_rate": 0.00013939328,
      "loss": 1.8099,
      "step": 47350
    },
    {
      "epoch": 1.5168,
      "grad_norm": 0.3378662168979645,
      "learning_rate": 0.00013932928,
      "loss": 1.7963,
      "step": 47400
    },
    {
      "epoch": 1.5184,
      "grad_norm": 0.3474682569503784,
      "learning_rate": 0.00013926528,
      "loss": 1.7805,
      "step": 47450
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.3776237368583679,
      "learning_rate": 0.00013920128,
      "loss": 1.7582,
      "step": 47500
    },
    {
      "epoch": 1.5215999999999998,
      "grad_norm": 0.3245265483856201,
      "learning_rate": 0.00013913728000000003,
      "loss": 1.7213,
      "step": 47550
    },
    {
      "epoch": 1.5232,
      "grad_norm": 0.3164421319961548,
      "learning_rate": 0.00013907328000000002,
      "loss": 1.821,
      "step": 47600
    },
    {
      "epoch": 1.5248,
      "grad_norm": 0.27926862239837646,
      "learning_rate": 0.00013900928,
      "loss": 1.7688,
      "step": 47650
    },
    {
      "epoch": 1.5264,
      "grad_norm": 0.34292861819267273,
      "learning_rate": 0.00013894528,
      "loss": 1.831,
      "step": 47700
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.3323930501937866,
      "learning_rate": 0.00013888128,
      "loss": 1.7462,
      "step": 47750
    },
    {
      "epoch": 1.5295999999999998,
      "grad_norm": 0.35896438360214233,
      "learning_rate": 0.00013881728,
      "loss": 1.7717,
      "step": 47800
    },
    {
      "epoch": 1.5312000000000001,
      "grad_norm": 0.29772141575813293,
      "learning_rate": 0.00013875328,
      "loss": 1.8434,
      "step": 47850
    },
    {
      "epoch": 1.5328,
      "grad_norm": 0.3294435143470764,
      "learning_rate": 0.00013868928000000002,
      "loss": 1.8527,
      "step": 47900
    },
    {
      "epoch": 1.5344,
      "grad_norm": 0.4177463948726654,
      "learning_rate": 0.00013862528000000001,
      "loss": 1.8304,
      "step": 47950
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.38832736015319824,
      "learning_rate": 0.00013856128,
      "loss": 1.7778,
      "step": 48000
    },
    {
      "epoch": 1.5375999999999999,
      "grad_norm": 0.3099517524242401,
      "learning_rate": 0.00013849728,
      "loss": 1.8286,
      "step": 48050
    },
    {
      "epoch": 1.5392000000000001,
      "grad_norm": 0.2700880765914917,
      "learning_rate": 0.00013843328,
      "loss": 1.7861,
      "step": 48100
    },
    {
      "epoch": 1.5408,
      "grad_norm": 0.29663896560668945,
      "learning_rate": 0.00013836928,
      "loss": 1.8183,
      "step": 48150
    },
    {
      "epoch": 1.5424,
      "grad_norm": 0.41660189628601074,
      "learning_rate": 0.00013830528,
      "loss": 1.7803,
      "step": 48200
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.343508780002594,
      "learning_rate": 0.00013824128,
      "loss": 1.8107,
      "step": 48250
    },
    {
      "epoch": 1.5455999999999999,
      "grad_norm": 0.40731048583984375,
      "learning_rate": 0.00013817728,
      "loss": 1.7895,
      "step": 48300
    },
    {
      "epoch": 1.5472000000000001,
      "grad_norm": 0.34533149003982544,
      "learning_rate": 0.00013811328,
      "loss": 1.7381,
      "step": 48350
    },
    {
      "epoch": 1.5488,
      "grad_norm": 0.3410246670246124,
      "learning_rate": 0.00013804928000000003,
      "loss": 1.8329,
      "step": 48400
    },
    {
      "epoch": 1.5504,
      "grad_norm": 0.2989223003387451,
      "learning_rate": 0.00013798528000000002,
      "loss": 1.7131,
      "step": 48450
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.3320437967777252,
      "learning_rate": 0.00013792128,
      "loss": 1.7387,
      "step": 48500
    },
    {
      "epoch": 1.5535999999999999,
      "grad_norm": 0.36477130651474,
      "learning_rate": 0.00013785728,
      "loss": 1.782,
      "step": 48550
    },
    {
      "epoch": 1.5552000000000001,
      "grad_norm": 0.533870279788971,
      "learning_rate": 0.00013779328,
      "loss": 1.7627,
      "step": 48600
    },
    {
      "epoch": 1.5568,
      "grad_norm": 0.31124457716941833,
      "learning_rate": 0.00013772928,
      "loss": 1.8385,
      "step": 48650
    },
    {
      "epoch": 1.5584,
      "grad_norm": 0.34571442008018494,
      "learning_rate": 0.00013766528,
      "loss": 1.7758,
      "step": 48700
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.3004976809024811,
      "learning_rate": 0.00013760128000000002,
      "loss": 1.8478,
      "step": 48750
    },
    {
      "epoch": 1.5615999999999999,
      "grad_norm": 0.4150134325027466,
      "learning_rate": 0.00013753728000000001,
      "loss": 1.728,
      "step": 48800
    },
    {
      "epoch": 1.5632000000000001,
      "grad_norm": 0.339130163192749,
      "learning_rate": 0.00013747328,
      "loss": 1.7817,
      "step": 48850
    },
    {
      "epoch": 1.5648,
      "grad_norm": 0.3626786470413208,
      "learning_rate": 0.00013740928,
      "loss": 1.7971,
      "step": 48900
    },
    {
      "epoch": 1.5664,
      "grad_norm": 0.48582950234413147,
      "learning_rate": 0.00013734528,
      "loss": 1.8243,
      "step": 48950
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.3527129888534546,
      "learning_rate": 0.00013728128,
      "loss": 1.8551,
      "step": 49000
    },
    {
      "epoch": 1.5695999999999999,
      "grad_norm": 0.29645639657974243,
      "learning_rate": 0.00013721728,
      "loss": 1.7771,
      "step": 49050
    },
    {
      "epoch": 1.5712000000000002,
      "grad_norm": 0.33496683835983276,
      "learning_rate": 0.00013715328,
      "loss": 1.8164,
      "step": 49100
    },
    {
      "epoch": 1.5728,
      "grad_norm": 0.2776281237602234,
      "learning_rate": 0.00013708928,
      "loss": 1.8039,
      "step": 49150
    },
    {
      "epoch": 1.5744,
      "grad_norm": 0.37936899065971375,
      "learning_rate": 0.00013702528,
      "loss": 1.8243,
      "step": 49200
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.3431994616985321,
      "learning_rate": 0.00013696128000000003,
      "loss": 1.8387,
      "step": 49250
    },
    {
      "epoch": 1.5776,
      "grad_norm": 0.3543933629989624,
      "learning_rate": 0.00013689728000000002,
      "loss": 1.85,
      "step": 49300
    },
    {
      "epoch": 1.5792000000000002,
      "grad_norm": 0.3371306359767914,
      "learning_rate": 0.00013683328,
      "loss": 1.7912,
      "step": 49350
    },
    {
      "epoch": 1.5808,
      "grad_norm": 0.33309945464134216,
      "learning_rate": 0.00013676928,
      "loss": 1.8333,
      "step": 49400
    },
    {
      "epoch": 1.5824,
      "grad_norm": 0.3868243396282196,
      "learning_rate": 0.00013670528,
      "loss": 1.7918,
      "step": 49450
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.3082011938095093,
      "learning_rate": 0.00013664128,
      "loss": 1.7935,
      "step": 49500
    },
    {
      "epoch": 1.5856,
      "grad_norm": 0.3688615560531616,
      "learning_rate": 0.00013657728,
      "loss": 1.8354,
      "step": 49550
    },
    {
      "epoch": 1.5872000000000002,
      "grad_norm": 0.3274746537208557,
      "learning_rate": 0.00013651328000000002,
      "loss": 1.816,
      "step": 49600
    },
    {
      "epoch": 1.5888,
      "grad_norm": 0.49161940813064575,
      "learning_rate": 0.00013644928000000001,
      "loss": 1.7763,
      "step": 49650
    },
    {
      "epoch": 1.5904,
      "grad_norm": 0.3239884376525879,
      "learning_rate": 0.00013638528,
      "loss": 1.7924,
      "step": 49700
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.3904115557670593,
      "learning_rate": 0.00013632128,
      "loss": 1.7581,
      "step": 49750
    },
    {
      "epoch": 1.5936,
      "grad_norm": 0.3994482755661011,
      "learning_rate": 0.00013625728,
      "loss": 1.8397,
      "step": 49800
    },
    {
      "epoch": 1.5952,
      "grad_norm": 0.3452296257019043,
      "learning_rate": 0.00013619328,
      "loss": 1.8052,
      "step": 49850
    },
    {
      "epoch": 1.5968,
      "grad_norm": 0.28380903601646423,
      "learning_rate": 0.00013612928000000002,
      "loss": 1.7299,
      "step": 49900
    },
    {
      "epoch": 1.5984,
      "grad_norm": 0.3219144642353058,
      "learning_rate": 0.00013606528,
      "loss": 1.8047,
      "step": 49950
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.30870765447616577,
      "learning_rate": 0.00013600128,
      "loss": 1.7805,
      "step": 50000
    },
    {
      "epoch": 1.6016,
      "grad_norm": 0.32827216386795044,
      "learning_rate": 0.00013593728,
      "loss": 1.8298,
      "step": 50050
    },
    {
      "epoch": 1.6032,
      "grad_norm": 0.292391300201416,
      "learning_rate": 0.00013587328000000002,
      "loss": 1.7425,
      "step": 50100
    },
    {
      "epoch": 1.6048,
      "grad_norm": 0.3521292209625244,
      "learning_rate": 0.00013580928000000002,
      "loss": 1.8655,
      "step": 50150
    },
    {
      "epoch": 1.6064,
      "grad_norm": 0.39102715253829956,
      "learning_rate": 0.00013574528,
      "loss": 1.8102,
      "step": 50200
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.3212563395500183,
      "learning_rate": 0.00013568128,
      "loss": 1.7931,
      "step": 50250
    },
    {
      "epoch": 1.6096,
      "grad_norm": 0.3183794915676117,
      "learning_rate": 0.00013561728,
      "loss": 1.7718,
      "step": 50300
    },
    {
      "epoch": 1.6112,
      "grad_norm": 0.4308573007583618,
      "learning_rate": 0.00013555328,
      "loss": 1.8284,
      "step": 50350
    },
    {
      "epoch": 1.6128,
      "grad_norm": 0.38182759284973145,
      "learning_rate": 0.00013548928,
      "loss": 1.785,
      "step": 50400
    },
    {
      "epoch": 1.6143999999999998,
      "grad_norm": 0.3198201656341553,
      "learning_rate": 0.00013542528000000002,
      "loss": 1.7962,
      "step": 50450
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.3390688896179199,
      "learning_rate": 0.00013536128,
      "loss": 1.8068,
      "step": 50500
    },
    {
      "epoch": 1.6176,
      "grad_norm": 0.35804077982902527,
      "learning_rate": 0.00013529728,
      "loss": 1.7643,
      "step": 50550
    },
    {
      "epoch": 1.6192,
      "grad_norm": 0.3260306417942047,
      "learning_rate": 0.00013523328,
      "loss": 1.8025,
      "step": 50600
    },
    {
      "epoch": 1.6208,
      "grad_norm": 0.2852477431297302,
      "learning_rate": 0.00013516928,
      "loss": 1.8417,
      "step": 50650
    },
    {
      "epoch": 1.6223999999999998,
      "grad_norm": 0.3149276077747345,
      "learning_rate": 0.00013510528,
      "loss": 1.8121,
      "step": 50700
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.3736206889152527,
      "learning_rate": 0.00013504128000000002,
      "loss": 1.7965,
      "step": 50750
    },
    {
      "epoch": 1.6256,
      "grad_norm": 0.2991108000278473,
      "learning_rate": 0.00013497728,
      "loss": 1.7931,
      "step": 50800
    },
    {
      "epoch": 1.6272,
      "grad_norm": 0.3993895649909973,
      "learning_rate": 0.00013491328,
      "loss": 1.8249,
      "step": 50850
    },
    {
      "epoch": 1.6288,
      "grad_norm": 0.3115958869457245,
      "learning_rate": 0.00013484928,
      "loss": 1.8078,
      "step": 50900
    },
    {
      "epoch": 1.6303999999999998,
      "grad_norm": 0.30166515707969666,
      "learning_rate": 0.00013478528000000002,
      "loss": 1.7584,
      "step": 50950
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.3476884067058563,
      "learning_rate": 0.00013472128000000002,
      "loss": 1.8469,
      "step": 51000
    },
    {
      "epoch": 1.6336,
      "grad_norm": 0.39050862193107605,
      "learning_rate": 0.00013465728,
      "loss": 1.7703,
      "step": 51050
    },
    {
      "epoch": 1.6352,
      "grad_norm": 0.3416283130645752,
      "learning_rate": 0.00013459328,
      "loss": 1.7699,
      "step": 51100
    },
    {
      "epoch": 1.6368,
      "grad_norm": 0.3436078727245331,
      "learning_rate": 0.00013452928,
      "loss": 1.7966,
      "step": 51150
    },
    {
      "epoch": 1.6383999999999999,
      "grad_norm": 0.30453357100486755,
      "learning_rate": 0.00013446528,
      "loss": 1.8339,
      "step": 51200
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.3937097489833832,
      "learning_rate": 0.00013440128,
      "loss": 1.8508,
      "step": 51250
    },
    {
      "epoch": 1.6416,
      "grad_norm": 0.4119071364402771,
      "learning_rate": 0.00013433728000000002,
      "loss": 1.8042,
      "step": 51300
    },
    {
      "epoch": 1.6432,
      "grad_norm": 0.33801567554473877,
      "learning_rate": 0.00013427328,
      "loss": 1.8245,
      "step": 51350
    },
    {
      "epoch": 1.6448,
      "grad_norm": 0.3699542284011841,
      "learning_rate": 0.00013420928,
      "loss": 1.7283,
      "step": 51400
    },
    {
      "epoch": 1.6463999999999999,
      "grad_norm": 0.3253808617591858,
      "learning_rate": 0.00013414528,
      "loss": 1.7737,
      "step": 51450
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.3295803964138031,
      "learning_rate": 0.00013408128,
      "loss": 1.8165,
      "step": 51500
    },
    {
      "epoch": 1.6496,
      "grad_norm": 0.3742276728153229,
      "learning_rate": 0.00013401728,
      "loss": 1.7932,
      "step": 51550
    },
    {
      "epoch": 1.6512,
      "grad_norm": 0.32813334465026855,
      "learning_rate": 0.00013395328000000002,
      "loss": 1.7346,
      "step": 51600
    },
    {
      "epoch": 1.6528,
      "grad_norm": 0.3196960687637329,
      "learning_rate": 0.00013388928,
      "loss": 1.7928,
      "step": 51650
    },
    {
      "epoch": 1.6543999999999999,
      "grad_norm": 0.32474133372306824,
      "learning_rate": 0.00013382528,
      "loss": 1.7758,
      "step": 51700
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.36656829714775085,
      "learning_rate": 0.00013376128,
      "loss": 1.843,
      "step": 51750
    },
    {
      "epoch": 1.6576,
      "grad_norm": 0.3898216784000397,
      "learning_rate": 0.00013369728000000002,
      "loss": 1.8147,
      "step": 51800
    },
    {
      "epoch": 1.6592,
      "grad_norm": 0.3426741063594818,
      "learning_rate": 0.00013363328000000002,
      "loss": 1.8255,
      "step": 51850
    },
    {
      "epoch": 1.6608,
      "grad_norm": 0.3185847997665405,
      "learning_rate": 0.00013356928,
      "loss": 1.8255,
      "step": 51900
    },
    {
      "epoch": 1.6623999999999999,
      "grad_norm": 0.3913620412349701,
      "learning_rate": 0.00013350528,
      "loss": 1.77,
      "step": 51950
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.312500923871994,
      "learning_rate": 0.00013344128,
      "loss": 1.7792,
      "step": 52000
    },
    {
      "epoch": 1.6656,
      "grad_norm": 0.3256523013114929,
      "learning_rate": 0.00013337728,
      "loss": 1.8138,
      "step": 52050
    },
    {
      "epoch": 1.6672,
      "grad_norm": 0.36118751764297485,
      "learning_rate": 0.00013331328,
      "loss": 1.8106,
      "step": 52100
    },
    {
      "epoch": 1.6688,
      "grad_norm": 0.3265744149684906,
      "learning_rate": 0.00013324928000000002,
      "loss": 1.7646,
      "step": 52150
    },
    {
      "epoch": 1.6703999999999999,
      "grad_norm": 0.3265053331851959,
      "learning_rate": 0.00013318528,
      "loss": 1.8196,
      "step": 52200
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.3501579463481903,
      "learning_rate": 0.00013312128,
      "loss": 1.7699,
      "step": 52250
    },
    {
      "epoch": 1.6736,
      "grad_norm": 0.3110390901565552,
      "learning_rate": 0.00013305728000000003,
      "loss": 1.7854,
      "step": 52300
    },
    {
      "epoch": 1.6752,
      "grad_norm": 0.28934746980667114,
      "learning_rate": 0.00013299328,
      "loss": 1.86,
      "step": 52350
    },
    {
      "epoch": 1.6768,
      "grad_norm": 0.34587809443473816,
      "learning_rate": 0.00013292928,
      "loss": 1.8081,
      "step": 52400
    },
    {
      "epoch": 1.6784,
      "grad_norm": 0.3811493217945099,
      "learning_rate": 0.00013286528000000002,
      "loss": 1.7994,
      "step": 52450
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.34285327792167664,
      "learning_rate": 0.00013280128,
      "loss": 1.7551,
      "step": 52500
    },
    {
      "epoch": 1.6816,
      "grad_norm": 0.30271902680397034,
      "learning_rate": 0.00013273728,
      "loss": 1.806,
      "step": 52550
    },
    {
      "epoch": 1.6832,
      "grad_norm": 0.335174024105072,
      "learning_rate": 0.00013267328,
      "loss": 1.838,
      "step": 52600
    },
    {
      "epoch": 1.6848,
      "grad_norm": 0.3723377287387848,
      "learning_rate": 0.00013260928000000002,
      "loss": 1.7897,
      "step": 52650
    },
    {
      "epoch": 1.6864,
      "grad_norm": 0.30979618430137634,
      "learning_rate": 0.00013254528000000002,
      "loss": 1.8346,
      "step": 52700
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.30569422245025635,
      "learning_rate": 0.00013248128,
      "loss": 1.8178,
      "step": 52750
    },
    {
      "epoch": 1.6896,
      "grad_norm": 0.3306587040424347,
      "learning_rate": 0.00013241728,
      "loss": 1.7864,
      "step": 52800
    },
    {
      "epoch": 1.6912,
      "grad_norm": 0.3549395799636841,
      "learning_rate": 0.00013235328,
      "loss": 1.8463,
      "step": 52850
    },
    {
      "epoch": 1.6928,
      "grad_norm": 0.40433332324028015,
      "learning_rate": 0.00013228928,
      "loss": 1.8443,
      "step": 52900
    },
    {
      "epoch": 1.6944,
      "grad_norm": 0.23859256505966187,
      "learning_rate": 0.00013222528,
      "loss": 1.7489,
      "step": 52950
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.3213012218475342,
      "learning_rate": 0.00013216128000000002,
      "loss": 1.8032,
      "step": 53000
    },
    {
      "epoch": 1.6976,
      "grad_norm": 0.41429272294044495,
      "learning_rate": 0.00013209728,
      "loss": 1.815,
      "step": 53050
    },
    {
      "epoch": 1.6992,
      "grad_norm": 0.331229567527771,
      "learning_rate": 0.00013203328,
      "loss": 1.7519,
      "step": 53100
    },
    {
      "epoch": 1.7008,
      "grad_norm": 0.3207787573337555,
      "learning_rate": 0.00013196928000000003,
      "loss": 1.8265,
      "step": 53150
    },
    {
      "epoch": 1.7024,
      "grad_norm": 0.3166579306125641,
      "learning_rate": 0.00013190528,
      "loss": 1.7599,
      "step": 53200
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.2953433096408844,
      "learning_rate": 0.00013184128,
      "loss": 1.8112,
      "step": 53250
    },
    {
      "epoch": 1.7056,
      "grad_norm": 0.294941782951355,
      "learning_rate": 0.00013177728000000002,
      "loss": 1.7679,
      "step": 53300
    },
    {
      "epoch": 1.7072,
      "grad_norm": 0.373136430978775,
      "learning_rate": 0.00013171328,
      "loss": 1.768,
      "step": 53350
    },
    {
      "epoch": 1.7088,
      "grad_norm": 0.34940025210380554,
      "learning_rate": 0.00013164928,
      "loss": 1.756,
      "step": 53400
    },
    {
      "epoch": 1.7104,
      "grad_norm": 0.36149853467941284,
      "learning_rate": 0.00013158528,
      "loss": 1.8094,
      "step": 53450
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.2876756489276886,
      "learning_rate": 0.00013152128000000002,
      "loss": 1.789,
      "step": 53500
    },
    {
      "epoch": 1.7136,
      "grad_norm": 0.474063515663147,
      "learning_rate": 0.00013145728000000002,
      "loss": 1.8145,
      "step": 53550
    },
    {
      "epoch": 1.7151999999999998,
      "grad_norm": 0.3288258910179138,
      "learning_rate": 0.00013139327999999999,
      "loss": 1.7603,
      "step": 53600
    },
    {
      "epoch": 1.7168,
      "grad_norm": 0.40347668528556824,
      "learning_rate": 0.00013132928,
      "loss": 1.7512,
      "step": 53650
    },
    {
      "epoch": 1.7184,
      "grad_norm": 0.3294921815395355,
      "learning_rate": 0.00013126528,
      "loss": 1.7837,
      "step": 53700
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.33821824193000793,
      "learning_rate": 0.00013120128,
      "loss": 1.8133,
      "step": 53750
    },
    {
      "epoch": 1.7216,
      "grad_norm": 0.33085745573043823,
      "learning_rate": 0.00013113728,
      "loss": 1.8201,
      "step": 53800
    },
    {
      "epoch": 1.7231999999999998,
      "grad_norm": 0.41051214933395386,
      "learning_rate": 0.00013107328000000002,
      "loss": 1.7599,
      "step": 53850
    },
    {
      "epoch": 1.7248,
      "grad_norm": 0.3561890721321106,
      "learning_rate": 0.00013100928,
      "loss": 1.7788,
      "step": 53900
    },
    {
      "epoch": 1.7264,
      "grad_norm": 0.3230489492416382,
      "learning_rate": 0.00013094528,
      "loss": 1.8562,
      "step": 53950
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.3939747214317322,
      "learning_rate": 0.00013088128000000003,
      "loss": 1.7963,
      "step": 54000
    },
    {
      "epoch": 1.7296,
      "grad_norm": 0.33905911445617676,
      "learning_rate": 0.00013081728,
      "loss": 1.8403,
      "step": 54050
    },
    {
      "epoch": 1.7311999999999999,
      "grad_norm": 0.3122127652168274,
      "learning_rate": 0.00013075328,
      "loss": 1.8197,
      "step": 54100
    },
    {
      "epoch": 1.7328000000000001,
      "grad_norm": 0.3262197971343994,
      "learning_rate": 0.00013068928000000001,
      "loss": 1.7727,
      "step": 54150
    },
    {
      "epoch": 1.7344,
      "grad_norm": 0.34806007146835327,
      "learning_rate": 0.00013062528,
      "loss": 1.7942,
      "step": 54200
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.3436368703842163,
      "learning_rate": 0.00013056128,
      "loss": 1.7748,
      "step": 54250
    },
    {
      "epoch": 1.7376,
      "grad_norm": 0.3393873870372772,
      "learning_rate": 0.00013049728,
      "loss": 1.7949,
      "step": 54300
    },
    {
      "epoch": 1.7391999999999999,
      "grad_norm": 0.33411309123039246,
      "learning_rate": 0.00013043328000000002,
      "loss": 1.7741,
      "step": 54350
    },
    {
      "epoch": 1.7408000000000001,
      "grad_norm": 0.27588844299316406,
      "learning_rate": 0.00013036928000000002,
      "loss": 1.7575,
      "step": 54400
    },
    {
      "epoch": 1.7424,
      "grad_norm": 0.3825654685497284,
      "learning_rate": 0.00013030527999999999,
      "loss": 1.8131,
      "step": 54450
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.29464831948280334,
      "learning_rate": 0.00013024128,
      "loss": 1.7841,
      "step": 54500
    },
    {
      "epoch": 1.7456,
      "grad_norm": 0.33515384793281555,
      "learning_rate": 0.00013017728,
      "loss": 1.782,
      "step": 54550
    },
    {
      "epoch": 1.7471999999999999,
      "grad_norm": 0.38535767793655396,
      "learning_rate": 0.00013011328,
      "loss": 1.7834,
      "step": 54600
    },
    {
      "epoch": 1.7488000000000001,
      "grad_norm": 0.30391523241996765,
      "learning_rate": 0.00013004928,
      "loss": 1.7869,
      "step": 54650
    },
    {
      "epoch": 1.7504,
      "grad_norm": 0.35315486788749695,
      "learning_rate": 0.00012998528000000002,
      "loss": 1.8277,
      "step": 54700
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.3468626141548157,
      "learning_rate": 0.00012992128,
      "loss": 1.7978,
      "step": 54750
    },
    {
      "epoch": 1.7536,
      "grad_norm": 0.359759658575058,
      "learning_rate": 0.00012985728,
      "loss": 1.8131,
      "step": 54800
    },
    {
      "epoch": 1.7551999999999999,
      "grad_norm": 0.4593498110771179,
      "learning_rate": 0.00012979328000000003,
      "loss": 1.8621,
      "step": 54850
    },
    {
      "epoch": 1.7568000000000001,
      "grad_norm": 0.3351189196109772,
      "learning_rate": 0.00012972928,
      "loss": 1.7787,
      "step": 54900
    },
    {
      "epoch": 1.7584,
      "grad_norm": 0.2708098590373993,
      "learning_rate": 0.00012966528,
      "loss": 1.7889,
      "step": 54950
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.3247899115085602,
      "learning_rate": 0.00012960128000000001,
      "loss": 1.7866,
      "step": 55000
    },
    {
      "epoch": 1.7616,
      "grad_norm": 0.33321428298950195,
      "learning_rate": 0.00012953728,
      "loss": 1.7817,
      "step": 55050
    },
    {
      "epoch": 1.7631999999999999,
      "grad_norm": 0.4021807909011841,
      "learning_rate": 0.00012947328,
      "loss": 1.8164,
      "step": 55100
    },
    {
      "epoch": 1.7648000000000001,
      "grad_norm": 0.3249843120574951,
      "learning_rate": 0.00012940928,
      "loss": 1.8118,
      "step": 55150
    },
    {
      "epoch": 1.7664,
      "grad_norm": 0.30894356966018677,
      "learning_rate": 0.00012934528000000002,
      "loss": 1.7844,
      "step": 55200
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.48009154200553894,
      "learning_rate": 0.00012928128000000002,
      "loss": 1.793,
      "step": 55250
    },
    {
      "epoch": 1.7696,
      "grad_norm": 0.3021048605442047,
      "learning_rate": 0.00012921727999999999,
      "loss": 1.7392,
      "step": 55300
    },
    {
      "epoch": 1.7711999999999999,
      "grad_norm": 0.30215293169021606,
      "learning_rate": 0.00012915328,
      "loss": 1.8001,
      "step": 55350
    },
    {
      "epoch": 1.7728000000000002,
      "grad_norm": 0.3127342760562897,
      "learning_rate": 0.00012908928,
      "loss": 1.7646,
      "step": 55400
    },
    {
      "epoch": 1.7744,
      "grad_norm": 0.3208213746547699,
      "learning_rate": 0.00012902528,
      "loss": 1.7907,
      "step": 55450
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.3375876545906067,
      "learning_rate": 0.00012896128,
      "loss": 1.7909,
      "step": 55500
    },
    {
      "epoch": 1.7776,
      "grad_norm": 0.36730802059173584,
      "learning_rate": 0.00012889728000000002,
      "loss": 1.8188,
      "step": 55550
    },
    {
      "epoch": 1.7792,
      "grad_norm": 0.3066891133785248,
      "learning_rate": 0.00012883328,
      "loss": 1.7623,
      "step": 55600
    },
    {
      "epoch": 1.7808000000000002,
      "grad_norm": 0.33221861720085144,
      "learning_rate": 0.00012876928,
      "loss": 1.7135,
      "step": 55650
    },
    {
      "epoch": 1.7824,
      "grad_norm": 0.3181212246417999,
      "learning_rate": 0.00012870528000000003,
      "loss": 1.8225,
      "step": 55700
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.4350883960723877,
      "learning_rate": 0.00012864128,
      "loss": 1.7836,
      "step": 55750
    },
    {
      "epoch": 1.7856,
      "grad_norm": 0.3624185621738434,
      "learning_rate": 0.00012857728,
      "loss": 1.8519,
      "step": 55800
    },
    {
      "epoch": 1.7872,
      "grad_norm": 0.3712734282016754,
      "learning_rate": 0.00012851328000000001,
      "loss": 1.7276,
      "step": 55850
    },
    {
      "epoch": 1.7888,
      "grad_norm": 0.30054423213005066,
      "learning_rate": 0.00012844928,
      "loss": 1.8413,
      "step": 55900
    },
    {
      "epoch": 1.7904,
      "grad_norm": 0.3342633545398712,
      "learning_rate": 0.00012838528,
      "loss": 1.8124,
      "step": 55950
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.36076074838638306,
      "learning_rate": 0.00012832128,
      "loss": 1.8046,
      "step": 56000
    },
    {
      "epoch": 1.7936,
      "grad_norm": 0.3309343159198761,
      "learning_rate": 0.00012825728000000002,
      "loss": 1.8089,
      "step": 56050
    },
    {
      "epoch": 1.7952,
      "grad_norm": 0.3437356650829315,
      "learning_rate": 0.00012819328000000002,
      "loss": 1.7978,
      "step": 56100
    },
    {
      "epoch": 1.7968,
      "grad_norm": 0.34441134333610535,
      "learning_rate": 0.00012812927999999998,
      "loss": 1.833,
      "step": 56150
    },
    {
      "epoch": 1.7984,
      "grad_norm": 0.2867406904697418,
      "learning_rate": 0.00012806528,
      "loss": 1.8059,
      "step": 56200
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.3394809365272522,
      "learning_rate": 0.00012800128,
      "loss": 1.7815,
      "step": 56250
    },
    {
      "epoch": 1.8016,
      "grad_norm": 0.2924313545227051,
      "learning_rate": 0.00012793728,
      "loss": 1.8401,
      "step": 56300
    },
    {
      "epoch": 1.8032,
      "grad_norm": 0.30663543939590454,
      "learning_rate": 0.00012787328000000002,
      "loss": 1.8285,
      "step": 56350
    },
    {
      "epoch": 1.8048,
      "grad_norm": 0.31721678376197815,
      "learning_rate": 0.00012780928000000002,
      "loss": 1.7707,
      "step": 56400
    },
    {
      "epoch": 1.8064,
      "grad_norm": 0.4204593002796173,
      "learning_rate": 0.00012774528,
      "loss": 1.7874,
      "step": 56450
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.3291283845901489,
      "learning_rate": 0.00012768128,
      "loss": 1.7578,
      "step": 56500
    },
    {
      "epoch": 1.8096,
      "grad_norm": 0.32389089465141296,
      "learning_rate": 0.00012761728000000003,
      "loss": 1.7765,
      "step": 56550
    },
    {
      "epoch": 1.8112,
      "grad_norm": 0.31695815920829773,
      "learning_rate": 0.00012755328,
      "loss": 1.827,
      "step": 56600
    },
    {
      "epoch": 1.8128,
      "grad_norm": 0.2674127519130707,
      "learning_rate": 0.00012748928,
      "loss": 1.7985,
      "step": 56650
    },
    {
      "epoch": 1.8144,
      "grad_norm": 0.2827083468437195,
      "learning_rate": 0.00012742528,
      "loss": 1.8026,
      "step": 56700
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.357789546251297,
      "learning_rate": 0.00012736128,
      "loss": 1.8066,
      "step": 56750
    },
    {
      "epoch": 1.8176,
      "grad_norm": 0.37356510758399963,
      "learning_rate": 0.00012729728,
      "loss": 1.8052,
      "step": 56800
    },
    {
      "epoch": 1.8192,
      "grad_norm": 0.42599475383758545,
      "learning_rate": 0.00012723328,
      "loss": 1.7626,
      "step": 56850
    },
    {
      "epoch": 1.8208,
      "grad_norm": 0.33610302209854126,
      "learning_rate": 0.00012716928000000002,
      "loss": 1.7935,
      "step": 56900
    },
    {
      "epoch": 1.8224,
      "grad_norm": 0.3378167152404785,
      "learning_rate": 0.00012710528000000002,
      "loss": 1.7971,
      "step": 56950
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.327311247587204,
      "learning_rate": 0.00012704127999999998,
      "loss": 1.8051,
      "step": 57000
    },
    {
      "epoch": 1.8256000000000001,
      "grad_norm": 0.37079930305480957,
      "learning_rate": 0.00012697728,
      "loss": 1.8009,
      "step": 57050
    },
    {
      "epoch": 1.8272,
      "grad_norm": 0.3332083523273468,
      "learning_rate": 0.00012691328,
      "loss": 1.7985,
      "step": 57100
    },
    {
      "epoch": 1.8288,
      "grad_norm": 0.35581639409065247,
      "learning_rate": 0.00012684928,
      "loss": 1.7775,
      "step": 57150
    },
    {
      "epoch": 1.8304,
      "grad_norm": 0.3214733600616455,
      "learning_rate": 0.00012678528000000002,
      "loss": 1.8113,
      "step": 57200
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.36396345496177673,
      "learning_rate": 0.00012672128000000001,
      "loss": 1.8179,
      "step": 57250
    },
    {
      "epoch": 1.8336000000000001,
      "grad_norm": 0.33553197979927063,
      "learning_rate": 0.00012665728,
      "loss": 1.7929,
      "step": 57300
    },
    {
      "epoch": 1.8352,
      "grad_norm": 0.3673279583454132,
      "learning_rate": 0.00012659328,
      "loss": 1.7771,
      "step": 57350
    },
    {
      "epoch": 1.8368,
      "grad_norm": 0.30355924367904663,
      "learning_rate": 0.00012652928000000003,
      "loss": 1.8059,
      "step": 57400
    },
    {
      "epoch": 1.8384,
      "grad_norm": 0.3098313808441162,
      "learning_rate": 0.00012646528,
      "loss": 1.7769,
      "step": 57450
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.5099276304244995,
      "learning_rate": 0.00012640128,
      "loss": 1.8356,
      "step": 57500
    },
    {
      "epoch": 1.8416000000000001,
      "grad_norm": 0.35132378339767456,
      "learning_rate": 0.00012633728,
      "loss": 1.7994,
      "step": 57550
    },
    {
      "epoch": 1.8432,
      "grad_norm": 0.3323289453983307,
      "learning_rate": 0.00012627328,
      "loss": 1.8144,
      "step": 57600
    },
    {
      "epoch": 1.8448,
      "grad_norm": 0.33057209849357605,
      "learning_rate": 0.00012620928,
      "loss": 1.8197,
      "step": 57650
    },
    {
      "epoch": 1.8464,
      "grad_norm": 0.35311707854270935,
      "learning_rate": 0.00012614528,
      "loss": 1.7606,
      "step": 57700
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.33472371101379395,
      "learning_rate": 0.00012608128000000002,
      "loss": 1.7914,
      "step": 57750
    },
    {
      "epoch": 1.8496000000000001,
      "grad_norm": 0.33087751269340515,
      "learning_rate": 0.00012601728000000002,
      "loss": 1.8181,
      "step": 57800
    },
    {
      "epoch": 1.8512,
      "grad_norm": 0.31726422905921936,
      "learning_rate": 0.00012595327999999998,
      "loss": 1.8335,
      "step": 57850
    },
    {
      "epoch": 1.8528,
      "grad_norm": 0.33755990862846375,
      "learning_rate": 0.00012588928,
      "loss": 1.7703,
      "step": 57900
    },
    {
      "epoch": 1.8544,
      "grad_norm": 0.30522552132606506,
      "learning_rate": 0.00012582528,
      "loss": 1.8183,
      "step": 57950
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.3621022403240204,
      "learning_rate": 0.00012576128,
      "loss": 1.7959,
      "step": 58000
    },
    {
      "epoch": 1.8576000000000001,
      "grad_norm": 0.31480708718299866,
      "learning_rate": 0.00012569728000000002,
      "loss": 1.8226,
      "step": 58050
    },
    {
      "epoch": 1.8592,
      "grad_norm": 0.35335469245910645,
      "learning_rate": 0.00012563328000000001,
      "loss": 1.8224,
      "step": 58100
    },
    {
      "epoch": 1.8608,
      "grad_norm": 0.3572898805141449,
      "learning_rate": 0.00012556928,
      "loss": 1.8033,
      "step": 58150
    },
    {
      "epoch": 1.8624,
      "grad_norm": 0.31330981850624084,
      "learning_rate": 0.00012550528,
      "loss": 1.8273,
      "step": 58200
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.37269076704978943,
      "learning_rate": 0.00012544128000000003,
      "loss": 1.7861,
      "step": 58250
    },
    {
      "epoch": 1.8656000000000001,
      "grad_norm": 0.3470678925514221,
      "learning_rate": 0.00012537728,
      "loss": 1.8029,
      "step": 58300
    },
    {
      "epoch": 1.8672,
      "grad_norm": 0.3896767497062683,
      "learning_rate": 0.00012531328,
      "loss": 1.8008,
      "step": 58350
    },
    {
      "epoch": 1.8688,
      "grad_norm": 0.2834184169769287,
      "learning_rate": 0.00012524928,
      "loss": 1.8166,
      "step": 58400
    },
    {
      "epoch": 1.8704,
      "grad_norm": 0.3580145239830017,
      "learning_rate": 0.00012518528,
      "loss": 1.8601,
      "step": 58450
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.34699997305870056,
      "learning_rate": 0.00012512128,
      "loss": 1.7771,
      "step": 58500
    },
    {
      "epoch": 1.8736000000000002,
      "grad_norm": 0.3070641756057739,
      "learning_rate": 0.00012505728,
      "loss": 1.7627,
      "step": 58550
    },
    {
      "epoch": 1.8752,
      "grad_norm": 0.3336299955844879,
      "learning_rate": 0.00012499328000000002,
      "loss": 1.7807,
      "step": 58600
    },
    {
      "epoch": 1.8768,
      "grad_norm": 0.4319930970668793,
      "learning_rate": 0.00012492928000000002,
      "loss": 1.8272,
      "step": 58650
    },
    {
      "epoch": 1.8784,
      "grad_norm": 0.382597953081131,
      "learning_rate": 0.00012486527999999998,
      "loss": 1.8687,
      "step": 58700
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.3382779061794281,
      "learning_rate": 0.00012480128,
      "loss": 1.8063,
      "step": 58750
    },
    {
      "epoch": 1.8816000000000002,
      "grad_norm": 0.30647075176239014,
      "learning_rate": 0.00012473728,
      "loss": 1.8335,
      "step": 58800
    },
    {
      "epoch": 1.8832,
      "grad_norm": 0.31843236088752747,
      "learning_rate": 0.00012467328,
      "loss": 1.8442,
      "step": 58850
    },
    {
      "epoch": 1.8848,
      "grad_norm": 0.4137955904006958,
      "learning_rate": 0.00012460928000000002,
      "loss": 1.7475,
      "step": 58900
    },
    {
      "epoch": 1.8864,
      "grad_norm": 0.2709572911262512,
      "learning_rate": 0.00012454528000000001,
      "loss": 1.7932,
      "step": 58950
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.3820211589336395,
      "learning_rate": 0.00012448128,
      "loss": 1.7937,
      "step": 59000
    },
    {
      "epoch": 1.8896,
      "grad_norm": 0.3626658320426941,
      "learning_rate": 0.00012441728,
      "loss": 1.7884,
      "step": 59050
    },
    {
      "epoch": 1.8912,
      "grad_norm": 0.3021959364414215,
      "learning_rate": 0.00012435328000000003,
      "loss": 1.8124,
      "step": 59100
    },
    {
      "epoch": 1.8928,
      "grad_norm": 0.2777247130870819,
      "learning_rate": 0.00012428928,
      "loss": 1.8007,
      "step": 59150
    },
    {
      "epoch": 1.8944,
      "grad_norm": 0.3446188271045685,
      "learning_rate": 0.00012422528,
      "loss": 1.8043,
      "step": 59200
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.3972095251083374,
      "learning_rate": 0.00012416128,
      "loss": 1.8041,
      "step": 59250
    },
    {
      "epoch": 1.8976,
      "grad_norm": 0.3362900912761688,
      "learning_rate": 0.00012409728,
      "loss": 1.7313,
      "step": 59300
    },
    {
      "epoch": 1.8992,
      "grad_norm": 0.3134367763996124,
      "learning_rate": 0.00012403328,
      "loss": 1.7581,
      "step": 59350
    },
    {
      "epoch": 1.9008,
      "grad_norm": 0.38287630677223206,
      "learning_rate": 0.00012396928,
      "loss": 1.7526,
      "step": 59400
    },
    {
      "epoch": 1.9024,
      "grad_norm": 0.35271915793418884,
      "learning_rate": 0.00012390528000000002,
      "loss": 1.8158,
      "step": 59450
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.35805585980415344,
      "learning_rate": 0.00012384128000000002,
      "loss": 1.7957,
      "step": 59500
    },
    {
      "epoch": 1.9056,
      "grad_norm": 0.30111798644065857,
      "learning_rate": 0.00012377727999999998,
      "loss": 1.8568,
      "step": 59550
    },
    {
      "epoch": 1.9072,
      "grad_norm": 0.35413986444473267,
      "learning_rate": 0.00012371328,
      "loss": 1.8226,
      "step": 59600
    },
    {
      "epoch": 1.9088,
      "grad_norm": 0.34698957204818726,
      "learning_rate": 0.00012364928,
      "loss": 1.7455,
      "step": 59650
    },
    {
      "epoch": 1.9104,
      "grad_norm": 0.2847079336643219,
      "learning_rate": 0.00012358528,
      "loss": 1.7721,
      "step": 59700
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.3453304171562195,
      "learning_rate": 0.00012352128000000002,
      "loss": 1.7577,
      "step": 59750
    },
    {
      "epoch": 1.9136,
      "grad_norm": 0.3847312331199646,
      "learning_rate": 0.00012345728,
      "loss": 1.8029,
      "step": 59800
    },
    {
      "epoch": 1.9152,
      "grad_norm": 0.4032408595085144,
      "learning_rate": 0.00012339328,
      "loss": 1.771,
      "step": 59850
    },
    {
      "epoch": 1.9167999999999998,
      "grad_norm": 0.3639885485172272,
      "learning_rate": 0.00012332928,
      "loss": 1.8251,
      "step": 59900
    },
    {
      "epoch": 1.9184,
      "grad_norm": 0.37706810235977173,
      "learning_rate": 0.00012326528000000003,
      "loss": 1.7536,
      "step": 59950
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.29745200276374817,
      "learning_rate": 0.00012320128,
      "loss": 1.8431,
      "step": 60000
    },
    {
      "epoch": 1.9216,
      "grad_norm": 0.27725452184677124,
      "learning_rate": 0.00012313728,
      "loss": 1.8222,
      "step": 60050
    },
    {
      "epoch": 1.9232,
      "grad_norm": 0.30074015259742737,
      "learning_rate": 0.00012307328,
      "loss": 1.8431,
      "step": 60100
    },
    {
      "epoch": 1.9247999999999998,
      "grad_norm": 0.2858835756778717,
      "learning_rate": 0.00012300928,
      "loss": 1.7946,
      "step": 60150
    },
    {
      "epoch": 1.9264000000000001,
      "grad_norm": 0.36102861166000366,
      "learning_rate": 0.00012294528,
      "loss": 1.8323,
      "step": 60200
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.34482645988464355,
      "learning_rate": 0.00012288128,
      "loss": 1.7896,
      "step": 60250
    },
    {
      "epoch": 1.9296,
      "grad_norm": 0.3904900848865509,
      "learning_rate": 0.00012281728000000002,
      "loss": 1.7932,
      "step": 60300
    },
    {
      "epoch": 1.9312,
      "grad_norm": 0.34593313932418823,
      "learning_rate": 0.00012275328000000001,
      "loss": 1.8439,
      "step": 60350
    },
    {
      "epoch": 1.9327999999999999,
      "grad_norm": 0.38504356145858765,
      "learning_rate": 0.00012268927999999998,
      "loss": 1.7603,
      "step": 60400
    },
    {
      "epoch": 1.9344000000000001,
      "grad_norm": 0.33928319811820984,
      "learning_rate": 0.00012262528,
      "loss": 1.7245,
      "step": 60450
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.3105151355266571,
      "learning_rate": 0.00012256128,
      "loss": 1.8697,
      "step": 60500
    },
    {
      "epoch": 1.9376,
      "grad_norm": 0.38391542434692383,
      "learning_rate": 0.00012249728,
      "loss": 1.8149,
      "step": 60550
    },
    {
      "epoch": 1.9392,
      "grad_norm": 0.3194175958633423,
      "learning_rate": 0.00012243328000000002,
      "loss": 1.7964,
      "step": 60600
    },
    {
      "epoch": 1.9407999999999999,
      "grad_norm": 0.31425222754478455,
      "learning_rate": 0.00012236928,
      "loss": 1.7284,
      "step": 60650
    },
    {
      "epoch": 1.9424000000000001,
      "grad_norm": 0.32176104187965393,
      "learning_rate": 0.00012230528,
      "loss": 1.8002,
      "step": 60700
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.2754189372062683,
      "learning_rate": 0.00012224128,
      "loss": 1.7564,
      "step": 60750
    },
    {
      "epoch": 1.9456,
      "grad_norm": 0.29478368163108826,
      "learning_rate": 0.00012217728000000003,
      "loss": 1.7747,
      "step": 60800
    },
    {
      "epoch": 1.9472,
      "grad_norm": 0.34239503741264343,
      "learning_rate": 0.00012211328,
      "loss": 1.7609,
      "step": 60850
    },
    {
      "epoch": 1.9487999999999999,
      "grad_norm": 0.35249289870262146,
      "learning_rate": 0.00012204928,
      "loss": 1.7914,
      "step": 60900
    },
    {
      "epoch": 1.9504000000000001,
      "grad_norm": 0.37087011337280273,
      "learning_rate": 0.00012198528,
      "loss": 1.7622,
      "step": 60950
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.44247815012931824,
      "learning_rate": 0.00012192128,
      "loss": 1.7924,
      "step": 61000
    },
    {
      "epoch": 1.9536,
      "grad_norm": 0.33928677439689636,
      "learning_rate": 0.00012185728,
      "loss": 1.759,
      "step": 61050
    },
    {
      "epoch": 1.9552,
      "grad_norm": 0.34854856133461,
      "learning_rate": 0.00012179328000000001,
      "loss": 1.7669,
      "step": 61100
    },
    {
      "epoch": 1.9567999999999999,
      "grad_norm": 0.4206058084964752,
      "learning_rate": 0.00012172928,
      "loss": 1.7918,
      "step": 61150
    },
    {
      "epoch": 1.9584000000000001,
      "grad_norm": 0.4001651704311371,
      "learning_rate": 0.00012166528000000001,
      "loss": 1.7734,
      "step": 61200
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.3789500296115875,
      "learning_rate": 0.00012160128,
      "loss": 1.7952,
      "step": 61250
    },
    {
      "epoch": 1.9616,
      "grad_norm": 0.4469720423221588,
      "learning_rate": 0.00012153727999999999,
      "loss": 1.8038,
      "step": 61300
    },
    {
      "epoch": 1.9632,
      "grad_norm": 0.3229030668735504,
      "learning_rate": 0.00012147328,
      "loss": 1.8371,
      "step": 61350
    },
    {
      "epoch": 1.9647999999999999,
      "grad_norm": 0.3441872298717499,
      "learning_rate": 0.00012140928000000001,
      "loss": 1.8584,
      "step": 61400
    },
    {
      "epoch": 1.9664000000000001,
      "grad_norm": 0.37659770250320435,
      "learning_rate": 0.00012134528,
      "loss": 1.8533,
      "step": 61450
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.30975857377052307,
      "learning_rate": 0.00012128128000000001,
      "loss": 1.8085,
      "step": 61500
    },
    {
      "epoch": 1.9696,
      "grad_norm": 0.3923731744289398,
      "learning_rate": 0.00012121728000000001,
      "loss": 1.7647,
      "step": 61550
    },
    {
      "epoch": 1.9712,
      "grad_norm": 0.40410691499710083,
      "learning_rate": 0.00012115328000000002,
      "loss": 1.8125,
      "step": 61600
    },
    {
      "epoch": 1.9727999999999999,
      "grad_norm": 0.3643122911453247,
      "learning_rate": 0.00012108928000000001,
      "loss": 1.8267,
      "step": 61650
    },
    {
      "epoch": 1.9744000000000002,
      "grad_norm": 0.4097936153411865,
      "learning_rate": 0.00012102528,
      "loss": 1.8061,
      "step": 61700
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.3565773069858551,
      "learning_rate": 0.00012096128,
      "loss": 1.7885,
      "step": 61750
    },
    {
      "epoch": 1.9776,
      "grad_norm": 0.4075963497161865,
      "learning_rate": 0.00012089728,
      "loss": 1.7997,
      "step": 61800
    },
    {
      "epoch": 1.9792,
      "grad_norm": 0.34337252378463745,
      "learning_rate": 0.00012083328,
      "loss": 1.802,
      "step": 61850
    },
    {
      "epoch": 1.9808,
      "grad_norm": 0.32608315348625183,
      "learning_rate": 0.00012076928,
      "loss": 1.7678,
      "step": 61900
    },
    {
      "epoch": 1.9824000000000002,
      "grad_norm": 0.29518944025039673,
      "learning_rate": 0.00012070528000000001,
      "loss": 1.8,
      "step": 61950
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.3161442279815674,
      "learning_rate": 0.00012064128000000002,
      "loss": 1.7401,
      "step": 62000
    },
    {
      "epoch": 1.9856,
      "grad_norm": 0.31202372908592224,
      "learning_rate": 0.00012057728000000001,
      "loss": 1.8162,
      "step": 62050
    },
    {
      "epoch": 1.9872,
      "grad_norm": 0.31507182121276855,
      "learning_rate": 0.00012051328,
      "loss": 1.7585,
      "step": 62100
    },
    {
      "epoch": 1.9888,
      "grad_norm": 0.3578028678894043,
      "learning_rate": 0.00012044928,
      "loss": 1.7881,
      "step": 62150
    },
    {
      "epoch": 1.9904,
      "grad_norm": 0.31578612327575684,
      "learning_rate": 0.00012038528,
      "loss": 1.7818,
      "step": 62200
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.3969416618347168,
      "learning_rate": 0.00012032128000000001,
      "loss": 1.7872,
      "step": 62250
    },
    {
      "epoch": 1.9936,
      "grad_norm": 0.32550203800201416,
      "learning_rate": 0.00012025728,
      "loss": 1.777,
      "step": 62300
    },
    {
      "epoch": 1.9952,
      "grad_norm": 0.4450845420360565,
      "learning_rate": 0.00012019328000000001,
      "loss": 1.7702,
      "step": 62350
    },
    {
      "epoch": 1.9968,
      "grad_norm": 0.3302866816520691,
      "learning_rate": 0.00012012928000000001,
      "loss": 1.7248,
      "step": 62400
    },
    {
      "epoch": 1.9984,
      "grad_norm": 0.3568701148033142,
      "learning_rate": 0.00012006528000000002,
      "loss": 1.7802,
      "step": 62450
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4416743814945221,
      "learning_rate": 0.00012000128000000001,
      "loss": 1.8314,
      "step": 62500
    },
    {
      "epoch": 2.0016,
      "grad_norm": 0.32209232449531555,
      "learning_rate": 0.00011993727999999999,
      "loss": 1.7743,
      "step": 62550
    },
    {
      "epoch": 2.0032,
      "grad_norm": 0.31986403465270996,
      "learning_rate": 0.00011987328,
      "loss": 1.7832,
      "step": 62600
    },
    {
      "epoch": 2.0048,
      "grad_norm": 0.3317173421382904,
      "learning_rate": 0.00011980928,
      "loss": 1.7828,
      "step": 62650
    },
    {
      "epoch": 2.0064,
      "grad_norm": 0.2917783856391907,
      "learning_rate": 0.00011974528,
      "loss": 1.8523,
      "step": 62700
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.35788458585739136,
      "learning_rate": 0.00011968128,
      "loss": 1.7935,
      "step": 62750
    },
    {
      "epoch": 2.0096,
      "grad_norm": 0.31561949849128723,
      "learning_rate": 0.00011961728000000001,
      "loss": 1.7982,
      "step": 62800
    },
    {
      "epoch": 2.0112,
      "grad_norm": 0.2874389588832855,
      "learning_rate": 0.00011955328000000002,
      "loss": 1.7708,
      "step": 62850
    },
    {
      "epoch": 2.0128,
      "grad_norm": 0.3693540394306183,
      "learning_rate": 0.00011948928000000001,
      "loss": 1.8246,
      "step": 62900
    },
    {
      "epoch": 2.0144,
      "grad_norm": 0.3612038493156433,
      "learning_rate": 0.00011942528,
      "loss": 1.7812,
      "step": 62950
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.3549264073371887,
      "learning_rate": 0.00011936128,
      "loss": 1.7868,
      "step": 63000
    },
    {
      "epoch": 2.0176,
      "grad_norm": 0.27336210012435913,
      "learning_rate": 0.00011929728,
      "loss": 1.7679,
      "step": 63050
    },
    {
      "epoch": 2.0192,
      "grad_norm": 0.3051566481590271,
      "learning_rate": 0.00011923328000000001,
      "loss": 1.769,
      "step": 63100
    },
    {
      "epoch": 2.0208,
      "grad_norm": 0.38644713163375854,
      "learning_rate": 0.00011916928,
      "loss": 1.7901,
      "step": 63150
    },
    {
      "epoch": 2.0224,
      "grad_norm": 0.34538984298706055,
      "learning_rate": 0.00011910528000000001,
      "loss": 1.7345,
      "step": 63200
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.40786615014076233,
      "learning_rate": 0.00011904128000000001,
      "loss": 1.7801,
      "step": 63250
    },
    {
      "epoch": 2.0256,
      "grad_norm": 0.3318387567996979,
      "learning_rate": 0.00011897728000000002,
      "loss": 1.7524,
      "step": 63300
    },
    {
      "epoch": 2.0272,
      "grad_norm": 0.31151965260505676,
      "learning_rate": 0.00011891328000000001,
      "loss": 1.8046,
      "step": 63350
    },
    {
      "epoch": 2.0288,
      "grad_norm": 0.5199648141860962,
      "learning_rate": 0.00011884927999999999,
      "loss": 1.7528,
      "step": 63400
    },
    {
      "epoch": 2.0304,
      "grad_norm": 0.4373025894165039,
      "learning_rate": 0.00011878528,
      "loss": 1.8052,
      "step": 63450
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.3040950894355774,
      "learning_rate": 0.00011872128,
      "loss": 1.747,
      "step": 63500
    },
    {
      "epoch": 2.0336,
      "grad_norm": 0.4483007490634918,
      "learning_rate": 0.00011865728,
      "loss": 1.7494,
      "step": 63550
    },
    {
      "epoch": 2.0352,
      "grad_norm": 0.3980253040790558,
      "learning_rate": 0.00011859328,
      "loss": 1.7265,
      "step": 63600
    },
    {
      "epoch": 2.0368,
      "grad_norm": 0.35800430178642273,
      "learning_rate": 0.00011852928000000001,
      "loss": 1.8066,
      "step": 63650
    },
    {
      "epoch": 2.0384,
      "grad_norm": 0.36807796359062195,
      "learning_rate": 0.00011846528000000002,
      "loss": 1.7726,
      "step": 63700
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.4447365701198578,
      "learning_rate": 0.00011840128000000001,
      "loss": 1.7501,
      "step": 63750
    },
    {
      "epoch": 2.0416,
      "grad_norm": 0.31578269600868225,
      "learning_rate": 0.00011833728,
      "loss": 1.7631,
      "step": 63800
    },
    {
      "epoch": 2.0432,
      "grad_norm": 0.36036252975463867,
      "learning_rate": 0.00011827328,
      "loss": 1.8444,
      "step": 63850
    },
    {
      "epoch": 2.0448,
      "grad_norm": 0.4076107144355774,
      "learning_rate": 0.00011820928,
      "loss": 1.7882,
      "step": 63900
    },
    {
      "epoch": 2.0464,
      "grad_norm": 0.44275784492492676,
      "learning_rate": 0.00011814528000000001,
      "loss": 1.7885,
      "step": 63950
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.4264393150806427,
      "learning_rate": 0.00011808128,
      "loss": 1.8036,
      "step": 64000
    },
    {
      "epoch": 2.0496,
      "grad_norm": 0.35691705346107483,
      "learning_rate": 0.00011801728000000001,
      "loss": 1.7994,
      "step": 64050
    },
    {
      "epoch": 2.0512,
      "grad_norm": 0.3544883728027344,
      "learning_rate": 0.00011795328,
      "loss": 1.8102,
      "step": 64100
    },
    {
      "epoch": 2.0528,
      "grad_norm": 0.3591892421245575,
      "learning_rate": 0.00011788928000000002,
      "loss": 1.7528,
      "step": 64150
    },
    {
      "epoch": 2.0544,
      "grad_norm": 0.337232768535614,
      "learning_rate": 0.00011782528000000001,
      "loss": 1.8215,
      "step": 64200
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.3314184844493866,
      "learning_rate": 0.00011776127999999999,
      "loss": 1.7434,
      "step": 64250
    },
    {
      "epoch": 2.0576,
      "grad_norm": 0.3309166133403778,
      "learning_rate": 0.00011769728,
      "loss": 1.7713,
      "step": 64300
    },
    {
      "epoch": 2.0592,
      "grad_norm": 0.3419507145881653,
      "learning_rate": 0.00011763328,
      "loss": 1.8272,
      "step": 64350
    },
    {
      "epoch": 2.0608,
      "grad_norm": 0.29748785495758057,
      "learning_rate": 0.00011756928,
      "loss": 1.7436,
      "step": 64400
    },
    {
      "epoch": 2.0624,
      "grad_norm": 0.3461412489414215,
      "learning_rate": 0.00011750528,
      "loss": 1.7956,
      "step": 64450
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.3183595836162567,
      "learning_rate": 0.00011744128000000001,
      "loss": 1.7495,
      "step": 64500
    },
    {
      "epoch": 2.0656,
      "grad_norm": 0.31884142756462097,
      "learning_rate": 0.00011737728000000002,
      "loss": 1.8003,
      "step": 64550
    },
    {
      "epoch": 2.0672,
      "grad_norm": 0.3533078730106354,
      "learning_rate": 0.00011731328000000001,
      "loss": 1.7849,
      "step": 64600
    },
    {
      "epoch": 2.0688,
      "grad_norm": 0.3571212887763977,
      "learning_rate": 0.00011724928,
      "loss": 1.7833,
      "step": 64650
    },
    {
      "epoch": 2.0704,
      "grad_norm": 0.33836057782173157,
      "learning_rate": 0.00011718528,
      "loss": 1.7737,
      "step": 64700
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.3936023414134979,
      "learning_rate": 0.00011712128,
      "loss": 1.8104,
      "step": 64750
    },
    {
      "epoch": 2.0736,
      "grad_norm": 0.2858947813510895,
      "learning_rate": 0.00011705728000000001,
      "loss": 1.8163,
      "step": 64800
    },
    {
      "epoch": 2.0752,
      "grad_norm": 0.35606706142425537,
      "learning_rate": 0.00011699328,
      "loss": 1.7347,
      "step": 64850
    },
    {
      "epoch": 2.0768,
      "grad_norm": 0.32423028349876404,
      "learning_rate": 0.00011692928000000001,
      "loss": 1.7601,
      "step": 64900
    },
    {
      "epoch": 2.0784,
      "grad_norm": 0.35539039969444275,
      "learning_rate": 0.00011686528,
      "loss": 1.7558,
      "step": 64950
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.3360976278781891,
      "learning_rate": 0.00011680128000000001,
      "loss": 1.7183,
      "step": 65000
    },
    {
      "epoch": 2.0816,
      "grad_norm": 0.37247586250305176,
      "learning_rate": 0.00011673728000000001,
      "loss": 1.7625,
      "step": 65050
    },
    {
      "epoch": 2.0832,
      "grad_norm": 0.32132288813591003,
      "learning_rate": 0.00011667327999999999,
      "loss": 1.7983,
      "step": 65100
    },
    {
      "epoch": 2.0848,
      "grad_norm": 0.3491019010543823,
      "learning_rate": 0.00011660928,
      "loss": 1.7506,
      "step": 65150
    },
    {
      "epoch": 2.0864,
      "grad_norm": 0.6678525805473328,
      "learning_rate": 0.00011654528,
      "loss": 1.7953,
      "step": 65200
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.37399065494537354,
      "learning_rate": 0.00011648128,
      "loss": 1.8244,
      "step": 65250
    },
    {
      "epoch": 2.0896,
      "grad_norm": 0.368939608335495,
      "learning_rate": 0.00011641728000000001,
      "loss": 1.7736,
      "step": 65300
    },
    {
      "epoch": 2.0912,
      "grad_norm": 0.37795084714889526,
      "learning_rate": 0.00011635328000000001,
      "loss": 1.8445,
      "step": 65350
    },
    {
      "epoch": 2.0928,
      "grad_norm": 0.2972967028617859,
      "learning_rate": 0.00011628928000000002,
      "loss": 1.724,
      "step": 65400
    },
    {
      "epoch": 2.0944,
      "grad_norm": 0.4311014711856842,
      "learning_rate": 0.00011622528000000001,
      "loss": 1.8149,
      "step": 65450
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.3116670846939087,
      "learning_rate": 0.00011616128,
      "loss": 1.7531,
      "step": 65500
    },
    {
      "epoch": 2.0976,
      "grad_norm": 0.3548980951309204,
      "learning_rate": 0.00011609728,
      "loss": 1.7675,
      "step": 65550
    },
    {
      "epoch": 2.0992,
      "grad_norm": 0.3162197470664978,
      "learning_rate": 0.00011603328,
      "loss": 1.7716,
      "step": 65600
    },
    {
      "epoch": 2.1008,
      "grad_norm": 0.33927473425865173,
      "learning_rate": 0.00011596928,
      "loss": 1.8166,
      "step": 65650
    },
    {
      "epoch": 2.1024,
      "grad_norm": 0.36589697003364563,
      "learning_rate": 0.00011590528,
      "loss": 1.8061,
      "step": 65700
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.3584336042404175,
      "learning_rate": 0.00011584128000000001,
      "loss": 1.7526,
      "step": 65750
    },
    {
      "epoch": 2.1056,
      "grad_norm": 0.2689482867717743,
      "learning_rate": 0.00011577728,
      "loss": 1.764,
      "step": 65800
    },
    {
      "epoch": 2.1072,
      "grad_norm": 0.337904155254364,
      "learning_rate": 0.00011571328000000001,
      "loss": 1.7723,
      "step": 65850
    },
    {
      "epoch": 2.1088,
      "grad_norm": 0.32341447472572327,
      "learning_rate": 0.00011564928000000001,
      "loss": 1.7847,
      "step": 65900
    },
    {
      "epoch": 2.1104,
      "grad_norm": 0.4077819585800171,
      "learning_rate": 0.00011558527999999999,
      "loss": 1.8056,
      "step": 65950
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.32748183608055115,
      "learning_rate": 0.00011552128,
      "loss": 1.8099,
      "step": 66000
    },
    {
      "epoch": 2.1136,
      "grad_norm": 0.32817351818084717,
      "learning_rate": 0.00011545728,
      "loss": 1.7758,
      "step": 66050
    },
    {
      "epoch": 2.1152,
      "grad_norm": 0.35471850633621216,
      "learning_rate": 0.00011539328,
      "loss": 1.8433,
      "step": 66100
    },
    {
      "epoch": 2.1168,
      "grad_norm": 0.330594003200531,
      "learning_rate": 0.00011532928000000001,
      "loss": 1.7737,
      "step": 66150
    },
    {
      "epoch": 2.1184,
      "grad_norm": 0.3804676830768585,
      "learning_rate": 0.00011526528000000001,
      "loss": 1.7303,
      "step": 66200
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.41556641459465027,
      "learning_rate": 0.00011520128000000002,
      "loss": 1.8523,
      "step": 66250
    },
    {
      "epoch": 2.1216,
      "grad_norm": 0.361579954624176,
      "learning_rate": 0.00011513728000000001,
      "loss": 1.7397,
      "step": 66300
    },
    {
      "epoch": 2.1232,
      "grad_norm": 0.3464890420436859,
      "learning_rate": 0.00011507328,
      "loss": 1.769,
      "step": 66350
    },
    {
      "epoch": 2.1248,
      "grad_norm": 0.34432944655418396,
      "learning_rate": 0.00011500928,
      "loss": 1.7986,
      "step": 66400
    },
    {
      "epoch": 2.1264,
      "grad_norm": 0.3522930443286896,
      "learning_rate": 0.00011494528,
      "loss": 1.7691,
      "step": 66450
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.39871445298194885,
      "learning_rate": 0.00011488128,
      "loss": 1.746,
      "step": 66500
    },
    {
      "epoch": 2.1296,
      "grad_norm": 0.3627643287181854,
      "learning_rate": 0.00011481728,
      "loss": 1.7538,
      "step": 66550
    },
    {
      "epoch": 2.1312,
      "grad_norm": 0.4386390149593353,
      "learning_rate": 0.00011475328000000001,
      "loss": 1.7236,
      "step": 66600
    },
    {
      "epoch": 2.1328,
      "grad_norm": 0.3982352018356323,
      "learning_rate": 0.00011468928,
      "loss": 1.7459,
      "step": 66650
    },
    {
      "epoch": 2.1344,
      "grad_norm": 0.32286131381988525,
      "learning_rate": 0.00011462528000000001,
      "loss": 1.8434,
      "step": 66700
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.32287535071372986,
      "learning_rate": 0.00011456128000000001,
      "loss": 1.792,
      "step": 66750
    },
    {
      "epoch": 2.1376,
      "grad_norm": 0.34995877742767334,
      "learning_rate": 0.00011449727999999999,
      "loss": 1.8078,
      "step": 66800
    },
    {
      "epoch": 2.1391999999999998,
      "grad_norm": 0.49688416719436646,
      "learning_rate": 0.00011443328,
      "loss": 1.7821,
      "step": 66850
    },
    {
      "epoch": 2.1408,
      "grad_norm": 0.31109490990638733,
      "learning_rate": 0.00011436928,
      "loss": 1.8138,
      "step": 66900
    },
    {
      "epoch": 2.1424,
      "grad_norm": 0.32572802901268005,
      "learning_rate": 0.00011430528,
      "loss": 1.7854,
      "step": 66950
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.3536951243877411,
      "learning_rate": 0.00011424128000000001,
      "loss": 1.7643,
      "step": 67000
    },
    {
      "epoch": 2.1456,
      "grad_norm": 0.29263079166412354,
      "learning_rate": 0.00011417728000000001,
      "loss": 1.8546,
      "step": 67050
    },
    {
      "epoch": 2.1471999999999998,
      "grad_norm": 0.33577585220336914,
      "learning_rate": 0.00011411328000000002,
      "loss": 1.8057,
      "step": 67100
    },
    {
      "epoch": 2.1488,
      "grad_norm": 0.4003257155418396,
      "learning_rate": 0.00011404928000000001,
      "loss": 1.7895,
      "step": 67150
    },
    {
      "epoch": 2.1504,
      "grad_norm": 0.344823956489563,
      "learning_rate": 0.00011398528000000002,
      "loss": 1.7872,
      "step": 67200
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.34580764174461365,
      "learning_rate": 0.00011392128,
      "loss": 1.7903,
      "step": 67250
    },
    {
      "epoch": 2.1536,
      "grad_norm": 0.321961909532547,
      "learning_rate": 0.00011385728,
      "loss": 1.801,
      "step": 67300
    },
    {
      "epoch": 2.1552,
      "grad_norm": 0.3502330780029297,
      "learning_rate": 0.00011379328,
      "loss": 1.7946,
      "step": 67350
    },
    {
      "epoch": 2.1568,
      "grad_norm": 0.3589295446872711,
      "learning_rate": 0.00011372928,
      "loss": 1.8126,
      "step": 67400
    },
    {
      "epoch": 2.1584,
      "grad_norm": 0.47480061650276184,
      "learning_rate": 0.00011366528000000001,
      "loss": 1.8178,
      "step": 67450
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.34883958101272583,
      "learning_rate": 0.00011360128,
      "loss": 1.8179,
      "step": 67500
    },
    {
      "epoch": 2.1616,
      "grad_norm": 0.387673020362854,
      "learning_rate": 0.00011353728000000001,
      "loss": 1.8104,
      "step": 67550
    },
    {
      "epoch": 2.1632,
      "grad_norm": 0.4255150556564331,
      "learning_rate": 0.00011347328000000001,
      "loss": 1.8229,
      "step": 67600
    },
    {
      "epoch": 2.1648,
      "grad_norm": 0.3508225977420807,
      "learning_rate": 0.00011340927999999999,
      "loss": 1.7932,
      "step": 67650
    },
    {
      "epoch": 2.1664,
      "grad_norm": 0.36025330424308777,
      "learning_rate": 0.00011334528,
      "loss": 1.806,
      "step": 67700
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.32860445976257324,
      "learning_rate": 0.00011328128,
      "loss": 1.7584,
      "step": 67750
    },
    {
      "epoch": 2.1696,
      "grad_norm": 0.3464173376560211,
      "learning_rate": 0.00011321728,
      "loss": 1.7847,
      "step": 67800
    },
    {
      "epoch": 2.1712,
      "grad_norm": 0.33436664938926697,
      "learning_rate": 0.00011315328000000001,
      "loss": 1.8076,
      "step": 67850
    },
    {
      "epoch": 2.1728,
      "grad_norm": 0.3321721851825714,
      "learning_rate": 0.00011308928000000001,
      "loss": 1.7917,
      "step": 67900
    },
    {
      "epoch": 2.1744,
      "grad_norm": 0.34950003027915955,
      "learning_rate": 0.00011302528000000002,
      "loss": 1.7462,
      "step": 67950
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.38727498054504395,
      "learning_rate": 0.00011296128000000001,
      "loss": 1.8068,
      "step": 68000
    },
    {
      "epoch": 2.1776,
      "grad_norm": 0.3359071910381317,
      "learning_rate": 0.00011289728000000002,
      "loss": 1.8157,
      "step": 68050
    },
    {
      "epoch": 2.1792,
      "grad_norm": 0.3792842924594879,
      "learning_rate": 0.00011283328,
      "loss": 1.7525,
      "step": 68100
    },
    {
      "epoch": 2.1808,
      "grad_norm": 0.3884830176830292,
      "learning_rate": 0.00011276928,
      "loss": 1.7773,
      "step": 68150
    },
    {
      "epoch": 2.1824,
      "grad_norm": 0.2661954164505005,
      "learning_rate": 0.00011270528,
      "loss": 1.7263,
      "step": 68200
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.32077547907829285,
      "learning_rate": 0.00011264128,
      "loss": 1.7962,
      "step": 68250
    },
    {
      "epoch": 2.1856,
      "grad_norm": 0.38043928146362305,
      "learning_rate": 0.00011257728000000001,
      "loss": 1.7723,
      "step": 68300
    },
    {
      "epoch": 2.1872,
      "grad_norm": 0.38160642981529236,
      "learning_rate": 0.00011251328,
      "loss": 1.8005,
      "step": 68350
    },
    {
      "epoch": 2.1888,
      "grad_norm": 0.37435173988342285,
      "learning_rate": 0.00011244928000000001,
      "loss": 1.8056,
      "step": 68400
    },
    {
      "epoch": 2.1904,
      "grad_norm": 0.3368656039237976,
      "learning_rate": 0.00011238528000000001,
      "loss": 1.7852,
      "step": 68450
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.386870414018631,
      "learning_rate": 0.00011232127999999999,
      "loss": 1.807,
      "step": 68500
    },
    {
      "epoch": 2.1936,
      "grad_norm": 0.4048953354358673,
      "learning_rate": 0.00011225728,
      "loss": 1.7621,
      "step": 68550
    },
    {
      "epoch": 2.1952,
      "grad_norm": 0.40057361125946045,
      "learning_rate": 0.00011219328,
      "loss": 1.7849,
      "step": 68600
    },
    {
      "epoch": 2.1968,
      "grad_norm": 0.34469571709632874,
      "learning_rate": 0.00011212928,
      "loss": 1.7956,
      "step": 68650
    },
    {
      "epoch": 2.1984,
      "grad_norm": 0.3213149309158325,
      "learning_rate": 0.00011206528000000001,
      "loss": 1.7618,
      "step": 68700
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.34642693400382996,
      "learning_rate": 0.00011200128,
      "loss": 1.835,
      "step": 68750
    },
    {
      "epoch": 2.2016,
      "grad_norm": 0.36465927958488464,
      "learning_rate": 0.00011193728000000002,
      "loss": 1.7813,
      "step": 68800
    },
    {
      "epoch": 2.2032,
      "grad_norm": 0.3154442310333252,
      "learning_rate": 0.00011187328000000001,
      "loss": 1.8269,
      "step": 68850
    },
    {
      "epoch": 2.2048,
      "grad_norm": 0.4106734097003937,
      "learning_rate": 0.00011180928000000002,
      "loss": 1.7527,
      "step": 68900
    },
    {
      "epoch": 2.2064,
      "grad_norm": 0.33668458461761475,
      "learning_rate": 0.00011174528,
      "loss": 1.8032,
      "step": 68950
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.3928300142288208,
      "learning_rate": 0.00011168128,
      "loss": 1.8152,
      "step": 69000
    },
    {
      "epoch": 2.2096,
      "grad_norm": 0.3742513656616211,
      "learning_rate": 0.00011161728,
      "loss": 1.8213,
      "step": 69050
    },
    {
      "epoch": 2.2112,
      "grad_norm": 0.31619793176651,
      "learning_rate": 0.00011155328,
      "loss": 1.7531,
      "step": 69100
    },
    {
      "epoch": 2.2128,
      "grad_norm": 0.32924744486808777,
      "learning_rate": 0.00011148928000000001,
      "loss": 1.7852,
      "step": 69150
    },
    {
      "epoch": 2.2144,
      "grad_norm": 0.3414762020111084,
      "learning_rate": 0.00011142528,
      "loss": 1.7774,
      "step": 69200
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.4311501979827881,
      "learning_rate": 0.00011136128000000001,
      "loss": 1.7734,
      "step": 69250
    },
    {
      "epoch": 2.2176,
      "grad_norm": 0.5324387550354004,
      "learning_rate": 0.00011129728000000002,
      "loss": 1.7551,
      "step": 69300
    },
    {
      "epoch": 2.2192,
      "grad_norm": 0.40622013807296753,
      "learning_rate": 0.00011123327999999999,
      "loss": 1.7196,
      "step": 69350
    },
    {
      "epoch": 2.2208,
      "grad_norm": 0.35346895456314087,
      "learning_rate": 0.00011116928,
      "loss": 1.7882,
      "step": 69400
    },
    {
      "epoch": 2.2224,
      "grad_norm": 0.4049971103668213,
      "learning_rate": 0.00011110528000000001,
      "loss": 1.7802,
      "step": 69450
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.35331812500953674,
      "learning_rate": 0.00011104128,
      "loss": 1.8261,
      "step": 69500
    },
    {
      "epoch": 2.2256,
      "grad_norm": 0.4374102056026459,
      "learning_rate": 0.00011097728000000001,
      "loss": 1.7638,
      "step": 69550
    },
    {
      "epoch": 2.2272,
      "grad_norm": 0.3348886966705322,
      "learning_rate": 0.00011091328,
      "loss": 1.7552,
      "step": 69600
    },
    {
      "epoch": 2.2288,
      "grad_norm": 0.30991482734680176,
      "learning_rate": 0.00011084928000000001,
      "loss": 1.7984,
      "step": 69650
    },
    {
      "epoch": 2.2304,
      "grad_norm": 0.3367389738559723,
      "learning_rate": 0.00011078528000000001,
      "loss": 1.8047,
      "step": 69700
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.28336596488952637,
      "learning_rate": 0.00011072128000000002,
      "loss": 1.8376,
      "step": 69750
    },
    {
      "epoch": 2.2336,
      "grad_norm": 0.3717215657234192,
      "learning_rate": 0.00011065728,
      "loss": 1.8068,
      "step": 69800
    },
    {
      "epoch": 2.2352,
      "grad_norm": 0.34234243631362915,
      "learning_rate": 0.00011059328,
      "loss": 1.8128,
      "step": 69850
    },
    {
      "epoch": 2.2368,
      "grad_norm": 0.3737369477748871,
      "learning_rate": 0.00011052928,
      "loss": 1.7743,
      "step": 69900
    },
    {
      "epoch": 2.2384,
      "grad_norm": 0.3593405485153198,
      "learning_rate": 0.00011046528,
      "loss": 1.7664,
      "step": 69950
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3689412772655487,
      "learning_rate": 0.00011040128000000001,
      "loss": 1.8208,
      "step": 70000
    },
    {
      "epoch": 2.2416,
      "grad_norm": 0.3286409080028534,
      "learning_rate": 0.00011033728,
      "loss": 1.7276,
      "step": 70050
    },
    {
      "epoch": 2.2432,
      "grad_norm": 0.32566627860069275,
      "learning_rate": 0.00011027328000000001,
      "loss": 1.7537,
      "step": 70100
    },
    {
      "epoch": 2.2448,
      "grad_norm": 0.34471097588539124,
      "learning_rate": 0.00011020928000000002,
      "loss": 1.731,
      "step": 70150
    },
    {
      "epoch": 2.2464,
      "grad_norm": 0.3579307496547699,
      "learning_rate": 0.00011014527999999999,
      "loss": 1.7932,
      "step": 70200
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.3711377680301666,
      "learning_rate": 0.00011008128,
      "loss": 1.7816,
      "step": 70250
    },
    {
      "epoch": 2.2496,
      "grad_norm": 0.42509961128234863,
      "learning_rate": 0.00011001728,
      "loss": 1.757,
      "step": 70300
    },
    {
      "epoch": 2.2512,
      "grad_norm": 0.3349001109600067,
      "learning_rate": 0.00010995328,
      "loss": 1.8,
      "step": 70350
    },
    {
      "epoch": 2.2528,
      "grad_norm": 0.34491947293281555,
      "learning_rate": 0.00010988928000000001,
      "loss": 1.782,
      "step": 70400
    },
    {
      "epoch": 2.2544,
      "grad_norm": 0.3519386053085327,
      "learning_rate": 0.00010982528,
      "loss": 1.8098,
      "step": 70450
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.2933812737464905,
      "learning_rate": 0.00010976128000000001,
      "loss": 1.7603,
      "step": 70500
    },
    {
      "epoch": 2.2576,
      "grad_norm": 0.3459121286869049,
      "learning_rate": 0.00010969728000000001,
      "loss": 1.7947,
      "step": 70550
    },
    {
      "epoch": 2.2592,
      "grad_norm": 0.3295935094356537,
      "learning_rate": 0.00010963328000000002,
      "loss": 1.8346,
      "step": 70600
    },
    {
      "epoch": 2.2608,
      "grad_norm": 0.3931347131729126,
      "learning_rate": 0.00010956928,
      "loss": 1.7995,
      "step": 70650
    },
    {
      "epoch": 2.2624,
      "grad_norm": 0.3605232834815979,
      "learning_rate": 0.00010950528,
      "loss": 1.7979,
      "step": 70700
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.37148451805114746,
      "learning_rate": 0.00010944128,
      "loss": 1.8155,
      "step": 70750
    },
    {
      "epoch": 2.2656,
      "grad_norm": 0.4022546112537384,
      "learning_rate": 0.00010937728,
      "loss": 1.7976,
      "step": 70800
    },
    {
      "epoch": 2.2672,
      "grad_norm": 0.41604647040367126,
      "learning_rate": 0.00010931328000000001,
      "loss": 1.7768,
      "step": 70850
    },
    {
      "epoch": 2.2688,
      "grad_norm": 0.3440415859222412,
      "learning_rate": 0.00010924928,
      "loss": 1.7635,
      "step": 70900
    },
    {
      "epoch": 2.2704,
      "grad_norm": 0.3969484865665436,
      "learning_rate": 0.00010918528000000001,
      "loss": 1.7805,
      "step": 70950
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.3660550117492676,
      "learning_rate": 0.00010912128000000002,
      "loss": 1.8133,
      "step": 71000
    },
    {
      "epoch": 2.2736,
      "grad_norm": 0.34080514311790466,
      "learning_rate": 0.00010905727999999999,
      "loss": 1.7988,
      "step": 71050
    },
    {
      "epoch": 2.2752,
      "grad_norm": 0.3819122612476349,
      "learning_rate": 0.00010899328,
      "loss": 1.8024,
      "step": 71100
    },
    {
      "epoch": 2.2768,
      "grad_norm": 0.3917717933654785,
      "learning_rate": 0.00010892928,
      "loss": 1.8301,
      "step": 71150
    },
    {
      "epoch": 2.2784,
      "grad_norm": 0.3449100852012634,
      "learning_rate": 0.00010886528,
      "loss": 1.7526,
      "step": 71200
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.48795849084854126,
      "learning_rate": 0.00010880128000000001,
      "loss": 1.744,
      "step": 71250
    },
    {
      "epoch": 2.2816,
      "grad_norm": 0.39261773228645325,
      "learning_rate": 0.00010873728,
      "loss": 1.8583,
      "step": 71300
    },
    {
      "epoch": 2.2832,
      "grad_norm": 0.3853922486305237,
      "learning_rate": 0.00010867328000000001,
      "loss": 1.7831,
      "step": 71350
    },
    {
      "epoch": 2.2848,
      "grad_norm": 0.3808620274066925,
      "learning_rate": 0.00010860928000000001,
      "loss": 1.802,
      "step": 71400
    },
    {
      "epoch": 2.2864,
      "grad_norm": 0.33058109879493713,
      "learning_rate": 0.00010854528000000002,
      "loss": 1.8079,
      "step": 71450
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.2833913266658783,
      "learning_rate": 0.00010848128,
      "loss": 1.8125,
      "step": 71500
    },
    {
      "epoch": 2.2896,
      "grad_norm": 0.3353569507598877,
      "learning_rate": 0.00010841728,
      "loss": 1.7393,
      "step": 71550
    },
    {
      "epoch": 2.2912,
      "grad_norm": 0.36504819989204407,
      "learning_rate": 0.00010835328,
      "loss": 1.785,
      "step": 71600
    },
    {
      "epoch": 2.2928,
      "grad_norm": 0.31936758756637573,
      "learning_rate": 0.00010828928,
      "loss": 1.7411,
      "step": 71650
    },
    {
      "epoch": 2.2944,
      "grad_norm": 0.3383426070213318,
      "learning_rate": 0.00010822528000000001,
      "loss": 1.8033,
      "step": 71700
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.38204526901245117,
      "learning_rate": 0.00010816128,
      "loss": 1.7437,
      "step": 71750
    },
    {
      "epoch": 2.2976,
      "grad_norm": 0.43531104922294617,
      "learning_rate": 0.00010809728000000001,
      "loss": 1.7781,
      "step": 71800
    },
    {
      "epoch": 2.2992,
      "grad_norm": 0.37583521008491516,
      "learning_rate": 0.00010803328000000002,
      "loss": 1.7593,
      "step": 71850
    },
    {
      "epoch": 2.3008,
      "grad_norm": 0.45284947752952576,
      "learning_rate": 0.00010796927999999999,
      "loss": 1.7838,
      "step": 71900
    },
    {
      "epoch": 2.3024,
      "grad_norm": 0.34860071539878845,
      "learning_rate": 0.00010790528,
      "loss": 1.8125,
      "step": 71950
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.31284698843955994,
      "learning_rate": 0.00010784128,
      "loss": 1.8367,
      "step": 72000
    },
    {
      "epoch": 2.3056,
      "grad_norm": 0.42527061700820923,
      "learning_rate": 0.00010777728,
      "loss": 1.7536,
      "step": 72050
    },
    {
      "epoch": 2.3072,
      "grad_norm": 0.40978023409843445,
      "learning_rate": 0.00010771328000000001,
      "loss": 1.7583,
      "step": 72100
    },
    {
      "epoch": 2.3088,
      "grad_norm": 0.3767531216144562,
      "learning_rate": 0.00010764928,
      "loss": 1.7382,
      "step": 72150
    },
    {
      "epoch": 2.3104,
      "grad_norm": 0.32369667291641235,
      "learning_rate": 0.00010758528000000001,
      "loss": 1.8163,
      "step": 72200
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.3745459318161011,
      "learning_rate": 0.00010752128000000001,
      "loss": 1.7418,
      "step": 72250
    },
    {
      "epoch": 2.3136,
      "grad_norm": 0.34581857919692993,
      "learning_rate": 0.00010745728000000002,
      "loss": 1.8095,
      "step": 72300
    },
    {
      "epoch": 2.3152,
      "grad_norm": 0.3897128999233246,
      "learning_rate": 0.00010739328,
      "loss": 1.7535,
      "step": 72350
    },
    {
      "epoch": 2.3168,
      "grad_norm": 0.3324000835418701,
      "learning_rate": 0.00010732928,
      "loss": 1.7956,
      "step": 72400
    },
    {
      "epoch": 2.3184,
      "grad_norm": 0.35778066515922546,
      "learning_rate": 0.00010726528,
      "loss": 1.7886,
      "step": 72450
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.31951579451560974,
      "learning_rate": 0.00010720128,
      "loss": 1.7517,
      "step": 72500
    },
    {
      "epoch": 2.3216,
      "grad_norm": 0.39087915420532227,
      "learning_rate": 0.00010713728000000001,
      "loss": 1.781,
      "step": 72550
    },
    {
      "epoch": 2.3232,
      "grad_norm": 0.3912598192691803,
      "learning_rate": 0.00010707328000000002,
      "loss": 1.8363,
      "step": 72600
    },
    {
      "epoch": 2.3247999999999998,
      "grad_norm": 0.387633740901947,
      "learning_rate": 0.00010700928000000001,
      "loss": 1.7828,
      "step": 72650
    },
    {
      "epoch": 2.3264,
      "grad_norm": 0.3434440493583679,
      "learning_rate": 0.00010694528000000002,
      "loss": 1.7674,
      "step": 72700
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.35165005922317505,
      "learning_rate": 0.00010688128,
      "loss": 1.7928,
      "step": 72750
    },
    {
      "epoch": 2.3296,
      "grad_norm": 0.3729408383369446,
      "learning_rate": 0.00010681728,
      "loss": 1.807,
      "step": 72800
    },
    {
      "epoch": 2.3312,
      "grad_norm": 0.3689764738082886,
      "learning_rate": 0.00010675328,
      "loss": 1.75,
      "step": 72850
    },
    {
      "epoch": 2.3327999999999998,
      "grad_norm": 0.36128610372543335,
      "learning_rate": 0.00010668928,
      "loss": 1.765,
      "step": 72900
    },
    {
      "epoch": 2.3344,
      "grad_norm": 0.30061623454093933,
      "learning_rate": 0.00010662528000000001,
      "loss": 1.8386,
      "step": 72950
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.4440901577472687,
      "learning_rate": 0.00010656128,
      "loss": 1.8051,
      "step": 73000
    },
    {
      "epoch": 2.3376,
      "grad_norm": 0.3691575825214386,
      "learning_rate": 0.00010649728000000001,
      "loss": 1.771,
      "step": 73050
    },
    {
      "epoch": 2.3392,
      "grad_norm": 0.350958913564682,
      "learning_rate": 0.00010643328000000001,
      "loss": 1.762,
      "step": 73100
    },
    {
      "epoch": 2.3407999999999998,
      "grad_norm": 0.37475332617759705,
      "learning_rate": 0.00010636928000000002,
      "loss": 1.8279,
      "step": 73150
    },
    {
      "epoch": 2.3424,
      "grad_norm": 0.37972360849380493,
      "learning_rate": 0.00010630528,
      "loss": 1.7391,
      "step": 73200
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.3498727083206177,
      "learning_rate": 0.00010624128,
      "loss": 1.7824,
      "step": 73250
    },
    {
      "epoch": 2.3456,
      "grad_norm": 0.4719019830226898,
      "learning_rate": 0.00010617728,
      "loss": 1.8318,
      "step": 73300
    },
    {
      "epoch": 2.3472,
      "grad_norm": 0.41803231835365295,
      "learning_rate": 0.00010611328,
      "loss": 1.7799,
      "step": 73350
    },
    {
      "epoch": 2.3487999999999998,
      "grad_norm": 0.4273277223110199,
      "learning_rate": 0.00010604928,
      "loss": 1.8097,
      "step": 73400
    },
    {
      "epoch": 2.3504,
      "grad_norm": 0.3649027645587921,
      "learning_rate": 0.00010598528000000002,
      "loss": 1.7746,
      "step": 73450
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.3702107071876526,
      "learning_rate": 0.00010592128000000001,
      "loss": 1.7388,
      "step": 73500
    },
    {
      "epoch": 2.3536,
      "grad_norm": 0.3965601623058319,
      "learning_rate": 0.00010585728000000002,
      "loss": 1.7527,
      "step": 73550
    },
    {
      "epoch": 2.3552,
      "grad_norm": 0.34353765845298767,
      "learning_rate": 0.00010579328,
      "loss": 1.7567,
      "step": 73600
    },
    {
      "epoch": 2.3568,
      "grad_norm": 0.36712148785591125,
      "learning_rate": 0.00010572928,
      "loss": 1.7678,
      "step": 73650
    },
    {
      "epoch": 2.3584,
      "grad_norm": 0.36602577567100525,
      "learning_rate": 0.00010566528,
      "loss": 1.8406,
      "step": 73700
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.3886759281158447,
      "learning_rate": 0.00010560128,
      "loss": 1.8005,
      "step": 73750
    },
    {
      "epoch": 2.3616,
      "grad_norm": 0.38925373554229736,
      "learning_rate": 0.00010553728000000001,
      "loss": 1.7824,
      "step": 73800
    },
    {
      "epoch": 2.3632,
      "grad_norm": 0.3343324065208435,
      "learning_rate": 0.00010547328,
      "loss": 1.7615,
      "step": 73850
    },
    {
      "epoch": 2.3648,
      "grad_norm": 0.33660265803337097,
      "learning_rate": 0.00010540928000000001,
      "loss": 1.8126,
      "step": 73900
    },
    {
      "epoch": 2.3664,
      "grad_norm": 0.34255024790763855,
      "learning_rate": 0.00010534528000000001,
      "loss": 1.763,
      "step": 73950
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.3316672444343567,
      "learning_rate": 0.00010528128000000002,
      "loss": 1.7928,
      "step": 74000
    },
    {
      "epoch": 2.3696,
      "grad_norm": 0.3841872215270996,
      "learning_rate": 0.00010521728,
      "loss": 1.7864,
      "step": 74050
    },
    {
      "epoch": 2.3712,
      "grad_norm": 0.3767967224121094,
      "learning_rate": 0.00010515328,
      "loss": 1.8068,
      "step": 74100
    },
    {
      "epoch": 2.3728,
      "grad_norm": 0.3879462778568268,
      "learning_rate": 0.00010508928,
      "loss": 1.7827,
      "step": 74150
    },
    {
      "epoch": 2.3744,
      "grad_norm": 0.32897835969924927,
      "learning_rate": 0.00010502528,
      "loss": 1.7927,
      "step": 74200
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.40055590867996216,
      "learning_rate": 0.00010496128,
      "loss": 1.8233,
      "step": 74250
    },
    {
      "epoch": 2.3776,
      "grad_norm": 0.42196616530418396,
      "learning_rate": 0.00010489728000000001,
      "loss": 1.8057,
      "step": 74300
    },
    {
      "epoch": 2.3792,
      "grad_norm": 0.3930339217185974,
      "learning_rate": 0.00010483328000000001,
      "loss": 1.7568,
      "step": 74350
    },
    {
      "epoch": 2.3808,
      "grad_norm": 0.37195491790771484,
      "learning_rate": 0.00010476928000000002,
      "loss": 1.7692,
      "step": 74400
    },
    {
      "epoch": 2.3824,
      "grad_norm": 0.42973214387893677,
      "learning_rate": 0.00010470528,
      "loss": 1.8064,
      "step": 74450
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.35973232984542847,
      "learning_rate": 0.00010464128,
      "loss": 1.7983,
      "step": 74500
    },
    {
      "epoch": 2.3856,
      "grad_norm": 0.3600378930568695,
      "learning_rate": 0.00010457728,
      "loss": 1.7993,
      "step": 74550
    },
    {
      "epoch": 2.3872,
      "grad_norm": 0.3550225794315338,
      "learning_rate": 0.00010451328,
      "loss": 1.7537,
      "step": 74600
    },
    {
      "epoch": 2.3888,
      "grad_norm": 0.3734232485294342,
      "learning_rate": 0.00010444928000000001,
      "loss": 1.7633,
      "step": 74650
    },
    {
      "epoch": 2.3904,
      "grad_norm": 0.2943480908870697,
      "learning_rate": 0.00010438528,
      "loss": 1.7932,
      "step": 74700
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.42549553513526917,
      "learning_rate": 0.00010432128000000001,
      "loss": 1.7867,
      "step": 74750
    },
    {
      "epoch": 2.3936,
      "grad_norm": 0.35768017172813416,
      "learning_rate": 0.00010425728000000001,
      "loss": 1.7766,
      "step": 74800
    },
    {
      "epoch": 2.3952,
      "grad_norm": 0.31255078315734863,
      "learning_rate": 0.00010419328000000002,
      "loss": 1.8583,
      "step": 74850
    },
    {
      "epoch": 2.3968,
      "grad_norm": 0.3225296437740326,
      "learning_rate": 0.00010412928,
      "loss": 1.7779,
      "step": 74900
    },
    {
      "epoch": 2.3984,
      "grad_norm": 0.32868364453315735,
      "learning_rate": 0.00010406527999999999,
      "loss": 1.7436,
      "step": 74950
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.3661361038684845,
      "learning_rate": 0.00010400128,
      "loss": 1.7998,
      "step": 75000
    },
    {
      "epoch": 2.4016,
      "grad_norm": 0.3329313099384308,
      "learning_rate": 0.00010393728,
      "loss": 1.7865,
      "step": 75050
    },
    {
      "epoch": 2.4032,
      "grad_norm": 0.31592485308647156,
      "learning_rate": 0.00010387328,
      "loss": 1.7391,
      "step": 75100
    },
    {
      "epoch": 2.4048,
      "grad_norm": 0.39931464195251465,
      "learning_rate": 0.00010380928000000001,
      "loss": 1.7621,
      "step": 75150
    },
    {
      "epoch": 2.4064,
      "grad_norm": 0.338186651468277,
      "learning_rate": 0.00010374528000000001,
      "loss": 1.7389,
      "step": 75200
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.3623238801956177,
      "learning_rate": 0.00010368128000000002,
      "loss": 1.7242,
      "step": 75250
    },
    {
      "epoch": 2.4096,
      "grad_norm": 0.36757251620292664,
      "learning_rate": 0.00010361728,
      "loss": 1.7845,
      "step": 75300
    },
    {
      "epoch": 2.4112,
      "grad_norm": 0.47276321053504944,
      "learning_rate": 0.00010355328,
      "loss": 1.7877,
      "step": 75350
    },
    {
      "epoch": 2.4128,
      "grad_norm": 0.3439908027648926,
      "learning_rate": 0.00010348928,
      "loss": 1.7655,
      "step": 75400
    },
    {
      "epoch": 2.4144,
      "grad_norm": 0.35871651768684387,
      "learning_rate": 0.00010342528,
      "loss": 1.7883,
      "step": 75450
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.35880041122436523,
      "learning_rate": 0.00010336128000000001,
      "loss": 1.8209,
      "step": 75500
    },
    {
      "epoch": 2.4176,
      "grad_norm": 0.3403953015804291,
      "learning_rate": 0.00010329728,
      "loss": 1.7506,
      "step": 75550
    },
    {
      "epoch": 2.4192,
      "grad_norm": 0.35193467140197754,
      "learning_rate": 0.00010323328000000001,
      "loss": 1.8111,
      "step": 75600
    },
    {
      "epoch": 2.4208,
      "grad_norm": 0.3411485254764557,
      "learning_rate": 0.00010316928000000001,
      "loss": 1.8077,
      "step": 75650
    },
    {
      "epoch": 2.4224,
      "grad_norm": 0.3923007547855377,
      "learning_rate": 0.00010310528000000002,
      "loss": 1.7501,
      "step": 75700
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.4666690528392792,
      "learning_rate": 0.00010304128,
      "loss": 1.7912,
      "step": 75750
    },
    {
      "epoch": 2.4256,
      "grad_norm": 0.3182010054588318,
      "learning_rate": 0.00010297727999999999,
      "loss": 1.8151,
      "step": 75800
    },
    {
      "epoch": 2.4272,
      "grad_norm": 0.39617547392845154,
      "learning_rate": 0.00010291328,
      "loss": 1.7635,
      "step": 75850
    },
    {
      "epoch": 2.4288,
      "grad_norm": 0.4530453383922577,
      "learning_rate": 0.00010284928000000001,
      "loss": 1.7602,
      "step": 75900
    },
    {
      "epoch": 2.4304,
      "grad_norm": 0.2970145046710968,
      "learning_rate": 0.00010278528,
      "loss": 1.7666,
      "step": 75950
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.3680613338947296,
      "learning_rate": 0.00010272128000000001,
      "loss": 1.7012,
      "step": 76000
    },
    {
      "epoch": 2.4336,
      "grad_norm": 0.3544616103172302,
      "learning_rate": 0.00010265728000000001,
      "loss": 1.7675,
      "step": 76050
    },
    {
      "epoch": 2.4352,
      "grad_norm": 0.3501278758049011,
      "learning_rate": 0.00010259328000000002,
      "loss": 1.7715,
      "step": 76100
    },
    {
      "epoch": 2.4368,
      "grad_norm": 0.3425305485725403,
      "learning_rate": 0.00010252928,
      "loss": 1.7614,
      "step": 76150
    },
    {
      "epoch": 2.4384,
      "grad_norm": 0.38998278975486755,
      "learning_rate": 0.00010246528,
      "loss": 1.7811,
      "step": 76200
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.3178989589214325,
      "learning_rate": 0.00010240128,
      "loss": 1.7403,
      "step": 76250
    },
    {
      "epoch": 2.4416,
      "grad_norm": 0.30773138999938965,
      "learning_rate": 0.00010233728,
      "loss": 1.7901,
      "step": 76300
    },
    {
      "epoch": 2.4432,
      "grad_norm": 0.362139493227005,
      "learning_rate": 0.00010227328000000001,
      "loss": 1.7638,
      "step": 76350
    },
    {
      "epoch": 2.4448,
      "grad_norm": 0.32295578718185425,
      "learning_rate": 0.00010220928,
      "loss": 1.7604,
      "step": 76400
    },
    {
      "epoch": 2.4464,
      "grad_norm": 0.34421229362487793,
      "learning_rate": 0.00010214528000000001,
      "loss": 1.7867,
      "step": 76450
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.4039080739021301,
      "learning_rate": 0.00010208128,
      "loss": 1.7598,
      "step": 76500
    },
    {
      "epoch": 2.4496,
      "grad_norm": 0.3488506078720093,
      "learning_rate": 0.00010201728000000002,
      "loss": 1.8154,
      "step": 76550
    },
    {
      "epoch": 2.4512,
      "grad_norm": 0.345414400100708,
      "learning_rate": 0.00010195328,
      "loss": 1.8234,
      "step": 76600
    },
    {
      "epoch": 2.4528,
      "grad_norm": 0.28580939769744873,
      "learning_rate": 0.00010188927999999999,
      "loss": 1.7996,
      "step": 76650
    },
    {
      "epoch": 2.4544,
      "grad_norm": 0.36894869804382324,
      "learning_rate": 0.00010182528,
      "loss": 1.8092,
      "step": 76700
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.37918052077293396,
      "learning_rate": 0.00010176128000000001,
      "loss": 1.7744,
      "step": 76750
    },
    {
      "epoch": 2.4576000000000002,
      "grad_norm": 0.3357853293418884,
      "learning_rate": 0.00010169728,
      "loss": 1.7439,
      "step": 76800
    },
    {
      "epoch": 2.4592,
      "grad_norm": 0.3827213943004608,
      "learning_rate": 0.00010163328000000001,
      "loss": 1.767,
      "step": 76850
    },
    {
      "epoch": 2.4608,
      "grad_norm": 0.3672788441181183,
      "learning_rate": 0.00010156928000000001,
      "loss": 1.7844,
      "step": 76900
    },
    {
      "epoch": 2.4624,
      "grad_norm": 0.3758030831813812,
      "learning_rate": 0.00010150528000000002,
      "loss": 1.8061,
      "step": 76950
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.37864047288894653,
      "learning_rate": 0.00010144128,
      "loss": 1.754,
      "step": 77000
    },
    {
      "epoch": 2.4656000000000002,
      "grad_norm": 0.3350575268268585,
      "learning_rate": 0.00010137728,
      "loss": 1.7887,
      "step": 77050
    },
    {
      "epoch": 2.4672,
      "grad_norm": 0.4236050546169281,
      "learning_rate": 0.00010131328,
      "loss": 1.8035,
      "step": 77100
    },
    {
      "epoch": 2.4688,
      "grad_norm": 0.42566734552383423,
      "learning_rate": 0.00010124928,
      "loss": 1.735,
      "step": 77150
    },
    {
      "epoch": 2.4704,
      "grad_norm": 0.38727355003356934,
      "learning_rate": 0.00010118528000000001,
      "loss": 1.7563,
      "step": 77200
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.33579862117767334,
      "learning_rate": 0.00010112128,
      "loss": 1.8246,
      "step": 77250
    },
    {
      "epoch": 2.4736000000000002,
      "grad_norm": 0.3758450448513031,
      "learning_rate": 0.00010105728000000001,
      "loss": 1.801,
      "step": 77300
    },
    {
      "epoch": 2.4752,
      "grad_norm": 0.3420323133468628,
      "learning_rate": 0.00010099328,
      "loss": 1.8396,
      "step": 77350
    },
    {
      "epoch": 2.4768,
      "grad_norm": 0.34562402963638306,
      "learning_rate": 0.00010092928000000001,
      "loss": 1.784,
      "step": 77400
    },
    {
      "epoch": 2.4784,
      "grad_norm": 0.343774676322937,
      "learning_rate": 0.00010086528,
      "loss": 1.7375,
      "step": 77450
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.40329328179359436,
      "learning_rate": 0.00010080127999999999,
      "loss": 1.7277,
      "step": 77500
    },
    {
      "epoch": 2.4816,
      "grad_norm": 0.405889630317688,
      "learning_rate": 0.00010073728,
      "loss": 1.7866,
      "step": 77550
    },
    {
      "epoch": 2.4832,
      "grad_norm": 0.3794993758201599,
      "learning_rate": 0.00010067328000000001,
      "loss": 1.8184,
      "step": 77600
    },
    {
      "epoch": 2.4848,
      "grad_norm": 0.36746278405189514,
      "learning_rate": 0.00010060928,
      "loss": 1.7753,
      "step": 77650
    },
    {
      "epoch": 2.4864,
      "grad_norm": 0.46660682559013367,
      "learning_rate": 0.00010054528000000001,
      "loss": 1.8119,
      "step": 77700
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.3192962110042572,
      "learning_rate": 0.00010048128000000001,
      "loss": 1.7629,
      "step": 77750
    },
    {
      "epoch": 2.4896,
      "grad_norm": 0.3682147264480591,
      "learning_rate": 0.00010041728000000002,
      "loss": 1.8231,
      "step": 77800
    },
    {
      "epoch": 2.4912,
      "grad_norm": 0.35655033588409424,
      "learning_rate": 0.00010035328,
      "loss": 1.7523,
      "step": 77850
    },
    {
      "epoch": 2.4928,
      "grad_norm": 0.4167242646217346,
      "learning_rate": 0.00010028928,
      "loss": 1.7966,
      "step": 77900
    },
    {
      "epoch": 2.4944,
      "grad_norm": 0.4255982041358948,
      "learning_rate": 0.00010022528,
      "loss": 1.7846,
      "step": 77950
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.3954516351222992,
      "learning_rate": 0.00010016128,
      "loss": 1.7561,
      "step": 78000
    },
    {
      "epoch": 2.4976,
      "grad_norm": 0.3398619294166565,
      "learning_rate": 0.00010009728,
      "loss": 1.7317,
      "step": 78050
    },
    {
      "epoch": 2.4992,
      "grad_norm": 0.31970009207725525,
      "learning_rate": 0.00010003328,
      "loss": 1.7298,
      "step": 78100
    },
    {
      "epoch": 2.5008,
      "grad_norm": 0.3394883871078491,
      "learning_rate": 9.996928000000001e-05,
      "loss": 1.7444,
      "step": 78150
    },
    {
      "epoch": 2.5023999999999997,
      "grad_norm": 0.3585743010044098,
      "learning_rate": 9.990528e-05,
      "loss": 1.7555,
      "step": 78200
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.3458460569381714,
      "learning_rate": 9.984128e-05,
      "loss": 1.8097,
      "step": 78250
    },
    {
      "epoch": 2.5056000000000003,
      "grad_norm": 0.3470669984817505,
      "learning_rate": 9.977728000000001e-05,
      "loss": 1.8333,
      "step": 78300
    },
    {
      "epoch": 2.5072,
      "grad_norm": 0.3583226203918457,
      "learning_rate": 9.971328e-05,
      "loss": 1.8038,
      "step": 78350
    },
    {
      "epoch": 2.5088,
      "grad_norm": 0.41249987483024597,
      "learning_rate": 9.964928e-05,
      "loss": 1.7404,
      "step": 78400
    },
    {
      "epoch": 2.5103999999999997,
      "grad_norm": 0.3910423219203949,
      "learning_rate": 9.958528000000001e-05,
      "loss": 1.8301,
      "step": 78450
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.39167413115501404,
      "learning_rate": 9.952128e-05,
      "loss": 1.7705,
      "step": 78500
    },
    {
      "epoch": 2.5136,
      "grad_norm": 0.3893461525440216,
      "learning_rate": 9.945728000000001e-05,
      "loss": 1.7978,
      "step": 78550
    },
    {
      "epoch": 2.5152,
      "grad_norm": 0.4211486876010895,
      "learning_rate": 9.939328e-05,
      "loss": 1.7881,
      "step": 78600
    },
    {
      "epoch": 2.5168,
      "grad_norm": 0.32347437739372253,
      "learning_rate": 9.932928e-05,
      "loss": 1.8037,
      "step": 78650
    },
    {
      "epoch": 2.5183999999999997,
      "grad_norm": 0.3617153465747833,
      "learning_rate": 9.926528e-05,
      "loss": 1.8204,
      "step": 78700
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.4298323690891266,
      "learning_rate": 9.920128000000001e-05,
      "loss": 1.8004,
      "step": 78750
    },
    {
      "epoch": 2.5216,
      "grad_norm": 0.376737117767334,
      "learning_rate": 9.913728000000002e-05,
      "loss": 1.786,
      "step": 78800
    },
    {
      "epoch": 2.5232,
      "grad_norm": 0.3787430226802826,
      "learning_rate": 9.907328e-05,
      "loss": 1.8434,
      "step": 78850
    },
    {
      "epoch": 2.5248,
      "grad_norm": 0.394322007894516,
      "learning_rate": 9.900928e-05,
      "loss": 1.8028,
      "step": 78900
    },
    {
      "epoch": 2.5263999999999998,
      "grad_norm": 0.4284490644931793,
      "learning_rate": 9.894528e-05,
      "loss": 1.8166,
      "step": 78950
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.3097984492778778,
      "learning_rate": 9.888128000000001e-05,
      "loss": 1.804,
      "step": 79000
    },
    {
      "epoch": 2.5296,
      "grad_norm": 0.3284173607826233,
      "learning_rate": 9.881728e-05,
      "loss": 1.7775,
      "step": 79050
    },
    {
      "epoch": 2.5312,
      "grad_norm": 0.354565292596817,
      "learning_rate": 9.875328e-05,
      "loss": 1.7942,
      "step": 79100
    },
    {
      "epoch": 2.5328,
      "grad_norm": 0.4022534191608429,
      "learning_rate": 9.868928000000001e-05,
      "loss": 1.7747,
      "step": 79150
    },
    {
      "epoch": 2.5343999999999998,
      "grad_norm": 0.3103424906730652,
      "learning_rate": 9.862528e-05,
      "loss": 1.7669,
      "step": 79200
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.3524884283542633,
      "learning_rate": 9.856128e-05,
      "loss": 1.7494,
      "step": 79250
    },
    {
      "epoch": 2.5376,
      "grad_norm": 0.37248632311820984,
      "learning_rate": 9.849728000000001e-05,
      "loss": 1.7905,
      "step": 79300
    },
    {
      "epoch": 2.5392,
      "grad_norm": 0.33835500478744507,
      "learning_rate": 9.843328e-05,
      "loss": 1.745,
      "step": 79350
    },
    {
      "epoch": 2.5408,
      "grad_norm": 0.38071081042289734,
      "learning_rate": 9.836928000000001e-05,
      "loss": 1.7635,
      "step": 79400
    },
    {
      "epoch": 2.5423999999999998,
      "grad_norm": 0.35786086320877075,
      "learning_rate": 9.830528e-05,
      "loss": 1.7772,
      "step": 79450
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.42152443528175354,
      "learning_rate": 9.824128e-05,
      "loss": 1.7791,
      "step": 79500
    },
    {
      "epoch": 2.5456,
      "grad_norm": 0.3929983675479889,
      "learning_rate": 9.817728000000001e-05,
      "loss": 1.7639,
      "step": 79550
    },
    {
      "epoch": 2.5472,
      "grad_norm": 0.39995062351226807,
      "learning_rate": 9.811328e-05,
      "loss": 1.8272,
      "step": 79600
    },
    {
      "epoch": 2.5488,
      "grad_norm": 0.31113895773887634,
      "learning_rate": 9.804928000000002e-05,
      "loss": 1.8311,
      "step": 79650
    },
    {
      "epoch": 2.5504,
      "grad_norm": 0.38836750388145447,
      "learning_rate": 9.798528e-05,
      "loss": 1.8022,
      "step": 79700
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.36161330342292786,
      "learning_rate": 9.792128e-05,
      "loss": 1.8125,
      "step": 79750
    },
    {
      "epoch": 2.5536,
      "grad_norm": 0.3381994664669037,
      "learning_rate": 9.785728e-05,
      "loss": 1.7625,
      "step": 79800
    },
    {
      "epoch": 2.5552,
      "grad_norm": 0.3395419120788574,
      "learning_rate": 9.779328000000001e-05,
      "loss": 1.7707,
      "step": 79850
    },
    {
      "epoch": 2.5568,
      "grad_norm": 0.5056413412094116,
      "learning_rate": 9.772928e-05,
      "loss": 1.7458,
      "step": 79900
    },
    {
      "epoch": 2.5584,
      "grad_norm": 0.4342784583568573,
      "learning_rate": 9.766528e-05,
      "loss": 1.7901,
      "step": 79950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.3243709206581116,
      "learning_rate": 9.760128000000001e-05,
      "loss": 1.7607,
      "step": 80000
    },
    {
      "epoch": 2.5616,
      "grad_norm": 0.3587730824947357,
      "learning_rate": 9.753728e-05,
      "loss": 1.7827,
      "step": 80050
    },
    {
      "epoch": 2.5632,
      "grad_norm": 0.3452949821949005,
      "learning_rate": 9.747328e-05,
      "loss": 1.7739,
      "step": 80100
    },
    {
      "epoch": 2.5648,
      "grad_norm": 0.3309682309627533,
      "learning_rate": 9.740928000000001e-05,
      "loss": 1.7709,
      "step": 80150
    },
    {
      "epoch": 2.5664,
      "grad_norm": 0.44368794560432434,
      "learning_rate": 9.734528e-05,
      "loss": 1.7225,
      "step": 80200
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.4095994532108307,
      "learning_rate": 9.728128000000001e-05,
      "loss": 1.8115,
      "step": 80250
    },
    {
      "epoch": 2.5696,
      "grad_norm": 0.3652920424938202,
      "learning_rate": 9.721728e-05,
      "loss": 1.7235,
      "step": 80300
    },
    {
      "epoch": 2.5712,
      "grad_norm": 0.30401912331581116,
      "learning_rate": 9.715328e-05,
      "loss": 1.7735,
      "step": 80350
    },
    {
      "epoch": 2.5728,
      "grad_norm": 0.371413916349411,
      "learning_rate": 9.708928000000001e-05,
      "loss": 1.7589,
      "step": 80400
    },
    {
      "epoch": 2.5744,
      "grad_norm": 0.365055114030838,
      "learning_rate": 9.702528e-05,
      "loss": 1.7717,
      "step": 80450
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.391579270362854,
      "learning_rate": 9.696128000000002e-05,
      "loss": 1.7565,
      "step": 80500
    },
    {
      "epoch": 2.5776,
      "grad_norm": 0.3142194151878357,
      "learning_rate": 9.689728e-05,
      "loss": 1.7799,
      "step": 80550
    },
    {
      "epoch": 2.5792,
      "grad_norm": 0.3323136568069458,
      "learning_rate": 9.683328e-05,
      "loss": 1.823,
      "step": 80600
    },
    {
      "epoch": 2.5808,
      "grad_norm": 0.37559351325035095,
      "learning_rate": 9.676928e-05,
      "loss": 1.7761,
      "step": 80650
    },
    {
      "epoch": 2.5824,
      "grad_norm": 0.37386277318000793,
      "learning_rate": 9.670528000000001e-05,
      "loss": 1.7847,
      "step": 80700
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.4174330532550812,
      "learning_rate": 9.664128e-05,
      "loss": 1.7493,
      "step": 80750
    },
    {
      "epoch": 2.5856,
      "grad_norm": 0.3262604773044586,
      "learning_rate": 9.657728e-05,
      "loss": 1.7598,
      "step": 80800
    },
    {
      "epoch": 2.5872,
      "grad_norm": 0.28560447692871094,
      "learning_rate": 9.651328000000001e-05,
      "loss": 1.8232,
      "step": 80850
    },
    {
      "epoch": 2.5888,
      "grad_norm": 0.3656684160232544,
      "learning_rate": 9.644928e-05,
      "loss": 1.7629,
      "step": 80900
    },
    {
      "epoch": 2.5904,
      "grad_norm": 0.47403496503829956,
      "learning_rate": 9.638528e-05,
      "loss": 1.7585,
      "step": 80950
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.31493517756462097,
      "learning_rate": 9.632128000000001e-05,
      "loss": 1.7575,
      "step": 81000
    },
    {
      "epoch": 2.5936,
      "grad_norm": 0.37965482473373413,
      "learning_rate": 9.625728e-05,
      "loss": 1.7725,
      "step": 81050
    },
    {
      "epoch": 2.5952,
      "grad_norm": 0.3680574297904968,
      "learning_rate": 9.619328000000001e-05,
      "loss": 1.821,
      "step": 81100
    },
    {
      "epoch": 2.5968,
      "grad_norm": 0.41722571849823,
      "learning_rate": 9.612927999999999e-05,
      "loss": 1.8235,
      "step": 81150
    },
    {
      "epoch": 2.5984,
      "grad_norm": 0.3788248896598816,
      "learning_rate": 9.606528e-05,
      "loss": 1.8231,
      "step": 81200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.40112560987472534,
      "learning_rate": 9.600128000000001e-05,
      "loss": 1.7637,
      "step": 81250
    },
    {
      "epoch": 2.6016,
      "grad_norm": 0.38355255126953125,
      "learning_rate": 9.593728e-05,
      "loss": 1.7944,
      "step": 81300
    },
    {
      "epoch": 2.6032,
      "grad_norm": 0.4076882302761078,
      "learning_rate": 9.587328000000001e-05,
      "loss": 1.7955,
      "step": 81350
    },
    {
      "epoch": 2.6048,
      "grad_norm": 0.32681670784950256,
      "learning_rate": 9.580928e-05,
      "loss": 1.7508,
      "step": 81400
    },
    {
      "epoch": 2.6064,
      "grad_norm": 0.439704030752182,
      "learning_rate": 9.574528e-05,
      "loss": 1.8159,
      "step": 81450
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.3693073093891144,
      "learning_rate": 9.568128e-05,
      "loss": 1.7936,
      "step": 81500
    },
    {
      "epoch": 2.6096,
      "grad_norm": 0.36742469668388367,
      "learning_rate": 9.561728000000001e-05,
      "loss": 1.806,
      "step": 81550
    },
    {
      "epoch": 2.6112,
      "grad_norm": 0.32152482867240906,
      "learning_rate": 9.555328e-05,
      "loss": 1.8484,
      "step": 81600
    },
    {
      "epoch": 2.6128,
      "grad_norm": 0.42041316628456116,
      "learning_rate": 9.548928e-05,
      "loss": 1.8325,
      "step": 81650
    },
    {
      "epoch": 2.6144,
      "grad_norm": 0.3713309168815613,
      "learning_rate": 9.542528000000001e-05,
      "loss": 1.774,
      "step": 81700
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.30265456438064575,
      "learning_rate": 9.536128e-05,
      "loss": 1.7704,
      "step": 81750
    },
    {
      "epoch": 2.6176,
      "grad_norm": 0.3428775370121002,
      "learning_rate": 9.529728e-05,
      "loss": 1.797,
      "step": 81800
    },
    {
      "epoch": 2.6192,
      "grad_norm": 0.3384716212749481,
      "learning_rate": 9.523328000000001e-05,
      "loss": 1.7872,
      "step": 81850
    },
    {
      "epoch": 2.6208,
      "grad_norm": 0.34694811701774597,
      "learning_rate": 9.516928e-05,
      "loss": 1.7215,
      "step": 81900
    },
    {
      "epoch": 2.6224,
      "grad_norm": 0.32314032316207886,
      "learning_rate": 9.510528000000001e-05,
      "loss": 1.8295,
      "step": 81950
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.41225573420524597,
      "learning_rate": 9.504127999999999e-05,
      "loss": 1.761,
      "step": 82000
    },
    {
      "epoch": 2.6256,
      "grad_norm": 0.3855501413345337,
      "learning_rate": 9.497728e-05,
      "loss": 1.8002,
      "step": 82050
    },
    {
      "epoch": 2.6272,
      "grad_norm": 0.37517890334129333,
      "learning_rate": 9.491328000000001e-05,
      "loss": 1.8043,
      "step": 82100
    },
    {
      "epoch": 2.6288,
      "grad_norm": 0.36347833275794983,
      "learning_rate": 9.484928e-05,
      "loss": 1.8366,
      "step": 82150
    },
    {
      "epoch": 2.6304,
      "grad_norm": 0.4339914619922638,
      "learning_rate": 9.478528000000001e-05,
      "loss": 1.8114,
      "step": 82200
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.43861523270606995,
      "learning_rate": 9.472128e-05,
      "loss": 1.7868,
      "step": 82250
    },
    {
      "epoch": 2.6336,
      "grad_norm": 0.39255091547966003,
      "learning_rate": 9.465728e-05,
      "loss": 1.7758,
      "step": 82300
    },
    {
      "epoch": 2.6352,
      "grad_norm": 0.45096418261528015,
      "learning_rate": 9.459328e-05,
      "loss": 1.7643,
      "step": 82350
    },
    {
      "epoch": 2.6368,
      "grad_norm": 0.36606308817863464,
      "learning_rate": 9.452928000000001e-05,
      "loss": 1.7592,
      "step": 82400
    },
    {
      "epoch": 2.6384,
      "grad_norm": 0.3675915598869324,
      "learning_rate": 9.446528e-05,
      "loss": 1.7765,
      "step": 82450
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.3741793930530548,
      "learning_rate": 9.440128e-05,
      "loss": 1.8425,
      "step": 82500
    },
    {
      "epoch": 2.6416,
      "grad_norm": 0.37118321657180786,
      "learning_rate": 9.433728000000001e-05,
      "loss": 1.7768,
      "step": 82550
    },
    {
      "epoch": 2.6432,
      "grad_norm": 0.3206852078437805,
      "learning_rate": 9.427328e-05,
      "loss": 1.7873,
      "step": 82600
    },
    {
      "epoch": 2.6448,
      "grad_norm": 0.36949458718299866,
      "learning_rate": 9.420928e-05,
      "loss": 1.8347,
      "step": 82650
    },
    {
      "epoch": 2.6464,
      "grad_norm": 0.3697563707828522,
      "learning_rate": 9.414528e-05,
      "loss": 1.7737,
      "step": 82700
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.3327485918998718,
      "learning_rate": 9.408128e-05,
      "loss": 1.837,
      "step": 82750
    },
    {
      "epoch": 2.6496,
      "grad_norm": 0.34610113501548767,
      "learning_rate": 9.401728000000001e-05,
      "loss": 1.7983,
      "step": 82800
    },
    {
      "epoch": 2.6512000000000002,
      "grad_norm": 0.3117445111274719,
      "learning_rate": 9.395327999999999e-05,
      "loss": 1.7859,
      "step": 82850
    },
    {
      "epoch": 2.6528,
      "grad_norm": 0.3934040665626526,
      "learning_rate": 9.388928e-05,
      "loss": 1.7874,
      "step": 82900
    },
    {
      "epoch": 2.6544,
      "grad_norm": 0.3438432216644287,
      "learning_rate": 9.382528000000001e-05,
      "loss": 1.8119,
      "step": 82950
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.36088261008262634,
      "learning_rate": 9.376128e-05,
      "loss": 1.8319,
      "step": 83000
    },
    {
      "epoch": 2.6576,
      "grad_norm": 0.3989555835723877,
      "learning_rate": 9.369728000000001e-05,
      "loss": 1.7315,
      "step": 83050
    },
    {
      "epoch": 2.6592000000000002,
      "grad_norm": 0.38533130288124084,
      "learning_rate": 9.363328e-05,
      "loss": 1.8192,
      "step": 83100
    },
    {
      "epoch": 2.6608,
      "grad_norm": 0.4764579236507416,
      "learning_rate": 9.356928e-05,
      "loss": 1.8194,
      "step": 83150
    },
    {
      "epoch": 2.6624,
      "grad_norm": 0.4287995398044586,
      "learning_rate": 9.350528000000001e-05,
      "loss": 1.7389,
      "step": 83200
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.3170551657676697,
      "learning_rate": 9.344128000000001e-05,
      "loss": 1.758,
      "step": 83250
    },
    {
      "epoch": 2.6656,
      "grad_norm": 0.3729094862937927,
      "learning_rate": 9.337728e-05,
      "loss": 1.7724,
      "step": 83300
    },
    {
      "epoch": 2.6672000000000002,
      "grad_norm": 0.3966962397098541,
      "learning_rate": 9.331328e-05,
      "loss": 1.7407,
      "step": 83350
    },
    {
      "epoch": 2.6688,
      "grad_norm": 0.4012914299964905,
      "learning_rate": 9.324928000000001e-05,
      "loss": 1.8423,
      "step": 83400
    },
    {
      "epoch": 2.6704,
      "grad_norm": 0.3905010521411896,
      "learning_rate": 9.318528e-05,
      "loss": 1.7756,
      "step": 83450
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.34583818912506104,
      "learning_rate": 9.312128e-05,
      "loss": 1.793,
      "step": 83500
    },
    {
      "epoch": 2.6736,
      "grad_norm": 0.31378430128097534,
      "learning_rate": 9.305728e-05,
      "loss": 1.7918,
      "step": 83550
    },
    {
      "epoch": 2.6752000000000002,
      "grad_norm": 0.3554064631462097,
      "learning_rate": 9.299328e-05,
      "loss": 1.7669,
      "step": 83600
    },
    {
      "epoch": 2.6768,
      "grad_norm": 0.3546786606311798,
      "learning_rate": 9.292928000000001e-05,
      "loss": 1.8044,
      "step": 83650
    },
    {
      "epoch": 2.6784,
      "grad_norm": 0.3880998492240906,
      "learning_rate": 9.286528e-05,
      "loss": 1.7666,
      "step": 83700
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.3951244056224823,
      "learning_rate": 9.280128e-05,
      "loss": 1.7949,
      "step": 83750
    },
    {
      "epoch": 2.6816,
      "grad_norm": 0.3381308913230896,
      "learning_rate": 9.273728000000001e-05,
      "loss": 1.813,
      "step": 83800
    },
    {
      "epoch": 2.6832000000000003,
      "grad_norm": 0.404512494802475,
      "learning_rate": 9.267328e-05,
      "loss": 1.807,
      "step": 83850
    },
    {
      "epoch": 2.6848,
      "grad_norm": 0.3431534171104431,
      "learning_rate": 9.260928000000001e-05,
      "loss": 1.7697,
      "step": 83900
    },
    {
      "epoch": 2.6864,
      "grad_norm": 0.4775344133377075,
      "learning_rate": 9.254528e-05,
      "loss": 1.7503,
      "step": 83950
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.321982204914093,
      "learning_rate": 9.248128e-05,
      "loss": 1.8351,
      "step": 84000
    },
    {
      "epoch": 2.6896,
      "grad_norm": 0.28309527039527893,
      "learning_rate": 9.241728000000001e-05,
      "loss": 1.8179,
      "step": 84050
    },
    {
      "epoch": 2.6912000000000003,
      "grad_norm": 0.34864503145217896,
      "learning_rate": 9.235328000000001e-05,
      "loss": 1.7685,
      "step": 84100
    },
    {
      "epoch": 2.6928,
      "grad_norm": 0.4393904209136963,
      "learning_rate": 9.228928e-05,
      "loss": 1.7943,
      "step": 84150
    },
    {
      "epoch": 2.6944,
      "grad_norm": 0.31923556327819824,
      "learning_rate": 9.222528e-05,
      "loss": 1.7533,
      "step": 84200
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.35935965180397034,
      "learning_rate": 9.216128e-05,
      "loss": 1.7919,
      "step": 84250
    },
    {
      "epoch": 2.6976,
      "grad_norm": 0.43216001987457275,
      "learning_rate": 9.209728e-05,
      "loss": 1.7712,
      "step": 84300
    },
    {
      "epoch": 2.6992000000000003,
      "grad_norm": 0.36382001638412476,
      "learning_rate": 9.203328e-05,
      "loss": 1.8034,
      "step": 84350
    },
    {
      "epoch": 2.7008,
      "grad_norm": 0.4098091721534729,
      "learning_rate": 9.196928e-05,
      "loss": 1.7813,
      "step": 84400
    },
    {
      "epoch": 2.7024,
      "grad_norm": 0.4043042063713074,
      "learning_rate": 9.190528e-05,
      "loss": 1.8092,
      "step": 84450
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.41726264357566833,
      "learning_rate": 9.184128000000001e-05,
      "loss": 1.7691,
      "step": 84500
    },
    {
      "epoch": 2.7056,
      "grad_norm": 0.42550745606422424,
      "learning_rate": 9.177728e-05,
      "loss": 1.7812,
      "step": 84550
    },
    {
      "epoch": 2.7072000000000003,
      "grad_norm": 0.35371512174606323,
      "learning_rate": 9.171328e-05,
      "loss": 1.8224,
      "step": 84600
    },
    {
      "epoch": 2.7088,
      "grad_norm": 0.480495423078537,
      "learning_rate": 9.164928000000001e-05,
      "loss": 1.7652,
      "step": 84650
    },
    {
      "epoch": 2.7104,
      "grad_norm": 0.33568260073661804,
      "learning_rate": 9.158528e-05,
      "loss": 1.8508,
      "step": 84700
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.36802971363067627,
      "learning_rate": 9.152128000000001e-05,
      "loss": 1.7772,
      "step": 84750
    },
    {
      "epoch": 2.7136,
      "grad_norm": 0.39334234595298767,
      "learning_rate": 9.145728e-05,
      "loss": 1.8277,
      "step": 84800
    },
    {
      "epoch": 2.7152,
      "grad_norm": 0.34799724817276,
      "learning_rate": 9.139328e-05,
      "loss": 1.8234,
      "step": 84850
    },
    {
      "epoch": 2.7168,
      "grad_norm": 0.35104498267173767,
      "learning_rate": 9.132928000000001e-05,
      "loss": 1.8376,
      "step": 84900
    },
    {
      "epoch": 2.7184,
      "grad_norm": 0.3121856451034546,
      "learning_rate": 9.126528000000001e-05,
      "loss": 1.8054,
      "step": 84950
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.3602032959461212,
      "learning_rate": 9.120128e-05,
      "loss": 1.7866,
      "step": 85000
    },
    {
      "epoch": 2.7216,
      "grad_norm": 0.4132910966873169,
      "learning_rate": 9.113728e-05,
      "loss": 1.7485,
      "step": 85050
    },
    {
      "epoch": 2.7232,
      "grad_norm": 0.30637025833129883,
      "learning_rate": 9.107328e-05,
      "loss": 1.7708,
      "step": 85100
    },
    {
      "epoch": 2.7248,
      "grad_norm": 0.3187505602836609,
      "learning_rate": 9.100928e-05,
      "loss": 1.7762,
      "step": 85150
    },
    {
      "epoch": 2.7264,
      "grad_norm": 0.39453306794166565,
      "learning_rate": 9.094528e-05,
      "loss": 1.8158,
      "step": 85200
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.2798173427581787,
      "learning_rate": 9.088128e-05,
      "loss": 1.7138,
      "step": 85250
    },
    {
      "epoch": 2.7296,
      "grad_norm": 0.41926729679107666,
      "learning_rate": 9.081728e-05,
      "loss": 1.7337,
      "step": 85300
    },
    {
      "epoch": 2.7312,
      "grad_norm": 0.3474878966808319,
      "learning_rate": 9.075328000000001e-05,
      "loss": 1.7864,
      "step": 85350
    },
    {
      "epoch": 2.7328,
      "grad_norm": 0.3973430097103119,
      "learning_rate": 9.068928e-05,
      "loss": 1.7601,
      "step": 85400
    },
    {
      "epoch": 2.7344,
      "grad_norm": 0.3184504806995392,
      "learning_rate": 9.062528e-05,
      "loss": 1.7455,
      "step": 85450
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.39420002698898315,
      "learning_rate": 9.056128000000001e-05,
      "loss": 1.8098,
      "step": 85500
    },
    {
      "epoch": 2.7376,
      "grad_norm": 0.4324435591697693,
      "learning_rate": 9.049728e-05,
      "loss": 1.7665,
      "step": 85550
    },
    {
      "epoch": 2.7392,
      "grad_norm": 0.3742274343967438,
      "learning_rate": 9.043328000000001e-05,
      "loss": 1.7533,
      "step": 85600
    },
    {
      "epoch": 2.7408,
      "grad_norm": 0.3901728689670563,
      "learning_rate": 9.036928e-05,
      "loss": 1.8005,
      "step": 85650
    },
    {
      "epoch": 2.7424,
      "grad_norm": 0.3547956645488739,
      "learning_rate": 9.030528e-05,
      "loss": 1.8111,
      "step": 85700
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.30496498942375183,
      "learning_rate": 9.024128000000001e-05,
      "loss": 1.7679,
      "step": 85750
    },
    {
      "epoch": 2.7456,
      "grad_norm": 0.366156667470932,
      "learning_rate": 9.017728000000001e-05,
      "loss": 1.7822,
      "step": 85800
    },
    {
      "epoch": 2.7472,
      "grad_norm": 0.3551873564720154,
      "learning_rate": 9.011328e-05,
      "loss": 1.781,
      "step": 85850
    },
    {
      "epoch": 2.7488,
      "grad_norm": 0.39921650290489197,
      "learning_rate": 9.004928e-05,
      "loss": 1.8524,
      "step": 85900
    },
    {
      "epoch": 2.7504,
      "grad_norm": 0.4004952907562256,
      "learning_rate": 8.998528e-05,
      "loss": 1.7829,
      "step": 85950
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.4448195993900299,
      "learning_rate": 8.992128e-05,
      "loss": 1.7839,
      "step": 86000
    },
    {
      "epoch": 2.7536,
      "grad_norm": 0.3590681254863739,
      "learning_rate": 8.985728e-05,
      "loss": 1.8223,
      "step": 86050
    },
    {
      "epoch": 2.7552,
      "grad_norm": 0.38620540499687195,
      "learning_rate": 8.979328e-05,
      "loss": 1.7782,
      "step": 86100
    },
    {
      "epoch": 2.7568,
      "grad_norm": 0.3164791464805603,
      "learning_rate": 8.972928e-05,
      "loss": 1.777,
      "step": 86150
    },
    {
      "epoch": 2.7584,
      "grad_norm": 0.333466112613678,
      "learning_rate": 8.966528000000001e-05,
      "loss": 1.7747,
      "step": 86200
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.38474076986312866,
      "learning_rate": 8.960128e-05,
      "loss": 1.8823,
      "step": 86250
    },
    {
      "epoch": 2.7616,
      "grad_norm": 0.3886101543903351,
      "learning_rate": 8.953728e-05,
      "loss": 1.7968,
      "step": 86300
    },
    {
      "epoch": 2.7632,
      "grad_norm": 0.457179993391037,
      "learning_rate": 8.947328000000001e-05,
      "loss": 1.7473,
      "step": 86350
    },
    {
      "epoch": 2.7648,
      "grad_norm": 0.396977961063385,
      "learning_rate": 8.940928e-05,
      "loss": 1.7575,
      "step": 86400
    },
    {
      "epoch": 2.7664,
      "grad_norm": 0.35977715253829956,
      "learning_rate": 8.934528000000001e-05,
      "loss": 1.7601,
      "step": 86450
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.3690318167209625,
      "learning_rate": 8.928128000000001e-05,
      "loss": 1.7476,
      "step": 86500
    },
    {
      "epoch": 2.7696,
      "grad_norm": 0.3563006818294525,
      "learning_rate": 8.921728e-05,
      "loss": 1.7973,
      "step": 86550
    },
    {
      "epoch": 2.7712,
      "grad_norm": 0.3578030467033386,
      "learning_rate": 8.915328000000001e-05,
      "loss": 1.8067,
      "step": 86600
    },
    {
      "epoch": 2.7728,
      "grad_norm": 0.37379366159439087,
      "learning_rate": 8.908928e-05,
      "loss": 1.7995,
      "step": 86650
    },
    {
      "epoch": 2.7744,
      "grad_norm": 0.3988574743270874,
      "learning_rate": 8.902528e-05,
      "loss": 1.77,
      "step": 86700
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.3777759075164795,
      "learning_rate": 8.896128e-05,
      "loss": 1.8221,
      "step": 86750
    },
    {
      "epoch": 2.7776,
      "grad_norm": 0.38407692313194275,
      "learning_rate": 8.889728e-05,
      "loss": 1.8101,
      "step": 86800
    },
    {
      "epoch": 2.7792,
      "grad_norm": 0.41910573840141296,
      "learning_rate": 8.883328000000001e-05,
      "loss": 1.7537,
      "step": 86850
    },
    {
      "epoch": 2.7808,
      "grad_norm": 0.3550972640514374,
      "learning_rate": 8.876928e-05,
      "loss": 1.8036,
      "step": 86900
    },
    {
      "epoch": 2.7824,
      "grad_norm": 0.37663280963897705,
      "learning_rate": 8.870528e-05,
      "loss": 1.8445,
      "step": 86950
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.3517484664916992,
      "learning_rate": 8.864128e-05,
      "loss": 1.7566,
      "step": 87000
    },
    {
      "epoch": 2.7856,
      "grad_norm": 0.4074387550354004,
      "learning_rate": 8.857728000000001e-05,
      "loss": 1.7535,
      "step": 87050
    },
    {
      "epoch": 2.7872,
      "grad_norm": 0.41353750228881836,
      "learning_rate": 8.851328e-05,
      "loss": 1.7874,
      "step": 87100
    },
    {
      "epoch": 2.7888,
      "grad_norm": 0.4351438879966736,
      "learning_rate": 8.844928e-05,
      "loss": 1.7998,
      "step": 87150
    },
    {
      "epoch": 2.7904,
      "grad_norm": 0.3986102044582367,
      "learning_rate": 8.838528000000001e-05,
      "loss": 1.8049,
      "step": 87200
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.34747058153152466,
      "learning_rate": 8.832128e-05,
      "loss": 1.7985,
      "step": 87250
    },
    {
      "epoch": 2.7936,
      "grad_norm": 0.375332772731781,
      "learning_rate": 8.825728000000001e-05,
      "loss": 1.8107,
      "step": 87300
    },
    {
      "epoch": 2.7952,
      "grad_norm": 0.3877508044242859,
      "learning_rate": 8.819328000000001e-05,
      "loss": 1.8043,
      "step": 87350
    },
    {
      "epoch": 2.7968,
      "grad_norm": 0.39037787914276123,
      "learning_rate": 8.812928e-05,
      "loss": 1.7359,
      "step": 87400
    },
    {
      "epoch": 2.7984,
      "grad_norm": 0.3413192927837372,
      "learning_rate": 8.806528000000001e-05,
      "loss": 1.7907,
      "step": 87450
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.33343929052352905,
      "learning_rate": 8.800128e-05,
      "loss": 1.7625,
      "step": 87500
    },
    {
      "epoch": 2.8016,
      "grad_norm": 0.46992626786231995,
      "learning_rate": 8.793728e-05,
      "loss": 1.7828,
      "step": 87550
    },
    {
      "epoch": 2.8032,
      "grad_norm": 0.369198739528656,
      "learning_rate": 8.787328e-05,
      "loss": 1.7594,
      "step": 87600
    },
    {
      "epoch": 2.8048,
      "grad_norm": 0.32311728596687317,
      "learning_rate": 8.780928e-05,
      "loss": 1.8247,
      "step": 87650
    },
    {
      "epoch": 2.8064,
      "grad_norm": 0.39572566747665405,
      "learning_rate": 8.774528000000001e-05,
      "loss": 1.7692,
      "step": 87700
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.3032287359237671,
      "learning_rate": 8.768128e-05,
      "loss": 1.8495,
      "step": 87750
    },
    {
      "epoch": 2.8096,
      "grad_norm": 0.3043964207172394,
      "learning_rate": 8.761728e-05,
      "loss": 1.7512,
      "step": 87800
    },
    {
      "epoch": 2.8112,
      "grad_norm": 0.34841111302375793,
      "learning_rate": 8.755328e-05,
      "loss": 1.7993,
      "step": 87850
    },
    {
      "epoch": 2.8128,
      "grad_norm": 0.3665354549884796,
      "learning_rate": 8.748928000000001e-05,
      "loss": 1.8197,
      "step": 87900
    },
    {
      "epoch": 2.8144,
      "grad_norm": 0.33401888608932495,
      "learning_rate": 8.742528e-05,
      "loss": 1.7178,
      "step": 87950
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.3371196985244751,
      "learning_rate": 8.736128e-05,
      "loss": 1.8295,
      "step": 88000
    },
    {
      "epoch": 2.8176,
      "grad_norm": 0.34324654936790466,
      "learning_rate": 8.729728000000001e-05,
      "loss": 1.758,
      "step": 88050
    },
    {
      "epoch": 2.8192,
      "grad_norm": 0.35935378074645996,
      "learning_rate": 8.723328e-05,
      "loss": 1.79,
      "step": 88100
    },
    {
      "epoch": 2.8208,
      "grad_norm": 0.43215271830558777,
      "learning_rate": 8.716928000000001e-05,
      "loss": 1.7969,
      "step": 88150
    },
    {
      "epoch": 2.8224,
      "grad_norm": 0.32943257689476013,
      "learning_rate": 8.710528e-05,
      "loss": 1.7859,
      "step": 88200
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.41418248414993286,
      "learning_rate": 8.704128e-05,
      "loss": 1.7211,
      "step": 88250
    },
    {
      "epoch": 2.8256,
      "grad_norm": 0.37863004207611084,
      "learning_rate": 8.697728000000001e-05,
      "loss": 1.782,
      "step": 88300
    },
    {
      "epoch": 2.8272,
      "grad_norm": 0.36597925424575806,
      "learning_rate": 8.691328e-05,
      "loss": 1.8285,
      "step": 88350
    },
    {
      "epoch": 2.8288,
      "grad_norm": 0.37127000093460083,
      "learning_rate": 8.684928e-05,
      "loss": 1.7758,
      "step": 88400
    },
    {
      "epoch": 2.8304,
      "grad_norm": 0.3666613698005676,
      "learning_rate": 8.678528e-05,
      "loss": 1.7911,
      "step": 88450
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.3550511598587036,
      "learning_rate": 8.672128e-05,
      "loss": 1.8084,
      "step": 88500
    },
    {
      "epoch": 2.8336,
      "grad_norm": 0.38204243779182434,
      "learning_rate": 8.665728000000001e-05,
      "loss": 1.7549,
      "step": 88550
    },
    {
      "epoch": 2.8352,
      "grad_norm": 0.34259140491485596,
      "learning_rate": 8.659328e-05,
      "loss": 1.7678,
      "step": 88600
    },
    {
      "epoch": 2.8368,
      "grad_norm": 0.3842692971229553,
      "learning_rate": 8.652928e-05,
      "loss": 1.7918,
      "step": 88650
    },
    {
      "epoch": 2.8384,
      "grad_norm": 0.37998393177986145,
      "learning_rate": 8.646528e-05,
      "loss": 1.8189,
      "step": 88700
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.3384447991847992,
      "learning_rate": 8.640128000000001e-05,
      "loss": 1.7873,
      "step": 88750
    },
    {
      "epoch": 2.8416,
      "grad_norm": 0.4483971893787384,
      "learning_rate": 8.633728e-05,
      "loss": 1.7649,
      "step": 88800
    },
    {
      "epoch": 2.8432,
      "grad_norm": 0.3967277407646179,
      "learning_rate": 8.627328e-05,
      "loss": 1.82,
      "step": 88850
    },
    {
      "epoch": 2.8448,
      "grad_norm": 0.3685227632522583,
      "learning_rate": 8.620928000000001e-05,
      "loss": 1.747,
      "step": 88900
    },
    {
      "epoch": 2.8464,
      "grad_norm": 0.4356946647167206,
      "learning_rate": 8.614528e-05,
      "loss": 1.851,
      "step": 88950
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.3635086119174957,
      "learning_rate": 8.608128000000001e-05,
      "loss": 1.7979,
      "step": 89000
    },
    {
      "epoch": 2.8496,
      "grad_norm": 0.38575366139411926,
      "learning_rate": 8.601728e-05,
      "loss": 1.7942,
      "step": 89050
    },
    {
      "epoch": 2.8512,
      "grad_norm": 0.38693320751190186,
      "learning_rate": 8.595328e-05,
      "loss": 1.7385,
      "step": 89100
    },
    {
      "epoch": 2.8528000000000002,
      "grad_norm": 0.42585092782974243,
      "learning_rate": 8.588928000000001e-05,
      "loss": 1.7983,
      "step": 89150
    },
    {
      "epoch": 2.8544,
      "grad_norm": 0.416362464427948,
      "learning_rate": 8.582528e-05,
      "loss": 1.7907,
      "step": 89200
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.3625655174255371,
      "learning_rate": 8.576128e-05,
      "loss": 1.7131,
      "step": 89250
    },
    {
      "epoch": 2.8576,
      "grad_norm": 0.39145565032958984,
      "learning_rate": 8.569728e-05,
      "loss": 1.7756,
      "step": 89300
    },
    {
      "epoch": 2.8592,
      "grad_norm": 0.4044032692909241,
      "learning_rate": 8.563328e-05,
      "loss": 1.7725,
      "step": 89350
    },
    {
      "epoch": 2.8608000000000002,
      "grad_norm": 0.405743271112442,
      "learning_rate": 8.556928000000001e-05,
      "loss": 1.8114,
      "step": 89400
    },
    {
      "epoch": 2.8624,
      "grad_norm": 0.3440065383911133,
      "learning_rate": 8.550528e-05,
      "loss": 1.8109,
      "step": 89450
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.3289276361465454,
      "learning_rate": 8.544128e-05,
      "loss": 1.784,
      "step": 89500
    },
    {
      "epoch": 2.8656,
      "grad_norm": 0.45685073733329773,
      "learning_rate": 8.537728e-05,
      "loss": 1.7271,
      "step": 89550
    },
    {
      "epoch": 2.8672,
      "grad_norm": 0.3911369740962982,
      "learning_rate": 8.531328000000001e-05,
      "loss": 1.7905,
      "step": 89600
    },
    {
      "epoch": 2.8688000000000002,
      "grad_norm": 0.3579930365085602,
      "learning_rate": 8.524928e-05,
      "loss": 1.7845,
      "step": 89650
    },
    {
      "epoch": 2.8704,
      "grad_norm": 0.3285764455795288,
      "learning_rate": 8.518528e-05,
      "loss": 1.8023,
      "step": 89700
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.296158105134964,
      "learning_rate": 8.512128e-05,
      "loss": 1.7764,
      "step": 89750
    },
    {
      "epoch": 2.8736,
      "grad_norm": 0.37088027596473694,
      "learning_rate": 8.505728e-05,
      "loss": 1.756,
      "step": 89800
    },
    {
      "epoch": 2.8752,
      "grad_norm": 0.3713204264640808,
      "learning_rate": 8.499328000000001e-05,
      "loss": 1.7873,
      "step": 89850
    },
    {
      "epoch": 2.8768000000000002,
      "grad_norm": 0.46410036087036133,
      "learning_rate": 8.492928e-05,
      "loss": 1.7957,
      "step": 89900
    },
    {
      "epoch": 2.8784,
      "grad_norm": 0.30758094787597656,
      "learning_rate": 8.486528e-05,
      "loss": 1.8093,
      "step": 89950
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.35438042879104614,
      "learning_rate": 8.480128000000001e-05,
      "loss": 1.7325,
      "step": 90000
    },
    {
      "epoch": 2.8816,
      "grad_norm": 0.43346449732780457,
      "learning_rate": 8.473728e-05,
      "loss": 1.8144,
      "step": 90050
    },
    {
      "epoch": 2.8832,
      "grad_norm": 0.3213645815849304,
      "learning_rate": 8.467328e-05,
      "loss": 1.7655,
      "step": 90100
    },
    {
      "epoch": 2.8848000000000003,
      "grad_norm": 0.3748520016670227,
      "learning_rate": 8.460928000000001e-05,
      "loss": 1.7963,
      "step": 90150
    },
    {
      "epoch": 2.8864,
      "grad_norm": 0.36150968074798584,
      "learning_rate": 8.454528e-05,
      "loss": 1.7713,
      "step": 90200
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.3716871738433838,
      "learning_rate": 8.448128000000001e-05,
      "loss": 1.7216,
      "step": 90250
    },
    {
      "epoch": 2.8895999999999997,
      "grad_norm": 0.3751429319381714,
      "learning_rate": 8.441728e-05,
      "loss": 1.7848,
      "step": 90300
    },
    {
      "epoch": 2.8912,
      "grad_norm": 0.40814581513404846,
      "learning_rate": 8.435328e-05,
      "loss": 1.8127,
      "step": 90350
    },
    {
      "epoch": 2.8928000000000003,
      "grad_norm": 0.3705672025680542,
      "learning_rate": 8.428928e-05,
      "loss": 1.8568,
      "step": 90400
    },
    {
      "epoch": 2.8944,
      "grad_norm": 0.4071732759475708,
      "learning_rate": 8.422528000000001e-05,
      "loss": 1.77,
      "step": 90450
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.37640151381492615,
      "learning_rate": 8.416128000000002e-05,
      "loss": 1.8108,
      "step": 90500
    },
    {
      "epoch": 2.8975999999999997,
      "grad_norm": 0.35305750370025635,
      "learning_rate": 8.409728e-05,
      "loss": 1.8156,
      "step": 90550
    },
    {
      "epoch": 2.8992,
      "grad_norm": 0.42481857538223267,
      "learning_rate": 8.403328e-05,
      "loss": 1.7911,
      "step": 90600
    },
    {
      "epoch": 2.9008000000000003,
      "grad_norm": 0.38706812262535095,
      "learning_rate": 8.396928e-05,
      "loss": 1.7977,
      "step": 90650
    },
    {
      "epoch": 2.9024,
      "grad_norm": 0.322243869304657,
      "learning_rate": 8.390528000000001e-05,
      "loss": 1.8117,
      "step": 90700
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.43688806891441345,
      "learning_rate": 8.384128e-05,
      "loss": 1.751,
      "step": 90750
    },
    {
      "epoch": 2.9055999999999997,
      "grad_norm": 0.3289779722690582,
      "learning_rate": 8.377728e-05,
      "loss": 1.7754,
      "step": 90800
    },
    {
      "epoch": 2.9072,
      "grad_norm": 0.37647199630737305,
      "learning_rate": 8.371328000000001e-05,
      "loss": 1.8294,
      "step": 90850
    },
    {
      "epoch": 2.9088000000000003,
      "grad_norm": 0.4347987771034241,
      "learning_rate": 8.364928e-05,
      "loss": 1.74,
      "step": 90900
    },
    {
      "epoch": 2.9104,
      "grad_norm": 0.3244728744029999,
      "learning_rate": 8.358528e-05,
      "loss": 1.8458,
      "step": 90950
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.3370799124240875,
      "learning_rate": 8.352128000000001e-05,
      "loss": 1.7801,
      "step": 91000
    },
    {
      "epoch": 2.9135999999999997,
      "grad_norm": 0.4246613681316376,
      "learning_rate": 8.345728e-05,
      "loss": 1.7908,
      "step": 91050
    },
    {
      "epoch": 2.9152,
      "grad_norm": 0.36667945981025696,
      "learning_rate": 8.339328000000001e-05,
      "loss": 1.778,
      "step": 91100
    },
    {
      "epoch": 2.9168,
      "grad_norm": 0.38187557458877563,
      "learning_rate": 8.332928e-05,
      "loss": 1.8197,
      "step": 91150
    },
    {
      "epoch": 2.9184,
      "grad_norm": 0.2937896251678467,
      "learning_rate": 8.326528e-05,
      "loss": 1.7744,
      "step": 91200
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.3215615451335907,
      "learning_rate": 8.320128e-05,
      "loss": 1.8046,
      "step": 91250
    },
    {
      "epoch": 2.9215999999999998,
      "grad_norm": 0.3785513937473297,
      "learning_rate": 8.313728e-05,
      "loss": 1.8591,
      "step": 91300
    },
    {
      "epoch": 2.9232,
      "grad_norm": 0.3727880120277405,
      "learning_rate": 8.307328000000002e-05,
      "loss": 1.7995,
      "step": 91350
    },
    {
      "epoch": 2.9248,
      "grad_norm": 0.4222721457481384,
      "learning_rate": 8.300928e-05,
      "loss": 1.817,
      "step": 91400
    },
    {
      "epoch": 2.9264,
      "grad_norm": 0.45141446590423584,
      "learning_rate": 8.294528e-05,
      "loss": 1.8014,
      "step": 91450
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.38227975368499756,
      "learning_rate": 8.288128e-05,
      "loss": 1.7933,
      "step": 91500
    },
    {
      "epoch": 2.9295999999999998,
      "grad_norm": 0.389717698097229,
      "learning_rate": 8.281728000000001e-05,
      "loss": 1.8354,
      "step": 91550
    },
    {
      "epoch": 2.9312,
      "grad_norm": 0.39787882566452026,
      "learning_rate": 8.275328e-05,
      "loss": 1.7613,
      "step": 91600
    },
    {
      "epoch": 2.9328,
      "grad_norm": 0.3860335350036621,
      "learning_rate": 8.268928e-05,
      "loss": 1.7735,
      "step": 91650
    },
    {
      "epoch": 2.9344,
      "grad_norm": 0.34536969661712646,
      "learning_rate": 8.262528000000001e-05,
      "loss": 1.7589,
      "step": 91700
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.40653902292251587,
      "learning_rate": 8.256128e-05,
      "loss": 1.7652,
      "step": 91750
    },
    {
      "epoch": 2.9375999999999998,
      "grad_norm": 0.3572383522987366,
      "learning_rate": 8.249728e-05,
      "loss": 1.7044,
      "step": 91800
    },
    {
      "epoch": 2.9392,
      "grad_norm": 0.3709873557090759,
      "learning_rate": 8.243328000000001e-05,
      "loss": 1.8058,
      "step": 91850
    },
    {
      "epoch": 2.9408,
      "grad_norm": 0.3185466527938843,
      "learning_rate": 8.236928e-05,
      "loss": 1.8367,
      "step": 91900
    },
    {
      "epoch": 2.9424,
      "grad_norm": 0.3907676935195923,
      "learning_rate": 8.230528000000001e-05,
      "loss": 1.7493,
      "step": 91950
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.33659735321998596,
      "learning_rate": 8.224128000000001e-05,
      "loss": 1.7328,
      "step": 92000
    },
    {
      "epoch": 2.9455999999999998,
      "grad_norm": 0.35484981536865234,
      "learning_rate": 8.217728e-05,
      "loss": 1.8223,
      "step": 92050
    },
    {
      "epoch": 2.9472,
      "grad_norm": 0.3604815602302551,
      "learning_rate": 8.211328e-05,
      "loss": 1.8257,
      "step": 92100
    },
    {
      "epoch": 2.9488,
      "grad_norm": 0.35805177688598633,
      "learning_rate": 8.204928e-05,
      "loss": 1.8088,
      "step": 92150
    },
    {
      "epoch": 2.9504,
      "grad_norm": 0.34388089179992676,
      "learning_rate": 8.198528000000001e-05,
      "loss": 1.7829,
      "step": 92200
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.39939993619918823,
      "learning_rate": 8.192128e-05,
      "loss": 1.7674,
      "step": 92250
    },
    {
      "epoch": 2.9536,
      "grad_norm": 0.39769113063812256,
      "learning_rate": 8.185728e-05,
      "loss": 1.736,
      "step": 92300
    },
    {
      "epoch": 2.9552,
      "grad_norm": 0.3976553976535797,
      "learning_rate": 8.179328e-05,
      "loss": 1.7819,
      "step": 92350
    },
    {
      "epoch": 2.9568,
      "grad_norm": 0.34977462887763977,
      "learning_rate": 8.172928000000001e-05,
      "loss": 1.7181,
      "step": 92400
    },
    {
      "epoch": 2.9584,
      "grad_norm": 0.4224594533443451,
      "learning_rate": 8.166528e-05,
      "loss": 1.8403,
      "step": 92450
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.39942818880081177,
      "learning_rate": 8.160128e-05,
      "loss": 1.7822,
      "step": 92500
    },
    {
      "epoch": 2.9616,
      "grad_norm": 0.3660743832588196,
      "learning_rate": 8.153728000000001e-05,
      "loss": 1.7753,
      "step": 92550
    },
    {
      "epoch": 2.9632,
      "grad_norm": 0.38513290882110596,
      "learning_rate": 8.147328e-05,
      "loss": 1.7677,
      "step": 92600
    },
    {
      "epoch": 2.9648,
      "grad_norm": 0.37662607431411743,
      "learning_rate": 8.140928e-05,
      "loss": 1.7145,
      "step": 92650
    },
    {
      "epoch": 2.9664,
      "grad_norm": 0.34881722927093506,
      "learning_rate": 8.134528000000001e-05,
      "loss": 1.7102,
      "step": 92700
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.4238484501838684,
      "learning_rate": 8.128128e-05,
      "loss": 1.7551,
      "step": 92750
    },
    {
      "epoch": 2.9696,
      "grad_norm": 0.34146881103515625,
      "learning_rate": 8.121728000000001e-05,
      "loss": 1.7694,
      "step": 92800
    },
    {
      "epoch": 2.9712,
      "grad_norm": 0.3582213222980499,
      "learning_rate": 8.115328e-05,
      "loss": 1.7858,
      "step": 92850
    },
    {
      "epoch": 2.9728,
      "grad_norm": 0.38289675116539,
      "learning_rate": 8.108928e-05,
      "loss": 1.7741,
      "step": 92900
    },
    {
      "epoch": 2.9744,
      "grad_norm": 0.3761269748210907,
      "learning_rate": 8.102528e-05,
      "loss": 1.7832,
      "step": 92950
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.47044795751571655,
      "learning_rate": 8.096128e-05,
      "loss": 1.811,
      "step": 93000
    },
    {
      "epoch": 2.9776,
      "grad_norm": 0.3552407920360565,
      "learning_rate": 8.089728000000001e-05,
      "loss": 1.764,
      "step": 93050
    },
    {
      "epoch": 2.9792,
      "grad_norm": 0.32443422079086304,
      "learning_rate": 8.083328e-05,
      "loss": 1.8317,
      "step": 93100
    },
    {
      "epoch": 2.9808,
      "grad_norm": 0.3584975004196167,
      "learning_rate": 8.076928e-05,
      "loss": 1.787,
      "step": 93150
    },
    {
      "epoch": 2.9824,
      "grad_norm": 0.3976190686225891,
      "learning_rate": 8.070528e-05,
      "loss": 1.7115,
      "step": 93200
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.357185423374176,
      "learning_rate": 8.064128000000001e-05,
      "loss": 1.7453,
      "step": 93250
    },
    {
      "epoch": 2.9856,
      "grad_norm": 0.359216570854187,
      "learning_rate": 8.057728e-05,
      "loss": 1.7668,
      "step": 93300
    },
    {
      "epoch": 2.9872,
      "grad_norm": 0.39917418360710144,
      "learning_rate": 8.051328e-05,
      "loss": 1.7751,
      "step": 93350
    },
    {
      "epoch": 2.9888,
      "grad_norm": 0.2923898994922638,
      "learning_rate": 8.044928000000001e-05,
      "loss": 1.8328,
      "step": 93400
    },
    {
      "epoch": 2.9904,
      "grad_norm": 0.3860589861869812,
      "learning_rate": 8.038528e-05,
      "loss": 1.819,
      "step": 93450
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.38614481687545776,
      "learning_rate": 8.032128e-05,
      "loss": 1.8128,
      "step": 93500
    },
    {
      "epoch": 2.9936,
      "grad_norm": 0.3774261772632599,
      "learning_rate": 8.025728000000001e-05,
      "loss": 1.7677,
      "step": 93550
    },
    {
      "epoch": 2.9952,
      "grad_norm": 0.3272389769554138,
      "learning_rate": 8.019328e-05,
      "loss": 1.7589,
      "step": 93600
    },
    {
      "epoch": 2.9968,
      "grad_norm": 0.3851340115070343,
      "learning_rate": 8.012928000000001e-05,
      "loss": 1.8195,
      "step": 93650
    },
    {
      "epoch": 2.9984,
      "grad_norm": 0.3527744710445404,
      "learning_rate": 8.006528e-05,
      "loss": 1.801,
      "step": 93700
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.4042298495769501,
      "learning_rate": 8.000128e-05,
      "loss": 1.7539,
      "step": 93750
    },
    {
      "epoch": 3.0016,
      "grad_norm": 0.3999415934085846,
      "learning_rate": 7.993728000000001e-05,
      "loss": 1.8026,
      "step": 93800
    },
    {
      "epoch": 3.0032,
      "grad_norm": 0.39924299716949463,
      "learning_rate": 7.987328e-05,
      "loss": 1.8005,
      "step": 93850
    },
    {
      "epoch": 3.0048,
      "grad_norm": 0.33995312452316284,
      "learning_rate": 7.980928000000001e-05,
      "loss": 1.7388,
      "step": 93900
    },
    {
      "epoch": 3.0064,
      "grad_norm": 0.45092085003852844,
      "learning_rate": 7.974528e-05,
      "loss": 1.7885,
      "step": 93950
    },
    {
      "epoch": 3.008,
      "grad_norm": 0.34225866198539734,
      "learning_rate": 7.968128e-05,
      "loss": 1.7608,
      "step": 94000
    },
    {
      "epoch": 3.0096,
      "grad_norm": 0.36102646589279175,
      "learning_rate": 7.961728e-05,
      "loss": 1.7283,
      "step": 94050
    },
    {
      "epoch": 3.0112,
      "grad_norm": 0.3519670069217682,
      "learning_rate": 7.955328000000001e-05,
      "loss": 1.7724,
      "step": 94100
    },
    {
      "epoch": 3.0128,
      "grad_norm": 0.44658970832824707,
      "learning_rate": 7.948928e-05,
      "loss": 1.7552,
      "step": 94150
    },
    {
      "epoch": 3.0144,
      "grad_norm": 0.4650832712650299,
      "learning_rate": 7.942528e-05,
      "loss": 1.697,
      "step": 94200
    },
    {
      "epoch": 3.016,
      "grad_norm": 0.3212844431400299,
      "learning_rate": 7.936128000000001e-05,
      "loss": 1.7694,
      "step": 94250
    },
    {
      "epoch": 3.0176,
      "grad_norm": 0.352021187543869,
      "learning_rate": 7.929728e-05,
      "loss": 1.7613,
      "step": 94300
    },
    {
      "epoch": 3.0192,
      "grad_norm": 0.3351536989212036,
      "learning_rate": 7.923328e-05,
      "loss": 1.7653,
      "step": 94350
    },
    {
      "epoch": 3.0208,
      "grad_norm": 0.4184243083000183,
      "learning_rate": 7.916928e-05,
      "loss": 1.8039,
      "step": 94400
    },
    {
      "epoch": 3.0224,
      "grad_norm": 0.3530484139919281,
      "learning_rate": 7.910528e-05,
      "loss": 1.7489,
      "step": 94450
    },
    {
      "epoch": 3.024,
      "grad_norm": 0.4391011595726013,
      "learning_rate": 7.904128000000001e-05,
      "loss": 1.778,
      "step": 94500
    },
    {
      "epoch": 3.0256,
      "grad_norm": 0.3997315466403961,
      "learning_rate": 7.897728e-05,
      "loss": 1.7625,
      "step": 94550
    },
    {
      "epoch": 3.0272,
      "grad_norm": 0.4661410450935364,
      "learning_rate": 7.891328e-05,
      "loss": 1.7569,
      "step": 94600
    },
    {
      "epoch": 3.0288,
      "grad_norm": 0.3317011594772339,
      "learning_rate": 7.884928000000001e-05,
      "loss": 1.8397,
      "step": 94650
    },
    {
      "epoch": 3.0304,
      "grad_norm": 0.43469393253326416,
      "learning_rate": 7.878528e-05,
      "loss": 1.8463,
      "step": 94700
    },
    {
      "epoch": 3.032,
      "grad_norm": 0.33033886551856995,
      "learning_rate": 7.872128000000001e-05,
      "loss": 1.7969,
      "step": 94750
    },
    {
      "epoch": 3.0336,
      "grad_norm": 0.336423397064209,
      "learning_rate": 7.865728e-05,
      "loss": 1.7998,
      "step": 94800
    },
    {
      "epoch": 3.0352,
      "grad_norm": 0.37787967920303345,
      "learning_rate": 7.859328e-05,
      "loss": 1.7862,
      "step": 94850
    },
    {
      "epoch": 3.0368,
      "grad_norm": 0.3977680802345276,
      "learning_rate": 7.852928e-05,
      "loss": 1.7459,
      "step": 94900
    },
    {
      "epoch": 3.0384,
      "grad_norm": 0.34079843759536743,
      "learning_rate": 7.846528000000001e-05,
      "loss": 1.7912,
      "step": 94950
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.41774678230285645,
      "learning_rate": 7.840128e-05,
      "loss": 1.7029,
      "step": 95000
    },
    {
      "epoch": 3.0416,
      "grad_norm": 0.38248950242996216,
      "learning_rate": 7.833728e-05,
      "loss": 1.7851,
      "step": 95050
    },
    {
      "epoch": 3.0432,
      "grad_norm": 0.39259788393974304,
      "learning_rate": 7.827328000000001e-05,
      "loss": 1.7378,
      "step": 95100
    },
    {
      "epoch": 3.0448,
      "grad_norm": 0.3905002772808075,
      "learning_rate": 7.820928e-05,
      "loss": 1.7712,
      "step": 95150
    },
    {
      "epoch": 3.0464,
      "grad_norm": 0.346940279006958,
      "learning_rate": 7.814528e-05,
      "loss": 1.7317,
      "step": 95200
    },
    {
      "epoch": 3.048,
      "grad_norm": 0.48276111483573914,
      "learning_rate": 7.808128e-05,
      "loss": 1.7256,
      "step": 95250
    },
    {
      "epoch": 3.0496,
      "grad_norm": 0.31786108016967773,
      "learning_rate": 7.801728e-05,
      "loss": 1.7319,
      "step": 95300
    },
    {
      "epoch": 3.0512,
      "grad_norm": 0.3365127444267273,
      "learning_rate": 7.795328000000001e-05,
      "loss": 1.674,
      "step": 95350
    },
    {
      "epoch": 3.0528,
      "grad_norm": 0.40543580055236816,
      "learning_rate": 7.788928e-05,
      "loss": 1.7556,
      "step": 95400
    },
    {
      "epoch": 3.0544,
      "grad_norm": 0.384202778339386,
      "learning_rate": 7.782528e-05,
      "loss": 1.806,
      "step": 95450
    },
    {
      "epoch": 3.056,
      "grad_norm": 0.36332178115844727,
      "learning_rate": 7.776128000000001e-05,
      "loss": 1.8407,
      "step": 95500
    },
    {
      "epoch": 3.0576,
      "grad_norm": 0.41115739941596985,
      "learning_rate": 7.769728e-05,
      "loss": 1.7625,
      "step": 95550
    },
    {
      "epoch": 3.0592,
      "grad_norm": 0.31737884879112244,
      "learning_rate": 7.763328000000001e-05,
      "loss": 1.754,
      "step": 95600
    },
    {
      "epoch": 3.0608,
      "grad_norm": 0.436600923538208,
      "learning_rate": 7.756928e-05,
      "loss": 1.7883,
      "step": 95650
    },
    {
      "epoch": 3.0624,
      "grad_norm": 0.2991808354854584,
      "learning_rate": 7.750528e-05,
      "loss": 1.7351,
      "step": 95700
    },
    {
      "epoch": 3.064,
      "grad_norm": 0.4434317648410797,
      "learning_rate": 7.744128e-05,
      "loss": 1.7227,
      "step": 95750
    },
    {
      "epoch": 3.0656,
      "grad_norm": 0.4240838587284088,
      "learning_rate": 7.737728000000001e-05,
      "loss": 1.8127,
      "step": 95800
    },
    {
      "epoch": 3.0672,
      "grad_norm": 0.39170899987220764,
      "learning_rate": 7.731328e-05,
      "loss": 1.8122,
      "step": 95850
    },
    {
      "epoch": 3.0688,
      "grad_norm": 0.40965306758880615,
      "learning_rate": 7.724928e-05,
      "loss": 1.7975,
      "step": 95900
    },
    {
      "epoch": 3.0704,
      "grad_norm": 0.32861289381980896,
      "learning_rate": 7.718528e-05,
      "loss": 1.766,
      "step": 95950
    },
    {
      "epoch": 3.072,
      "grad_norm": 0.3977653980255127,
      "learning_rate": 7.712128e-05,
      "loss": 1.8202,
      "step": 96000
    },
    {
      "epoch": 3.0736,
      "grad_norm": 0.3572162687778473,
      "learning_rate": 7.705728e-05,
      "loss": 1.7934,
      "step": 96050
    },
    {
      "epoch": 3.0752,
      "grad_norm": 0.3759081959724426,
      "learning_rate": 7.699328e-05,
      "loss": 1.8187,
      "step": 96100
    },
    {
      "epoch": 3.0768,
      "grad_norm": 0.5614993572235107,
      "learning_rate": 7.692928e-05,
      "loss": 1.7572,
      "step": 96150
    },
    {
      "epoch": 3.0784,
      "grad_norm": 0.3967827558517456,
      "learning_rate": 7.686528000000001e-05,
      "loss": 1.8205,
      "step": 96200
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.3286421597003937,
      "learning_rate": 7.680128e-05,
      "loss": 1.7926,
      "step": 96250
    },
    {
      "epoch": 3.0816,
      "grad_norm": 0.3582170307636261,
      "learning_rate": 7.673728e-05,
      "loss": 1.7698,
      "step": 96300
    },
    {
      "epoch": 3.0832,
      "grad_norm": 0.45974957942962646,
      "learning_rate": 7.667328000000001e-05,
      "loss": 1.7852,
      "step": 96350
    },
    {
      "epoch": 3.0848,
      "grad_norm": 0.4214136302471161,
      "learning_rate": 7.660928e-05,
      "loss": 1.7633,
      "step": 96400
    },
    {
      "epoch": 3.0864,
      "grad_norm": 0.34806618094444275,
      "learning_rate": 7.654528000000001e-05,
      "loss": 1.7629,
      "step": 96450
    },
    {
      "epoch": 3.088,
      "grad_norm": 0.323807030916214,
      "learning_rate": 7.648128e-05,
      "loss": 1.7402,
      "step": 96500
    },
    {
      "epoch": 3.0896,
      "grad_norm": 0.37095338106155396,
      "learning_rate": 7.641728e-05,
      "loss": 1.7567,
      "step": 96550
    },
    {
      "epoch": 3.0912,
      "grad_norm": 0.3804415762424469,
      "learning_rate": 7.635328e-05,
      "loss": 1.7799,
      "step": 96600
    },
    {
      "epoch": 3.0928,
      "grad_norm": 0.3541668951511383,
      "learning_rate": 7.628928000000001e-05,
      "loss": 1.7558,
      "step": 96650
    },
    {
      "epoch": 3.0944,
      "grad_norm": 0.39286109805107117,
      "learning_rate": 7.622528e-05,
      "loss": 1.847,
      "step": 96700
    },
    {
      "epoch": 3.096,
      "grad_norm": 0.3026064932346344,
      "learning_rate": 7.616128e-05,
      "loss": 1.7667,
      "step": 96750
    },
    {
      "epoch": 3.0976,
      "grad_norm": 0.34368622303009033,
      "learning_rate": 7.609728e-05,
      "loss": 1.7745,
      "step": 96800
    },
    {
      "epoch": 3.0992,
      "grad_norm": 0.3611186146736145,
      "learning_rate": 7.603328e-05,
      "loss": 1.7362,
      "step": 96850
    },
    {
      "epoch": 3.1008,
      "grad_norm": 0.36709386110305786,
      "learning_rate": 7.596928e-05,
      "loss": 1.8288,
      "step": 96900
    },
    {
      "epoch": 3.1024,
      "grad_norm": 0.40823614597320557,
      "learning_rate": 7.590528e-05,
      "loss": 1.7846,
      "step": 96950
    },
    {
      "epoch": 3.104,
      "grad_norm": 0.36353063583374023,
      "learning_rate": 7.584128e-05,
      "loss": 1.7617,
      "step": 97000
    },
    {
      "epoch": 3.1056,
      "grad_norm": 0.4515739679336548,
      "learning_rate": 7.577728000000001e-05,
      "loss": 1.7967,
      "step": 97050
    },
    {
      "epoch": 3.1072,
      "grad_norm": 0.44774508476257324,
      "learning_rate": 7.571328e-05,
      "loss": 1.7573,
      "step": 97100
    },
    {
      "epoch": 3.1088,
      "grad_norm": 0.32424309849739075,
      "learning_rate": 7.564928e-05,
      "loss": 1.8224,
      "step": 97150
    },
    {
      "epoch": 3.1104,
      "grad_norm": 0.43345651030540466,
      "learning_rate": 7.558528000000001e-05,
      "loss": 1.7623,
      "step": 97200
    },
    {
      "epoch": 3.112,
      "grad_norm": 0.4712494909763336,
      "learning_rate": 7.552128e-05,
      "loss": 1.7595,
      "step": 97250
    },
    {
      "epoch": 3.1136,
      "grad_norm": 0.39919909834861755,
      "learning_rate": 7.545728000000001e-05,
      "loss": 1.8042,
      "step": 97300
    },
    {
      "epoch": 3.1152,
      "grad_norm": 0.3579983115196228,
      "learning_rate": 7.539328e-05,
      "loss": 1.7531,
      "step": 97350
    },
    {
      "epoch": 3.1168,
      "grad_norm": 0.34610652923583984,
      "learning_rate": 7.532928e-05,
      "loss": 1.7712,
      "step": 97400
    },
    {
      "epoch": 3.1184,
      "grad_norm": 0.4055287539958954,
      "learning_rate": 7.526528000000001e-05,
      "loss": 1.8333,
      "step": 97450
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.4801543056964874,
      "learning_rate": 7.520128e-05,
      "loss": 1.8022,
      "step": 97500
    },
    {
      "epoch": 3.1216,
      "grad_norm": 0.38641780614852905,
      "learning_rate": 7.513728e-05,
      "loss": 1.7711,
      "step": 97550
    },
    {
      "epoch": 3.1232,
      "grad_norm": 0.4195464253425598,
      "learning_rate": 7.507328e-05,
      "loss": 1.7843,
      "step": 97600
    },
    {
      "epoch": 3.1248,
      "grad_norm": 0.3457532823085785,
      "learning_rate": 7.500928e-05,
      "loss": 1.8053,
      "step": 97650
    },
    {
      "epoch": 3.1264,
      "grad_norm": 0.3947533071041107,
      "learning_rate": 7.494528e-05,
      "loss": 1.7976,
      "step": 97700
    },
    {
      "epoch": 3.128,
      "grad_norm": 0.3556593060493469,
      "learning_rate": 7.488128e-05,
      "loss": 1.7405,
      "step": 97750
    },
    {
      "epoch": 3.1296,
      "grad_norm": 0.4033799171447754,
      "learning_rate": 7.481728e-05,
      "loss": 1.7706,
      "step": 97800
    },
    {
      "epoch": 3.1312,
      "grad_norm": 0.3265429437160492,
      "learning_rate": 7.475328e-05,
      "loss": 1.7545,
      "step": 97850
    },
    {
      "epoch": 3.1328,
      "grad_norm": 0.42980948090553284,
      "learning_rate": 7.468928000000001e-05,
      "loss": 1.7477,
      "step": 97900
    },
    {
      "epoch": 3.1344,
      "grad_norm": 0.4519645571708679,
      "learning_rate": 7.462528e-05,
      "loss": 1.8198,
      "step": 97950
    },
    {
      "epoch": 3.136,
      "grad_norm": 0.36576011776924133,
      "learning_rate": 7.456128e-05,
      "loss": 1.7344,
      "step": 98000
    },
    {
      "epoch": 3.1376,
      "grad_norm": 0.3682537078857422,
      "learning_rate": 7.449728000000001e-05,
      "loss": 1.8054,
      "step": 98050
    },
    {
      "epoch": 3.1391999999999998,
      "grad_norm": 0.378639280796051,
      "learning_rate": 7.443328e-05,
      "loss": 1.7204,
      "step": 98100
    },
    {
      "epoch": 3.1408,
      "grad_norm": 0.3743065893650055,
      "learning_rate": 7.436928000000001e-05,
      "loss": 1.801,
      "step": 98150
    },
    {
      "epoch": 3.1424,
      "grad_norm": 0.30796971917152405,
      "learning_rate": 7.430528e-05,
      "loss": 1.7882,
      "step": 98200
    },
    {
      "epoch": 3.144,
      "grad_norm": 0.3815135061740875,
      "learning_rate": 7.424128e-05,
      "loss": 1.7732,
      "step": 98250
    },
    {
      "epoch": 3.1456,
      "grad_norm": 0.3499683141708374,
      "learning_rate": 7.417728000000001e-05,
      "loss": 1.7603,
      "step": 98300
    },
    {
      "epoch": 3.1471999999999998,
      "grad_norm": 0.4495147168636322,
      "learning_rate": 7.411328e-05,
      "loss": 1.7878,
      "step": 98350
    },
    {
      "epoch": 3.1488,
      "grad_norm": 0.39507749676704407,
      "learning_rate": 7.404928e-05,
      "loss": 1.781,
      "step": 98400
    },
    {
      "epoch": 3.1504,
      "grad_norm": 0.31894269585609436,
      "learning_rate": 7.398528e-05,
      "loss": 1.7856,
      "step": 98450
    },
    {
      "epoch": 3.152,
      "grad_norm": 0.41283923387527466,
      "learning_rate": 7.392128e-05,
      "loss": 1.8039,
      "step": 98500
    },
    {
      "epoch": 3.1536,
      "grad_norm": 0.35089191794395447,
      "learning_rate": 7.385728e-05,
      "loss": 1.8053,
      "step": 98550
    },
    {
      "epoch": 3.1552,
      "grad_norm": 0.4373128116130829,
      "learning_rate": 7.379328000000001e-05,
      "loss": 1.7059,
      "step": 98600
    },
    {
      "epoch": 3.1568,
      "grad_norm": 0.42612147331237793,
      "learning_rate": 7.372928e-05,
      "loss": 1.787,
      "step": 98650
    },
    {
      "epoch": 3.1584,
      "grad_norm": 0.4218231737613678,
      "learning_rate": 7.366528e-05,
      "loss": 1.7879,
      "step": 98700
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.42436906695365906,
      "learning_rate": 7.360128000000001e-05,
      "loss": 1.7734,
      "step": 98750
    },
    {
      "epoch": 3.1616,
      "grad_norm": 0.414922297000885,
      "learning_rate": 7.353728e-05,
      "loss": 1.6981,
      "step": 98800
    },
    {
      "epoch": 3.1632,
      "grad_norm": 0.3903064429759979,
      "learning_rate": 7.347328e-05,
      "loss": 1.7893,
      "step": 98850
    },
    {
      "epoch": 3.1648,
      "grad_norm": 0.3472117781639099,
      "learning_rate": 7.340928000000001e-05,
      "loss": 1.715,
      "step": 98900
    },
    {
      "epoch": 3.1664,
      "grad_norm": 0.40661337971687317,
      "learning_rate": 7.334528e-05,
      "loss": 1.7924,
      "step": 98950
    },
    {
      "epoch": 3.168,
      "grad_norm": 0.40737229585647583,
      "learning_rate": 7.328128000000001e-05,
      "loss": 1.7583,
      "step": 99000
    },
    {
      "epoch": 3.1696,
      "grad_norm": 0.4087611734867096,
      "learning_rate": 7.321727999999999e-05,
      "loss": 1.7766,
      "step": 99050
    },
    {
      "epoch": 3.1712,
      "grad_norm": 0.48807069659233093,
      "learning_rate": 7.315328e-05,
      "loss": 1.813,
      "step": 99100
    },
    {
      "epoch": 3.1728,
      "grad_norm": 0.4324985146522522,
      "learning_rate": 7.308928000000001e-05,
      "loss": 1.8216,
      "step": 99150
    },
    {
      "epoch": 3.1744,
      "grad_norm": 0.3640301823616028,
      "learning_rate": 7.302528e-05,
      "loss": 1.7789,
      "step": 99200
    },
    {
      "epoch": 3.176,
      "grad_norm": 0.41889306902885437,
      "learning_rate": 7.296128e-05,
      "loss": 1.7428,
      "step": 99250
    },
    {
      "epoch": 3.1776,
      "grad_norm": 0.42738473415374756,
      "learning_rate": 7.289728e-05,
      "loss": 1.7903,
      "step": 99300
    },
    {
      "epoch": 3.1792,
      "grad_norm": 0.32386162877082825,
      "learning_rate": 7.283328e-05,
      "loss": 1.7541,
      "step": 99350
    },
    {
      "epoch": 3.1808,
      "grad_norm": 0.36515143513679504,
      "learning_rate": 7.276928e-05,
      "loss": 1.7083,
      "step": 99400
    },
    {
      "epoch": 3.1824,
      "grad_norm": 0.404073566198349,
      "learning_rate": 7.270528000000001e-05,
      "loss": 1.763,
      "step": 99450
    },
    {
      "epoch": 3.184,
      "grad_norm": 0.4541586637496948,
      "learning_rate": 7.264128e-05,
      "loss": 1.7181,
      "step": 99500
    },
    {
      "epoch": 3.1856,
      "grad_norm": 0.4848594069480896,
      "learning_rate": 7.257728e-05,
      "loss": 1.7599,
      "step": 99550
    },
    {
      "epoch": 3.1872,
      "grad_norm": 0.3775961399078369,
      "learning_rate": 7.251328000000001e-05,
      "loss": 1.6295,
      "step": 99600
    },
    {
      "epoch": 3.1888,
      "grad_norm": 0.3670421540737152,
      "learning_rate": 7.244928e-05,
      "loss": 1.8218,
      "step": 99650
    },
    {
      "epoch": 3.1904,
      "grad_norm": 0.3981527090072632,
      "learning_rate": 7.238528e-05,
      "loss": 1.7196,
      "step": 99700
    },
    {
      "epoch": 3.192,
      "grad_norm": 0.42643436789512634,
      "learning_rate": 7.232128000000001e-05,
      "loss": 1.7343,
      "step": 99750
    },
    {
      "epoch": 3.1936,
      "grad_norm": 0.5196478366851807,
      "learning_rate": 7.225728e-05,
      "loss": 1.7462,
      "step": 99800
    },
    {
      "epoch": 3.1952,
      "grad_norm": 0.4354279041290283,
      "learning_rate": 7.219328000000001e-05,
      "loss": 1.7904,
      "step": 99850
    },
    {
      "epoch": 3.1968,
      "grad_norm": 0.47157734632492065,
      "learning_rate": 7.212927999999999e-05,
      "loss": 1.8185,
      "step": 99900
    },
    {
      "epoch": 3.1984,
      "grad_norm": 0.4038999378681183,
      "learning_rate": 7.206528e-05,
      "loss": 1.7572,
      "step": 99950
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.39709657430648804,
      "learning_rate": 7.200128000000001e-05,
      "loss": 1.8376,
      "step": 100000
    },
    {
      "epoch": 3.2016,
      "grad_norm": 0.43065330386161804,
      "learning_rate": 7.193728e-05,
      "loss": 1.8178,
      "step": 100050
    },
    {
      "epoch": 3.2032,
      "grad_norm": 0.36306896805763245,
      "learning_rate": 7.187328e-05,
      "loss": 1.7675,
      "step": 100100
    },
    {
      "epoch": 3.2048,
      "grad_norm": 0.32471561431884766,
      "learning_rate": 7.180928e-05,
      "loss": 1.7868,
      "step": 100150
    },
    {
      "epoch": 3.2064,
      "grad_norm": 0.40280047059059143,
      "learning_rate": 7.174528e-05,
      "loss": 1.775,
      "step": 100200
    },
    {
      "epoch": 3.208,
      "grad_norm": 0.5576446056365967,
      "learning_rate": 7.168128e-05,
      "loss": 1.7106,
      "step": 100250
    },
    {
      "epoch": 3.2096,
      "grad_norm": 0.3849457800388336,
      "learning_rate": 7.161728000000001e-05,
      "loss": 1.7764,
      "step": 100300
    },
    {
      "epoch": 3.2112,
      "grad_norm": 0.36729034781455994,
      "learning_rate": 7.155328e-05,
      "loss": 1.7857,
      "step": 100350
    },
    {
      "epoch": 3.2128,
      "grad_norm": 0.35261452198028564,
      "learning_rate": 7.148928e-05,
      "loss": 1.7648,
      "step": 100400
    },
    {
      "epoch": 3.2144,
      "grad_norm": 0.4310184717178345,
      "learning_rate": 7.142528000000001e-05,
      "loss": 1.7366,
      "step": 100450
    },
    {
      "epoch": 3.216,
      "grad_norm": 0.3707617521286011,
      "learning_rate": 7.136128e-05,
      "loss": 1.7383,
      "step": 100500
    },
    {
      "epoch": 3.2176,
      "grad_norm": 0.33809274435043335,
      "learning_rate": 7.129728e-05,
      "loss": 1.7809,
      "step": 100550
    },
    {
      "epoch": 3.2192,
      "grad_norm": 0.41193920373916626,
      "learning_rate": 7.123328e-05,
      "loss": 1.7581,
      "step": 100600
    },
    {
      "epoch": 3.2208,
      "grad_norm": 0.44266608357429504,
      "learning_rate": 7.116928e-05,
      "loss": 1.7506,
      "step": 100650
    },
    {
      "epoch": 3.2224,
      "grad_norm": 0.3803257644176483,
      "learning_rate": 7.110528000000001e-05,
      "loss": 1.7481,
      "step": 100700
    },
    {
      "epoch": 3.224,
      "grad_norm": 0.47771209478378296,
      "learning_rate": 7.104128e-05,
      "loss": 1.7671,
      "step": 100750
    },
    {
      "epoch": 3.2256,
      "grad_norm": 0.4289107620716095,
      "learning_rate": 7.097728e-05,
      "loss": 1.7595,
      "step": 100800
    },
    {
      "epoch": 3.2272,
      "grad_norm": 0.37946444749832153,
      "learning_rate": 7.091328000000001e-05,
      "loss": 1.8411,
      "step": 100850
    },
    {
      "epoch": 3.2288,
      "grad_norm": 0.42189306020736694,
      "learning_rate": 7.084928e-05,
      "loss": 1.761,
      "step": 100900
    },
    {
      "epoch": 3.2304,
      "grad_norm": 0.46037691831588745,
      "learning_rate": 7.078528e-05,
      "loss": 1.8008,
      "step": 100950
    },
    {
      "epoch": 3.232,
      "grad_norm": 0.39035236835479736,
      "learning_rate": 7.072128e-05,
      "loss": 1.7623,
      "step": 101000
    },
    {
      "epoch": 3.2336,
      "grad_norm": 0.45962703227996826,
      "learning_rate": 7.065728e-05,
      "loss": 1.8188,
      "step": 101050
    },
    {
      "epoch": 3.2352,
      "grad_norm": 0.4382787048816681,
      "learning_rate": 7.059328000000001e-05,
      "loss": 1.7511,
      "step": 101100
    },
    {
      "epoch": 3.2368,
      "grad_norm": 0.363369882106781,
      "learning_rate": 7.052928000000001e-05,
      "loss": 1.7109,
      "step": 101150
    },
    {
      "epoch": 3.2384,
      "grad_norm": 0.4395459294319153,
      "learning_rate": 7.046528e-05,
      "loss": 1.7417,
      "step": 101200
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.4095819592475891,
      "learning_rate": 7.040128e-05,
      "loss": 1.7398,
      "step": 101250
    },
    {
      "epoch": 3.2416,
      "grad_norm": 0.43955349922180176,
      "learning_rate": 7.033728000000001e-05,
      "loss": 1.7523,
      "step": 101300
    },
    {
      "epoch": 3.2432,
      "grad_norm": 0.4580343961715698,
      "learning_rate": 7.027328e-05,
      "loss": 1.7827,
      "step": 101350
    },
    {
      "epoch": 3.2448,
      "grad_norm": 0.39180028438568115,
      "learning_rate": 7.020928e-05,
      "loss": 1.751,
      "step": 101400
    },
    {
      "epoch": 3.2464,
      "grad_norm": 0.37486591935157776,
      "learning_rate": 7.014528e-05,
      "loss": 1.8079,
      "step": 101450
    },
    {
      "epoch": 3.248,
      "grad_norm": 0.38300129771232605,
      "learning_rate": 7.008128e-05,
      "loss": 1.7317,
      "step": 101500
    },
    {
      "epoch": 3.2496,
      "grad_norm": 0.36906176805496216,
      "learning_rate": 7.001728000000001e-05,
      "loss": 1.7849,
      "step": 101550
    },
    {
      "epoch": 3.2512,
      "grad_norm": 0.4001976549625397,
      "learning_rate": 6.995328e-05,
      "loss": 1.7883,
      "step": 101600
    },
    {
      "epoch": 3.2528,
      "grad_norm": 0.36889708042144775,
      "learning_rate": 6.988928e-05,
      "loss": 1.7591,
      "step": 101650
    },
    {
      "epoch": 3.2544,
      "grad_norm": 0.40273529291152954,
      "learning_rate": 6.982528000000001e-05,
      "loss": 1.7912,
      "step": 101700
    },
    {
      "epoch": 3.2560000000000002,
      "grad_norm": 0.3744947612285614,
      "learning_rate": 6.976128e-05,
      "loss": 1.7503,
      "step": 101750
    },
    {
      "epoch": 3.2576,
      "grad_norm": 0.33644479513168335,
      "learning_rate": 6.969728e-05,
      "loss": 1.7254,
      "step": 101800
    },
    {
      "epoch": 3.2592,
      "grad_norm": 0.3673704266548157,
      "learning_rate": 6.963328e-05,
      "loss": 1.7666,
      "step": 101850
    },
    {
      "epoch": 3.2608,
      "grad_norm": 0.4079018533229828,
      "learning_rate": 6.956928e-05,
      "loss": 1.8164,
      "step": 101900
    },
    {
      "epoch": 3.2624,
      "grad_norm": 0.3862692713737488,
      "learning_rate": 6.950528000000001e-05,
      "loss": 1.7577,
      "step": 101950
    },
    {
      "epoch": 3.2640000000000002,
      "grad_norm": 0.34463679790496826,
      "learning_rate": 6.944128000000001e-05,
      "loss": 1.7338,
      "step": 102000
    },
    {
      "epoch": 3.2656,
      "grad_norm": 0.3352329432964325,
      "learning_rate": 6.937728e-05,
      "loss": 1.7552,
      "step": 102050
    },
    {
      "epoch": 3.2672,
      "grad_norm": 0.33604538440704346,
      "learning_rate": 6.931328e-05,
      "loss": 1.772,
      "step": 102100
    },
    {
      "epoch": 3.2688,
      "grad_norm": 0.4259146451950073,
      "learning_rate": 6.924928e-05,
      "loss": 1.736,
      "step": 102150
    },
    {
      "epoch": 3.2704,
      "grad_norm": 0.3926599621772766,
      "learning_rate": 6.918528e-05,
      "loss": 1.8062,
      "step": 102200
    },
    {
      "epoch": 3.2720000000000002,
      "grad_norm": 0.3615584373474121,
      "learning_rate": 6.912128e-05,
      "loss": 1.7965,
      "step": 102250
    },
    {
      "epoch": 3.2736,
      "grad_norm": 0.40691038966178894,
      "learning_rate": 6.905728e-05,
      "loss": 1.7968,
      "step": 102300
    },
    {
      "epoch": 3.2752,
      "grad_norm": 0.3723047375679016,
      "learning_rate": 6.899328e-05,
      "loss": 1.7478,
      "step": 102350
    },
    {
      "epoch": 3.2768,
      "grad_norm": 0.3629545271396637,
      "learning_rate": 6.892928000000001e-05,
      "loss": 1.7638,
      "step": 102400
    },
    {
      "epoch": 3.2784,
      "grad_norm": 0.3818487823009491,
      "learning_rate": 6.886528e-05,
      "loss": 1.7418,
      "step": 102450
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.4015181064605713,
      "learning_rate": 6.880128e-05,
      "loss": 1.7797,
      "step": 102500
    },
    {
      "epoch": 3.2816,
      "grad_norm": 0.4720790684223175,
      "learning_rate": 6.873728000000001e-05,
      "loss": 1.8222,
      "step": 102550
    },
    {
      "epoch": 3.2832,
      "grad_norm": 0.3711100220680237,
      "learning_rate": 6.867328e-05,
      "loss": 1.772,
      "step": 102600
    },
    {
      "epoch": 3.2848,
      "grad_norm": 0.3447846472263336,
      "learning_rate": 6.860928e-05,
      "loss": 1.7614,
      "step": 102650
    },
    {
      "epoch": 3.2864,
      "grad_norm": 0.40753573179244995,
      "learning_rate": 6.854528e-05,
      "loss": 1.7988,
      "step": 102700
    },
    {
      "epoch": 3.288,
      "grad_norm": 0.34635666012763977,
      "learning_rate": 6.848128e-05,
      "loss": 1.7058,
      "step": 102750
    },
    {
      "epoch": 3.2896,
      "grad_norm": 0.37292954325675964,
      "learning_rate": 6.841728000000001e-05,
      "loss": 1.7224,
      "step": 102800
    },
    {
      "epoch": 3.2912,
      "grad_norm": 0.4563635289669037,
      "learning_rate": 6.835328000000001e-05,
      "loss": 1.7927,
      "step": 102850
    },
    {
      "epoch": 3.2928,
      "grad_norm": 0.4307396709918976,
      "learning_rate": 6.828928e-05,
      "loss": 1.7926,
      "step": 102900
    },
    {
      "epoch": 3.2944,
      "grad_norm": 0.3193362057209015,
      "learning_rate": 6.822528e-05,
      "loss": 1.7553,
      "step": 102950
    },
    {
      "epoch": 3.296,
      "grad_norm": 0.3947739601135254,
      "learning_rate": 6.816128e-05,
      "loss": 1.7611,
      "step": 103000
    },
    {
      "epoch": 3.2976,
      "grad_norm": 0.3903130292892456,
      "learning_rate": 6.809728e-05,
      "loss": 1.7445,
      "step": 103050
    },
    {
      "epoch": 3.2992,
      "grad_norm": 0.4070461094379425,
      "learning_rate": 6.803328e-05,
      "loss": 1.7304,
      "step": 103100
    },
    {
      "epoch": 3.3008,
      "grad_norm": 0.4735458791255951,
      "learning_rate": 6.796928e-05,
      "loss": 1.7526,
      "step": 103150
    },
    {
      "epoch": 3.3024,
      "grad_norm": 0.37610626220703125,
      "learning_rate": 6.790528e-05,
      "loss": 1.749,
      "step": 103200
    },
    {
      "epoch": 3.304,
      "grad_norm": 0.40474796295166016,
      "learning_rate": 6.784128000000001e-05,
      "loss": 1.7869,
      "step": 103250
    },
    {
      "epoch": 3.3056,
      "grad_norm": 0.3953711688518524,
      "learning_rate": 6.777728e-05,
      "loss": 1.7883,
      "step": 103300
    },
    {
      "epoch": 3.3072,
      "grad_norm": 0.33759981393814087,
      "learning_rate": 6.771328e-05,
      "loss": 1.8008,
      "step": 103350
    },
    {
      "epoch": 3.3088,
      "grad_norm": 0.3570740818977356,
      "learning_rate": 6.764928000000001e-05,
      "loss": 1.7264,
      "step": 103400
    },
    {
      "epoch": 3.3104,
      "grad_norm": 0.37675172090530396,
      "learning_rate": 6.758528e-05,
      "loss": 1.8605,
      "step": 103450
    },
    {
      "epoch": 3.312,
      "grad_norm": 0.41137903928756714,
      "learning_rate": 6.752128e-05,
      "loss": 1.7269,
      "step": 103500
    },
    {
      "epoch": 3.3136,
      "grad_norm": 0.3453836441040039,
      "learning_rate": 6.745728e-05,
      "loss": 1.6838,
      "step": 103550
    },
    {
      "epoch": 3.3152,
      "grad_norm": 0.37358948588371277,
      "learning_rate": 6.739328e-05,
      "loss": 1.7597,
      "step": 103600
    },
    {
      "epoch": 3.3168,
      "grad_norm": 0.3992234766483307,
      "learning_rate": 6.732928000000001e-05,
      "loss": 1.798,
      "step": 103650
    },
    {
      "epoch": 3.3184,
      "grad_norm": 0.38584083318710327,
      "learning_rate": 6.726528e-05,
      "loss": 1.8197,
      "step": 103700
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.3474726676940918,
      "learning_rate": 6.720128e-05,
      "loss": 1.7862,
      "step": 103750
    },
    {
      "epoch": 3.3216,
      "grad_norm": 0.39817172288894653,
      "learning_rate": 6.713728e-05,
      "loss": 1.8148,
      "step": 103800
    },
    {
      "epoch": 3.3232,
      "grad_norm": 0.3596416711807251,
      "learning_rate": 6.707328e-05,
      "loss": 1.7927,
      "step": 103850
    },
    {
      "epoch": 3.3247999999999998,
      "grad_norm": 0.5307477712631226,
      "learning_rate": 6.700928e-05,
      "loss": 1.7976,
      "step": 103900
    },
    {
      "epoch": 3.3264,
      "grad_norm": 0.37949877977371216,
      "learning_rate": 6.694528e-05,
      "loss": 1.7757,
      "step": 103950
    },
    {
      "epoch": 3.328,
      "grad_norm": 0.33890578150749207,
      "learning_rate": 6.688128e-05,
      "loss": 1.7434,
      "step": 104000
    },
    {
      "epoch": 3.3296,
      "grad_norm": 0.3415808081626892,
      "learning_rate": 6.681728e-05,
      "loss": 1.7569,
      "step": 104050
    },
    {
      "epoch": 3.3312,
      "grad_norm": 0.44361868500709534,
      "learning_rate": 6.675328000000001e-05,
      "loss": 1.7943,
      "step": 104100
    },
    {
      "epoch": 3.3327999999999998,
      "grad_norm": 0.3803403377532959,
      "learning_rate": 6.668928e-05,
      "loss": 1.7812,
      "step": 104150
    },
    {
      "epoch": 3.3344,
      "grad_norm": 0.3675329387187958,
      "learning_rate": 6.662528e-05,
      "loss": 1.7456,
      "step": 104200
    },
    {
      "epoch": 3.336,
      "grad_norm": 0.4808189868927002,
      "learning_rate": 6.656128000000001e-05,
      "loss": 1.7256,
      "step": 104250
    },
    {
      "epoch": 3.3376,
      "grad_norm": 0.4196336567401886,
      "learning_rate": 6.649728e-05,
      "loss": 1.7932,
      "step": 104300
    },
    {
      "epoch": 3.3392,
      "grad_norm": 0.42375633120536804,
      "learning_rate": 6.643328e-05,
      "loss": 1.7434,
      "step": 104350
    },
    {
      "epoch": 3.3407999999999998,
      "grad_norm": 0.3692416846752167,
      "learning_rate": 6.636928000000001e-05,
      "loss": 1.7523,
      "step": 104400
    },
    {
      "epoch": 3.3424,
      "grad_norm": 0.4534858465194702,
      "learning_rate": 6.630528e-05,
      "loss": 1.8421,
      "step": 104450
    },
    {
      "epoch": 3.344,
      "grad_norm": 0.36671048402786255,
      "learning_rate": 6.624128000000001e-05,
      "loss": 1.7926,
      "step": 104500
    },
    {
      "epoch": 3.3456,
      "grad_norm": 0.39698684215545654,
      "learning_rate": 6.617728e-05,
      "loss": 1.7813,
      "step": 104550
    },
    {
      "epoch": 3.3472,
      "grad_norm": 0.40376976132392883,
      "learning_rate": 6.611328e-05,
      "loss": 1.7941,
      "step": 104600
    },
    {
      "epoch": 3.3487999999999998,
      "grad_norm": 0.3736523389816284,
      "learning_rate": 6.604928e-05,
      "loss": 1.7538,
      "step": 104650
    },
    {
      "epoch": 3.3504,
      "grad_norm": 0.38737231492996216,
      "learning_rate": 6.598528e-05,
      "loss": 1.8096,
      "step": 104700
    },
    {
      "epoch": 3.352,
      "grad_norm": 0.3829905390739441,
      "learning_rate": 6.592128000000001e-05,
      "loss": 1.7916,
      "step": 104750
    },
    {
      "epoch": 3.3536,
      "grad_norm": 0.39660364389419556,
      "learning_rate": 6.585728e-05,
      "loss": 1.7681,
      "step": 104800
    },
    {
      "epoch": 3.3552,
      "grad_norm": 0.37653791904449463,
      "learning_rate": 6.579328e-05,
      "loss": 1.776,
      "step": 104850
    },
    {
      "epoch": 3.3568,
      "grad_norm": 0.33461347222328186,
      "learning_rate": 6.572928e-05,
      "loss": 1.7685,
      "step": 104900
    },
    {
      "epoch": 3.3584,
      "grad_norm": 0.4294792115688324,
      "learning_rate": 6.566528000000001e-05,
      "loss": 1.7499,
      "step": 104950
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.3966517150402069,
      "learning_rate": 6.560128e-05,
      "loss": 1.7666,
      "step": 105000
    },
    {
      "epoch": 3.3616,
      "grad_norm": 0.3643849194049835,
      "learning_rate": 6.553728e-05,
      "loss": 1.8019,
      "step": 105050
    },
    {
      "epoch": 3.3632,
      "grad_norm": 0.3624576926231384,
      "learning_rate": 6.547328000000001e-05,
      "loss": 1.7221,
      "step": 105100
    },
    {
      "epoch": 3.3648,
      "grad_norm": 0.3416152000427246,
      "learning_rate": 6.540928e-05,
      "loss": 1.7829,
      "step": 105150
    },
    {
      "epoch": 3.3664,
      "grad_norm": 0.3853614330291748,
      "learning_rate": 6.534528e-05,
      "loss": 1.7261,
      "step": 105200
    },
    {
      "epoch": 3.368,
      "grad_norm": 0.3853461742401123,
      "learning_rate": 6.528128e-05,
      "loss": 1.7526,
      "step": 105250
    },
    {
      "epoch": 3.3696,
      "grad_norm": 0.4444691836833954,
      "learning_rate": 6.521728e-05,
      "loss": 1.7314,
      "step": 105300
    },
    {
      "epoch": 3.3712,
      "grad_norm": 0.363334983587265,
      "learning_rate": 6.515328000000001e-05,
      "loss": 1.781,
      "step": 105350
    },
    {
      "epoch": 3.3728,
      "grad_norm": 0.4173089563846588,
      "learning_rate": 6.508928e-05,
      "loss": 1.7592,
      "step": 105400
    },
    {
      "epoch": 3.3744,
      "grad_norm": 0.36933720111846924,
      "learning_rate": 6.502528e-05,
      "loss": 1.7594,
      "step": 105450
    },
    {
      "epoch": 3.376,
      "grad_norm": 0.4631873071193695,
      "learning_rate": 6.496128e-05,
      "loss": 1.8114,
      "step": 105500
    },
    {
      "epoch": 3.3776,
      "grad_norm": 0.3501669466495514,
      "learning_rate": 6.489728e-05,
      "loss": 1.804,
      "step": 105550
    },
    {
      "epoch": 3.3792,
      "grad_norm": 0.4216543436050415,
      "learning_rate": 6.483328000000001e-05,
      "loss": 1.7585,
      "step": 105600
    },
    {
      "epoch": 3.3808,
      "grad_norm": 0.3430185317993164,
      "learning_rate": 6.476928e-05,
      "loss": 1.7475,
      "step": 105650
    },
    {
      "epoch": 3.3824,
      "grad_norm": 0.3884725570678711,
      "learning_rate": 6.470528e-05,
      "loss": 1.7858,
      "step": 105700
    },
    {
      "epoch": 3.384,
      "grad_norm": 0.3963124752044678,
      "learning_rate": 6.464128e-05,
      "loss": 1.7404,
      "step": 105750
    },
    {
      "epoch": 3.3856,
      "grad_norm": 0.4144190549850464,
      "learning_rate": 6.457728000000001e-05,
      "loss": 1.8626,
      "step": 105800
    },
    {
      "epoch": 3.3872,
      "grad_norm": 0.5136156678199768,
      "learning_rate": 6.451328e-05,
      "loss": 1.7506,
      "step": 105850
    },
    {
      "epoch": 3.3888,
      "grad_norm": 0.48793283104896545,
      "learning_rate": 6.444928e-05,
      "loss": 1.8273,
      "step": 105900
    },
    {
      "epoch": 3.3904,
      "grad_norm": 0.39377593994140625,
      "learning_rate": 6.438528000000001e-05,
      "loss": 1.7811,
      "step": 105950
    },
    {
      "epoch": 3.392,
      "grad_norm": 0.3565760850906372,
      "learning_rate": 6.432128e-05,
      "loss": 1.785,
      "step": 106000
    },
    {
      "epoch": 3.3936,
      "grad_norm": 0.4782869815826416,
      "learning_rate": 6.425728000000001e-05,
      "loss": 1.7749,
      "step": 106050
    },
    {
      "epoch": 3.3952,
      "grad_norm": 0.4079434275627136,
      "learning_rate": 6.419328e-05,
      "loss": 1.804,
      "step": 106100
    },
    {
      "epoch": 3.3968,
      "grad_norm": 0.46518999338150024,
      "learning_rate": 6.412928e-05,
      "loss": 1.7172,
      "step": 106150
    },
    {
      "epoch": 3.3984,
      "grad_norm": 0.44113588333129883,
      "learning_rate": 6.406528000000001e-05,
      "loss": 1.7801,
      "step": 106200
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.36594322323799133,
      "learning_rate": 6.400128e-05,
      "loss": 1.78,
      "step": 106250
    },
    {
      "epoch": 3.4016,
      "grad_norm": 0.3632660210132599,
      "learning_rate": 6.393728e-05,
      "loss": 1.757,
      "step": 106300
    },
    {
      "epoch": 3.4032,
      "grad_norm": 0.3477111756801605,
      "learning_rate": 6.387328e-05,
      "loss": 1.8126,
      "step": 106350
    },
    {
      "epoch": 3.4048,
      "grad_norm": 0.40130507946014404,
      "learning_rate": 6.380928e-05,
      "loss": 1.7954,
      "step": 106400
    },
    {
      "epoch": 3.4064,
      "grad_norm": 0.3806648552417755,
      "learning_rate": 6.374528000000001e-05,
      "loss": 1.7473,
      "step": 106450
    },
    {
      "epoch": 3.408,
      "grad_norm": 0.37542563676834106,
      "learning_rate": 6.368128e-05,
      "loss": 1.782,
      "step": 106500
    },
    {
      "epoch": 3.4096,
      "grad_norm": 0.39267122745513916,
      "learning_rate": 6.361728e-05,
      "loss": 1.746,
      "step": 106550
    },
    {
      "epoch": 3.4112,
      "grad_norm": 0.39009809494018555,
      "learning_rate": 6.355328e-05,
      "loss": 1.8189,
      "step": 106600
    },
    {
      "epoch": 3.4128,
      "grad_norm": 0.4864007532596588,
      "learning_rate": 6.348928000000001e-05,
      "loss": 1.764,
      "step": 106650
    },
    {
      "epoch": 3.4144,
      "grad_norm": 0.4063318371772766,
      "learning_rate": 6.342528e-05,
      "loss": 1.7698,
      "step": 106700
    },
    {
      "epoch": 3.416,
      "grad_norm": 0.43251070380210876,
      "learning_rate": 6.336128e-05,
      "loss": 1.7788,
      "step": 106750
    },
    {
      "epoch": 3.4176,
      "grad_norm": 0.3698689639568329,
      "learning_rate": 6.329728e-05,
      "loss": 1.8376,
      "step": 106800
    },
    {
      "epoch": 3.4192,
      "grad_norm": 0.419341117143631,
      "learning_rate": 6.323328e-05,
      "loss": 1.7846,
      "step": 106850
    },
    {
      "epoch": 3.4208,
      "grad_norm": 0.5649207234382629,
      "learning_rate": 6.316928000000001e-05,
      "loss": 1.7803,
      "step": 106900
    },
    {
      "epoch": 3.4224,
      "grad_norm": 0.4238814115524292,
      "learning_rate": 6.310528e-05,
      "loss": 1.7479,
      "step": 106950
    },
    {
      "epoch": 3.424,
      "grad_norm": 0.3928944170475006,
      "learning_rate": 6.304128e-05,
      "loss": 1.746,
      "step": 107000
    },
    {
      "epoch": 3.4256,
      "grad_norm": 0.4060905873775482,
      "learning_rate": 6.297728000000001e-05,
      "loss": 1.7749,
      "step": 107050
    },
    {
      "epoch": 3.4272,
      "grad_norm": 0.378304123878479,
      "learning_rate": 6.291328e-05,
      "loss": 1.8173,
      "step": 107100
    },
    {
      "epoch": 3.4288,
      "grad_norm": 0.4210657775402069,
      "learning_rate": 6.284928e-05,
      "loss": 1.7732,
      "step": 107150
    },
    {
      "epoch": 3.4304,
      "grad_norm": 0.3742945194244385,
      "learning_rate": 6.278528e-05,
      "loss": 1.8114,
      "step": 107200
    },
    {
      "epoch": 3.432,
      "grad_norm": 0.3589221239089966,
      "learning_rate": 6.272128e-05,
      "loss": 1.8108,
      "step": 107250
    },
    {
      "epoch": 3.4336,
      "grad_norm": 0.38938578963279724,
      "learning_rate": 6.265728000000001e-05,
      "loss": 1.7771,
      "step": 107300
    },
    {
      "epoch": 3.4352,
      "grad_norm": 0.3915381133556366,
      "learning_rate": 6.259328e-05,
      "loss": 1.7958,
      "step": 107350
    },
    {
      "epoch": 3.4368,
      "grad_norm": 0.46985676884651184,
      "learning_rate": 6.252928e-05,
      "loss": 1.8266,
      "step": 107400
    },
    {
      "epoch": 3.4384,
      "grad_norm": 0.37840536236763,
      "learning_rate": 6.246528e-05,
      "loss": 1.7888,
      "step": 107450
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.45864954590797424,
      "learning_rate": 6.240128000000001e-05,
      "loss": 1.7995,
      "step": 107500
    },
    {
      "epoch": 3.4416,
      "grad_norm": 0.4022655189037323,
      "learning_rate": 6.233728e-05,
      "loss": 1.7845,
      "step": 107550
    },
    {
      "epoch": 3.4432,
      "grad_norm": 0.43071019649505615,
      "learning_rate": 6.227328e-05,
      "loss": 1.7817,
      "step": 107600
    },
    {
      "epoch": 3.4448,
      "grad_norm": 0.370937705039978,
      "learning_rate": 6.220928e-05,
      "loss": 1.7619,
      "step": 107650
    },
    {
      "epoch": 3.4464,
      "grad_norm": 0.35498547554016113,
      "learning_rate": 6.214528e-05,
      "loss": 1.7638,
      "step": 107700
    },
    {
      "epoch": 3.448,
      "grad_norm": 0.3536228537559509,
      "learning_rate": 6.208128000000001e-05,
      "loss": 1.7519,
      "step": 107750
    },
    {
      "epoch": 3.4496,
      "grad_norm": 0.42958948016166687,
      "learning_rate": 6.201728e-05,
      "loss": 1.7864,
      "step": 107800
    },
    {
      "epoch": 3.4512,
      "grad_norm": 0.4135376811027527,
      "learning_rate": 6.195328e-05,
      "loss": 1.7999,
      "step": 107850
    },
    {
      "epoch": 3.4528,
      "grad_norm": 0.45956024527549744,
      "learning_rate": 6.188928000000001e-05,
      "loss": 1.7576,
      "step": 107900
    },
    {
      "epoch": 3.4544,
      "grad_norm": 0.38437792658805847,
      "learning_rate": 6.182528e-05,
      "loss": 1.7839,
      "step": 107950
    },
    {
      "epoch": 3.456,
      "grad_norm": 0.35017848014831543,
      "learning_rate": 6.176128e-05,
      "loss": 1.7751,
      "step": 108000
    },
    {
      "epoch": 3.4576000000000002,
      "grad_norm": 0.40934935212135315,
      "learning_rate": 6.169728000000001e-05,
      "loss": 1.7878,
      "step": 108050
    },
    {
      "epoch": 3.4592,
      "grad_norm": 0.3602641224861145,
      "learning_rate": 6.163328e-05,
      "loss": 1.7585,
      "step": 108100
    },
    {
      "epoch": 3.4608,
      "grad_norm": 0.36428093910217285,
      "learning_rate": 6.156928000000001e-05,
      "loss": 1.7994,
      "step": 108150
    },
    {
      "epoch": 3.4624,
      "grad_norm": 0.36535248160362244,
      "learning_rate": 6.150528e-05,
      "loss": 1.7751,
      "step": 108200
    },
    {
      "epoch": 3.464,
      "grad_norm": 0.3902694582939148,
      "learning_rate": 6.144128e-05,
      "loss": 1.7609,
      "step": 108250
    },
    {
      "epoch": 3.4656000000000002,
      "grad_norm": 0.4102986454963684,
      "learning_rate": 6.137728e-05,
      "loss": 1.7537,
      "step": 108300
    },
    {
      "epoch": 3.4672,
      "grad_norm": 0.41265955567359924,
      "learning_rate": 6.131328e-05,
      "loss": 1.7779,
      "step": 108350
    },
    {
      "epoch": 3.4688,
      "grad_norm": 0.3699754774570465,
      "learning_rate": 6.124928e-05,
      "loss": 1.7393,
      "step": 108400
    },
    {
      "epoch": 3.4704,
      "grad_norm": 0.36903929710388184,
      "learning_rate": 6.118528e-05,
      "loss": 1.7274,
      "step": 108450
    },
    {
      "epoch": 3.472,
      "grad_norm": 0.38582074642181396,
      "learning_rate": 6.112128e-05,
      "loss": 1.8295,
      "step": 108500
    },
    {
      "epoch": 3.4736000000000002,
      "grad_norm": 0.372895747423172,
      "learning_rate": 6.105728e-05,
      "loss": 1.7946,
      "step": 108550
    },
    {
      "epoch": 3.4752,
      "grad_norm": 0.39164888858795166,
      "learning_rate": 6.099328000000001e-05,
      "loss": 1.7866,
      "step": 108600
    },
    {
      "epoch": 3.4768,
      "grad_norm": 0.3881748616695404,
      "learning_rate": 6.092928e-05,
      "loss": 1.7823,
      "step": 108650
    },
    {
      "epoch": 3.4784,
      "grad_norm": 0.4456944763660431,
      "learning_rate": 6.086528e-05,
      "loss": 1.772,
      "step": 108700
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.3971540033817291,
      "learning_rate": 6.080128e-05,
      "loss": 1.7829,
      "step": 108750
    },
    {
      "epoch": 3.4816,
      "grad_norm": 0.34905463457107544,
      "learning_rate": 6.073728000000001e-05,
      "loss": 1.7573,
      "step": 108800
    },
    {
      "epoch": 3.4832,
      "grad_norm": 0.4052094519138336,
      "learning_rate": 6.067328e-05,
      "loss": 1.8071,
      "step": 108850
    },
    {
      "epoch": 3.4848,
      "grad_norm": 0.6290667057037354,
      "learning_rate": 6.060928e-05,
      "loss": 1.7357,
      "step": 108900
    },
    {
      "epoch": 3.4864,
      "grad_norm": 0.43633636832237244,
      "learning_rate": 6.054528e-05,
      "loss": 1.7917,
      "step": 108950
    },
    {
      "epoch": 3.488,
      "grad_norm": 0.397024005651474,
      "learning_rate": 6.0481280000000005e-05,
      "loss": 1.7669,
      "step": 109000
    },
    {
      "epoch": 3.4896,
      "grad_norm": 0.34357765316963196,
      "learning_rate": 6.041728e-05,
      "loss": 1.7578,
      "step": 109050
    },
    {
      "epoch": 3.4912,
      "grad_norm": 0.3491401970386505,
      "learning_rate": 6.035328e-05,
      "loss": 1.8107,
      "step": 109100
    },
    {
      "epoch": 3.4928,
      "grad_norm": 0.4228615462779999,
      "learning_rate": 6.0289280000000004e-05,
      "loss": 1.7524,
      "step": 109150
    },
    {
      "epoch": 3.4944,
      "grad_norm": 0.36629587411880493,
      "learning_rate": 6.0225280000000006e-05,
      "loss": 1.7198,
      "step": 109200
    },
    {
      "epoch": 3.496,
      "grad_norm": 0.34310367703437805,
      "learning_rate": 6.0161279999999995e-05,
      "loss": 1.7704,
      "step": 109250
    },
    {
      "epoch": 3.4976,
      "grad_norm": 0.5021296739578247,
      "learning_rate": 6.0097280000000003e-05,
      "loss": 1.805,
      "step": 109300
    },
    {
      "epoch": 3.4992,
      "grad_norm": 0.5023942589759827,
      "learning_rate": 6.0033280000000005e-05,
      "loss": 1.7672,
      "step": 109350
    },
    {
      "epoch": 3.5008,
      "grad_norm": 0.32833749055862427,
      "learning_rate": 5.996928000000001e-05,
      "loss": 1.6948,
      "step": 109400
    },
    {
      "epoch": 3.5023999999999997,
      "grad_norm": 0.3809494376182556,
      "learning_rate": 5.990528000000001e-05,
      "loss": 1.8152,
      "step": 109450
    },
    {
      "epoch": 3.504,
      "grad_norm": 0.4086986482143402,
      "learning_rate": 5.984128e-05,
      "loss": 1.7813,
      "step": 109500
    },
    {
      "epoch": 3.5056000000000003,
      "grad_norm": 0.3567870259284973,
      "learning_rate": 5.977728e-05,
      "loss": 1.7812,
      "step": 109550
    },
    {
      "epoch": 3.5072,
      "grad_norm": 0.40887337923049927,
      "learning_rate": 5.971328e-05,
      "loss": 1.7722,
      "step": 109600
    },
    {
      "epoch": 3.5088,
      "grad_norm": 0.3445742726325989,
      "learning_rate": 5.964928000000001e-05,
      "loss": 1.7481,
      "step": 109650
    },
    {
      "epoch": 3.5103999999999997,
      "grad_norm": 0.3353881537914276,
      "learning_rate": 5.958528e-05,
      "loss": 1.7646,
      "step": 109700
    },
    {
      "epoch": 3.512,
      "grad_norm": 0.33631449937820435,
      "learning_rate": 5.952128e-05,
      "loss": 1.7212,
      "step": 109750
    },
    {
      "epoch": 3.5136,
      "grad_norm": 0.4021776616573334,
      "learning_rate": 5.945728e-05,
      "loss": 1.7831,
      "step": 109800
    },
    {
      "epoch": 3.5152,
      "grad_norm": 0.3677290678024292,
      "learning_rate": 5.9393280000000005e-05,
      "loss": 1.769,
      "step": 109850
    },
    {
      "epoch": 3.5168,
      "grad_norm": 0.35067325830459595,
      "learning_rate": 5.932928e-05,
      "loss": 1.7752,
      "step": 109900
    },
    {
      "epoch": 3.5183999999999997,
      "grad_norm": 0.4115915596485138,
      "learning_rate": 5.926528e-05,
      "loss": 1.7214,
      "step": 109950
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.46321573853492737,
      "learning_rate": 5.9201280000000004e-05,
      "loss": 1.8097,
      "step": 110000
    },
    {
      "epoch": 3.5216,
      "grad_norm": 0.3448592722415924,
      "learning_rate": 5.9137280000000006e-05,
      "loss": 1.7971,
      "step": 110050
    },
    {
      "epoch": 3.5232,
      "grad_norm": 0.4580966532230377,
      "learning_rate": 5.9073279999999994e-05,
      "loss": 1.7956,
      "step": 110100
    },
    {
      "epoch": 3.5248,
      "grad_norm": 0.34563711285591125,
      "learning_rate": 5.900928e-05,
      "loss": 1.7298,
      "step": 110150
    },
    {
      "epoch": 3.5263999999999998,
      "grad_norm": 0.38101041316986084,
      "learning_rate": 5.8945280000000005e-05,
      "loss": 1.7959,
      "step": 110200
    },
    {
      "epoch": 3.528,
      "grad_norm": 0.38010892271995544,
      "learning_rate": 5.888128000000001e-05,
      "loss": 1.773,
      "step": 110250
    },
    {
      "epoch": 3.5296,
      "grad_norm": 0.4128110706806183,
      "learning_rate": 5.881728000000001e-05,
      "loss": 1.7526,
      "step": 110300
    },
    {
      "epoch": 3.5312,
      "grad_norm": 0.4030020236968994,
      "learning_rate": 5.875328e-05,
      "loss": 1.7964,
      "step": 110350
    },
    {
      "epoch": 3.5328,
      "grad_norm": 0.3593822121620178,
      "learning_rate": 5.868928e-05,
      "loss": 1.8319,
      "step": 110400
    },
    {
      "epoch": 3.5343999999999998,
      "grad_norm": 0.3111472427845001,
      "learning_rate": 5.862528000000001e-05,
      "loss": 1.7541,
      "step": 110450
    },
    {
      "epoch": 3.536,
      "grad_norm": 0.3944147527217865,
      "learning_rate": 5.856128000000001e-05,
      "loss": 1.7515,
      "step": 110500
    },
    {
      "epoch": 3.5376,
      "grad_norm": 0.5023753046989441,
      "learning_rate": 5.849728e-05,
      "loss": 1.7823,
      "step": 110550
    },
    {
      "epoch": 3.5392,
      "grad_norm": 0.36783361434936523,
      "learning_rate": 5.843328e-05,
      "loss": 1.7919,
      "step": 110600
    },
    {
      "epoch": 3.5408,
      "grad_norm": 0.3914094567298889,
      "learning_rate": 5.836928e-05,
      "loss": 1.7942,
      "step": 110650
    },
    {
      "epoch": 3.5423999999999998,
      "grad_norm": 0.3548855483531952,
      "learning_rate": 5.8305280000000004e-05,
      "loss": 1.7132,
      "step": 110700
    },
    {
      "epoch": 3.544,
      "grad_norm": 0.38929933309555054,
      "learning_rate": 5.824128e-05,
      "loss": 1.7558,
      "step": 110750
    },
    {
      "epoch": 3.5456,
      "grad_norm": 0.4728584289550781,
      "learning_rate": 5.817728e-05,
      "loss": 1.7887,
      "step": 110800
    },
    {
      "epoch": 3.5472,
      "grad_norm": 0.39763331413269043,
      "learning_rate": 5.8113280000000003e-05,
      "loss": 1.7503,
      "step": 110850
    },
    {
      "epoch": 3.5488,
      "grad_norm": 0.40613308548927307,
      "learning_rate": 5.8049280000000005e-05,
      "loss": 1.8172,
      "step": 110900
    },
    {
      "epoch": 3.5504,
      "grad_norm": 0.35145995020866394,
      "learning_rate": 5.798528e-05,
      "loss": 1.7682,
      "step": 110950
    },
    {
      "epoch": 3.552,
      "grad_norm": 0.36823150515556335,
      "learning_rate": 5.792128e-05,
      "loss": 1.8101,
      "step": 111000
    },
    {
      "epoch": 3.5536,
      "grad_norm": 0.4713309109210968,
      "learning_rate": 5.7857280000000005e-05,
      "loss": 1.7909,
      "step": 111050
    },
    {
      "epoch": 3.5552,
      "grad_norm": 0.37893611192703247,
      "learning_rate": 5.7793280000000006e-05,
      "loss": 1.7827,
      "step": 111100
    },
    {
      "epoch": 3.5568,
      "grad_norm": 0.40629100799560547,
      "learning_rate": 5.772928000000001e-05,
      "loss": 1.7505,
      "step": 111150
    },
    {
      "epoch": 3.5584,
      "grad_norm": 0.41887885332107544,
      "learning_rate": 5.766528e-05,
      "loss": 1.7501,
      "step": 111200
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.48665958642959595,
      "learning_rate": 5.760128e-05,
      "loss": 1.7286,
      "step": 111250
    },
    {
      "epoch": 3.5616,
      "grad_norm": 0.38599228858947754,
      "learning_rate": 5.753728000000001e-05,
      "loss": 1.7455,
      "step": 111300
    },
    {
      "epoch": 3.5632,
      "grad_norm": 0.4045752286911011,
      "learning_rate": 5.747328000000001e-05,
      "loss": 1.77,
      "step": 111350
    },
    {
      "epoch": 3.5648,
      "grad_norm": 0.39748743176460266,
      "learning_rate": 5.740928e-05,
      "loss": 1.756,
      "step": 111400
    },
    {
      "epoch": 3.5664,
      "grad_norm": 0.3642809987068176,
      "learning_rate": 5.734528e-05,
      "loss": 1.7651,
      "step": 111450
    },
    {
      "epoch": 3.568,
      "grad_norm": 0.35497403144836426,
      "learning_rate": 5.728128e-05,
      "loss": 1.7822,
      "step": 111500
    },
    {
      "epoch": 3.5696,
      "grad_norm": 0.4364767074584961,
      "learning_rate": 5.7217280000000004e-05,
      "loss": 1.7111,
      "step": 111550
    },
    {
      "epoch": 3.5712,
      "grad_norm": 0.45078045129776,
      "learning_rate": 5.715328e-05,
      "loss": 1.7887,
      "step": 111600
    },
    {
      "epoch": 3.5728,
      "grad_norm": 0.4746285378932953,
      "learning_rate": 5.708928e-05,
      "loss": 1.7843,
      "step": 111650
    },
    {
      "epoch": 3.5744,
      "grad_norm": 0.3639757037162781,
      "learning_rate": 5.702528e-05,
      "loss": 1.7648,
      "step": 111700
    },
    {
      "epoch": 3.576,
      "grad_norm": 0.4300604462623596,
      "learning_rate": 5.6961280000000005e-05,
      "loss": 1.7881,
      "step": 111750
    },
    {
      "epoch": 3.5776,
      "grad_norm": 0.3686964809894562,
      "learning_rate": 5.689728e-05,
      "loss": 1.8267,
      "step": 111800
    },
    {
      "epoch": 3.5792,
      "grad_norm": 0.3248128592967987,
      "learning_rate": 5.683328e-05,
      "loss": 1.7645,
      "step": 111850
    },
    {
      "epoch": 3.5808,
      "grad_norm": 0.322416752576828,
      "learning_rate": 5.6769280000000004e-05,
      "loss": 1.768,
      "step": 111900
    },
    {
      "epoch": 3.5824,
      "grad_norm": 0.42931827902793884,
      "learning_rate": 5.6705280000000006e-05,
      "loss": 1.7634,
      "step": 111950
    },
    {
      "epoch": 3.584,
      "grad_norm": 0.3867063820362091,
      "learning_rate": 5.664128000000001e-05,
      "loss": 1.7614,
      "step": 112000
    },
    {
      "epoch": 3.5856,
      "grad_norm": 0.4227484166622162,
      "learning_rate": 5.6577279999999996e-05,
      "loss": 1.7922,
      "step": 112050
    },
    {
      "epoch": 3.5872,
      "grad_norm": 0.42383459210395813,
      "learning_rate": 5.651328e-05,
      "loss": 1.7629,
      "step": 112100
    },
    {
      "epoch": 3.5888,
      "grad_norm": 0.40762391686439514,
      "learning_rate": 5.644928000000001e-05,
      "loss": 1.7331,
      "step": 112150
    },
    {
      "epoch": 3.5904,
      "grad_norm": 0.42833587527275085,
      "learning_rate": 5.638528000000001e-05,
      "loss": 1.818,
      "step": 112200
    },
    {
      "epoch": 3.592,
      "grad_norm": 0.424712598323822,
      "learning_rate": 5.632128e-05,
      "loss": 1.777,
      "step": 112250
    },
    {
      "epoch": 3.5936,
      "grad_norm": 0.40045586228370667,
      "learning_rate": 5.625728e-05,
      "loss": 1.7704,
      "step": 112300
    },
    {
      "epoch": 3.5952,
      "grad_norm": 0.4541044533252716,
      "learning_rate": 5.619328e-05,
      "loss": 1.8011,
      "step": 112350
    },
    {
      "epoch": 3.5968,
      "grad_norm": 0.39923110604286194,
      "learning_rate": 5.6129280000000003e-05,
      "loss": 1.7455,
      "step": 112400
    },
    {
      "epoch": 3.5984,
      "grad_norm": 0.5006463527679443,
      "learning_rate": 5.606528e-05,
      "loss": 1.739,
      "step": 112450
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.398732453584671,
      "learning_rate": 5.600128e-05,
      "loss": 1.8026,
      "step": 112500
    },
    {
      "epoch": 3.6016,
      "grad_norm": 0.42780113220214844,
      "learning_rate": 5.593728e-05,
      "loss": 1.8261,
      "step": 112550
    },
    {
      "epoch": 3.6032,
      "grad_norm": 0.4549556374549866,
      "learning_rate": 5.5873280000000005e-05,
      "loss": 1.7813,
      "step": 112600
    },
    {
      "epoch": 3.6048,
      "grad_norm": 0.4039981961250305,
      "learning_rate": 5.5809280000000007e-05,
      "loss": 1.7175,
      "step": 112650
    },
    {
      "epoch": 3.6064,
      "grad_norm": 0.3530554473400116,
      "learning_rate": 5.574528e-05,
      "loss": 1.7205,
      "step": 112700
    },
    {
      "epoch": 3.608,
      "grad_norm": 0.3364805579185486,
      "learning_rate": 5.5681280000000004e-05,
      "loss": 1.743,
      "step": 112750
    },
    {
      "epoch": 3.6096,
      "grad_norm": 0.34028321504592896,
      "learning_rate": 5.5617280000000006e-05,
      "loss": 1.7839,
      "step": 112800
    },
    {
      "epoch": 3.6112,
      "grad_norm": 0.43566206097602844,
      "learning_rate": 5.555328000000001e-05,
      "loss": 1.8195,
      "step": 112850
    },
    {
      "epoch": 3.6128,
      "grad_norm": 0.38787347078323364,
      "learning_rate": 5.5489279999999996e-05,
      "loss": 1.7476,
      "step": 112900
    },
    {
      "epoch": 3.6144,
      "grad_norm": 0.3315525949001312,
      "learning_rate": 5.5425280000000005e-05,
      "loss": 1.7895,
      "step": 112950
    },
    {
      "epoch": 3.616,
      "grad_norm": 0.4589475393295288,
      "learning_rate": 5.536128000000001e-05,
      "loss": 1.8184,
      "step": 113000
    },
    {
      "epoch": 3.6176,
      "grad_norm": 0.4540156424045563,
      "learning_rate": 5.529728000000001e-05,
      "loss": 1.7891,
      "step": 113050
    },
    {
      "epoch": 3.6192,
      "grad_norm": 0.45473235845565796,
      "learning_rate": 5.523328e-05,
      "loss": 1.8196,
      "step": 113100
    },
    {
      "epoch": 3.6208,
      "grad_norm": 0.4193419814109802,
      "learning_rate": 5.516928e-05,
      "loss": 1.7452,
      "step": 113150
    },
    {
      "epoch": 3.6224,
      "grad_norm": 0.4418955445289612,
      "learning_rate": 5.510528e-05,
      "loss": 1.7119,
      "step": 113200
    },
    {
      "epoch": 3.624,
      "grad_norm": 0.39656758308410645,
      "learning_rate": 5.504128e-05,
      "loss": 1.7751,
      "step": 113250
    },
    {
      "epoch": 3.6256,
      "grad_norm": 0.4296487867832184,
      "learning_rate": 5.497728e-05,
      "loss": 1.7357,
      "step": 113300
    },
    {
      "epoch": 3.6272,
      "grad_norm": 0.4219454526901245,
      "learning_rate": 5.491328e-05,
      "loss": 1.798,
      "step": 113350
    },
    {
      "epoch": 3.6288,
      "grad_norm": 0.34038808941841125,
      "learning_rate": 5.484928e-05,
      "loss": 1.7503,
      "step": 113400
    },
    {
      "epoch": 3.6304,
      "grad_norm": 0.38717448711395264,
      "learning_rate": 5.4785280000000004e-05,
      "loss": 1.7829,
      "step": 113450
    },
    {
      "epoch": 3.632,
      "grad_norm": 0.33859753608703613,
      "learning_rate": 5.4721280000000006e-05,
      "loss": 1.7684,
      "step": 113500
    },
    {
      "epoch": 3.6336,
      "grad_norm": 0.42967021465301514,
      "learning_rate": 5.465728e-05,
      "loss": 1.8219,
      "step": 113550
    },
    {
      "epoch": 3.6352,
      "grad_norm": 0.38149234652519226,
      "learning_rate": 5.459328e-05,
      "loss": 1.7654,
      "step": 113600
    },
    {
      "epoch": 3.6368,
      "grad_norm": 0.34536948800086975,
      "learning_rate": 5.4529280000000005e-05,
      "loss": 1.8086,
      "step": 113650
    },
    {
      "epoch": 3.6384,
      "grad_norm": 0.3654027581214905,
      "learning_rate": 5.446528000000001e-05,
      "loss": 1.8167,
      "step": 113700
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.41977041959762573,
      "learning_rate": 5.4401279999999996e-05,
      "loss": 1.7409,
      "step": 113750
    },
    {
      "epoch": 3.6416,
      "grad_norm": 0.3491817116737366,
      "learning_rate": 5.4337280000000004e-05,
      "loss": 1.748,
      "step": 113800
    },
    {
      "epoch": 3.6432,
      "grad_norm": 0.40987369418144226,
      "learning_rate": 5.4273280000000006e-05,
      "loss": 1.7701,
      "step": 113850
    },
    {
      "epoch": 3.6448,
      "grad_norm": 0.42657482624053955,
      "learning_rate": 5.420928000000001e-05,
      "loss": 1.7803,
      "step": 113900
    },
    {
      "epoch": 3.6464,
      "grad_norm": 0.39280450344085693,
      "learning_rate": 5.414528e-05,
      "loss": 1.7877,
      "step": 113950
    },
    {
      "epoch": 3.648,
      "grad_norm": 0.40147465467453003,
      "learning_rate": 5.408128e-05,
      "loss": 1.7664,
      "step": 114000
    },
    {
      "epoch": 3.6496,
      "grad_norm": 0.3796442449092865,
      "learning_rate": 5.401728e-05,
      "loss": 1.7909,
      "step": 114050
    },
    {
      "epoch": 3.6512000000000002,
      "grad_norm": 0.4085484743118286,
      "learning_rate": 5.395328000000001e-05,
      "loss": 1.7966,
      "step": 114100
    },
    {
      "epoch": 3.6528,
      "grad_norm": 0.412714421749115,
      "learning_rate": 5.388928e-05,
      "loss": 1.8217,
      "step": 114150
    },
    {
      "epoch": 3.6544,
      "grad_norm": 0.4219871163368225,
      "learning_rate": 5.382528e-05,
      "loss": 1.7633,
      "step": 114200
    },
    {
      "epoch": 3.656,
      "grad_norm": 0.40587320923805237,
      "learning_rate": 5.376128e-05,
      "loss": 1.7845,
      "step": 114250
    },
    {
      "epoch": 3.6576,
      "grad_norm": 0.41299623250961304,
      "learning_rate": 5.3697280000000004e-05,
      "loss": 1.7975,
      "step": 114300
    },
    {
      "epoch": 3.6592000000000002,
      "grad_norm": 0.4030800759792328,
      "learning_rate": 5.3633280000000006e-05,
      "loss": 1.811,
      "step": 114350
    },
    {
      "epoch": 3.6608,
      "grad_norm": 0.5164320468902588,
      "learning_rate": 5.356928e-05,
      "loss": 1.8215,
      "step": 114400
    },
    {
      "epoch": 3.6624,
      "grad_norm": 0.45449337363243103,
      "learning_rate": 5.350528e-05,
      "loss": 1.8013,
      "step": 114450
    },
    {
      "epoch": 3.664,
      "grad_norm": 0.35176703333854675,
      "learning_rate": 5.3441280000000005e-05,
      "loss": 1.7659,
      "step": 114500
    },
    {
      "epoch": 3.6656,
      "grad_norm": 0.4115297496318817,
      "learning_rate": 5.337728000000001e-05,
      "loss": 1.7525,
      "step": 114550
    },
    {
      "epoch": 3.6672000000000002,
      "grad_norm": 0.42568063735961914,
      "learning_rate": 5.331328e-05,
      "loss": 1.7195,
      "step": 114600
    },
    {
      "epoch": 3.6688,
      "grad_norm": 0.35011622309684753,
      "learning_rate": 5.3249280000000004e-05,
      "loss": 1.7622,
      "step": 114650
    },
    {
      "epoch": 3.6704,
      "grad_norm": 0.3443470597267151,
      "learning_rate": 5.3185280000000006e-05,
      "loss": 1.7444,
      "step": 114700
    },
    {
      "epoch": 3.672,
      "grad_norm": 0.3846464455127716,
      "learning_rate": 5.312128000000001e-05,
      "loss": 1.6982,
      "step": 114750
    },
    {
      "epoch": 3.6736,
      "grad_norm": 0.4052509069442749,
      "learning_rate": 5.3057279999999996e-05,
      "loss": 1.8037,
      "step": 114800
    },
    {
      "epoch": 3.6752000000000002,
      "grad_norm": 0.5651122331619263,
      "learning_rate": 5.299328e-05,
      "loss": 1.7291,
      "step": 114850
    },
    {
      "epoch": 3.6768,
      "grad_norm": 0.431231826543808,
      "learning_rate": 5.292928e-05,
      "loss": 1.7791,
      "step": 114900
    },
    {
      "epoch": 3.6784,
      "grad_norm": 0.44774124026298523,
      "learning_rate": 5.286528000000001e-05,
      "loss": 1.8078,
      "step": 114950
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.36917832493782043,
      "learning_rate": 5.280128e-05,
      "loss": 1.7964,
      "step": 115000
    },
    {
      "epoch": 3.6816,
      "grad_norm": 0.44736096262931824,
      "learning_rate": 5.273728e-05,
      "loss": 1.7917,
      "step": 115050
    },
    {
      "epoch": 3.6832000000000003,
      "grad_norm": 0.41034165024757385,
      "learning_rate": 5.267328e-05,
      "loss": 1.7513,
      "step": 115100
    },
    {
      "epoch": 3.6848,
      "grad_norm": 0.3754499554634094,
      "learning_rate": 5.260928e-05,
      "loss": 1.7542,
      "step": 115150
    },
    {
      "epoch": 3.6864,
      "grad_norm": 0.3426894247531891,
      "learning_rate": 5.2545280000000005e-05,
      "loss": 1.7722,
      "step": 115200
    },
    {
      "epoch": 3.6879999999999997,
      "grad_norm": 0.4467681050300598,
      "learning_rate": 5.248128e-05,
      "loss": 1.8092,
      "step": 115250
    },
    {
      "epoch": 3.6896,
      "grad_norm": 0.43375828862190247,
      "learning_rate": 5.241728e-05,
      "loss": 1.7837,
      "step": 115300
    },
    {
      "epoch": 3.6912000000000003,
      "grad_norm": 0.3387943506240845,
      "learning_rate": 5.2353280000000004e-05,
      "loss": 1.7946,
      "step": 115350
    },
    {
      "epoch": 3.6928,
      "grad_norm": 0.3779081106185913,
      "learning_rate": 5.2289280000000006e-05,
      "loss": 1.7369,
      "step": 115400
    },
    {
      "epoch": 3.6944,
      "grad_norm": 0.42539849877357483,
      "learning_rate": 5.222528e-05,
      "loss": 1.8055,
      "step": 115450
    },
    {
      "epoch": 3.6959999999999997,
      "grad_norm": 0.3979891836643219,
      "learning_rate": 5.2161280000000003e-05,
      "loss": 1.7997,
      "step": 115500
    },
    {
      "epoch": 3.6976,
      "grad_norm": 0.41433581709861755,
      "learning_rate": 5.2097280000000005e-05,
      "loss": 1.8348,
      "step": 115550
    },
    {
      "epoch": 3.6992000000000003,
      "grad_norm": 0.4217745065689087,
      "learning_rate": 5.203328000000001e-05,
      "loss": 1.8288,
      "step": 115600
    },
    {
      "epoch": 3.7008,
      "grad_norm": 0.3763046860694885,
      "learning_rate": 5.1969279999999996e-05,
      "loss": 1.8207,
      "step": 115650
    },
    {
      "epoch": 3.7024,
      "grad_norm": 0.5409653782844543,
      "learning_rate": 5.190528e-05,
      "loss": 1.7391,
      "step": 115700
    },
    {
      "epoch": 3.7039999999999997,
      "grad_norm": 0.5646820664405823,
      "learning_rate": 5.1841280000000007e-05,
      "loss": 1.7971,
      "step": 115750
    },
    {
      "epoch": 3.7056,
      "grad_norm": 0.37622398138046265,
      "learning_rate": 5.177728000000001e-05,
      "loss": 1.77,
      "step": 115800
    },
    {
      "epoch": 3.7072000000000003,
      "grad_norm": 0.45191386342048645,
      "learning_rate": 5.171328e-05,
      "loss": 1.8501,
      "step": 115850
    },
    {
      "epoch": 3.7088,
      "grad_norm": 0.38392892479896545,
      "learning_rate": 5.164928e-05,
      "loss": 1.7746,
      "step": 115900
    },
    {
      "epoch": 3.7104,
      "grad_norm": 0.357605516910553,
      "learning_rate": 5.158528e-05,
      "loss": 1.7634,
      "step": 115950
    },
    {
      "epoch": 3.7119999999999997,
      "grad_norm": 0.32250046730041504,
      "learning_rate": 5.152128e-05,
      "loss": 1.7619,
      "step": 116000
    },
    {
      "epoch": 3.7136,
      "grad_norm": 0.3951961398124695,
      "learning_rate": 5.1457280000000005e-05,
      "loss": 1.7612,
      "step": 116050
    },
    {
      "epoch": 3.7152,
      "grad_norm": 0.4450327157974243,
      "learning_rate": 5.139328e-05,
      "loss": 1.7815,
      "step": 116100
    },
    {
      "epoch": 3.7168,
      "grad_norm": 0.4067762792110443,
      "learning_rate": 5.132928e-05,
      "loss": 1.7932,
      "step": 116150
    },
    {
      "epoch": 3.7184,
      "grad_norm": 0.40107598900794983,
      "learning_rate": 5.1265280000000004e-05,
      "loss": 1.7918,
      "step": 116200
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.36011043190956116,
      "learning_rate": 5.1201280000000006e-05,
      "loss": 1.7815,
      "step": 116250
    },
    {
      "epoch": 3.7216,
      "grad_norm": 0.35120877623558044,
      "learning_rate": 5.113728e-05,
      "loss": 1.7793,
      "step": 116300
    },
    {
      "epoch": 3.7232,
      "grad_norm": 0.38198795914649963,
      "learning_rate": 5.107328e-05,
      "loss": 1.7726,
      "step": 116350
    },
    {
      "epoch": 3.7248,
      "grad_norm": 0.35498490929603577,
      "learning_rate": 5.1009280000000005e-05,
      "loss": 1.7487,
      "step": 116400
    },
    {
      "epoch": 3.7264,
      "grad_norm": 0.3948269486427307,
      "learning_rate": 5.094528000000001e-05,
      "loss": 1.8094,
      "step": 116450
    },
    {
      "epoch": 3.7279999999999998,
      "grad_norm": 0.37175729870796204,
      "learning_rate": 5.0881279999999995e-05,
      "loss": 1.761,
      "step": 116500
    },
    {
      "epoch": 3.7296,
      "grad_norm": 0.4018790125846863,
      "learning_rate": 5.081728e-05,
      "loss": 1.7653,
      "step": 116550
    },
    {
      "epoch": 3.7312,
      "grad_norm": 0.3397933542728424,
      "learning_rate": 5.0753280000000006e-05,
      "loss": 1.7934,
      "step": 116600
    },
    {
      "epoch": 3.7328,
      "grad_norm": 0.37617650628089905,
      "learning_rate": 5.068928000000001e-05,
      "loss": 1.7936,
      "step": 116650
    },
    {
      "epoch": 3.7344,
      "grad_norm": 0.3390241265296936,
      "learning_rate": 5.0625279999999997e-05,
      "loss": 1.7502,
      "step": 116700
    },
    {
      "epoch": 3.7359999999999998,
      "grad_norm": 0.4020402431488037,
      "learning_rate": 5.056128e-05,
      "loss": 1.7735,
      "step": 116750
    },
    {
      "epoch": 3.7376,
      "grad_norm": 0.42140671610832214,
      "learning_rate": 5.049728e-05,
      "loss": 1.7454,
      "step": 116800
    },
    {
      "epoch": 3.7392,
      "grad_norm": 0.38856041431427,
      "learning_rate": 5.043328e-05,
      "loss": 1.8068,
      "step": 116850
    },
    {
      "epoch": 3.7408,
      "grad_norm": 0.4298483729362488,
      "learning_rate": 5.0369280000000004e-05,
      "loss": 1.7377,
      "step": 116900
    },
    {
      "epoch": 3.7424,
      "grad_norm": 0.3813944160938263,
      "learning_rate": 5.030528e-05,
      "loss": 1.7689,
      "step": 116950
    },
    {
      "epoch": 3.7439999999999998,
      "grad_norm": 0.3695072531700134,
      "learning_rate": 5.024128e-05,
      "loss": 1.7853,
      "step": 117000
    },
    {
      "epoch": 3.7456,
      "grad_norm": 0.39046069979667664,
      "learning_rate": 5.0177280000000004e-05,
      "loss": 1.7648,
      "step": 117050
    },
    {
      "epoch": 3.7472,
      "grad_norm": 0.43746086955070496,
      "learning_rate": 5.0113280000000005e-05,
      "loss": 1.7814,
      "step": 117100
    },
    {
      "epoch": 3.7488,
      "grad_norm": 0.39111095666885376,
      "learning_rate": 5.004928e-05,
      "loss": 1.8148,
      "step": 117150
    },
    {
      "epoch": 3.7504,
      "grad_norm": 0.40195232629776,
      "learning_rate": 4.998528e-05,
      "loss": 1.7886,
      "step": 117200
    },
    {
      "epoch": 3.752,
      "grad_norm": 0.31364905834198,
      "learning_rate": 4.9921280000000005e-05,
      "loss": 1.7747,
      "step": 117250
    },
    {
      "epoch": 3.7536,
      "grad_norm": 0.34115901589393616,
      "learning_rate": 4.985728e-05,
      "loss": 1.7484,
      "step": 117300
    },
    {
      "epoch": 3.7552,
      "grad_norm": 0.37098684906959534,
      "learning_rate": 4.979328e-05,
      "loss": 1.7957,
      "step": 117350
    },
    {
      "epoch": 3.7568,
      "grad_norm": 0.42594704031944275,
      "learning_rate": 4.972928e-05,
      "loss": 1.7728,
      "step": 117400
    },
    {
      "epoch": 3.7584,
      "grad_norm": 0.4295347034931183,
      "learning_rate": 4.9665280000000006e-05,
      "loss": 1.7398,
      "step": 117450
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.4144977629184723,
      "learning_rate": 4.960128e-05,
      "loss": 1.7673,
      "step": 117500
    },
    {
      "epoch": 3.7616,
      "grad_norm": 0.40613478422164917,
      "learning_rate": 4.953728e-05,
      "loss": 1.7817,
      "step": 117550
    },
    {
      "epoch": 3.7632,
      "grad_norm": 0.3250367343425751,
      "learning_rate": 4.947328e-05,
      "loss": 1.803,
      "step": 117600
    },
    {
      "epoch": 3.7648,
      "grad_norm": 0.4297170341014862,
      "learning_rate": 4.940928e-05,
      "loss": 1.7424,
      "step": 117650
    },
    {
      "epoch": 3.7664,
      "grad_norm": 0.483887255191803,
      "learning_rate": 4.934528e-05,
      "loss": 1.7421,
      "step": 117700
    },
    {
      "epoch": 3.768,
      "grad_norm": 0.38166311383247375,
      "learning_rate": 4.9281280000000004e-05,
      "loss": 1.7816,
      "step": 117750
    },
    {
      "epoch": 3.7696,
      "grad_norm": 0.42450717091560364,
      "learning_rate": 4.9217280000000006e-05,
      "loss": 1.7909,
      "step": 117800
    },
    {
      "epoch": 3.7712,
      "grad_norm": 0.4843239188194275,
      "learning_rate": 4.915328e-05,
      "loss": 1.7847,
      "step": 117850
    },
    {
      "epoch": 3.7728,
      "grad_norm": 0.38642218708992004,
      "learning_rate": 4.908928e-05,
      "loss": 1.8396,
      "step": 117900
    },
    {
      "epoch": 3.7744,
      "grad_norm": 0.41778862476348877,
      "learning_rate": 4.902528e-05,
      "loss": 1.8257,
      "step": 117950
    },
    {
      "epoch": 3.776,
      "grad_norm": 0.36643046140670776,
      "learning_rate": 4.896128000000001e-05,
      "loss": 1.7888,
      "step": 118000
    },
    {
      "epoch": 3.7776,
      "grad_norm": 0.3804270625114441,
      "learning_rate": 4.889728e-05,
      "loss": 1.8142,
      "step": 118050
    },
    {
      "epoch": 3.7792,
      "grad_norm": 0.377851277589798,
      "learning_rate": 4.8833280000000004e-05,
      "loss": 1.7727,
      "step": 118100
    },
    {
      "epoch": 3.7808,
      "grad_norm": 0.39642152190208435,
      "learning_rate": 4.876928e-05,
      "loss": 1.7369,
      "step": 118150
    },
    {
      "epoch": 3.7824,
      "grad_norm": 0.3401721119880676,
      "learning_rate": 4.870528e-05,
      "loss": 1.7739,
      "step": 118200
    },
    {
      "epoch": 3.784,
      "grad_norm": 0.38731464743614197,
      "learning_rate": 4.864128e-05,
      "loss": 1.7598,
      "step": 118250
    },
    {
      "epoch": 3.7856,
      "grad_norm": 0.4826756715774536,
      "learning_rate": 4.8577280000000005e-05,
      "loss": 1.7757,
      "step": 118300
    },
    {
      "epoch": 3.7872,
      "grad_norm": 0.3581557869911194,
      "learning_rate": 4.851328e-05,
      "loss": 1.79,
      "step": 118350
    },
    {
      "epoch": 3.7888,
      "grad_norm": 0.35755154490470886,
      "learning_rate": 4.844928e-05,
      "loss": 1.7187,
      "step": 118400
    },
    {
      "epoch": 3.7904,
      "grad_norm": 0.44300031661987305,
      "learning_rate": 4.8385280000000004e-05,
      "loss": 1.7466,
      "step": 118450
    },
    {
      "epoch": 3.792,
      "grad_norm": 0.37140747904777527,
      "learning_rate": 4.832128e-05,
      "loss": 1.758,
      "step": 118500
    },
    {
      "epoch": 3.7936,
      "grad_norm": 0.4704631268978119,
      "learning_rate": 4.825728e-05,
      "loss": 1.7924,
      "step": 118550
    },
    {
      "epoch": 3.7952,
      "grad_norm": 0.3949165642261505,
      "learning_rate": 4.8193280000000004e-05,
      "loss": 1.7773,
      "step": 118600
    },
    {
      "epoch": 3.7968,
      "grad_norm": 0.4868442714214325,
      "learning_rate": 4.8129280000000006e-05,
      "loss": 1.7344,
      "step": 118650
    },
    {
      "epoch": 3.7984,
      "grad_norm": 0.44227322936058044,
      "learning_rate": 4.806528e-05,
      "loss": 1.7815,
      "step": 118700
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.46667519211769104,
      "learning_rate": 4.800128e-05,
      "loss": 1.7187,
      "step": 118750
    },
    {
      "epoch": 3.8016,
      "grad_norm": 0.35829171538352966,
      "learning_rate": 4.793728e-05,
      "loss": 1.8364,
      "step": 118800
    },
    {
      "epoch": 3.8032,
      "grad_norm": 0.3773699700832367,
      "learning_rate": 4.7873280000000007e-05,
      "loss": 1.7798,
      "step": 118850
    },
    {
      "epoch": 3.8048,
      "grad_norm": 0.3970821499824524,
      "learning_rate": 4.780928e-05,
      "loss": 1.7765,
      "step": 118900
    },
    {
      "epoch": 3.8064,
      "grad_norm": 0.4096861481666565,
      "learning_rate": 4.7745280000000004e-05,
      "loss": 1.7962,
      "step": 118950
    },
    {
      "epoch": 3.808,
      "grad_norm": 0.38947007060050964,
      "learning_rate": 4.768128e-05,
      "loss": 1.7436,
      "step": 119000
    },
    {
      "epoch": 3.8096,
      "grad_norm": 0.38203808665275574,
      "learning_rate": 4.761728e-05,
      "loss": 1.8231,
      "step": 119050
    },
    {
      "epoch": 3.8112,
      "grad_norm": 0.38434624671936035,
      "learning_rate": 4.755328e-05,
      "loss": 1.7553,
      "step": 119100
    },
    {
      "epoch": 3.8128,
      "grad_norm": 0.43189889192581177,
      "learning_rate": 4.7489280000000005e-05,
      "loss": 1.7696,
      "step": 119150
    },
    {
      "epoch": 3.8144,
      "grad_norm": 0.30616772174835205,
      "learning_rate": 4.742528e-05,
      "loss": 1.7681,
      "step": 119200
    },
    {
      "epoch": 3.816,
      "grad_norm": 0.4103303551673889,
      "learning_rate": 4.736128e-05,
      "loss": 1.7789,
      "step": 119250
    },
    {
      "epoch": 3.8176,
      "grad_norm": 0.4246387779712677,
      "learning_rate": 4.7297280000000004e-05,
      "loss": 1.807,
      "step": 119300
    },
    {
      "epoch": 3.8192,
      "grad_norm": 0.42136135697364807,
      "learning_rate": 4.723328e-05,
      "loss": 1.7457,
      "step": 119350
    },
    {
      "epoch": 3.8208,
      "grad_norm": 0.48513373732566833,
      "learning_rate": 4.716928000000001e-05,
      "loss": 1.7327,
      "step": 119400
    },
    {
      "epoch": 3.8224,
      "grad_norm": 0.37937209010124207,
      "learning_rate": 4.710528e-05,
      "loss": 1.75,
      "step": 119450
    },
    {
      "epoch": 3.824,
      "grad_norm": 0.37272369861602783,
      "learning_rate": 4.7041280000000005e-05,
      "loss": 1.7682,
      "step": 119500
    },
    {
      "epoch": 3.8256,
      "grad_norm": 0.4109598696231842,
      "learning_rate": 4.697728e-05,
      "loss": 1.7901,
      "step": 119550
    },
    {
      "epoch": 3.8272,
      "grad_norm": 0.412590891122818,
      "learning_rate": 4.691328e-05,
      "loss": 1.7993,
      "step": 119600
    },
    {
      "epoch": 3.8288,
      "grad_norm": 0.36019420623779297,
      "learning_rate": 4.6849280000000004e-05,
      "loss": 1.7705,
      "step": 119650
    },
    {
      "epoch": 3.8304,
      "grad_norm": 0.34137478470802307,
      "learning_rate": 4.6785280000000006e-05,
      "loss": 1.7783,
      "step": 119700
    },
    {
      "epoch": 3.832,
      "grad_norm": 0.3999260365962982,
      "learning_rate": 4.672128e-05,
      "loss": 1.8034,
      "step": 119750
    },
    {
      "epoch": 3.8336,
      "grad_norm": 0.3731790781021118,
      "learning_rate": 4.665728e-05,
      "loss": 1.7855,
      "step": 119800
    },
    {
      "epoch": 3.8352,
      "grad_norm": 0.3220200836658478,
      "learning_rate": 4.659328e-05,
      "loss": 1.7915,
      "step": 119850
    },
    {
      "epoch": 3.8368,
      "grad_norm": 0.39224913716316223,
      "learning_rate": 4.652928e-05,
      "loss": 1.808,
      "step": 119900
    },
    {
      "epoch": 3.8384,
      "grad_norm": 0.4151133596897125,
      "learning_rate": 4.646528e-05,
      "loss": 1.7734,
      "step": 119950
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.4558384120464325,
      "learning_rate": 4.6401280000000004e-05,
      "loss": 1.8206,
      "step": 120000
    },
    {
      "epoch": 3.8416,
      "grad_norm": 0.36436718702316284,
      "learning_rate": 4.633728e-05,
      "loss": 1.7513,
      "step": 120050
    },
    {
      "epoch": 3.8432,
      "grad_norm": 0.4767054617404938,
      "learning_rate": 4.627328e-05,
      "loss": 1.7898,
      "step": 120100
    },
    {
      "epoch": 3.8448,
      "grad_norm": 0.3187929391860962,
      "learning_rate": 4.6209280000000004e-05,
      "loss": 1.7598,
      "step": 120150
    },
    {
      "epoch": 3.8464,
      "grad_norm": 0.3837836980819702,
      "learning_rate": 4.614528e-05,
      "loss": 1.8028,
      "step": 120200
    },
    {
      "epoch": 3.848,
      "grad_norm": 0.34858402609825134,
      "learning_rate": 4.608128000000001e-05,
      "loss": 1.75,
      "step": 120250
    },
    {
      "epoch": 3.8496,
      "grad_norm": 0.47809773683547974,
      "learning_rate": 4.601728e-05,
      "loss": 1.7056,
      "step": 120300
    },
    {
      "epoch": 3.8512,
      "grad_norm": 0.37152278423309326,
      "learning_rate": 4.5953280000000005e-05,
      "loss": 1.7597,
      "step": 120350
    },
    {
      "epoch": 3.8528000000000002,
      "grad_norm": 0.3923037648200989,
      "learning_rate": 4.588928e-05,
      "loss": 1.767,
      "step": 120400
    },
    {
      "epoch": 3.8544,
      "grad_norm": 0.4244837760925293,
      "learning_rate": 4.582528e-05,
      "loss": 1.7625,
      "step": 120450
    },
    {
      "epoch": 3.856,
      "grad_norm": 0.40160760283470154,
      "learning_rate": 4.5761280000000004e-05,
      "loss": 1.7778,
      "step": 120500
    },
    {
      "epoch": 3.8576,
      "grad_norm": 0.48419952392578125,
      "learning_rate": 4.5697280000000006e-05,
      "loss": 1.718,
      "step": 120550
    },
    {
      "epoch": 3.8592,
      "grad_norm": 0.3759668171405792,
      "learning_rate": 4.563328e-05,
      "loss": 1.8052,
      "step": 120600
    },
    {
      "epoch": 3.8608000000000002,
      "grad_norm": 0.4208413064479828,
      "learning_rate": 4.556928e-05,
      "loss": 1.78,
      "step": 120650
    },
    {
      "epoch": 3.8624,
      "grad_norm": 0.379893958568573,
      "learning_rate": 4.550528e-05,
      "loss": 1.7703,
      "step": 120700
    },
    {
      "epoch": 3.864,
      "grad_norm": 0.44779106974601746,
      "learning_rate": 4.544128e-05,
      "loss": 1.7194,
      "step": 120750
    },
    {
      "epoch": 3.8656,
      "grad_norm": 0.3418933153152466,
      "learning_rate": 4.537728e-05,
      "loss": 1.7282,
      "step": 120800
    },
    {
      "epoch": 3.8672,
      "grad_norm": 0.38818326592445374,
      "learning_rate": 4.5313280000000004e-05,
      "loss": 1.8357,
      "step": 120850
    },
    {
      "epoch": 3.8688000000000002,
      "grad_norm": 0.4167572259902954,
      "learning_rate": 4.524928e-05,
      "loss": 1.7913,
      "step": 120900
    },
    {
      "epoch": 3.8704,
      "grad_norm": 0.36184102296829224,
      "learning_rate": 4.518528e-05,
      "loss": 1.784,
      "step": 120950
    },
    {
      "epoch": 3.872,
      "grad_norm": 0.3441062867641449,
      "learning_rate": 4.512128e-05,
      "loss": 1.7546,
      "step": 121000
    },
    {
      "epoch": 3.8736,
      "grad_norm": 0.4853668808937073,
      "learning_rate": 4.505728e-05,
      "loss": 1.8003,
      "step": 121050
    },
    {
      "epoch": 3.8752,
      "grad_norm": 0.3097454309463501,
      "learning_rate": 4.499328000000001e-05,
      "loss": 1.749,
      "step": 121100
    },
    {
      "epoch": 3.8768000000000002,
      "grad_norm": 0.39432263374328613,
      "learning_rate": 4.492928e-05,
      "loss": 1.8155,
      "step": 121150
    },
    {
      "epoch": 3.8784,
      "grad_norm": 0.3447466790676117,
      "learning_rate": 4.4865280000000004e-05,
      "loss": 1.8107,
      "step": 121200
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.4673617482185364,
      "learning_rate": 4.480128e-05,
      "loss": 1.7955,
      "step": 121250
    },
    {
      "epoch": 3.8816,
      "grad_norm": 0.40189385414123535,
      "learning_rate": 4.473728e-05,
      "loss": 1.781,
      "step": 121300
    },
    {
      "epoch": 3.8832,
      "grad_norm": 0.42872869968414307,
      "learning_rate": 4.467328e-05,
      "loss": 1.7434,
      "step": 121350
    },
    {
      "epoch": 3.8848000000000003,
      "grad_norm": 0.3429153263568878,
      "learning_rate": 4.4609280000000005e-05,
      "loss": 1.7439,
      "step": 121400
    },
    {
      "epoch": 3.8864,
      "grad_norm": 0.41435015201568604,
      "learning_rate": 4.454528e-05,
      "loss": 1.7959,
      "step": 121450
    },
    {
      "epoch": 3.888,
      "grad_norm": 0.38480162620544434,
      "learning_rate": 4.448128e-05,
      "loss": 1.7566,
      "step": 121500
    },
    {
      "epoch": 3.8895999999999997,
      "grad_norm": 0.40616846084594727,
      "learning_rate": 4.441728e-05,
      "loss": 1.8032,
      "step": 121550
    },
    {
      "epoch": 3.8912,
      "grad_norm": 0.41678544878959656,
      "learning_rate": 4.435328e-05,
      "loss": 1.7179,
      "step": 121600
    },
    {
      "epoch": 3.8928000000000003,
      "grad_norm": 0.4155212938785553,
      "learning_rate": 4.428928e-05,
      "loss": 1.7496,
      "step": 121650
    },
    {
      "epoch": 3.8944,
      "grad_norm": 0.4966466426849365,
      "learning_rate": 4.4225280000000004e-05,
      "loss": 1.7694,
      "step": 121700
    },
    {
      "epoch": 3.896,
      "grad_norm": 0.4331347346305847,
      "learning_rate": 4.4161280000000006e-05,
      "loss": 1.7907,
      "step": 121750
    },
    {
      "epoch": 3.8975999999999997,
      "grad_norm": 0.4532674551010132,
      "learning_rate": 4.409728e-05,
      "loss": 1.7379,
      "step": 121800
    },
    {
      "epoch": 3.8992,
      "grad_norm": 0.4418942630290985,
      "learning_rate": 4.403328e-05,
      "loss": 1.7936,
      "step": 121850
    },
    {
      "epoch": 3.9008000000000003,
      "grad_norm": 0.3378139138221741,
      "learning_rate": 4.3969280000000005e-05,
      "loss": 1.7481,
      "step": 121900
    },
    {
      "epoch": 3.9024,
      "grad_norm": 0.3347783386707306,
      "learning_rate": 4.390528000000001e-05,
      "loss": 1.7525,
      "step": 121950
    },
    {
      "epoch": 3.904,
      "grad_norm": 0.4028964936733246,
      "learning_rate": 4.384128e-05,
      "loss": 1.7053,
      "step": 122000
    },
    {
      "epoch": 3.9055999999999997,
      "grad_norm": 0.44078195095062256,
      "learning_rate": 4.3777280000000004e-05,
      "loss": 1.8412,
      "step": 122050
    },
    {
      "epoch": 3.9072,
      "grad_norm": 0.4496699869632721,
      "learning_rate": 4.371328e-05,
      "loss": 1.7732,
      "step": 122100
    },
    {
      "epoch": 3.9088000000000003,
      "grad_norm": 0.36339902877807617,
      "learning_rate": 4.364928e-05,
      "loss": 1.7287,
      "step": 122150
    },
    {
      "epoch": 3.9104,
      "grad_norm": 0.36418086290359497,
      "learning_rate": 4.358528e-05,
      "loss": 1.7183,
      "step": 122200
    },
    {
      "epoch": 3.912,
      "grad_norm": 0.3611706793308258,
      "learning_rate": 4.3521280000000005e-05,
      "loss": 1.7982,
      "step": 122250
    },
    {
      "epoch": 3.9135999999999997,
      "grad_norm": 0.435222327709198,
      "learning_rate": 4.345728e-05,
      "loss": 1.7963,
      "step": 122300
    },
    {
      "epoch": 3.9152,
      "grad_norm": 0.42174234986305237,
      "learning_rate": 4.339328e-05,
      "loss": 1.7275,
      "step": 122350
    },
    {
      "epoch": 3.9168,
      "grad_norm": 0.37435275316238403,
      "learning_rate": 4.332928e-05,
      "loss": 1.7106,
      "step": 122400
    },
    {
      "epoch": 3.9184,
      "grad_norm": 0.47203198075294495,
      "learning_rate": 4.326528e-05,
      "loss": 1.8033,
      "step": 122450
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.38081684708595276,
      "learning_rate": 4.320128e-05,
      "loss": 1.7192,
      "step": 122500
    },
    {
      "epoch": 3.9215999999999998,
      "grad_norm": 0.4903521239757538,
      "learning_rate": 4.313728e-05,
      "loss": 1.7761,
      "step": 122550
    },
    {
      "epoch": 3.9232,
      "grad_norm": 0.3614014685153961,
      "learning_rate": 4.3073280000000005e-05,
      "loss": 1.8209,
      "step": 122600
    },
    {
      "epoch": 3.9248,
      "grad_norm": 0.3894631564617157,
      "learning_rate": 4.300928e-05,
      "loss": 1.7689,
      "step": 122650
    },
    {
      "epoch": 3.9264,
      "grad_norm": 0.36516329646110535,
      "learning_rate": 4.294528e-05,
      "loss": 1.7716,
      "step": 122700
    },
    {
      "epoch": 3.928,
      "grad_norm": 0.3886740505695343,
      "learning_rate": 4.2881280000000004e-05,
      "loss": 1.7283,
      "step": 122750
    },
    {
      "epoch": 3.9295999999999998,
      "grad_norm": 0.3812468349933624,
      "learning_rate": 4.2817280000000006e-05,
      "loss": 1.7458,
      "step": 122800
    },
    {
      "epoch": 3.9312,
      "grad_norm": 0.4603159725666046,
      "learning_rate": 4.275328e-05,
      "loss": 1.8084,
      "step": 122850
    },
    {
      "epoch": 3.9328,
      "grad_norm": 0.3668663203716278,
      "learning_rate": 4.268928e-05,
      "loss": 1.7319,
      "step": 122900
    },
    {
      "epoch": 3.9344,
      "grad_norm": 0.4009353220462799,
      "learning_rate": 4.262528e-05,
      "loss": 1.7594,
      "step": 122950
    },
    {
      "epoch": 3.936,
      "grad_norm": 0.36072349548339844,
      "learning_rate": 4.256128e-05,
      "loss": 1.7574,
      "step": 123000
    },
    {
      "epoch": 3.9375999999999998,
      "grad_norm": 0.351833313703537,
      "learning_rate": 4.249728e-05,
      "loss": 1.7983,
      "step": 123050
    },
    {
      "epoch": 3.9392,
      "grad_norm": 0.4405704140663147,
      "learning_rate": 4.2433280000000004e-05,
      "loss": 1.7208,
      "step": 123100
    },
    {
      "epoch": 3.9408,
      "grad_norm": 0.42770063877105713,
      "learning_rate": 4.236928e-05,
      "loss": 1.7355,
      "step": 123150
    },
    {
      "epoch": 3.9424,
      "grad_norm": 0.37784913182258606,
      "learning_rate": 4.230528e-05,
      "loss": 1.7964,
      "step": 123200
    },
    {
      "epoch": 3.944,
      "grad_norm": 0.36131343245506287,
      "learning_rate": 4.224128e-05,
      "loss": 1.7761,
      "step": 123250
    },
    {
      "epoch": 3.9455999999999998,
      "grad_norm": 0.42064937949180603,
      "learning_rate": 4.2177280000000006e-05,
      "loss": 1.7875,
      "step": 123300
    },
    {
      "epoch": 3.9472,
      "grad_norm": 0.36667516827583313,
      "learning_rate": 4.211328e-05,
      "loss": 1.7769,
      "step": 123350
    },
    {
      "epoch": 3.9488,
      "grad_norm": 0.37001529335975647,
      "learning_rate": 4.204928e-05,
      "loss": 1.7594,
      "step": 123400
    },
    {
      "epoch": 3.9504,
      "grad_norm": 0.3790760040283203,
      "learning_rate": 4.1985280000000005e-05,
      "loss": 1.7928,
      "step": 123450
    },
    {
      "epoch": 3.952,
      "grad_norm": 0.40402355790138245,
      "learning_rate": 4.192128e-05,
      "loss": 1.817,
      "step": 123500
    },
    {
      "epoch": 3.9536,
      "grad_norm": 0.35076436400413513,
      "learning_rate": 4.185728e-05,
      "loss": 1.7817,
      "step": 123550
    },
    {
      "epoch": 3.9552,
      "grad_norm": 0.41888517141342163,
      "learning_rate": 4.1793280000000004e-05,
      "loss": 1.7535,
      "step": 123600
    },
    {
      "epoch": 3.9568,
      "grad_norm": 0.40422290563583374,
      "learning_rate": 4.1729280000000006e-05,
      "loss": 1.7996,
      "step": 123650
    },
    {
      "epoch": 3.9584,
      "grad_norm": 0.3540049195289612,
      "learning_rate": 4.166528e-05,
      "loss": 1.8117,
      "step": 123700
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.42683765292167664,
      "learning_rate": 4.160128e-05,
      "loss": 1.7983,
      "step": 123750
    },
    {
      "epoch": 3.9616,
      "grad_norm": 0.40734633803367615,
      "learning_rate": 4.153728e-05,
      "loss": 1.7476,
      "step": 123800
    },
    {
      "epoch": 3.9632,
      "grad_norm": 0.3709624707698822,
      "learning_rate": 4.147328e-05,
      "loss": 1.7989,
      "step": 123850
    },
    {
      "epoch": 3.9648,
      "grad_norm": 0.3904838263988495,
      "learning_rate": 4.140928e-05,
      "loss": 1.821,
      "step": 123900
    },
    {
      "epoch": 3.9664,
      "grad_norm": 0.346242755651474,
      "learning_rate": 4.1345280000000004e-05,
      "loss": 1.8098,
      "step": 123950
    },
    {
      "epoch": 3.968,
      "grad_norm": 0.3805115818977356,
      "learning_rate": 4.128128e-05,
      "loss": 1.7834,
      "step": 124000
    },
    {
      "epoch": 3.9696,
      "grad_norm": 0.41254734992980957,
      "learning_rate": 4.121728e-05,
      "loss": 1.763,
      "step": 124050
    },
    {
      "epoch": 3.9712,
      "grad_norm": 0.3624923825263977,
      "learning_rate": 4.1153279999999996e-05,
      "loss": 1.8039,
      "step": 124100
    },
    {
      "epoch": 3.9728,
      "grad_norm": 0.3499321937561035,
      "learning_rate": 4.1089280000000005e-05,
      "loss": 1.7439,
      "step": 124150
    },
    {
      "epoch": 3.9744,
      "grad_norm": 0.398416668176651,
      "learning_rate": 4.102528e-05,
      "loss": 1.7984,
      "step": 124200
    },
    {
      "epoch": 3.976,
      "grad_norm": 0.36531519889831543,
      "learning_rate": 4.096128e-05,
      "loss": 1.8018,
      "step": 124250
    },
    {
      "epoch": 3.9776,
      "grad_norm": 0.42777368426322937,
      "learning_rate": 4.0897280000000004e-05,
      "loss": 1.7756,
      "step": 124300
    },
    {
      "epoch": 3.9792,
      "grad_norm": 0.3832618296146393,
      "learning_rate": 4.083328e-05,
      "loss": 1.7758,
      "step": 124350
    },
    {
      "epoch": 3.9808,
      "grad_norm": 0.5337307453155518,
      "learning_rate": 4.076928e-05,
      "loss": 1.826,
      "step": 124400
    },
    {
      "epoch": 3.9824,
      "grad_norm": 0.41812804341316223,
      "learning_rate": 4.0705280000000003e-05,
      "loss": 1.8229,
      "step": 124450
    },
    {
      "epoch": 3.984,
      "grad_norm": 0.37645021080970764,
      "learning_rate": 4.0641280000000005e-05,
      "loss": 1.7416,
      "step": 124500
    },
    {
      "epoch": 3.9856,
      "grad_norm": 0.4091265797615051,
      "learning_rate": 4.057728e-05,
      "loss": 1.7755,
      "step": 124550
    },
    {
      "epoch": 3.9872,
      "grad_norm": 0.4663824141025543,
      "learning_rate": 4.051328e-05,
      "loss": 1.7237,
      "step": 124600
    },
    {
      "epoch": 3.9888,
      "grad_norm": 0.3911625146865845,
      "learning_rate": 4.044928e-05,
      "loss": 1.7,
      "step": 124650
    },
    {
      "epoch": 3.9904,
      "grad_norm": 0.40286582708358765,
      "learning_rate": 4.0385280000000006e-05,
      "loss": 1.7302,
      "step": 124700
    },
    {
      "epoch": 3.992,
      "grad_norm": 0.3842273950576782,
      "learning_rate": 4.032128e-05,
      "loss": 1.7766,
      "step": 124750
    },
    {
      "epoch": 3.9936,
      "grad_norm": 0.48580822348594666,
      "learning_rate": 4.0257280000000004e-05,
      "loss": 1.7741,
      "step": 124800
    },
    {
      "epoch": 3.9952,
      "grad_norm": 0.39539119601249695,
      "learning_rate": 4.019328e-05,
      "loss": 1.768,
      "step": 124850
    },
    {
      "epoch": 3.9968,
      "grad_norm": 0.4278053343296051,
      "learning_rate": 4.012928e-05,
      "loss": 1.7834,
      "step": 124900
    },
    {
      "epoch": 3.9984,
      "grad_norm": 0.41272518038749695,
      "learning_rate": 4.006528e-05,
      "loss": 1.8024,
      "step": 124950
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.34138762950897217,
      "learning_rate": 4.0001280000000005e-05,
      "loss": 1.7368,
      "step": 125000
    },
    {
      "epoch": 4.0016,
      "grad_norm": 0.41191986203193665,
      "learning_rate": 3.993728e-05,
      "loss": 1.8001,
      "step": 125050
    },
    {
      "epoch": 4.0032,
      "grad_norm": 0.3783815801143646,
      "learning_rate": 3.987328e-05,
      "loss": 1.7476,
      "step": 125100
    },
    {
      "epoch": 4.0048,
      "grad_norm": 0.4319954812526703,
      "learning_rate": 3.9809280000000004e-05,
      "loss": 1.7425,
      "step": 125150
    },
    {
      "epoch": 4.0064,
      "grad_norm": 0.44808292388916016,
      "learning_rate": 3.974528e-05,
      "loss": 1.7829,
      "step": 125200
    },
    {
      "epoch": 4.008,
      "grad_norm": 0.4345794916152954,
      "learning_rate": 3.968128e-05,
      "loss": 1.7144,
      "step": 125250
    },
    {
      "epoch": 4.0096,
      "grad_norm": 0.4559631645679474,
      "learning_rate": 3.961728e-05,
      "loss": 1.7714,
      "step": 125300
    },
    {
      "epoch": 4.0112,
      "grad_norm": 0.34032538533210754,
      "learning_rate": 3.9553280000000005e-05,
      "loss": 1.7152,
      "step": 125350
    },
    {
      "epoch": 4.0128,
      "grad_norm": 0.4129309356212616,
      "learning_rate": 3.948928e-05,
      "loss": 1.7991,
      "step": 125400
    },
    {
      "epoch": 4.0144,
      "grad_norm": 0.44813597202301025,
      "learning_rate": 3.942528e-05,
      "loss": 1.7532,
      "step": 125450
    },
    {
      "epoch": 4.016,
      "grad_norm": 0.42398932576179504,
      "learning_rate": 3.936128e-05,
      "loss": 1.8155,
      "step": 125500
    },
    {
      "epoch": 4.0176,
      "grad_norm": 0.3598460257053375,
      "learning_rate": 3.9297280000000006e-05,
      "loss": 1.7064,
      "step": 125550
    },
    {
      "epoch": 4.0192,
      "grad_norm": 0.40746212005615234,
      "learning_rate": 3.923328e-05,
      "loss": 1.7522,
      "step": 125600
    },
    {
      "epoch": 4.0208,
      "grad_norm": 0.3532629907131195,
      "learning_rate": 3.916928e-05,
      "loss": 1.7797,
      "step": 125650
    },
    {
      "epoch": 4.0224,
      "grad_norm": 0.4912891089916229,
      "learning_rate": 3.910528e-05,
      "loss": 1.7617,
      "step": 125700
    },
    {
      "epoch": 4.024,
      "grad_norm": 0.4422912895679474,
      "learning_rate": 3.904128e-05,
      "loss": 1.7702,
      "step": 125750
    },
    {
      "epoch": 4.0256,
      "grad_norm": 0.3796157240867615,
      "learning_rate": 3.897728e-05,
      "loss": 1.7328,
      "step": 125800
    },
    {
      "epoch": 4.0272,
      "grad_norm": 0.4813831150531769,
      "learning_rate": 3.8913280000000004e-05,
      "loss": 1.7985,
      "step": 125850
    },
    {
      "epoch": 4.0288,
      "grad_norm": 0.41408875584602356,
      "learning_rate": 3.8849280000000006e-05,
      "loss": 1.7896,
      "step": 125900
    },
    {
      "epoch": 4.0304,
      "grad_norm": 0.3814068138599396,
      "learning_rate": 3.878528e-05,
      "loss": 1.7794,
      "step": 125950
    },
    {
      "epoch": 4.032,
      "grad_norm": 0.34309324622154236,
      "learning_rate": 3.8721280000000003e-05,
      "loss": 1.7532,
      "step": 126000
    },
    {
      "epoch": 4.0336,
      "grad_norm": 0.43300724029541016,
      "learning_rate": 3.865728e-05,
      "loss": 1.8036,
      "step": 126050
    },
    {
      "epoch": 4.0352,
      "grad_norm": 0.41182810068130493,
      "learning_rate": 3.859328e-05,
      "loss": 1.725,
      "step": 126100
    },
    {
      "epoch": 4.0368,
      "grad_norm": 0.3929501175880432,
      "learning_rate": 3.852928e-05,
      "loss": 1.7962,
      "step": 126150
    },
    {
      "epoch": 4.0384,
      "grad_norm": 0.3326629102230072,
      "learning_rate": 3.8465280000000005e-05,
      "loss": 1.7457,
      "step": 126200
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.3639194667339325,
      "learning_rate": 3.840128e-05,
      "loss": 1.7912,
      "step": 126250
    },
    {
      "epoch": 4.0416,
      "grad_norm": 0.37921756505966187,
      "learning_rate": 3.833728e-05,
      "loss": 1.8047,
      "step": 126300
    },
    {
      "epoch": 4.0432,
      "grad_norm": 0.3478313982486725,
      "learning_rate": 3.827328e-05,
      "loss": 1.7389,
      "step": 126350
    },
    {
      "epoch": 4.0448,
      "grad_norm": 0.43274110555648804,
      "learning_rate": 3.8209280000000006e-05,
      "loss": 1.7759,
      "step": 126400
    },
    {
      "epoch": 4.0464,
      "grad_norm": 0.49269750714302063,
      "learning_rate": 3.814528e-05,
      "loss": 1.7697,
      "step": 126450
    },
    {
      "epoch": 4.048,
      "grad_norm": 0.45889925956726074,
      "learning_rate": 3.808128e-05,
      "loss": 1.8116,
      "step": 126500
    },
    {
      "epoch": 4.0496,
      "grad_norm": 0.35915857553482056,
      "learning_rate": 3.801728e-05,
      "loss": 1.7667,
      "step": 126550
    },
    {
      "epoch": 4.0512,
      "grad_norm": 0.37805497646331787,
      "learning_rate": 3.795328e-05,
      "loss": 1.7351,
      "step": 126600
    },
    {
      "epoch": 4.0528,
      "grad_norm": 0.4603809714317322,
      "learning_rate": 3.788928e-05,
      "loss": 1.7773,
      "step": 126650
    },
    {
      "epoch": 4.0544,
      "grad_norm": 0.420568585395813,
      "learning_rate": 3.7825280000000004e-05,
      "loss": 1.7617,
      "step": 126700
    },
    {
      "epoch": 4.056,
      "grad_norm": 0.34369203448295593,
      "learning_rate": 3.7761280000000006e-05,
      "loss": 1.8175,
      "step": 126750
    },
    {
      "epoch": 4.0576,
      "grad_norm": 0.4312291741371155,
      "learning_rate": 3.769728e-05,
      "loss": 1.7629,
      "step": 126800
    },
    {
      "epoch": 4.0592,
      "grad_norm": 0.39432746171951294,
      "learning_rate": 3.763328e-05,
      "loss": 1.7097,
      "step": 126850
    },
    {
      "epoch": 4.0608,
      "grad_norm": 0.40086328983306885,
      "learning_rate": 3.756928e-05,
      "loss": 1.7814,
      "step": 126900
    },
    {
      "epoch": 4.0624,
      "grad_norm": 0.42429137229919434,
      "learning_rate": 3.750528000000001e-05,
      "loss": 1.7321,
      "step": 126950
    },
    {
      "epoch": 4.064,
      "grad_norm": 0.36031270027160645,
      "learning_rate": 3.744128e-05,
      "loss": 1.7169,
      "step": 127000
    },
    {
      "epoch": 4.0656,
      "grad_norm": 0.4246329963207245,
      "learning_rate": 3.7377280000000004e-05,
      "loss": 1.7361,
      "step": 127050
    },
    {
      "epoch": 4.0672,
      "grad_norm": 0.4454500377178192,
      "learning_rate": 3.731328e-05,
      "loss": 1.8045,
      "step": 127100
    },
    {
      "epoch": 4.0688,
      "grad_norm": 0.4337879717350006,
      "learning_rate": 3.724928e-05,
      "loss": 1.808,
      "step": 127150
    },
    {
      "epoch": 4.0704,
      "grad_norm": 0.40053895115852356,
      "learning_rate": 3.718528e-05,
      "loss": 1.7993,
      "step": 127200
    },
    {
      "epoch": 4.072,
      "grad_norm": 0.38938552141189575,
      "learning_rate": 3.7121280000000005e-05,
      "loss": 1.7515,
      "step": 127250
    },
    {
      "epoch": 4.0736,
      "grad_norm": 0.4797811806201935,
      "learning_rate": 3.705728e-05,
      "loss": 1.7794,
      "step": 127300
    },
    {
      "epoch": 4.0752,
      "grad_norm": 0.4174382984638214,
      "learning_rate": 3.699328e-05,
      "loss": 1.7779,
      "step": 127350
    },
    {
      "epoch": 4.0768,
      "grad_norm": 0.3723672330379486,
      "learning_rate": 3.692928e-05,
      "loss": 1.7972,
      "step": 127400
    },
    {
      "epoch": 4.0784,
      "grad_norm": 0.3898349702358246,
      "learning_rate": 3.686528e-05,
      "loss": 1.8117,
      "step": 127450
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.3813548982143402,
      "learning_rate": 3.680128e-05,
      "loss": 1.7259,
      "step": 127500
    },
    {
      "epoch": 4.0816,
      "grad_norm": 0.3813994526863098,
      "learning_rate": 3.6737280000000003e-05,
      "loss": 1.7889,
      "step": 127550
    },
    {
      "epoch": 4.0832,
      "grad_norm": 0.436109721660614,
      "learning_rate": 3.6673280000000005e-05,
      "loss": 1.7927,
      "step": 127600
    },
    {
      "epoch": 4.0848,
      "grad_norm": 0.36511534452438354,
      "learning_rate": 3.660928e-05,
      "loss": 1.7569,
      "step": 127650
    },
    {
      "epoch": 4.0864,
      "grad_norm": 0.4006075859069824,
      "learning_rate": 3.654528e-05,
      "loss": 1.7339,
      "step": 127700
    },
    {
      "epoch": 4.088,
      "grad_norm": 0.4085969030857086,
      "learning_rate": 3.648128e-05,
      "loss": 1.7798,
      "step": 127750
    },
    {
      "epoch": 4.0896,
      "grad_norm": 0.4032723903656006,
      "learning_rate": 3.6417280000000007e-05,
      "loss": 1.7815,
      "step": 127800
    },
    {
      "epoch": 4.0912,
      "grad_norm": 0.45712316036224365,
      "learning_rate": 3.635328e-05,
      "loss": 1.7675,
      "step": 127850
    },
    {
      "epoch": 4.0928,
      "grad_norm": 0.41559621691703796,
      "learning_rate": 3.6289280000000004e-05,
      "loss": 1.7205,
      "step": 127900
    },
    {
      "epoch": 4.0944,
      "grad_norm": 0.4381864070892334,
      "learning_rate": 3.622528e-05,
      "loss": 1.7602,
      "step": 127950
    },
    {
      "epoch": 4.096,
      "grad_norm": 0.38852357864379883,
      "learning_rate": 3.616128e-05,
      "loss": 1.7388,
      "step": 128000
    },
    {
      "epoch": 4.0976,
      "grad_norm": 0.40254464745521545,
      "learning_rate": 3.609728e-05,
      "loss": 1.8023,
      "step": 128050
    },
    {
      "epoch": 4.0992,
      "grad_norm": 0.4765555262565613,
      "learning_rate": 3.6033280000000005e-05,
      "loss": 1.7882,
      "step": 128100
    },
    {
      "epoch": 4.1008,
      "grad_norm": 0.4422112703323364,
      "learning_rate": 3.596928e-05,
      "loss": 1.7373,
      "step": 128150
    },
    {
      "epoch": 4.1024,
      "grad_norm": 0.41468197107315063,
      "learning_rate": 3.590528e-05,
      "loss": 1.7962,
      "step": 128200
    },
    {
      "epoch": 4.104,
      "grad_norm": 0.3741786479949951,
      "learning_rate": 3.584128e-05,
      "loss": 1.7712,
      "step": 128250
    },
    {
      "epoch": 4.1056,
      "grad_norm": 0.4281790256500244,
      "learning_rate": 3.577728e-05,
      "loss": 1.8227,
      "step": 128300
    },
    {
      "epoch": 4.1072,
      "grad_norm": 0.4072685241699219,
      "learning_rate": 3.571328e-05,
      "loss": 1.8334,
      "step": 128350
    },
    {
      "epoch": 4.1088,
      "grad_norm": 0.3758835792541504,
      "learning_rate": 3.564928e-05,
      "loss": 1.728,
      "step": 128400
    },
    {
      "epoch": 4.1104,
      "grad_norm": 0.44011083245277405,
      "learning_rate": 3.5585280000000005e-05,
      "loss": 1.7982,
      "step": 128450
    },
    {
      "epoch": 4.112,
      "grad_norm": 0.4284288287162781,
      "learning_rate": 3.552128e-05,
      "loss": 1.8314,
      "step": 128500
    },
    {
      "epoch": 4.1136,
      "grad_norm": 0.40949881076812744,
      "learning_rate": 3.545728e-05,
      "loss": 1.7204,
      "step": 128550
    },
    {
      "epoch": 4.1152,
      "grad_norm": 0.40541374683380127,
      "learning_rate": 3.5393280000000004e-05,
      "loss": 1.7377,
      "step": 128600
    },
    {
      "epoch": 4.1168,
      "grad_norm": 0.33741357922554016,
      "learning_rate": 3.5329280000000006e-05,
      "loss": 1.7592,
      "step": 128650
    },
    {
      "epoch": 4.1184,
      "grad_norm": 0.4092457592487335,
      "learning_rate": 3.526528e-05,
      "loss": 1.771,
      "step": 128700
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.41592806577682495,
      "learning_rate": 3.520128e-05,
      "loss": 1.7011,
      "step": 128750
    },
    {
      "epoch": 4.1216,
      "grad_norm": 0.37610965967178345,
      "learning_rate": 3.513728e-05,
      "loss": 1.7923,
      "step": 128800
    },
    {
      "epoch": 4.1232,
      "grad_norm": 0.48628556728363037,
      "learning_rate": 3.507328e-05,
      "loss": 1.7745,
      "step": 128850
    },
    {
      "epoch": 4.1248,
      "grad_norm": 0.3484880030155182,
      "learning_rate": 3.500928e-05,
      "loss": 1.7868,
      "step": 128900
    },
    {
      "epoch": 4.1264,
      "grad_norm": 0.3883596658706665,
      "learning_rate": 3.4945280000000004e-05,
      "loss": 1.7728,
      "step": 128950
    },
    {
      "epoch": 4.128,
      "grad_norm": 0.44187334179878235,
      "learning_rate": 3.488128e-05,
      "loss": 1.7426,
      "step": 129000
    },
    {
      "epoch": 4.1296,
      "grad_norm": 0.4078713655471802,
      "learning_rate": 3.481728e-05,
      "loss": 1.7588,
      "step": 129050
    },
    {
      "epoch": 4.1312,
      "grad_norm": 0.4381645917892456,
      "learning_rate": 3.475328e-05,
      "loss": 1.7575,
      "step": 129100
    },
    {
      "epoch": 4.1328,
      "grad_norm": 0.4376615583896637,
      "learning_rate": 3.468928e-05,
      "loss": 1.8139,
      "step": 129150
    },
    {
      "epoch": 4.1344,
      "grad_norm": 0.456892728805542,
      "learning_rate": 3.462528000000001e-05,
      "loss": 1.7216,
      "step": 129200
    },
    {
      "epoch": 4.136,
      "grad_norm": 0.4352523684501648,
      "learning_rate": 3.456128e-05,
      "loss": 1.7519,
      "step": 129250
    },
    {
      "epoch": 4.1376,
      "grad_norm": 0.5197759866714478,
      "learning_rate": 3.4497280000000005e-05,
      "loss": 1.7528,
      "step": 129300
    },
    {
      "epoch": 4.1392,
      "grad_norm": 0.37021324038505554,
      "learning_rate": 3.443328e-05,
      "loss": 1.7531,
      "step": 129350
    },
    {
      "epoch": 4.1408,
      "grad_norm": 0.49488645792007446,
      "learning_rate": 3.436928e-05,
      "loss": 1.7433,
      "step": 129400
    },
    {
      "epoch": 4.1424,
      "grad_norm": 0.4366689622402191,
      "learning_rate": 3.4305280000000004e-05,
      "loss": 1.7642,
      "step": 129450
    },
    {
      "epoch": 4.144,
      "grad_norm": 0.3852319121360779,
      "learning_rate": 3.4241280000000006e-05,
      "loss": 1.7236,
      "step": 129500
    },
    {
      "epoch": 4.1456,
      "grad_norm": 0.40640702843666077,
      "learning_rate": 3.417728e-05,
      "loss": 1.8153,
      "step": 129550
    },
    {
      "epoch": 4.1472,
      "grad_norm": 0.3737415671348572,
      "learning_rate": 3.411328e-05,
      "loss": 1.7567,
      "step": 129600
    },
    {
      "epoch": 4.1488,
      "grad_norm": 0.3921526074409485,
      "learning_rate": 3.404928e-05,
      "loss": 1.7296,
      "step": 129650
    },
    {
      "epoch": 4.1504,
      "grad_norm": 0.3876691460609436,
      "learning_rate": 3.398528e-05,
      "loss": 1.7407,
      "step": 129700
    },
    {
      "epoch": 4.152,
      "grad_norm": 0.373249351978302,
      "learning_rate": 3.392128e-05,
      "loss": 1.7268,
      "step": 129750
    },
    {
      "epoch": 4.1536,
      "grad_norm": 0.3896702229976654,
      "learning_rate": 3.3857280000000004e-05,
      "loss": 1.7629,
      "step": 129800
    },
    {
      "epoch": 4.1552,
      "grad_norm": 0.44059380888938904,
      "learning_rate": 3.379328e-05,
      "loss": 1.7609,
      "step": 129850
    },
    {
      "epoch": 4.1568,
      "grad_norm": 0.4145008325576782,
      "learning_rate": 3.372928e-05,
      "loss": 1.7215,
      "step": 129900
    },
    {
      "epoch": 4.1584,
      "grad_norm": 0.35136666893959045,
      "learning_rate": 3.3665279999999996e-05,
      "loss": 1.7149,
      "step": 129950
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.3562013506889343,
      "learning_rate": 3.3601280000000005e-05,
      "loss": 1.7837,
      "step": 130000
    },
    {
      "epoch": 4.1616,
      "grad_norm": 0.5007980465888977,
      "learning_rate": 3.353728000000001e-05,
      "loss": 1.7544,
      "step": 130050
    },
    {
      "epoch": 4.1632,
      "grad_norm": 0.4079759120941162,
      "learning_rate": 3.347328e-05,
      "loss": 1.7396,
      "step": 130100
    },
    {
      "epoch": 4.1648,
      "grad_norm": 0.4539996087551117,
      "learning_rate": 3.3409280000000004e-05,
      "loss": 1.6996,
      "step": 130150
    },
    {
      "epoch": 4.1664,
      "grad_norm": 0.45083144307136536,
      "learning_rate": 3.334528e-05,
      "loss": 1.8208,
      "step": 130200
    },
    {
      "epoch": 4.168,
      "grad_norm": 0.39571937918663025,
      "learning_rate": 3.328128e-05,
      "loss": 1.7166,
      "step": 130250
    },
    {
      "epoch": 4.1696,
      "grad_norm": 0.3642788529396057,
      "learning_rate": 3.321728e-05,
      "loss": 1.7853,
      "step": 130300
    },
    {
      "epoch": 4.1712,
      "grad_norm": 0.4975512623786926,
      "learning_rate": 3.3153280000000005e-05,
      "loss": 1.7332,
      "step": 130350
    },
    {
      "epoch": 4.1728,
      "grad_norm": 0.48632168769836426,
      "learning_rate": 3.308928e-05,
      "loss": 1.752,
      "step": 130400
    },
    {
      "epoch": 4.1744,
      "grad_norm": 0.3770265579223633,
      "learning_rate": 3.302528e-05,
      "loss": 1.8075,
      "step": 130450
    },
    {
      "epoch": 4.176,
      "grad_norm": 0.4514397978782654,
      "learning_rate": 3.296128e-05,
      "loss": 1.7608,
      "step": 130500
    },
    {
      "epoch": 4.1776,
      "grad_norm": 0.46240290999412537,
      "learning_rate": 3.289728e-05,
      "loss": 1.7928,
      "step": 130550
    },
    {
      "epoch": 4.1792,
      "grad_norm": 0.3704444169998169,
      "learning_rate": 3.283328e-05,
      "loss": 1.7567,
      "step": 130600
    },
    {
      "epoch": 4.1808,
      "grad_norm": 0.4177597761154175,
      "learning_rate": 3.2769280000000003e-05,
      "loss": 1.7545,
      "step": 130650
    },
    {
      "epoch": 4.1824,
      "grad_norm": 0.4032481610774994,
      "learning_rate": 3.270528e-05,
      "loss": 1.7687,
      "step": 130700
    },
    {
      "epoch": 4.184,
      "grad_norm": 0.39761871099472046,
      "learning_rate": 3.264128e-05,
      "loss": 1.7773,
      "step": 130750
    },
    {
      "epoch": 4.1856,
      "grad_norm": 0.44227614998817444,
      "learning_rate": 3.2577279999999996e-05,
      "loss": 1.7952,
      "step": 130800
    },
    {
      "epoch": 4.1872,
      "grad_norm": 0.473326712846756,
      "learning_rate": 3.2513280000000005e-05,
      "loss": 1.7647,
      "step": 130850
    },
    {
      "epoch": 4.1888,
      "grad_norm": 0.4553089439868927,
      "learning_rate": 3.2449280000000007e-05,
      "loss": 1.7947,
      "step": 130900
    },
    {
      "epoch": 4.1904,
      "grad_norm": 0.34305137395858765,
      "learning_rate": 3.238528e-05,
      "loss": 1.7621,
      "step": 130950
    },
    {
      "epoch": 4.192,
      "grad_norm": 0.3977181315422058,
      "learning_rate": 3.2321280000000004e-05,
      "loss": 1.7167,
      "step": 131000
    },
    {
      "epoch": 4.1936,
      "grad_norm": 0.3637913763523102,
      "learning_rate": 3.225728e-05,
      "loss": 1.7603,
      "step": 131050
    },
    {
      "epoch": 4.1952,
      "grad_norm": 0.37789928913116455,
      "learning_rate": 3.219328e-05,
      "loss": 1.8062,
      "step": 131100
    },
    {
      "epoch": 4.1968,
      "grad_norm": 0.35763493180274963,
      "learning_rate": 3.212928e-05,
      "loss": 1.7631,
      "step": 131150
    },
    {
      "epoch": 4.1984,
      "grad_norm": 0.4388721287250519,
      "learning_rate": 3.2065280000000005e-05,
      "loss": 1.7687,
      "step": 131200
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.3604622185230255,
      "learning_rate": 3.200128e-05,
      "loss": 1.7354,
      "step": 131250
    },
    {
      "epoch": 4.2016,
      "grad_norm": 0.3821284770965576,
      "learning_rate": 3.193728e-05,
      "loss": 1.7363,
      "step": 131300
    },
    {
      "epoch": 4.2032,
      "grad_norm": 0.3958726227283478,
      "learning_rate": 3.187328e-05,
      "loss": 1.7517,
      "step": 131350
    },
    {
      "epoch": 4.2048,
      "grad_norm": 0.36220335960388184,
      "learning_rate": 3.180928e-05,
      "loss": 1.7625,
      "step": 131400
    },
    {
      "epoch": 4.2064,
      "grad_norm": 0.3291603624820709,
      "learning_rate": 3.174528e-05,
      "loss": 1.7218,
      "step": 131450
    },
    {
      "epoch": 4.208,
      "grad_norm": 0.3806557357311249,
      "learning_rate": 3.168128e-05,
      "loss": 1.7972,
      "step": 131500
    },
    {
      "epoch": 4.2096,
      "grad_norm": 0.36584511399269104,
      "learning_rate": 3.161728e-05,
      "loss": 1.7052,
      "step": 131550
    },
    {
      "epoch": 4.2112,
      "grad_norm": 0.38640961050987244,
      "learning_rate": 3.155328e-05,
      "loss": 1.7538,
      "step": 131600
    },
    {
      "epoch": 4.2128,
      "grad_norm": 0.41296929121017456,
      "learning_rate": 3.1489279999999995e-05,
      "loss": 1.7776,
      "step": 131650
    },
    {
      "epoch": 4.2144,
      "grad_norm": 0.39400729537010193,
      "learning_rate": 3.1425280000000004e-05,
      "loss": 1.7349,
      "step": 131700
    },
    {
      "epoch": 4.216,
      "grad_norm": 0.46243393421173096,
      "learning_rate": 3.1361280000000006e-05,
      "loss": 1.714,
      "step": 131750
    },
    {
      "epoch": 4.2176,
      "grad_norm": 0.41267746686935425,
      "learning_rate": 3.129728e-05,
      "loss": 1.7596,
      "step": 131800
    },
    {
      "epoch": 4.2192,
      "grad_norm": 0.41291528940200806,
      "learning_rate": 3.123328e-05,
      "loss": 1.7093,
      "step": 131850
    },
    {
      "epoch": 4.2208,
      "grad_norm": 0.3771187663078308,
      "learning_rate": 3.116928e-05,
      "loss": 1.7366,
      "step": 131900
    },
    {
      "epoch": 4.2224,
      "grad_norm": 0.5231824517250061,
      "learning_rate": 3.110528e-05,
      "loss": 1.7411,
      "step": 131950
    },
    {
      "epoch": 4.224,
      "grad_norm": 0.39084112644195557,
      "learning_rate": 3.104128e-05,
      "loss": 1.7087,
      "step": 132000
    },
    {
      "epoch": 4.2256,
      "grad_norm": 0.3550046682357788,
      "learning_rate": 3.0977280000000004e-05,
      "loss": 1.7783,
      "step": 132050
    },
    {
      "epoch": 4.2272,
      "grad_norm": 0.465982586145401,
      "learning_rate": 3.091328e-05,
      "loss": 1.835,
      "step": 132100
    },
    {
      "epoch": 4.2288,
      "grad_norm": 0.3950716555118561,
      "learning_rate": 3.084928e-05,
      "loss": 1.7191,
      "step": 132150
    },
    {
      "epoch": 4.2304,
      "grad_norm": 0.4174615144729614,
      "learning_rate": 3.078528e-05,
      "loss": 1.8163,
      "step": 132200
    },
    {
      "epoch": 4.232,
      "grad_norm": 0.47201138734817505,
      "learning_rate": 3.0721280000000005e-05,
      "loss": 1.8248,
      "step": 132250
    },
    {
      "epoch": 4.2336,
      "grad_norm": 0.3896562159061432,
      "learning_rate": 3.065728e-05,
      "loss": 1.7964,
      "step": 132300
    },
    {
      "epoch": 4.2352,
      "grad_norm": 0.40334847569465637,
      "learning_rate": 3.059328e-05,
      "loss": 1.8164,
      "step": 132350
    },
    {
      "epoch": 4.2368,
      "grad_norm": 0.45535969734191895,
      "learning_rate": 3.052928e-05,
      "loss": 1.8251,
      "step": 132400
    },
    {
      "epoch": 4.2384,
      "grad_norm": 0.42405393719673157,
      "learning_rate": 3.0465280000000003e-05,
      "loss": 1.7877,
      "step": 132450
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.33558791875839233,
      "learning_rate": 3.0401280000000005e-05,
      "loss": 1.7959,
      "step": 132500
    },
    {
      "epoch": 4.2416,
      "grad_norm": 0.3954451382160187,
      "learning_rate": 3.033728e-05,
      "loss": 1.8088,
      "step": 132550
    },
    {
      "epoch": 4.2432,
      "grad_norm": 0.405661016702652,
      "learning_rate": 3.0273280000000002e-05,
      "loss": 1.7658,
      "step": 132600
    },
    {
      "epoch": 4.2448,
      "grad_norm": 0.42801886796951294,
      "learning_rate": 3.020928e-05,
      "loss": 1.7453,
      "step": 132650
    },
    {
      "epoch": 4.2464,
      "grad_norm": 0.46543633937835693,
      "learning_rate": 3.0145280000000003e-05,
      "loss": 1.7386,
      "step": 132700
    },
    {
      "epoch": 4.248,
      "grad_norm": 0.4168168306350708,
      "learning_rate": 3.008128e-05,
      "loss": 1.7674,
      "step": 132750
    },
    {
      "epoch": 4.2496,
      "grad_norm": 0.37444785237312317,
      "learning_rate": 3.0017280000000003e-05,
      "loss": 1.7852,
      "step": 132800
    },
    {
      "epoch": 4.2512,
      "grad_norm": 0.4170636832714081,
      "learning_rate": 2.995328e-05,
      "loss": 1.8065,
      "step": 132850
    },
    {
      "epoch": 4.2528,
      "grad_norm": 0.4209556579589844,
      "learning_rate": 2.9889280000000004e-05,
      "loss": 1.7664,
      "step": 132900
    },
    {
      "epoch": 4.2544,
      "grad_norm": 0.3452260196208954,
      "learning_rate": 2.982528e-05,
      "loss": 1.7177,
      "step": 132950
    },
    {
      "epoch": 4.256,
      "grad_norm": 0.4602728486061096,
      "learning_rate": 2.976128e-05,
      "loss": 1.7273,
      "step": 133000
    },
    {
      "epoch": 4.2576,
      "grad_norm": 0.46372100710868835,
      "learning_rate": 2.969728e-05,
      "loss": 1.7972,
      "step": 133050
    },
    {
      "epoch": 4.2592,
      "grad_norm": 0.46190282702445984,
      "learning_rate": 2.963328e-05,
      "loss": 1.7771,
      "step": 133100
    },
    {
      "epoch": 4.2608,
      "grad_norm": 0.48026105761528015,
      "learning_rate": 2.956928e-05,
      "loss": 1.7256,
      "step": 133150
    },
    {
      "epoch": 4.2624,
      "grad_norm": 0.3891874849796295,
      "learning_rate": 2.9505280000000002e-05,
      "loss": 1.7859,
      "step": 133200
    },
    {
      "epoch": 4.264,
      "grad_norm": 0.4161439538002014,
      "learning_rate": 2.9441279999999997e-05,
      "loss": 1.7904,
      "step": 133250
    },
    {
      "epoch": 4.2656,
      "grad_norm": 0.47802114486694336,
      "learning_rate": 2.9377280000000003e-05,
      "loss": 1.7078,
      "step": 133300
    },
    {
      "epoch": 4.2672,
      "grad_norm": 0.5018448233604431,
      "learning_rate": 2.9313280000000005e-05,
      "loss": 1.7978,
      "step": 133350
    },
    {
      "epoch": 4.2688,
      "grad_norm": 0.40903711318969727,
      "learning_rate": 2.924928e-05,
      "loss": 1.7529,
      "step": 133400
    },
    {
      "epoch": 4.2704,
      "grad_norm": 0.3701683282852173,
      "learning_rate": 2.9185280000000005e-05,
      "loss": 1.7544,
      "step": 133450
    },
    {
      "epoch": 4.272,
      "grad_norm": 0.4699590802192688,
      "learning_rate": 2.912128e-05,
      "loss": 1.7394,
      "step": 133500
    },
    {
      "epoch": 4.2736,
      "grad_norm": 0.4415106773376465,
      "learning_rate": 2.9057280000000002e-05,
      "loss": 1.7704,
      "step": 133550
    },
    {
      "epoch": 4.2752,
      "grad_norm": 0.40530508756637573,
      "learning_rate": 2.899328e-05,
      "loss": 1.7729,
      "step": 133600
    },
    {
      "epoch": 4.2768,
      "grad_norm": 0.4071703851222992,
      "learning_rate": 2.8929280000000003e-05,
      "loss": 1.7763,
      "step": 133650
    },
    {
      "epoch": 4.2783999999999995,
      "grad_norm": 0.457675576210022,
      "learning_rate": 2.886528e-05,
      "loss": 1.7811,
      "step": 133700
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.47321075201034546,
      "learning_rate": 2.8801280000000004e-05,
      "loss": 1.7372,
      "step": 133750
    },
    {
      "epoch": 4.2816,
      "grad_norm": 0.40937498211860657,
      "learning_rate": 2.873728e-05,
      "loss": 1.7541,
      "step": 133800
    },
    {
      "epoch": 4.2832,
      "grad_norm": 0.42128437757492065,
      "learning_rate": 2.867328e-05,
      "loss": 1.792,
      "step": 133850
    },
    {
      "epoch": 4.2848,
      "grad_norm": 0.38223797082901,
      "learning_rate": 2.860928e-05,
      "loss": 1.8271,
      "step": 133900
    },
    {
      "epoch": 4.2864,
      "grad_norm": 0.3648390769958496,
      "learning_rate": 2.854528e-05,
      "loss": 1.7561,
      "step": 133950
    },
    {
      "epoch": 4.288,
      "grad_norm": 0.3975238502025604,
      "learning_rate": 2.848128e-05,
      "loss": 1.7418,
      "step": 134000
    },
    {
      "epoch": 4.2896,
      "grad_norm": 0.4175010025501251,
      "learning_rate": 2.8417280000000002e-05,
      "loss": 1.7587,
      "step": 134050
    },
    {
      "epoch": 4.2912,
      "grad_norm": 0.4200953245162964,
      "learning_rate": 2.835328e-05,
      "loss": 1.7536,
      "step": 134100
    },
    {
      "epoch": 4.2928,
      "grad_norm": 0.4544427692890167,
      "learning_rate": 2.8289280000000002e-05,
      "loss": 1.7701,
      "step": 134150
    },
    {
      "epoch": 4.2943999999999996,
      "grad_norm": 0.4057215750217438,
      "learning_rate": 2.8225280000000004e-05,
      "loss": 1.7642,
      "step": 134200
    },
    {
      "epoch": 4.296,
      "grad_norm": 0.37639734148979187,
      "learning_rate": 2.816128e-05,
      "loss": 1.75,
      "step": 134250
    },
    {
      "epoch": 4.2976,
      "grad_norm": 0.4448997378349304,
      "learning_rate": 2.8097280000000005e-05,
      "loss": 1.7481,
      "step": 134300
    },
    {
      "epoch": 4.2992,
      "grad_norm": 0.42246177792549133,
      "learning_rate": 2.803328e-05,
      "loss": 1.7465,
      "step": 134350
    },
    {
      "epoch": 4.3008,
      "grad_norm": 0.3649190366268158,
      "learning_rate": 2.7969280000000002e-05,
      "loss": 1.7084,
      "step": 134400
    },
    {
      "epoch": 4.3024000000000004,
      "grad_norm": 0.3844453692436218,
      "learning_rate": 2.790528e-05,
      "loss": 1.724,
      "step": 134450
    },
    {
      "epoch": 4.304,
      "grad_norm": 0.4788132905960083,
      "learning_rate": 2.7841280000000003e-05,
      "loss": 1.7577,
      "step": 134500
    },
    {
      "epoch": 4.3056,
      "grad_norm": 0.3365366458892822,
      "learning_rate": 2.777728e-05,
      "loss": 1.7819,
      "step": 134550
    },
    {
      "epoch": 4.3072,
      "grad_norm": 0.4185377359390259,
      "learning_rate": 2.7713280000000003e-05,
      "loss": 1.7851,
      "step": 134600
    },
    {
      "epoch": 4.3088,
      "grad_norm": 0.3834024667739868,
      "learning_rate": 2.7649279999999998e-05,
      "loss": 1.7568,
      "step": 134650
    },
    {
      "epoch": 4.3104,
      "grad_norm": 0.4284251630306244,
      "learning_rate": 2.7585280000000004e-05,
      "loss": 1.7127,
      "step": 134700
    },
    {
      "epoch": 4.312,
      "grad_norm": 0.38737568259239197,
      "learning_rate": 2.752128e-05,
      "loss": 1.7647,
      "step": 134750
    },
    {
      "epoch": 4.3136,
      "grad_norm": 0.40045857429504395,
      "learning_rate": 2.745728e-05,
      "loss": 1.7381,
      "step": 134800
    },
    {
      "epoch": 4.3152,
      "grad_norm": 0.4050670266151428,
      "learning_rate": 2.739328e-05,
      "loss": 1.7775,
      "step": 134850
    },
    {
      "epoch": 4.3168,
      "grad_norm": 0.4016090929508209,
      "learning_rate": 2.732928e-05,
      "loss": 1.7694,
      "step": 134900
    },
    {
      "epoch": 4.3184000000000005,
      "grad_norm": 0.479482501745224,
      "learning_rate": 2.726528e-05,
      "loss": 1.7898,
      "step": 134950
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.4443546235561371,
      "learning_rate": 2.7201280000000002e-05,
      "loss": 1.7,
      "step": 135000
    },
    {
      "epoch": 4.3216,
      "grad_norm": 0.34042179584503174,
      "learning_rate": 2.7137280000000004e-05,
      "loss": 1.7783,
      "step": 135050
    },
    {
      "epoch": 4.3232,
      "grad_norm": 0.352287232875824,
      "learning_rate": 2.7073280000000002e-05,
      "loss": 1.7297,
      "step": 135100
    },
    {
      "epoch": 4.3248,
      "grad_norm": 0.42762070894241333,
      "learning_rate": 2.7009280000000004e-05,
      "loss": 1.7744,
      "step": 135150
    },
    {
      "epoch": 4.3264,
      "grad_norm": 0.3715914487838745,
      "learning_rate": 2.694528e-05,
      "loss": 1.7756,
      "step": 135200
    },
    {
      "epoch": 4.328,
      "grad_norm": 0.44647476077079773,
      "learning_rate": 2.688128e-05,
      "loss": 1.7962,
      "step": 135250
    },
    {
      "epoch": 4.3296,
      "grad_norm": 0.44415733218193054,
      "learning_rate": 2.681728e-05,
      "loss": 1.7623,
      "step": 135300
    },
    {
      "epoch": 4.3312,
      "grad_norm": 0.39378875494003296,
      "learning_rate": 2.6753280000000002e-05,
      "loss": 1.7565,
      "step": 135350
    },
    {
      "epoch": 4.3328,
      "grad_norm": 0.3755338788032532,
      "learning_rate": 2.668928e-05,
      "loss": 1.802,
      "step": 135400
    },
    {
      "epoch": 4.3344,
      "grad_norm": 0.3958839774131775,
      "learning_rate": 2.6625280000000003e-05,
      "loss": 1.7458,
      "step": 135450
    },
    {
      "epoch": 4.336,
      "grad_norm": 0.34025099873542786,
      "learning_rate": 2.6561279999999998e-05,
      "loss": 1.7578,
      "step": 135500
    },
    {
      "epoch": 4.3376,
      "grad_norm": 0.40010592341423035,
      "learning_rate": 2.6497280000000003e-05,
      "loss": 1.8062,
      "step": 135550
    },
    {
      "epoch": 4.3392,
      "grad_norm": 0.3711099922657013,
      "learning_rate": 2.643328e-05,
      "loss": 1.783,
      "step": 135600
    },
    {
      "epoch": 4.3408,
      "grad_norm": 0.34184497594833374,
      "learning_rate": 2.636928e-05,
      "loss": 1.7432,
      "step": 135650
    },
    {
      "epoch": 4.3424,
      "grad_norm": 0.4419390857219696,
      "learning_rate": 2.630528e-05,
      "loss": 1.7815,
      "step": 135700
    },
    {
      "epoch": 4.344,
      "grad_norm": 0.39249786734580994,
      "learning_rate": 2.624128e-05,
      "loss": 1.7161,
      "step": 135750
    },
    {
      "epoch": 4.3456,
      "grad_norm": 0.4337780475616455,
      "learning_rate": 2.6177280000000003e-05,
      "loss": 1.7535,
      "step": 135800
    },
    {
      "epoch": 4.3472,
      "grad_norm": 0.4334585964679718,
      "learning_rate": 2.611328e-05,
      "loss": 1.7817,
      "step": 135850
    },
    {
      "epoch": 4.3488,
      "grad_norm": 0.37674641609191895,
      "learning_rate": 2.6049280000000003e-05,
      "loss": 1.7269,
      "step": 135900
    },
    {
      "epoch": 4.3504,
      "grad_norm": 0.44826698303222656,
      "learning_rate": 2.5985280000000002e-05,
      "loss": 1.7862,
      "step": 135950
    },
    {
      "epoch": 4.352,
      "grad_norm": 0.4511890411376953,
      "learning_rate": 2.5921280000000004e-05,
      "loss": 1.7581,
      "step": 136000
    },
    {
      "epoch": 4.3536,
      "grad_norm": 0.3465085029602051,
      "learning_rate": 2.585728e-05,
      "loss": 1.7291,
      "step": 136050
    },
    {
      "epoch": 4.3552,
      "grad_norm": 0.4063110947608948,
      "learning_rate": 2.5793280000000005e-05,
      "loss": 1.7588,
      "step": 136100
    },
    {
      "epoch": 4.3568,
      "grad_norm": 0.3970423638820648,
      "learning_rate": 2.572928e-05,
      "loss": 1.7484,
      "step": 136150
    },
    {
      "epoch": 4.3584,
      "grad_norm": 0.4459491968154907,
      "learning_rate": 2.5665280000000002e-05,
      "loss": 1.7461,
      "step": 136200
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.38445350527763367,
      "learning_rate": 2.560128e-05,
      "loss": 1.7961,
      "step": 136250
    },
    {
      "epoch": 4.3616,
      "grad_norm": 0.39402273297309875,
      "learning_rate": 2.5537280000000002e-05,
      "loss": 1.8591,
      "step": 136300
    },
    {
      "epoch": 4.3632,
      "grad_norm": 0.3706757128238678,
      "learning_rate": 2.547328e-05,
      "loss": 1.716,
      "step": 136350
    },
    {
      "epoch": 4.3648,
      "grad_norm": 0.429150253534317,
      "learning_rate": 2.5409280000000003e-05,
      "loss": 1.7768,
      "step": 136400
    },
    {
      "epoch": 4.3664,
      "grad_norm": 0.4336698651313782,
      "learning_rate": 2.5345279999999998e-05,
      "loss": 1.8172,
      "step": 136450
    },
    {
      "epoch": 4.368,
      "grad_norm": 0.4739641547203064,
      "learning_rate": 2.528128e-05,
      "loss": 1.7539,
      "step": 136500
    },
    {
      "epoch": 4.3696,
      "grad_norm": 0.3534994125366211,
      "learning_rate": 2.521728e-05,
      "loss": 1.7312,
      "step": 136550
    },
    {
      "epoch": 4.3712,
      "grad_norm": 0.37758004665374756,
      "learning_rate": 2.515328e-05,
      "loss": 1.8233,
      "step": 136600
    },
    {
      "epoch": 4.3728,
      "grad_norm": 0.45005002617836,
      "learning_rate": 2.5089280000000002e-05,
      "loss": 1.7087,
      "step": 136650
    },
    {
      "epoch": 4.3744,
      "grad_norm": 0.40389540791511536,
      "learning_rate": 2.502528e-05,
      "loss": 1.8092,
      "step": 136700
    },
    {
      "epoch": 4.376,
      "grad_norm": 0.3957095444202423,
      "learning_rate": 2.496128e-05,
      "loss": 1.8186,
      "step": 136750
    },
    {
      "epoch": 4.3776,
      "grad_norm": 0.37112757563591003,
      "learning_rate": 2.489728e-05,
      "loss": 1.7303,
      "step": 136800
    },
    {
      "epoch": 4.3792,
      "grad_norm": 0.40948328375816345,
      "learning_rate": 2.483328e-05,
      "loss": 1.7624,
      "step": 136850
    },
    {
      "epoch": 4.3808,
      "grad_norm": 0.49920111894607544,
      "learning_rate": 2.476928e-05,
      "loss": 1.8106,
      "step": 136900
    },
    {
      "epoch": 4.3824,
      "grad_norm": 0.41925233602523804,
      "learning_rate": 2.470528e-05,
      "loss": 1.7768,
      "step": 136950
    },
    {
      "epoch": 4.384,
      "grad_norm": 0.4422839283943176,
      "learning_rate": 2.464128e-05,
      "loss": 1.7893,
      "step": 137000
    },
    {
      "epoch": 4.3856,
      "grad_norm": 0.3591611981391907,
      "learning_rate": 2.457728e-05,
      "loss": 1.794,
      "step": 137050
    },
    {
      "epoch": 4.3872,
      "grad_norm": 0.40322235226631165,
      "learning_rate": 2.4513280000000003e-05,
      "loss": 1.8013,
      "step": 137100
    },
    {
      "epoch": 4.3888,
      "grad_norm": 0.38914647698402405,
      "learning_rate": 2.4449280000000002e-05,
      "loss": 1.7916,
      "step": 137150
    },
    {
      "epoch": 4.3904,
      "grad_norm": 0.4601389169692993,
      "learning_rate": 2.438528e-05,
      "loss": 1.7782,
      "step": 137200
    },
    {
      "epoch": 4.392,
      "grad_norm": 0.45051145553588867,
      "learning_rate": 2.4321280000000002e-05,
      "loss": 1.8068,
      "step": 137250
    },
    {
      "epoch": 4.3936,
      "grad_norm": 0.4255218207836151,
      "learning_rate": 2.425728e-05,
      "loss": 1.768,
      "step": 137300
    },
    {
      "epoch": 4.3952,
      "grad_norm": 0.48245730996131897,
      "learning_rate": 2.4193280000000003e-05,
      "loss": 1.7563,
      "step": 137350
    },
    {
      "epoch": 4.3968,
      "grad_norm": 0.43584203720092773,
      "learning_rate": 2.412928e-05,
      "loss": 1.7477,
      "step": 137400
    },
    {
      "epoch": 4.3984,
      "grad_norm": 0.34295204281806946,
      "learning_rate": 2.406528e-05,
      "loss": 1.7575,
      "step": 137450
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.41360363364219666,
      "learning_rate": 2.4001280000000002e-05,
      "loss": 1.7617,
      "step": 137500
    },
    {
      "epoch": 4.4016,
      "grad_norm": 0.4031216502189636,
      "learning_rate": 2.393728e-05,
      "loss": 1.7152,
      "step": 137550
    },
    {
      "epoch": 4.4032,
      "grad_norm": 0.4445989429950714,
      "learning_rate": 2.387328e-05,
      "loss": 1.7651,
      "step": 137600
    },
    {
      "epoch": 4.4048,
      "grad_norm": 0.391650527715683,
      "learning_rate": 2.380928e-05,
      "loss": 1.7797,
      "step": 137650
    },
    {
      "epoch": 4.4064,
      "grad_norm": 0.3942619860172272,
      "learning_rate": 2.374528e-05,
      "loss": 1.7574,
      "step": 137700
    },
    {
      "epoch": 4.408,
      "grad_norm": 0.3333786725997925,
      "learning_rate": 2.3681280000000002e-05,
      "loss": 1.846,
      "step": 137750
    },
    {
      "epoch": 4.4096,
      "grad_norm": 0.4692038893699646,
      "learning_rate": 2.361728e-05,
      "loss": 1.8045,
      "step": 137800
    },
    {
      "epoch": 4.4112,
      "grad_norm": 0.34880530834198,
      "learning_rate": 2.355328e-05,
      "loss": 1.745,
      "step": 137850
    },
    {
      "epoch": 4.4128,
      "grad_norm": 0.4379875957965851,
      "learning_rate": 2.348928e-05,
      "loss": 1.7688,
      "step": 137900
    },
    {
      "epoch": 4.4144,
      "grad_norm": 0.36104685068130493,
      "learning_rate": 2.3425280000000003e-05,
      "loss": 1.8184,
      "step": 137950
    },
    {
      "epoch": 4.416,
      "grad_norm": 0.37088367342948914,
      "learning_rate": 2.336128e-05,
      "loss": 1.7837,
      "step": 138000
    },
    {
      "epoch": 4.4176,
      "grad_norm": 0.4414064288139343,
      "learning_rate": 2.3297280000000003e-05,
      "loss": 1.8086,
      "step": 138050
    },
    {
      "epoch": 4.4192,
      "grad_norm": 0.4342130720615387,
      "learning_rate": 2.3233280000000002e-05,
      "loss": 1.7554,
      "step": 138100
    },
    {
      "epoch": 4.4208,
      "grad_norm": 0.4491097331047058,
      "learning_rate": 2.316928e-05,
      "loss": 1.8226,
      "step": 138150
    },
    {
      "epoch": 4.4224,
      "grad_norm": 0.4072745740413666,
      "learning_rate": 2.3105280000000003e-05,
      "loss": 1.7956,
      "step": 138200
    },
    {
      "epoch": 4.424,
      "grad_norm": 0.3590741455554962,
      "learning_rate": 2.304128e-05,
      "loss": 1.7802,
      "step": 138250
    },
    {
      "epoch": 4.4256,
      "grad_norm": 0.35141295194625854,
      "learning_rate": 2.297728e-05,
      "loss": 1.7799,
      "step": 138300
    },
    {
      "epoch": 4.4272,
      "grad_norm": 0.3990476727485657,
      "learning_rate": 2.291328e-05,
      "loss": 1.7675,
      "step": 138350
    },
    {
      "epoch": 4.4288,
      "grad_norm": 0.41534197330474854,
      "learning_rate": 2.284928e-05,
      "loss": 1.7774,
      "step": 138400
    },
    {
      "epoch": 4.4304,
      "grad_norm": 0.5477338433265686,
      "learning_rate": 2.2785280000000002e-05,
      "loss": 1.7361,
      "step": 138450
    },
    {
      "epoch": 4.432,
      "grad_norm": 0.38752681016921997,
      "learning_rate": 2.272128e-05,
      "loss": 1.751,
      "step": 138500
    },
    {
      "epoch": 4.4336,
      "grad_norm": 0.3461146652698517,
      "learning_rate": 2.265728e-05,
      "loss": 1.7833,
      "step": 138550
    },
    {
      "epoch": 4.4352,
      "grad_norm": 0.3658662438392639,
      "learning_rate": 2.259328e-05,
      "loss": 1.7466,
      "step": 138600
    },
    {
      "epoch": 4.4368,
      "grad_norm": 0.3600664436817169,
      "learning_rate": 2.252928e-05,
      "loss": 1.7447,
      "step": 138650
    },
    {
      "epoch": 4.4384,
      "grad_norm": 0.40104958415031433,
      "learning_rate": 2.2465280000000002e-05,
      "loss": 1.7399,
      "step": 138700
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.5829355120658875,
      "learning_rate": 2.2401280000000004e-05,
      "loss": 1.7257,
      "step": 138750
    },
    {
      "epoch": 4.4416,
      "grad_norm": 0.3834543824195862,
      "learning_rate": 2.2337280000000002e-05,
      "loss": 1.7513,
      "step": 138800
    },
    {
      "epoch": 4.4432,
      "grad_norm": 0.458420068025589,
      "learning_rate": 2.227328e-05,
      "loss": 1.7357,
      "step": 138850
    },
    {
      "epoch": 4.4448,
      "grad_norm": 0.46934670209884644,
      "learning_rate": 2.2209280000000003e-05,
      "loss": 1.7078,
      "step": 138900
    },
    {
      "epoch": 4.4464,
      "grad_norm": 0.3862663507461548,
      "learning_rate": 2.214528e-05,
      "loss": 1.7677,
      "step": 138950
    },
    {
      "epoch": 4.448,
      "grad_norm": 0.42301449179649353,
      "learning_rate": 2.208128e-05,
      "loss": 1.7777,
      "step": 139000
    },
    {
      "epoch": 4.4496,
      "grad_norm": 0.3891770541667938,
      "learning_rate": 2.2017280000000002e-05,
      "loss": 1.8695,
      "step": 139050
    },
    {
      "epoch": 4.4512,
      "grad_norm": 0.464749276638031,
      "learning_rate": 2.195328e-05,
      "loss": 1.782,
      "step": 139100
    },
    {
      "epoch": 4.4528,
      "grad_norm": 0.43369171023368835,
      "learning_rate": 2.188928e-05,
      "loss": 1.7352,
      "step": 139150
    },
    {
      "epoch": 4.4544,
      "grad_norm": 0.3859674036502838,
      "learning_rate": 2.182528e-05,
      "loss": 1.7554,
      "step": 139200
    },
    {
      "epoch": 4.456,
      "grad_norm": 0.40571993589401245,
      "learning_rate": 2.176128e-05,
      "loss": 1.7569,
      "step": 139250
    },
    {
      "epoch": 4.4576,
      "grad_norm": 0.4691516160964966,
      "learning_rate": 2.1697280000000002e-05,
      "loss": 1.8232,
      "step": 139300
    },
    {
      "epoch": 4.4592,
      "grad_norm": 0.45802634954452515,
      "learning_rate": 2.163328e-05,
      "loss": 1.6822,
      "step": 139350
    },
    {
      "epoch": 4.4608,
      "grad_norm": 0.42632314562797546,
      "learning_rate": 2.156928e-05,
      "loss": 1.7877,
      "step": 139400
    },
    {
      "epoch": 4.4624,
      "grad_norm": 0.4926222860813141,
      "learning_rate": 2.150528e-05,
      "loss": 1.7806,
      "step": 139450
    },
    {
      "epoch": 4.464,
      "grad_norm": 0.4763455390930176,
      "learning_rate": 2.144128e-05,
      "loss": 1.7752,
      "step": 139500
    },
    {
      "epoch": 4.4656,
      "grad_norm": 0.37019994854927063,
      "learning_rate": 2.137728e-05,
      "loss": 1.7445,
      "step": 139550
    },
    {
      "epoch": 4.4672,
      "grad_norm": 0.4056251645088196,
      "learning_rate": 2.1313280000000003e-05,
      "loss": 1.7528,
      "step": 139600
    },
    {
      "epoch": 4.4688,
      "grad_norm": 0.42594876885414124,
      "learning_rate": 2.1249280000000002e-05,
      "loss": 1.8268,
      "step": 139650
    },
    {
      "epoch": 4.4704,
      "grad_norm": 0.451857328414917,
      "learning_rate": 2.118528e-05,
      "loss": 1.7169,
      "step": 139700
    },
    {
      "epoch": 4.4719999999999995,
      "grad_norm": 0.38929229974746704,
      "learning_rate": 2.1121280000000003e-05,
      "loss": 1.7751,
      "step": 139750
    },
    {
      "epoch": 4.4736,
      "grad_norm": 0.3913410007953644,
      "learning_rate": 2.105728e-05,
      "loss": 1.7946,
      "step": 139800
    },
    {
      "epoch": 4.4752,
      "grad_norm": 0.4008369743824005,
      "learning_rate": 2.099328e-05,
      "loss": 1.7009,
      "step": 139850
    },
    {
      "epoch": 4.4768,
      "grad_norm": 0.4475737512111664,
      "learning_rate": 2.092928e-05,
      "loss": 1.7347,
      "step": 139900
    },
    {
      "epoch": 4.4784,
      "grad_norm": 0.44699862599372864,
      "learning_rate": 2.086528e-05,
      "loss": 1.766,
      "step": 139950
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.36991873383522034,
      "learning_rate": 2.0801280000000002e-05,
      "loss": 1.7617,
      "step": 140000
    },
    {
      "epoch": 4.4816,
      "grad_norm": 0.39609476923942566,
      "learning_rate": 2.073728e-05,
      "loss": 1.7418,
      "step": 140050
    },
    {
      "epoch": 4.4832,
      "grad_norm": 0.38674378395080566,
      "learning_rate": 2.067328e-05,
      "loss": 1.793,
      "step": 140100
    },
    {
      "epoch": 4.4848,
      "grad_norm": 0.4283759891986847,
      "learning_rate": 2.060928e-05,
      "loss": 1.786,
      "step": 140150
    },
    {
      "epoch": 4.4864,
      "grad_norm": 0.49277549982070923,
      "learning_rate": 2.054528e-05,
      "loss": 1.7298,
      "step": 140200
    },
    {
      "epoch": 4.4879999999999995,
      "grad_norm": 0.3846072256565094,
      "learning_rate": 2.048128e-05,
      "loss": 1.7175,
      "step": 140250
    },
    {
      "epoch": 4.4896,
      "grad_norm": 0.4108431339263916,
      "learning_rate": 2.041728e-05,
      "loss": 1.835,
      "step": 140300
    },
    {
      "epoch": 4.4912,
      "grad_norm": 0.5188635587692261,
      "learning_rate": 2.0353280000000002e-05,
      "loss": 1.7883,
      "step": 140350
    },
    {
      "epoch": 4.4928,
      "grad_norm": 0.4599972665309906,
      "learning_rate": 2.028928e-05,
      "loss": 1.7813,
      "step": 140400
    },
    {
      "epoch": 4.4944,
      "grad_norm": 0.43399977684020996,
      "learning_rate": 2.0225280000000003e-05,
      "loss": 1.7954,
      "step": 140450
    },
    {
      "epoch": 4.496,
      "grad_norm": 0.35517755150794983,
      "learning_rate": 2.016128e-05,
      "loss": 1.8013,
      "step": 140500
    },
    {
      "epoch": 4.4976,
      "grad_norm": 0.43955492973327637,
      "learning_rate": 2.009728e-05,
      "loss": 1.7997,
      "step": 140550
    },
    {
      "epoch": 4.4992,
      "grad_norm": 0.3539118766784668,
      "learning_rate": 2.0033280000000002e-05,
      "loss": 1.8271,
      "step": 140600
    },
    {
      "epoch": 4.5008,
      "grad_norm": 0.3772091567516327,
      "learning_rate": 1.996928e-05,
      "loss": 1.7611,
      "step": 140650
    },
    {
      "epoch": 4.5024,
      "grad_norm": 0.3458874225616455,
      "learning_rate": 1.9905280000000003e-05,
      "loss": 1.8071,
      "step": 140700
    },
    {
      "epoch": 4.504,
      "grad_norm": 0.425296425819397,
      "learning_rate": 1.984128e-05,
      "loss": 1.7685,
      "step": 140750
    },
    {
      "epoch": 4.5056,
      "grad_norm": 0.36608177423477173,
      "learning_rate": 1.977728e-05,
      "loss": 1.761,
      "step": 140800
    },
    {
      "epoch": 4.5072,
      "grad_norm": 0.40742045640945435,
      "learning_rate": 1.9713280000000002e-05,
      "loss": 1.8036,
      "step": 140850
    },
    {
      "epoch": 4.5088,
      "grad_norm": 0.4486866593360901,
      "learning_rate": 1.964928e-05,
      "loss": 1.7929,
      "step": 140900
    },
    {
      "epoch": 4.5104,
      "grad_norm": 0.3730704188346863,
      "learning_rate": 1.958528e-05,
      "loss": 1.767,
      "step": 140950
    },
    {
      "epoch": 4.5120000000000005,
      "grad_norm": 0.38247182965278625,
      "learning_rate": 1.952128e-05,
      "loss": 1.7511,
      "step": 141000
    },
    {
      "epoch": 4.5136,
      "grad_norm": 0.39931827783584595,
      "learning_rate": 1.945728e-05,
      "loss": 1.7161,
      "step": 141050
    },
    {
      "epoch": 4.5152,
      "grad_norm": 0.4305303394794464,
      "learning_rate": 1.939328e-05,
      "loss": 1.7507,
      "step": 141100
    },
    {
      "epoch": 4.5168,
      "grad_norm": 0.43458470702171326,
      "learning_rate": 1.932928e-05,
      "loss": 1.7729,
      "step": 141150
    },
    {
      "epoch": 4.5184,
      "grad_norm": 0.3514322340488434,
      "learning_rate": 1.9265280000000002e-05,
      "loss": 1.7785,
      "step": 141200
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.39936327934265137,
      "learning_rate": 1.920128e-05,
      "loss": 1.8373,
      "step": 141250
    },
    {
      "epoch": 4.5216,
      "grad_norm": 0.37988778948783875,
      "learning_rate": 1.9137280000000003e-05,
      "loss": 1.7684,
      "step": 141300
    },
    {
      "epoch": 4.5232,
      "grad_norm": 0.45340049266815186,
      "learning_rate": 1.907328e-05,
      "loss": 1.7448,
      "step": 141350
    },
    {
      "epoch": 4.5248,
      "grad_norm": 0.4789466857910156,
      "learning_rate": 1.9009280000000003e-05,
      "loss": 1.7803,
      "step": 141400
    },
    {
      "epoch": 4.5264,
      "grad_norm": 0.3611297905445099,
      "learning_rate": 1.894528e-05,
      "loss": 1.7016,
      "step": 141450
    },
    {
      "epoch": 4.5280000000000005,
      "grad_norm": 0.39117109775543213,
      "learning_rate": 1.888128e-05,
      "loss": 1.7914,
      "step": 141500
    },
    {
      "epoch": 4.5296,
      "grad_norm": 0.4698856770992279,
      "learning_rate": 1.8817280000000002e-05,
      "loss": 1.7852,
      "step": 141550
    },
    {
      "epoch": 4.5312,
      "grad_norm": 0.41877639293670654,
      "learning_rate": 1.875328e-05,
      "loss": 1.7641,
      "step": 141600
    },
    {
      "epoch": 4.5328,
      "grad_norm": 0.4093172252178192,
      "learning_rate": 1.868928e-05,
      "loss": 1.7335,
      "step": 141650
    },
    {
      "epoch": 4.5344,
      "grad_norm": 0.3924884498119354,
      "learning_rate": 1.862528e-05,
      "loss": 1.7291,
      "step": 141700
    },
    {
      "epoch": 4.536,
      "grad_norm": 0.46029990911483765,
      "learning_rate": 1.856128e-05,
      "loss": 1.7379,
      "step": 141750
    },
    {
      "epoch": 4.5376,
      "grad_norm": 0.3773218095302582,
      "learning_rate": 1.849728e-05,
      "loss": 1.8434,
      "step": 141800
    },
    {
      "epoch": 4.5392,
      "grad_norm": 0.322907418012619,
      "learning_rate": 1.843328e-05,
      "loss": 1.7601,
      "step": 141850
    },
    {
      "epoch": 4.5408,
      "grad_norm": 0.3581220507621765,
      "learning_rate": 1.836928e-05,
      "loss": 1.7121,
      "step": 141900
    },
    {
      "epoch": 4.5424,
      "grad_norm": 0.2870436906814575,
      "learning_rate": 1.830528e-05,
      "loss": 1.792,
      "step": 141950
    },
    {
      "epoch": 4.5440000000000005,
      "grad_norm": 0.4548421800136566,
      "learning_rate": 1.8241280000000003e-05,
      "loss": 1.7626,
      "step": 142000
    },
    {
      "epoch": 4.5456,
      "grad_norm": 0.4004223346710205,
      "learning_rate": 1.817728e-05,
      "loss": 1.7144,
      "step": 142050
    },
    {
      "epoch": 4.5472,
      "grad_norm": 0.33785301446914673,
      "learning_rate": 1.8113280000000004e-05,
      "loss": 1.7151,
      "step": 142100
    },
    {
      "epoch": 4.5488,
      "grad_norm": 0.3879592716693878,
      "learning_rate": 1.8049280000000002e-05,
      "loss": 1.7312,
      "step": 142150
    },
    {
      "epoch": 4.5504,
      "grad_norm": 0.4133906364440918,
      "learning_rate": 1.798528e-05,
      "loss": 1.7638,
      "step": 142200
    },
    {
      "epoch": 4.552,
      "grad_norm": 0.3510582149028778,
      "learning_rate": 1.7921280000000003e-05,
      "loss": 1.7333,
      "step": 142250
    },
    {
      "epoch": 4.5536,
      "grad_norm": 0.4371779263019562,
      "learning_rate": 1.785728e-05,
      "loss": 1.7805,
      "step": 142300
    },
    {
      "epoch": 4.5552,
      "grad_norm": 0.42856869101524353,
      "learning_rate": 1.779328e-05,
      "loss": 1.7553,
      "step": 142350
    },
    {
      "epoch": 4.5568,
      "grad_norm": 0.3535807728767395,
      "learning_rate": 1.7729280000000002e-05,
      "loss": 1.7367,
      "step": 142400
    },
    {
      "epoch": 4.5584,
      "grad_norm": 0.3585919737815857,
      "learning_rate": 1.766528e-05,
      "loss": 1.7485,
      "step": 142450
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.4230442941188812,
      "learning_rate": 1.760128e-05,
      "loss": 1.8121,
      "step": 142500
    },
    {
      "epoch": 4.5616,
      "grad_norm": 0.36848798394203186,
      "learning_rate": 1.753728e-05,
      "loss": 1.7379,
      "step": 142550
    },
    {
      "epoch": 4.5632,
      "grad_norm": 0.37112903594970703,
      "learning_rate": 1.747328e-05,
      "loss": 1.7428,
      "step": 142600
    },
    {
      "epoch": 4.5648,
      "grad_norm": 0.38881051540374756,
      "learning_rate": 1.740928e-05,
      "loss": 1.806,
      "step": 142650
    },
    {
      "epoch": 4.5664,
      "grad_norm": 0.363862544298172,
      "learning_rate": 1.734528e-05,
      "loss": 1.8051,
      "step": 142700
    },
    {
      "epoch": 4.568,
      "grad_norm": 0.3809419870376587,
      "learning_rate": 1.728128e-05,
      "loss": 1.8005,
      "step": 142750
    },
    {
      "epoch": 4.5696,
      "grad_norm": 0.4053639769554138,
      "learning_rate": 1.721728e-05,
      "loss": 1.7846,
      "step": 142800
    },
    {
      "epoch": 4.5712,
      "grad_norm": 0.3919622302055359,
      "learning_rate": 1.7153280000000003e-05,
      "loss": 1.7543,
      "step": 142850
    },
    {
      "epoch": 4.5728,
      "grad_norm": 0.39159056544303894,
      "learning_rate": 1.708928e-05,
      "loss": 1.7531,
      "step": 142900
    },
    {
      "epoch": 4.5744,
      "grad_norm": 0.4059768617153168,
      "learning_rate": 1.7025280000000003e-05,
      "loss": 1.7452,
      "step": 142950
    },
    {
      "epoch": 4.576,
      "grad_norm": 0.40291687846183777,
      "learning_rate": 1.6961280000000002e-05,
      "loss": 1.7401,
      "step": 143000
    },
    {
      "epoch": 4.5776,
      "grad_norm": 0.38000503182411194,
      "learning_rate": 1.689728e-05,
      "loss": 1.7353,
      "step": 143050
    },
    {
      "epoch": 4.5792,
      "grad_norm": 0.4852999150753021,
      "learning_rate": 1.6833280000000002e-05,
      "loss": 1.7718,
      "step": 143100
    },
    {
      "epoch": 4.5808,
      "grad_norm": 0.3320191204547882,
      "learning_rate": 1.676928e-05,
      "loss": 1.7984,
      "step": 143150
    },
    {
      "epoch": 4.5824,
      "grad_norm": 0.4802783727645874,
      "learning_rate": 1.670528e-05,
      "loss": 1.8158,
      "step": 143200
    },
    {
      "epoch": 4.584,
      "grad_norm": 0.4381293058395386,
      "learning_rate": 1.664128e-05,
      "loss": 1.7719,
      "step": 143250
    },
    {
      "epoch": 4.5856,
      "grad_norm": 0.45788654685020447,
      "learning_rate": 1.657728e-05,
      "loss": 1.7577,
      "step": 143300
    },
    {
      "epoch": 4.5872,
      "grad_norm": 0.43105119466781616,
      "learning_rate": 1.6513280000000002e-05,
      "loss": 1.7644,
      "step": 143350
    },
    {
      "epoch": 4.5888,
      "grad_norm": 0.35658231377601624,
      "learning_rate": 1.644928e-05,
      "loss": 1.7726,
      "step": 143400
    },
    {
      "epoch": 4.5904,
      "grad_norm": 0.39550307393074036,
      "learning_rate": 1.638528e-05,
      "loss": 1.7216,
      "step": 143450
    },
    {
      "epoch": 4.592,
      "grad_norm": 0.4348881244659424,
      "learning_rate": 1.632128e-05,
      "loss": 1.7455,
      "step": 143500
    },
    {
      "epoch": 4.5936,
      "grad_norm": 0.38064441084861755,
      "learning_rate": 1.625728e-05,
      "loss": 1.723,
      "step": 143550
    },
    {
      "epoch": 4.5952,
      "grad_norm": 0.40478190779685974,
      "learning_rate": 1.6193279999999998e-05,
      "loss": 1.757,
      "step": 143600
    },
    {
      "epoch": 4.5968,
      "grad_norm": 0.4232740104198456,
      "learning_rate": 1.612928e-05,
      "loss": 1.7586,
      "step": 143650
    },
    {
      "epoch": 4.5984,
      "grad_norm": 0.4662103056907654,
      "learning_rate": 1.6065280000000002e-05,
      "loss": 1.751,
      "step": 143700
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.3579649031162262,
      "learning_rate": 1.600128e-05,
      "loss": 1.754,
      "step": 143750
    },
    {
      "epoch": 4.6016,
      "grad_norm": 0.39066988229751587,
      "learning_rate": 1.5937280000000003e-05,
      "loss": 1.7425,
      "step": 143800
    },
    {
      "epoch": 4.6032,
      "grad_norm": 0.37702420353889465,
      "learning_rate": 1.587328e-05,
      "loss": 1.7666,
      "step": 143850
    },
    {
      "epoch": 4.6048,
      "grad_norm": 0.40386760234832764,
      "learning_rate": 1.580928e-05,
      "loss": 1.8227,
      "step": 143900
    },
    {
      "epoch": 4.6064,
      "grad_norm": 0.40309974551200867,
      "learning_rate": 1.5745280000000002e-05,
      "loss": 1.7591,
      "step": 143950
    },
    {
      "epoch": 4.608,
      "grad_norm": 0.40271833539009094,
      "learning_rate": 1.568128e-05,
      "loss": 1.7405,
      "step": 144000
    },
    {
      "epoch": 4.6096,
      "grad_norm": 0.3120358884334564,
      "learning_rate": 1.5617280000000002e-05,
      "loss": 1.7851,
      "step": 144050
    },
    {
      "epoch": 4.6112,
      "grad_norm": 0.4143650233745575,
      "learning_rate": 1.555328e-05,
      "loss": 1.7239,
      "step": 144100
    },
    {
      "epoch": 4.6128,
      "grad_norm": 0.38154634833335876,
      "learning_rate": 1.548928e-05,
      "loss": 1.7732,
      "step": 144150
    },
    {
      "epoch": 4.6144,
      "grad_norm": 0.4121951162815094,
      "learning_rate": 1.542528e-05,
      "loss": 1.7783,
      "step": 144200
    },
    {
      "epoch": 4.616,
      "grad_norm": 0.4238017499446869,
      "learning_rate": 1.536128e-05,
      "loss": 1.798,
      "step": 144250
    },
    {
      "epoch": 4.6176,
      "grad_norm": 0.40930432081222534,
      "learning_rate": 1.529728e-05,
      "loss": 1.7125,
      "step": 144300
    },
    {
      "epoch": 4.6192,
      "grad_norm": 0.4263787567615509,
      "learning_rate": 1.5233279999999999e-05,
      "loss": 1.795,
      "step": 144350
    },
    {
      "epoch": 4.6208,
      "grad_norm": 0.35475942492485046,
      "learning_rate": 1.516928e-05,
      "loss": 1.7118,
      "step": 144400
    },
    {
      "epoch": 4.6224,
      "grad_norm": 0.4003359377384186,
      "learning_rate": 1.510528e-05,
      "loss": 1.78,
      "step": 144450
    },
    {
      "epoch": 4.624,
      "grad_norm": 0.35630205273628235,
      "learning_rate": 1.5041280000000001e-05,
      "loss": 1.7154,
      "step": 144500
    },
    {
      "epoch": 4.6256,
      "grad_norm": 0.366211473941803,
      "learning_rate": 1.4977280000000002e-05,
      "loss": 1.7637,
      "step": 144550
    },
    {
      "epoch": 4.6272,
      "grad_norm": 0.3920750617980957,
      "learning_rate": 1.4913280000000002e-05,
      "loss": 1.8021,
      "step": 144600
    },
    {
      "epoch": 4.6288,
      "grad_norm": 0.4271814525127411,
      "learning_rate": 1.4849280000000002e-05,
      "loss": 1.7709,
      "step": 144650
    },
    {
      "epoch": 4.6304,
      "grad_norm": 0.4230140447616577,
      "learning_rate": 1.4785280000000001e-05,
      "loss": 1.7397,
      "step": 144700
    },
    {
      "epoch": 4.632,
      "grad_norm": 0.37774857878685,
      "learning_rate": 1.4721280000000001e-05,
      "loss": 1.7461,
      "step": 144750
    },
    {
      "epoch": 4.6336,
      "grad_norm": 0.4295414984226227,
      "learning_rate": 1.4657280000000001e-05,
      "loss": 1.7463,
      "step": 144800
    },
    {
      "epoch": 4.6352,
      "grad_norm": 0.4147737920284271,
      "learning_rate": 1.4593280000000002e-05,
      "loss": 1.7379,
      "step": 144850
    },
    {
      "epoch": 4.6368,
      "grad_norm": 0.4567839503288269,
      "learning_rate": 1.452928e-05,
      "loss": 1.7548,
      "step": 144900
    },
    {
      "epoch": 4.6384,
      "grad_norm": 0.3779716193675995,
      "learning_rate": 1.446528e-05,
      "loss": 1.8273,
      "step": 144950
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.43892788887023926,
      "learning_rate": 1.440128e-05,
      "loss": 1.7351,
      "step": 145000
    },
    {
      "epoch": 4.6416,
      "grad_norm": 0.4263569712638855,
      "learning_rate": 1.433728e-05,
      "loss": 1.7879,
      "step": 145050
    },
    {
      "epoch": 4.6432,
      "grad_norm": 0.3261556923389435,
      "learning_rate": 1.427328e-05,
      "loss": 1.7849,
      "step": 145100
    },
    {
      "epoch": 4.6448,
      "grad_norm": 0.3917696177959442,
      "learning_rate": 1.420928e-05,
      "loss": 1.7846,
      "step": 145150
    },
    {
      "epoch": 4.6464,
      "grad_norm": 0.41994351148605347,
      "learning_rate": 1.414528e-05,
      "loss": 1.7785,
      "step": 145200
    },
    {
      "epoch": 4.648,
      "grad_norm": 0.4041617214679718,
      "learning_rate": 1.4081279999999999e-05,
      "loss": 1.8249,
      "step": 145250
    },
    {
      "epoch": 4.6495999999999995,
      "grad_norm": 0.3652779459953308,
      "learning_rate": 1.4017279999999999e-05,
      "loss": 1.7464,
      "step": 145300
    },
    {
      "epoch": 4.6512,
      "grad_norm": 0.5092748403549194,
      "learning_rate": 1.3953280000000003e-05,
      "loss": 1.7871,
      "step": 145350
    },
    {
      "epoch": 4.6528,
      "grad_norm": 0.40684404969215393,
      "learning_rate": 1.3889280000000001e-05,
      "loss": 1.755,
      "step": 145400
    },
    {
      "epoch": 4.6544,
      "grad_norm": 0.41243675351142883,
      "learning_rate": 1.3825280000000002e-05,
      "loss": 1.7641,
      "step": 145450
    },
    {
      "epoch": 4.656,
      "grad_norm": 0.4153679609298706,
      "learning_rate": 1.3761280000000002e-05,
      "loss": 1.7287,
      "step": 145500
    },
    {
      "epoch": 4.6576,
      "grad_norm": 0.39565467834472656,
      "learning_rate": 1.369728e-05,
      "loss": 1.804,
      "step": 145550
    },
    {
      "epoch": 4.6592,
      "grad_norm": 0.4073837697505951,
      "learning_rate": 1.363328e-05,
      "loss": 1.7449,
      "step": 145600
    },
    {
      "epoch": 4.6608,
      "grad_norm": 0.3752530813217163,
      "learning_rate": 1.3569280000000001e-05,
      "loss": 1.7967,
      "step": 145650
    },
    {
      "epoch": 4.6624,
      "grad_norm": 0.4433126151561737,
      "learning_rate": 1.3505280000000001e-05,
      "loss": 1.7406,
      "step": 145700
    },
    {
      "epoch": 4.664,
      "grad_norm": 0.3662157356739044,
      "learning_rate": 1.344128e-05,
      "loss": 1.7483,
      "step": 145750
    },
    {
      "epoch": 4.6655999999999995,
      "grad_norm": 0.43538177013397217,
      "learning_rate": 1.337728e-05,
      "loss": 1.779,
      "step": 145800
    },
    {
      "epoch": 4.6672,
      "grad_norm": 0.44954365491867065,
      "learning_rate": 1.331328e-05,
      "loss": 1.8324,
      "step": 145850
    },
    {
      "epoch": 4.6688,
      "grad_norm": 0.42911297082901,
      "learning_rate": 1.324928e-05,
      "loss": 1.8369,
      "step": 145900
    },
    {
      "epoch": 4.6704,
      "grad_norm": 0.3690597712993622,
      "learning_rate": 1.318528e-05,
      "loss": 1.7581,
      "step": 145950
    },
    {
      "epoch": 4.672,
      "grad_norm": 0.41467517614364624,
      "learning_rate": 1.312128e-05,
      "loss": 1.7707,
      "step": 146000
    },
    {
      "epoch": 4.6736,
      "grad_norm": 0.3544228672981262,
      "learning_rate": 1.305728e-05,
      "loss": 1.7659,
      "step": 146050
    },
    {
      "epoch": 4.6752,
      "grad_norm": 0.41878825426101685,
      "learning_rate": 1.299328e-05,
      "loss": 1.8139,
      "step": 146100
    },
    {
      "epoch": 4.6768,
      "grad_norm": 0.39000430703163147,
      "learning_rate": 1.2929280000000002e-05,
      "loss": 1.7514,
      "step": 146150
    },
    {
      "epoch": 4.6784,
      "grad_norm": 0.4276009202003479,
      "learning_rate": 1.2865280000000002e-05,
      "loss": 1.7898,
      "step": 146200
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.47937676310539246,
      "learning_rate": 1.2801280000000001e-05,
      "loss": 1.7905,
      "step": 146250
    },
    {
      "epoch": 4.6815999999999995,
      "grad_norm": 0.36547794938087463,
      "learning_rate": 1.2737280000000001e-05,
      "loss": 1.7196,
      "step": 146300
    },
    {
      "epoch": 4.6832,
      "grad_norm": 0.44602730870246887,
      "learning_rate": 1.2673280000000001e-05,
      "loss": 1.7474,
      "step": 146350
    },
    {
      "epoch": 4.6848,
      "grad_norm": 0.4502098560333252,
      "learning_rate": 1.2609280000000002e-05,
      "loss": 1.7857,
      "step": 146400
    },
    {
      "epoch": 4.6864,
      "grad_norm": 0.40112707018852234,
      "learning_rate": 1.254528e-05,
      "loss": 1.7417,
      "step": 146450
    },
    {
      "epoch": 4.688,
      "grad_norm": 0.41791802644729614,
      "learning_rate": 1.248128e-05,
      "loss": 1.7989,
      "step": 146500
    },
    {
      "epoch": 4.6896,
      "grad_norm": 0.43831899762153625,
      "learning_rate": 1.241728e-05,
      "loss": 1.7755,
      "step": 146550
    },
    {
      "epoch": 4.6912,
      "grad_norm": 0.507810652256012,
      "learning_rate": 1.2353280000000001e-05,
      "loss": 1.754,
      "step": 146600
    },
    {
      "epoch": 4.6928,
      "grad_norm": 0.4493933320045471,
      "learning_rate": 1.228928e-05,
      "loss": 1.7206,
      "step": 146650
    },
    {
      "epoch": 4.6944,
      "grad_norm": 0.4642764925956726,
      "learning_rate": 1.222528e-05,
      "loss": 1.8307,
      "step": 146700
    },
    {
      "epoch": 4.696,
      "grad_norm": 0.38673636317253113,
      "learning_rate": 1.216128e-05,
      "loss": 1.7742,
      "step": 146750
    },
    {
      "epoch": 4.6975999999999996,
      "grad_norm": 0.3686034381389618,
      "learning_rate": 1.209728e-05,
      "loss": 1.7743,
      "step": 146800
    },
    {
      "epoch": 4.6992,
      "grad_norm": 0.38365209102630615,
      "learning_rate": 1.203328e-05,
      "loss": 1.7541,
      "step": 146850
    },
    {
      "epoch": 4.7008,
      "grad_norm": 0.4448857605457306,
      "learning_rate": 1.1969280000000001e-05,
      "loss": 1.7459,
      "step": 146900
    },
    {
      "epoch": 4.7024,
      "grad_norm": 0.5178660154342651,
      "learning_rate": 1.1905280000000001e-05,
      "loss": 1.7845,
      "step": 146950
    },
    {
      "epoch": 4.704,
      "grad_norm": 0.5560616254806519,
      "learning_rate": 1.184128e-05,
      "loss": 1.7674,
      "step": 147000
    },
    {
      "epoch": 4.7056000000000004,
      "grad_norm": 0.4528466463088989,
      "learning_rate": 1.177728e-05,
      "loss": 1.8098,
      "step": 147050
    },
    {
      "epoch": 4.7072,
      "grad_norm": 0.3769230842590332,
      "learning_rate": 1.171328e-05,
      "loss": 1.7746,
      "step": 147100
    },
    {
      "epoch": 4.7088,
      "grad_norm": 0.33740827441215515,
      "learning_rate": 1.164928e-05,
      "loss": 1.7492,
      "step": 147150
    },
    {
      "epoch": 4.7104,
      "grad_norm": 0.3458103537559509,
      "learning_rate": 1.1585280000000001e-05,
      "loss": 1.7722,
      "step": 147200
    },
    {
      "epoch": 4.712,
      "grad_norm": 0.470995157957077,
      "learning_rate": 1.1521280000000001e-05,
      "loss": 1.7197,
      "step": 147250
    },
    {
      "epoch": 4.7136,
      "grad_norm": 0.39516952633857727,
      "learning_rate": 1.1457280000000002e-05,
      "loss": 1.7482,
      "step": 147300
    },
    {
      "epoch": 4.7152,
      "grad_norm": 0.4079236686229706,
      "learning_rate": 1.139328e-05,
      "loss": 1.8048,
      "step": 147350
    },
    {
      "epoch": 4.7168,
      "grad_norm": 0.41126200556755066,
      "learning_rate": 1.132928e-05,
      "loss": 1.7772,
      "step": 147400
    },
    {
      "epoch": 4.7184,
      "grad_norm": 0.43124493956565857,
      "learning_rate": 1.126528e-05,
      "loss": 1.7387,
      "step": 147450
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.5176995396614075,
      "learning_rate": 1.1201280000000001e-05,
      "loss": 1.739,
      "step": 147500
    },
    {
      "epoch": 4.7216000000000005,
      "grad_norm": 0.368573397397995,
      "learning_rate": 1.113728e-05,
      "loss": 1.7982,
      "step": 147550
    },
    {
      "epoch": 4.7232,
      "grad_norm": 0.47546595335006714,
      "learning_rate": 1.1073280000000001e-05,
      "loss": 1.7524,
      "step": 147600
    },
    {
      "epoch": 4.7248,
      "grad_norm": 0.34465110301971436,
      "learning_rate": 1.1009280000000002e-05,
      "loss": 1.7562,
      "step": 147650
    },
    {
      "epoch": 4.7264,
      "grad_norm": 0.3842443525791168,
      "learning_rate": 1.094528e-05,
      "loss": 1.7538,
      "step": 147700
    },
    {
      "epoch": 4.728,
      "grad_norm": 0.45925676822662354,
      "learning_rate": 1.088128e-05,
      "loss": 1.7782,
      "step": 147750
    },
    {
      "epoch": 4.7296,
      "grad_norm": 0.3902326226234436,
      "learning_rate": 1.0817280000000001e-05,
      "loss": 1.778,
      "step": 147800
    },
    {
      "epoch": 4.7312,
      "grad_norm": 0.40572816133499146,
      "learning_rate": 1.075328e-05,
      "loss": 1.7395,
      "step": 147850
    },
    {
      "epoch": 4.7328,
      "grad_norm": 0.4129238724708557,
      "learning_rate": 1.068928e-05,
      "loss": 1.7833,
      "step": 147900
    },
    {
      "epoch": 4.7344,
      "grad_norm": 0.5013947486877441,
      "learning_rate": 1.062528e-05,
      "loss": 1.7418,
      "step": 147950
    },
    {
      "epoch": 4.736,
      "grad_norm": 0.3993840515613556,
      "learning_rate": 1.0561280000000002e-05,
      "loss": 1.8013,
      "step": 148000
    },
    {
      "epoch": 4.7376000000000005,
      "grad_norm": 0.37247732281684875,
      "learning_rate": 1.049728e-05,
      "loss": 1.8128,
      "step": 148050
    },
    {
      "epoch": 4.7392,
      "grad_norm": 0.4415261447429657,
      "learning_rate": 1.043328e-05,
      "loss": 1.749,
      "step": 148100
    },
    {
      "epoch": 4.7408,
      "grad_norm": 0.4398854374885559,
      "learning_rate": 1.0369280000000001e-05,
      "loss": 1.7441,
      "step": 148150
    },
    {
      "epoch": 4.7424,
      "grad_norm": 0.40569934248924255,
      "learning_rate": 1.030528e-05,
      "loss": 1.7732,
      "step": 148200
    },
    {
      "epoch": 4.744,
      "grad_norm": 0.37702664732933044,
      "learning_rate": 1.024128e-05,
      "loss": 1.7898,
      "step": 148250
    },
    {
      "epoch": 4.7456,
      "grad_norm": 0.4221964478492737,
      "learning_rate": 1.017728e-05,
      "loss": 1.8021,
      "step": 148300
    },
    {
      "epoch": 4.7472,
      "grad_norm": 0.49162721633911133,
      "learning_rate": 1.011328e-05,
      "loss": 1.7996,
      "step": 148350
    },
    {
      "epoch": 4.7488,
      "grad_norm": 0.36136341094970703,
      "learning_rate": 1.0049279999999999e-05,
      "loss": 1.7813,
      "step": 148400
    },
    {
      "epoch": 4.7504,
      "grad_norm": 0.4183562695980072,
      "learning_rate": 9.985280000000001e-06,
      "loss": 1.7697,
      "step": 148450
    },
    {
      "epoch": 4.752,
      "grad_norm": 0.42455464601516724,
      "learning_rate": 9.921280000000001e-06,
      "loss": 1.7778,
      "step": 148500
    },
    {
      "epoch": 4.7536000000000005,
      "grad_norm": 0.4658253788948059,
      "learning_rate": 9.85728e-06,
      "loss": 1.7614,
      "step": 148550
    },
    {
      "epoch": 4.7552,
      "grad_norm": 0.36095598340034485,
      "learning_rate": 9.79328e-06,
      "loss": 1.7316,
      "step": 148600
    },
    {
      "epoch": 4.7568,
      "grad_norm": 0.4153849184513092,
      "learning_rate": 9.72928e-06,
      "loss": 1.8115,
      "step": 148650
    },
    {
      "epoch": 4.7584,
      "grad_norm": 0.4667525589466095,
      "learning_rate": 9.66528e-06,
      "loss": 1.7392,
      "step": 148700
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.41840681433677673,
      "learning_rate": 9.60128e-06,
      "loss": 1.764,
      "step": 148750
    },
    {
      "epoch": 4.7616,
      "grad_norm": 0.40541747212409973,
      "learning_rate": 9.53728e-06,
      "loss": 1.7585,
      "step": 148800
    },
    {
      "epoch": 4.7632,
      "grad_norm": 0.4682837426662445,
      "learning_rate": 9.473280000000002e-06,
      "loss": 1.7586,
      "step": 148850
    },
    {
      "epoch": 4.7648,
      "grad_norm": 0.4566345810890198,
      "learning_rate": 9.40928e-06,
      "loss": 1.7327,
      "step": 148900
    },
    {
      "epoch": 4.7664,
      "grad_norm": 0.3910771906375885,
      "learning_rate": 9.34528e-06,
      "loss": 1.8231,
      "step": 148950
    },
    {
      "epoch": 4.768,
      "grad_norm": 0.4315970540046692,
      "learning_rate": 9.28128e-06,
      "loss": 1.7804,
      "step": 149000
    },
    {
      "epoch": 4.7696,
      "grad_norm": 0.38975194096565247,
      "learning_rate": 9.217280000000001e-06,
      "loss": 1.7472,
      "step": 149050
    },
    {
      "epoch": 4.7712,
      "grad_norm": 0.3719891607761383,
      "learning_rate": 9.15328e-06,
      "loss": 1.7661,
      "step": 149100
    },
    {
      "epoch": 4.7728,
      "grad_norm": 0.397693395614624,
      "learning_rate": 9.08928e-06,
      "loss": 1.7961,
      "step": 149150
    },
    {
      "epoch": 4.7744,
      "grad_norm": 0.35434332489967346,
      "learning_rate": 9.02528e-06,
      "loss": 1.7371,
      "step": 149200
    },
    {
      "epoch": 4.776,
      "grad_norm": 0.39711642265319824,
      "learning_rate": 8.96128e-06,
      "loss": 1.7501,
      "step": 149250
    },
    {
      "epoch": 4.7776,
      "grad_norm": 0.42083823680877686,
      "learning_rate": 8.89728e-06,
      "loss": 1.7476,
      "step": 149300
    },
    {
      "epoch": 4.7792,
      "grad_norm": 0.43047383427619934,
      "learning_rate": 8.833280000000001e-06,
      "loss": 1.7493,
      "step": 149350
    },
    {
      "epoch": 4.7808,
      "grad_norm": 0.3891640603542328,
      "learning_rate": 8.769280000000001e-06,
      "loss": 1.7609,
      "step": 149400
    },
    {
      "epoch": 4.7824,
      "grad_norm": 0.3732357323169708,
      "learning_rate": 8.70528e-06,
      "loss": 1.8257,
      "step": 149450
    },
    {
      "epoch": 4.784,
      "grad_norm": 0.3961440324783325,
      "learning_rate": 8.64128e-06,
      "loss": 1.7622,
      "step": 149500
    },
    {
      "epoch": 4.7856,
      "grad_norm": 0.45870187878608704,
      "learning_rate": 8.57728e-06,
      "loss": 1.7436,
      "step": 149550
    },
    {
      "epoch": 4.7872,
      "grad_norm": 0.4007242023944855,
      "learning_rate": 8.51328e-06,
      "loss": 1.7669,
      "step": 149600
    },
    {
      "epoch": 4.7888,
      "grad_norm": 0.48498740792274475,
      "learning_rate": 8.449280000000001e-06,
      "loss": 1.778,
      "step": 149650
    },
    {
      "epoch": 4.7904,
      "grad_norm": 0.39881235361099243,
      "learning_rate": 8.385280000000001e-06,
      "loss": 1.7765,
      "step": 149700
    },
    {
      "epoch": 4.792,
      "grad_norm": 0.5333601832389832,
      "learning_rate": 8.321280000000001e-06,
      "loss": 1.7181,
      "step": 149750
    },
    {
      "epoch": 4.7936,
      "grad_norm": 0.4820985198020935,
      "learning_rate": 8.25728e-06,
      "loss": 1.753,
      "step": 149800
    },
    {
      "epoch": 4.7952,
      "grad_norm": 0.38579389452934265,
      "learning_rate": 8.19328e-06,
      "loss": 1.747,
      "step": 149850
    },
    {
      "epoch": 4.7968,
      "grad_norm": 0.44084984064102173,
      "learning_rate": 8.12928e-06,
      "loss": 1.7305,
      "step": 149900
    },
    {
      "epoch": 4.7984,
      "grad_norm": 0.4299899637699127,
      "learning_rate": 8.06528e-06,
      "loss": 1.7529,
      "step": 149950
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.5256110429763794,
      "learning_rate": 8.00128e-06,
      "loss": 1.7401,
      "step": 150000
    },
    {
      "epoch": 4.8016,
      "grad_norm": 0.4477381706237793,
      "learning_rate": 7.93728e-06,
      "loss": 1.7806,
      "step": 150050
    },
    {
      "epoch": 4.8032,
      "grad_norm": 0.3707333207130432,
      "learning_rate": 7.873280000000002e-06,
      "loss": 1.7374,
      "step": 150100
    },
    {
      "epoch": 4.8048,
      "grad_norm": 0.3529437780380249,
      "learning_rate": 7.80928e-06,
      "loss": 1.7403,
      "step": 150150
    },
    {
      "epoch": 4.8064,
      "grad_norm": 0.4307253956794739,
      "learning_rate": 7.74528e-06,
      "loss": 1.8092,
      "step": 150200
    },
    {
      "epoch": 4.808,
      "grad_norm": 0.40351566672325134,
      "learning_rate": 7.68128e-06,
      "loss": 1.7367,
      "step": 150250
    },
    {
      "epoch": 4.8096,
      "grad_norm": 0.3867236375808716,
      "learning_rate": 7.61728e-06,
      "loss": 1.729,
      "step": 150300
    },
    {
      "epoch": 4.8112,
      "grad_norm": 0.445304811000824,
      "learning_rate": 7.5532800000000005e-06,
      "loss": 1.7128,
      "step": 150350
    },
    {
      "epoch": 4.8128,
      "grad_norm": 0.38095736503601074,
      "learning_rate": 7.48928e-06,
      "loss": 1.7755,
      "step": 150400
    },
    {
      "epoch": 4.8144,
      "grad_norm": 0.40427058935165405,
      "learning_rate": 7.425279999999999e-06,
      "loss": 1.7848,
      "step": 150450
    },
    {
      "epoch": 4.816,
      "grad_norm": 0.4505023658275604,
      "learning_rate": 7.361280000000001e-06,
      "loss": 1.7351,
      "step": 150500
    },
    {
      "epoch": 4.8176,
      "grad_norm": 0.358650803565979,
      "learning_rate": 7.297280000000001e-06,
      "loss": 1.7201,
      "step": 150550
    },
    {
      "epoch": 4.8192,
      "grad_norm": 0.43230578303337097,
      "learning_rate": 7.233280000000001e-06,
      "loss": 1.7733,
      "step": 150600
    },
    {
      "epoch": 4.8208,
      "grad_norm": 0.41315850615501404,
      "learning_rate": 7.16928e-06,
      "loss": 1.7814,
      "step": 150650
    },
    {
      "epoch": 4.8224,
      "grad_norm": 0.4380911588668823,
      "learning_rate": 7.105280000000001e-06,
      "loss": 1.8174,
      "step": 150700
    },
    {
      "epoch": 4.824,
      "grad_norm": 0.4960993528366089,
      "learning_rate": 7.04128e-06,
      "loss": 1.7714,
      "step": 150750
    },
    {
      "epoch": 4.8256,
      "grad_norm": 0.37411627173423767,
      "learning_rate": 6.9772799999999995e-06,
      "loss": 1.7778,
      "step": 150800
    },
    {
      "epoch": 4.8272,
      "grad_norm": 0.3840142488479614,
      "learning_rate": 6.91328e-06,
      "loss": 1.7302,
      "step": 150850
    },
    {
      "epoch": 4.8288,
      "grad_norm": 0.3817523717880249,
      "learning_rate": 6.849280000000001e-06,
      "loss": 1.7968,
      "step": 150900
    },
    {
      "epoch": 4.8304,
      "grad_norm": 0.4247678220272064,
      "learning_rate": 6.785280000000001e-06,
      "loss": 1.7518,
      "step": 150950
    },
    {
      "epoch": 4.832,
      "grad_norm": 0.39033243060112,
      "learning_rate": 6.721280000000001e-06,
      "loss": 1.7699,
      "step": 151000
    },
    {
      "epoch": 4.8336,
      "grad_norm": 0.4697851538658142,
      "learning_rate": 6.65728e-06,
      "loss": 1.7744,
      "step": 151050
    },
    {
      "epoch": 4.8352,
      "grad_norm": 0.3739733099937439,
      "learning_rate": 6.59328e-06,
      "loss": 1.7691,
      "step": 151100
    },
    {
      "epoch": 4.8368,
      "grad_norm": 0.37308159470558167,
      "learning_rate": 6.52928e-06,
      "loss": 1.7493,
      "step": 151150
    },
    {
      "epoch": 4.8384,
      "grad_norm": 0.4991733431816101,
      "learning_rate": 6.46528e-06,
      "loss": 1.8179,
      "step": 151200
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.4601374566555023,
      "learning_rate": 6.4012799999999995e-06,
      "loss": 1.7999,
      "step": 151250
    },
    {
      "epoch": 4.8416,
      "grad_norm": 0.4059813618659973,
      "learning_rate": 6.337280000000001e-06,
      "loss": 1.7635,
      "step": 151300
    },
    {
      "epoch": 4.8431999999999995,
      "grad_norm": 0.34751343727111816,
      "learning_rate": 6.273280000000001e-06,
      "loss": 1.7965,
      "step": 151350
    },
    {
      "epoch": 4.8448,
      "grad_norm": 0.3957991600036621,
      "learning_rate": 6.20928e-06,
      "loss": 1.7304,
      "step": 151400
    },
    {
      "epoch": 4.8464,
      "grad_norm": 0.4324933588504791,
      "learning_rate": 6.1452800000000006e-06,
      "loss": 1.7165,
      "step": 151450
    },
    {
      "epoch": 4.848,
      "grad_norm": 0.4654870331287384,
      "learning_rate": 6.08128e-06,
      "loss": 1.7602,
      "step": 151500
    },
    {
      "epoch": 4.8496,
      "grad_norm": 0.37665024399757385,
      "learning_rate": 6.01728e-06,
      "loss": 1.712,
      "step": 151550
    },
    {
      "epoch": 4.8512,
      "grad_norm": 0.4284614622592926,
      "learning_rate": 5.95328e-06,
      "loss": 1.7445,
      "step": 151600
    },
    {
      "epoch": 4.8528,
      "grad_norm": 0.37981346249580383,
      "learning_rate": 5.889280000000001e-06,
      "loss": 1.7811,
      "step": 151650
    },
    {
      "epoch": 4.8544,
      "grad_norm": 0.36869892477989197,
      "learning_rate": 5.82528e-06,
      "loss": 1.7629,
      "step": 151700
    },
    {
      "epoch": 4.856,
      "grad_norm": 0.3833613693714142,
      "learning_rate": 5.7612800000000005e-06,
      "loss": 1.7305,
      "step": 151750
    },
    {
      "epoch": 4.8576,
      "grad_norm": 0.4597334563732147,
      "learning_rate": 5.69728e-06,
      "loss": 1.7735,
      "step": 151800
    },
    {
      "epoch": 4.8591999999999995,
      "grad_norm": 0.4379129409790039,
      "learning_rate": 5.63328e-06,
      "loss": 1.7273,
      "step": 151850
    },
    {
      "epoch": 4.8608,
      "grad_norm": 0.4511782228946686,
      "learning_rate": 5.5692800000000005e-06,
      "loss": 1.761,
      "step": 151900
    },
    {
      "epoch": 4.8624,
      "grad_norm": 0.47562381625175476,
      "learning_rate": 5.50528e-06,
      "loss": 1.7536,
      "step": 151950
    },
    {
      "epoch": 4.864,
      "grad_norm": 0.4616549015045166,
      "learning_rate": 5.44128e-06,
      "loss": 1.7844,
      "step": 152000
    },
    {
      "epoch": 4.8656,
      "grad_norm": 0.348409503698349,
      "learning_rate": 5.3772800000000005e-06,
      "loss": 1.7763,
      "step": 152050
    },
    {
      "epoch": 4.8672,
      "grad_norm": 0.3347533941268921,
      "learning_rate": 5.313280000000001e-06,
      "loss": 1.7573,
      "step": 152100
    },
    {
      "epoch": 4.8688,
      "grad_norm": 0.4338652193546295,
      "learning_rate": 5.24928e-06,
      "loss": 1.8418,
      "step": 152150
    },
    {
      "epoch": 4.8704,
      "grad_norm": 0.42406049370765686,
      "learning_rate": 5.18528e-06,
      "loss": 1.7209,
      "step": 152200
    },
    {
      "epoch": 4.872,
      "grad_norm": 0.4281766414642334,
      "learning_rate": 5.121280000000001e-06,
      "loss": 1.756,
      "step": 152250
    },
    {
      "epoch": 4.8736,
      "grad_norm": 0.4154515266418457,
      "learning_rate": 5.05728e-06,
      "loss": 1.7922,
      "step": 152300
    },
    {
      "epoch": 4.8751999999999995,
      "grad_norm": 0.5286784172058105,
      "learning_rate": 4.99328e-06,
      "loss": 1.7282,
      "step": 152350
    },
    {
      "epoch": 4.8768,
      "grad_norm": 0.47873547673225403,
      "learning_rate": 4.92928e-06,
      "loss": 1.7849,
      "step": 152400
    },
    {
      "epoch": 4.8784,
      "grad_norm": 0.4598826766014099,
      "learning_rate": 4.86528e-06,
      "loss": 1.6758,
      "step": 152450
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.4344317317008972,
      "learning_rate": 4.80128e-06,
      "loss": 1.7552,
      "step": 152500
    },
    {
      "epoch": 4.8816,
      "grad_norm": 0.38247665762901306,
      "learning_rate": 4.73728e-06,
      "loss": 1.7769,
      "step": 152550
    },
    {
      "epoch": 4.8832,
      "grad_norm": 0.4447712004184723,
      "learning_rate": 4.67328e-06,
      "loss": 1.7636,
      "step": 152600
    },
    {
      "epoch": 4.8848,
      "grad_norm": 0.43606889247894287,
      "learning_rate": 4.60928e-06,
      "loss": 1.7412,
      "step": 152650
    },
    {
      "epoch": 4.8864,
      "grad_norm": 0.4227811396121979,
      "learning_rate": 4.545280000000001e-06,
      "loss": 1.7569,
      "step": 152700
    },
    {
      "epoch": 4.888,
      "grad_norm": 0.43779486417770386,
      "learning_rate": 4.48128e-06,
      "loss": 1.8192,
      "step": 152750
    },
    {
      "epoch": 4.8896,
      "grad_norm": 0.4549025595188141,
      "learning_rate": 4.41728e-06,
      "loss": 1.6953,
      "step": 152800
    },
    {
      "epoch": 4.8911999999999995,
      "grad_norm": 0.3952715992927551,
      "learning_rate": 4.353280000000001e-06,
      "loss": 1.7702,
      "step": 152850
    },
    {
      "epoch": 4.8928,
      "grad_norm": 0.35248881578445435,
      "learning_rate": 4.28928e-06,
      "loss": 1.7649,
      "step": 152900
    },
    {
      "epoch": 4.8944,
      "grad_norm": 0.4539744257926941,
      "learning_rate": 4.22528e-06,
      "loss": 1.7402,
      "step": 152950
    },
    {
      "epoch": 4.896,
      "grad_norm": 0.45024728775024414,
      "learning_rate": 4.16128e-06,
      "loss": 1.7707,
      "step": 153000
    },
    {
      "epoch": 4.8976,
      "grad_norm": 0.42877110838890076,
      "learning_rate": 4.09728e-06,
      "loss": 1.7957,
      "step": 153050
    },
    {
      "epoch": 4.8992,
      "grad_norm": 0.4475555717945099,
      "learning_rate": 4.03328e-06,
      "loss": 1.7498,
      "step": 153100
    },
    {
      "epoch": 4.9008,
      "grad_norm": 0.403713196516037,
      "learning_rate": 3.9692800000000006e-06,
      "loss": 1.7433,
      "step": 153150
    },
    {
      "epoch": 4.9024,
      "grad_norm": 0.4880930185317993,
      "learning_rate": 3.90528e-06,
      "loss": 1.7749,
      "step": 153200
    },
    {
      "epoch": 4.904,
      "grad_norm": 0.42155370116233826,
      "learning_rate": 3.84128e-06,
      "loss": 1.7607,
      "step": 153250
    },
    {
      "epoch": 4.9056,
      "grad_norm": 0.3707256615161896,
      "learning_rate": 3.7772800000000005e-06,
      "loss": 1.7452,
      "step": 153300
    },
    {
      "epoch": 4.9072,
      "grad_norm": 0.4064672589302063,
      "learning_rate": 3.7132800000000004e-06,
      "loss": 1.7375,
      "step": 153350
    },
    {
      "epoch": 4.9088,
      "grad_norm": 0.4729595184326172,
      "learning_rate": 3.6492800000000002e-06,
      "loss": 1.7205,
      "step": 153400
    },
    {
      "epoch": 4.9104,
      "grad_norm": 0.4095061421394348,
      "learning_rate": 3.58528e-06,
      "loss": 1.7629,
      "step": 153450
    },
    {
      "epoch": 4.912,
      "grad_norm": 0.39500319957733154,
      "learning_rate": 3.5212800000000004e-06,
      "loss": 1.7289,
      "step": 153500
    },
    {
      "epoch": 4.9136,
      "grad_norm": 0.49845701456069946,
      "learning_rate": 3.45728e-06,
      "loss": 1.7502,
      "step": 153550
    },
    {
      "epoch": 4.9152000000000005,
      "grad_norm": 0.3799401819705963,
      "learning_rate": 3.39328e-06,
      "loss": 1.7937,
      "step": 153600
    },
    {
      "epoch": 4.9168,
      "grad_norm": 0.36354243755340576,
      "learning_rate": 3.32928e-06,
      "loss": 1.7813,
      "step": 153650
    },
    {
      "epoch": 4.9184,
      "grad_norm": 0.4445604085922241,
      "learning_rate": 3.2652800000000006e-06,
      "loss": 1.8143,
      "step": 153700
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.4080004394054413,
      "learning_rate": 3.2012800000000005e-06,
      "loss": 1.7486,
      "step": 153750
    },
    {
      "epoch": 4.9216,
      "grad_norm": 0.45232272148132324,
      "learning_rate": 3.13728e-06,
      "loss": 1.7171,
      "step": 153800
    },
    {
      "epoch": 4.9232,
      "grad_norm": 0.46775779128074646,
      "learning_rate": 3.07328e-06,
      "loss": 1.758,
      "step": 153850
    },
    {
      "epoch": 4.9248,
      "grad_norm": 0.36578601598739624,
      "learning_rate": 3.00928e-06,
      "loss": 1.7791,
      "step": 153900
    },
    {
      "epoch": 4.9264,
      "grad_norm": 0.42461299896240234,
      "learning_rate": 2.9452800000000003e-06,
      "loss": 1.7823,
      "step": 153950
    },
    {
      "epoch": 4.928,
      "grad_norm": 0.418519526720047,
      "learning_rate": 2.88128e-06,
      "loss": 1.7751,
      "step": 154000
    },
    {
      "epoch": 4.9296,
      "grad_norm": 0.49383530020713806,
      "learning_rate": 2.8172800000000004e-06,
      "loss": 1.7933,
      "step": 154050
    },
    {
      "epoch": 4.9312000000000005,
      "grad_norm": 0.49610912799835205,
      "learning_rate": 2.7532800000000003e-06,
      "loss": 1.7442,
      "step": 154100
    },
    {
      "epoch": 4.9328,
      "grad_norm": 0.4737817347049713,
      "learning_rate": 2.68928e-06,
      "loss": 1.7447,
      "step": 154150
    },
    {
      "epoch": 4.9344,
      "grad_norm": 0.38131216168403625,
      "learning_rate": 2.62528e-06,
      "loss": 1.7483,
      "step": 154200
    },
    {
      "epoch": 4.936,
      "grad_norm": 0.45676371455192566,
      "learning_rate": 2.5612800000000002e-06,
      "loss": 1.7895,
      "step": 154250
    },
    {
      "epoch": 4.9376,
      "grad_norm": 0.39580604434013367,
      "learning_rate": 2.49728e-06,
      "loss": 1.7975,
      "step": 154300
    },
    {
      "epoch": 4.9392,
      "grad_norm": 0.3903430998325348,
      "learning_rate": 2.4332800000000004e-06,
      "loss": 1.6828,
      "step": 154350
    },
    {
      "epoch": 4.9408,
      "grad_norm": 0.4254056215286255,
      "learning_rate": 2.36928e-06,
      "loss": 1.7581,
      "step": 154400
    },
    {
      "epoch": 4.9424,
      "grad_norm": 0.3708435893058777,
      "learning_rate": 2.30528e-06,
      "loss": 1.7376,
      "step": 154450
    },
    {
      "epoch": 4.944,
      "grad_norm": 0.5443485975265503,
      "learning_rate": 2.24128e-06,
      "loss": 1.7936,
      "step": 154500
    },
    {
      "epoch": 4.9456,
      "grad_norm": 0.43997111916542053,
      "learning_rate": 2.1772799999999998e-06,
      "loss": 1.7402,
      "step": 154550
    },
    {
      "epoch": 4.9472000000000005,
      "grad_norm": 0.43713098764419556,
      "learning_rate": 2.11328e-06,
      "loss": 1.8197,
      "step": 154600
    },
    {
      "epoch": 4.9488,
      "grad_norm": 0.4158182144165039,
      "learning_rate": 2.04928e-06,
      "loss": 1.7644,
      "step": 154650
    },
    {
      "epoch": 4.9504,
      "grad_norm": 0.4489150047302246,
      "learning_rate": 1.98528e-06,
      "loss": 1.7658,
      "step": 154700
    },
    {
      "epoch": 4.952,
      "grad_norm": 0.43061816692352295,
      "learning_rate": 1.92128e-06,
      "loss": 1.8255,
      "step": 154750
    },
    {
      "epoch": 4.9536,
      "grad_norm": 0.3334057033061981,
      "learning_rate": 1.85728e-06,
      "loss": 1.7853,
      "step": 154800
    },
    {
      "epoch": 4.9552,
      "grad_norm": 0.4825080633163452,
      "learning_rate": 1.79328e-06,
      "loss": 1.75,
      "step": 154850
    },
    {
      "epoch": 4.9568,
      "grad_norm": 0.3378443717956543,
      "learning_rate": 1.7292800000000002e-06,
      "loss": 1.8132,
      "step": 154900
    },
    {
      "epoch": 4.9584,
      "grad_norm": 0.4080735445022583,
      "learning_rate": 1.66528e-06,
      "loss": 1.7907,
      "step": 154950
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.39938706159591675,
      "learning_rate": 1.6012800000000001e-06,
      "loss": 1.8073,
      "step": 155000
    }
  ],
  "logging_steps": 50,
  "max_steps": 156250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4755550655184896e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
