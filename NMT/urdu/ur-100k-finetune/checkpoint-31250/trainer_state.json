{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 5000,
  "global_step": 31250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 0.23300547897815704,
      "learning_rate": 0.0001996864,
      "loss": 2.2911,
      "step": 50
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.27220407128334045,
      "learning_rate": 0.00019936640000000003,
      "loss": 1.9679,
      "step": 100
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.28464439511299133,
      "learning_rate": 0.0001990464,
      "loss": 1.8955,
      "step": 150
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.3967932164669037,
      "learning_rate": 0.0001987264,
      "loss": 1.8858,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3120657503604889,
      "learning_rate": 0.0001984064,
      "loss": 1.8452,
      "step": 250
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.32597342133522034,
      "learning_rate": 0.00019808640000000001,
      "loss": 1.8556,
      "step": 300
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.3075876832008362,
      "learning_rate": 0.00019776640000000002,
      "loss": 1.853,
      "step": 350
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.2797912657260895,
      "learning_rate": 0.00019744640000000002,
      "loss": 1.8741,
      "step": 400
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.3443928062915802,
      "learning_rate": 0.0001971264,
      "loss": 1.8909,
      "step": 450
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.30267810821533203,
      "learning_rate": 0.0001968064,
      "loss": 1.8556,
      "step": 500
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.2941358983516693,
      "learning_rate": 0.0001964864,
      "loss": 1.8372,
      "step": 550
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.2935379147529602,
      "learning_rate": 0.0001961664,
      "loss": 1.8897,
      "step": 600
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.3161439299583435,
      "learning_rate": 0.0001958464,
      "loss": 1.8221,
      "step": 650
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.3323405086994171,
      "learning_rate": 0.00019552639999999999,
      "loss": 1.8338,
      "step": 700
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.31366977095603943,
      "learning_rate": 0.00019520640000000002,
      "loss": 1.8613,
      "step": 750
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.32064002752304077,
      "learning_rate": 0.0001948864,
      "loss": 1.8287,
      "step": 800
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.32164475321769714,
      "learning_rate": 0.00019456640000000002,
      "loss": 1.8767,
      "step": 850
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.2954748272895813,
      "learning_rate": 0.0001942464,
      "loss": 1.7819,
      "step": 900
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.2845984101295471,
      "learning_rate": 0.00019392640000000003,
      "loss": 1.8955,
      "step": 950
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3305647075176239,
      "learning_rate": 0.0001936064,
      "loss": 1.8228,
      "step": 1000
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.29870060086250305,
      "learning_rate": 0.0001932864,
      "loss": 1.8755,
      "step": 1050
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.39113849401474,
      "learning_rate": 0.0001929664,
      "loss": 1.8782,
      "step": 1100
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.2913914918899536,
      "learning_rate": 0.0001926464,
      "loss": 1.7836,
      "step": 1150
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.29783254861831665,
      "learning_rate": 0.00019232640000000002,
      "loss": 1.784,
      "step": 1200
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.26744797825813293,
      "learning_rate": 0.00019200640000000002,
      "loss": 1.8115,
      "step": 1250
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.3689098656177521,
      "learning_rate": 0.0001916864,
      "loss": 1.8275,
      "step": 1300
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.25513818860054016,
      "learning_rate": 0.00019136640000000003,
      "loss": 1.8417,
      "step": 1350
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.3138687312602997,
      "learning_rate": 0.0001910464,
      "loss": 1.7896,
      "step": 1400
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.29479435086250305,
      "learning_rate": 0.0001907264,
      "loss": 1.8213,
      "step": 1450
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3022027015686035,
      "learning_rate": 0.0001904064,
      "loss": 1.8722,
      "step": 1500
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.28099462389945984,
      "learning_rate": 0.0001900864,
      "loss": 1.832,
      "step": 1550
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.2938997149467468,
      "learning_rate": 0.0001897664,
      "loss": 1.8394,
      "step": 1600
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.29442527890205383,
      "learning_rate": 0.0001894464,
      "loss": 1.8445,
      "step": 1650
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.26747623085975647,
      "learning_rate": 0.00018912640000000002,
      "loss": 1.8244,
      "step": 1700
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.37424972653388977,
      "learning_rate": 0.0001888064,
      "loss": 1.7868,
      "step": 1750
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.2751738429069519,
      "learning_rate": 0.00018848640000000003,
      "loss": 1.8217,
      "step": 1800
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.30962181091308594,
      "learning_rate": 0.0001881664,
      "loss": 1.8514,
      "step": 1850
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.30445247888565063,
      "learning_rate": 0.0001878464,
      "loss": 1.862,
      "step": 1900
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.25602105259895325,
      "learning_rate": 0.0001875264,
      "loss": 1.8536,
      "step": 1950
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.34330737590789795,
      "learning_rate": 0.0001872064,
      "loss": 1.8404,
      "step": 2000
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.2559821307659149,
      "learning_rate": 0.00018688640000000001,
      "loss": 1.8347,
      "step": 2050
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.3189801871776581,
      "learning_rate": 0.00018656640000000002,
      "loss": 1.7976,
      "step": 2100
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.2889607846736908,
      "learning_rate": 0.0001862464,
      "loss": 1.7917,
      "step": 2150
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.31197482347488403,
      "learning_rate": 0.00018592640000000002,
      "loss": 1.8069,
      "step": 2200
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.27993252873420715,
      "learning_rate": 0.0001856064,
      "loss": 1.863,
      "step": 2250
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.31531834602355957,
      "learning_rate": 0.00018528640000000003,
      "loss": 1.8765,
      "step": 2300
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.3088688850402832,
      "learning_rate": 0.0001849664,
      "loss": 1.8029,
      "step": 2350
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.30794546008110046,
      "learning_rate": 0.0001846464,
      "loss": 1.7856,
      "step": 2400
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.3006215989589691,
      "learning_rate": 0.0001843264,
      "loss": 1.8699,
      "step": 2450
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.30312180519104004,
      "learning_rate": 0.00018400640000000001,
      "loss": 1.8434,
      "step": 2500
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.31464457511901855,
      "learning_rate": 0.00018368640000000002,
      "loss": 1.8206,
      "step": 2550
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.32993176579475403,
      "learning_rate": 0.0001833664,
      "loss": 1.8468,
      "step": 2600
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.26309460401535034,
      "learning_rate": 0.00018304640000000002,
      "loss": 1.8037,
      "step": 2650
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.2736586630344391,
      "learning_rate": 0.0001827264,
      "loss": 1.8057,
      "step": 2700
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.32662901282310486,
      "learning_rate": 0.0001824064,
      "loss": 1.8766,
      "step": 2750
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.30695590376853943,
      "learning_rate": 0.0001820864,
      "loss": 1.8341,
      "step": 2800
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.24556465446949005,
      "learning_rate": 0.0001817664,
      "loss": 1.7834,
      "step": 2850
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.2583151161670685,
      "learning_rate": 0.0001814464,
      "loss": 1.8655,
      "step": 2900
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.284271776676178,
      "learning_rate": 0.00018112640000000001,
      "loss": 1.8481,
      "step": 2950
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2683824598789215,
      "learning_rate": 0.0001808064,
      "loss": 1.8111,
      "step": 3000
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.2489641308784485,
      "learning_rate": 0.00018048640000000002,
      "loss": 1.8432,
      "step": 3050
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.28633546829223633,
      "learning_rate": 0.0001801664,
      "loss": 1.8057,
      "step": 3100
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.32642483711242676,
      "learning_rate": 0.00017984640000000003,
      "loss": 1.8146,
      "step": 3150
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.277486115694046,
      "learning_rate": 0.0001795264,
      "loss": 1.7594,
      "step": 3200
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.2957281470298767,
      "learning_rate": 0.0001792064,
      "loss": 1.7801,
      "step": 3250
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.2727285325527191,
      "learning_rate": 0.0001788864,
      "loss": 1.8397,
      "step": 3300
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.3246215283870697,
      "learning_rate": 0.0001785664,
      "loss": 1.8505,
      "step": 3350
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.3336552083492279,
      "learning_rate": 0.00017824640000000002,
      "loss": 1.8105,
      "step": 3400
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.3132810592651367,
      "learning_rate": 0.0001779264,
      "loss": 1.7821,
      "step": 3450
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2633548378944397,
      "learning_rate": 0.00017760640000000002,
      "loss": 1.8294,
      "step": 3500
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.262789785861969,
      "learning_rate": 0.0001772864,
      "loss": 1.8164,
      "step": 3550
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.27595841884613037,
      "learning_rate": 0.0001769664,
      "loss": 1.8244,
      "step": 3600
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.2657415270805359,
      "learning_rate": 0.0001766464,
      "loss": 1.8672,
      "step": 3650
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.27257075905799866,
      "learning_rate": 0.0001763264,
      "loss": 1.8329,
      "step": 3700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4952845871448517,
      "learning_rate": 0.0001760064,
      "loss": 1.8215,
      "step": 3750
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.2666738033294678,
      "learning_rate": 0.0001756864,
      "loss": 1.8212,
      "step": 3800
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.24640397727489471,
      "learning_rate": 0.0001753664,
      "loss": 1.8206,
      "step": 3850
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.3183533251285553,
      "learning_rate": 0.00017504640000000002,
      "loss": 1.7225,
      "step": 3900
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.27515316009521484,
      "learning_rate": 0.0001747264,
      "loss": 1.8143,
      "step": 3950
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.26649704575538635,
      "learning_rate": 0.00017440640000000002,
      "loss": 1.8255,
      "step": 4000
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.24169960618019104,
      "learning_rate": 0.0001740864,
      "loss": 1.7594,
      "step": 4050
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.241970494389534,
      "learning_rate": 0.00017376640000000003,
      "loss": 1.8644,
      "step": 4100
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.31658217310905457,
      "learning_rate": 0.0001734464,
      "loss": 1.8339,
      "step": 4150
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.25176802277565,
      "learning_rate": 0.0001731264,
      "loss": 1.849,
      "step": 4200
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3142668604850769,
      "learning_rate": 0.0001728064,
      "loss": 1.875,
      "step": 4250
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.30798834562301636,
      "learning_rate": 0.00017248640000000002,
      "loss": 1.8365,
      "step": 4300
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.22547468543052673,
      "learning_rate": 0.00017216640000000002,
      "loss": 1.8026,
      "step": 4350
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.29908475279808044,
      "learning_rate": 0.0001718464,
      "loss": 1.8447,
      "step": 4400
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.2893669009208679,
      "learning_rate": 0.0001715264,
      "loss": 1.8452,
      "step": 4450
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.28423643112182617,
      "learning_rate": 0.0001712064,
      "loss": 1.8305,
      "step": 4500
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.30257195234298706,
      "learning_rate": 0.0001708864,
      "loss": 1.8127,
      "step": 4550
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.283355176448822,
      "learning_rate": 0.0001705664,
      "loss": 1.8492,
      "step": 4600
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.30706384778022766,
      "learning_rate": 0.0001702464,
      "loss": 1.8183,
      "step": 4650
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.2431240975856781,
      "learning_rate": 0.0001699264,
      "loss": 1.7501,
      "step": 4700
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.33388230204582214,
      "learning_rate": 0.00016960640000000002,
      "loss": 1.7816,
      "step": 4750
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.30309760570526123,
      "learning_rate": 0.0001692864,
      "loss": 1.789,
      "step": 4800
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.351467490196228,
      "learning_rate": 0.00016896640000000002,
      "loss": 1.8117,
      "step": 4850
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.2584853768348694,
      "learning_rate": 0.0001686464,
      "loss": 1.8399,
      "step": 4900
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.2503414750099182,
      "learning_rate": 0.00016832640000000003,
      "loss": 1.8045,
      "step": 4950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2554073631763458,
      "learning_rate": 0.0001680064,
      "loss": 1.793,
      "step": 5000
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.28950148820877075,
      "learning_rate": 0.0001676864,
      "loss": 1.8723,
      "step": 5050
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.27120789885520935,
      "learning_rate": 0.0001673664,
      "loss": 1.8401,
      "step": 5100
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.30373990535736084,
      "learning_rate": 0.00016704640000000001,
      "loss": 1.8311,
      "step": 5150
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.29873359203338623,
      "learning_rate": 0.00016672640000000002,
      "loss": 1.8425,
      "step": 5200
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3045836389064789,
      "learning_rate": 0.00016640640000000002,
      "loss": 1.8163,
      "step": 5250
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.2885095477104187,
      "learning_rate": 0.0001660864,
      "loss": 1.8452,
      "step": 5300
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.2953316569328308,
      "learning_rate": 0.0001657664,
      "loss": 1.8269,
      "step": 5350
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.2748069167137146,
      "learning_rate": 0.0001654464,
      "loss": 1.8105,
      "step": 5400
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.25362706184387207,
      "learning_rate": 0.0001651264,
      "loss": 1.8119,
      "step": 5450
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.26703545451164246,
      "learning_rate": 0.0001648064,
      "loss": 1.831,
      "step": 5500
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.2890569567680359,
      "learning_rate": 0.0001644864,
      "loss": 1.9354,
      "step": 5550
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.26525986194610596,
      "learning_rate": 0.00016416640000000001,
      "loss": 1.836,
      "step": 5600
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.32845252752304077,
      "learning_rate": 0.0001638464,
      "loss": 1.8278,
      "step": 5650
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.30705398321151733,
      "learning_rate": 0.00016352640000000002,
      "loss": 1.8518,
      "step": 5700
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.27314493060112,
      "learning_rate": 0.0001632064,
      "loss": 1.7953,
      "step": 5750
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.26667702198028564,
      "learning_rate": 0.00016288640000000003,
      "loss": 1.8363,
      "step": 5800
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.319967657327652,
      "learning_rate": 0.0001625664,
      "loss": 1.8707,
      "step": 5850
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.30057284235954285,
      "learning_rate": 0.0001622464,
      "loss": 1.8619,
      "step": 5900
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.24954883754253387,
      "learning_rate": 0.0001619264,
      "loss": 1.8179,
      "step": 5950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.31648489832878113,
      "learning_rate": 0.0001616064,
      "loss": 1.863,
      "step": 6000
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.29374489188194275,
      "learning_rate": 0.00016128640000000001,
      "loss": 1.814,
      "step": 6050
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.3574003279209137,
      "learning_rate": 0.00016096640000000002,
      "loss": 1.8188,
      "step": 6100
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.2578407824039459,
      "learning_rate": 0.0001606464,
      "loss": 1.8063,
      "step": 6150
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.2919488251209259,
      "learning_rate": 0.0001603264,
      "loss": 1.8308,
      "step": 6200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3198879659175873,
      "learning_rate": 0.0001600064,
      "loss": 1.8359,
      "step": 6250
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.2592307925224304,
      "learning_rate": 0.0001596864,
      "loss": 1.7817,
      "step": 6300
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.29379531741142273,
      "learning_rate": 0.0001593664,
      "loss": 1.7779,
      "step": 6350
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.3429791331291199,
      "learning_rate": 0.0001590464,
      "loss": 1.7889,
      "step": 6400
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.26973044872283936,
      "learning_rate": 0.0001587264,
      "loss": 1.7861,
      "step": 6450
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.293984591960907,
      "learning_rate": 0.0001584064,
      "loss": 1.8299,
      "step": 6500
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.2883875370025635,
      "learning_rate": 0.00015808640000000002,
      "loss": 1.7688,
      "step": 6550
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.2997824251651764,
      "learning_rate": 0.0001577664,
      "loss": 1.7831,
      "step": 6600
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.26931411027908325,
      "learning_rate": 0.00015744640000000002,
      "loss": 1.8347,
      "step": 6650
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.27632156014442444,
      "learning_rate": 0.0001571264,
      "loss": 1.8374,
      "step": 6700
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.3418457508087158,
      "learning_rate": 0.0001568064,
      "loss": 1.7919,
      "step": 6750
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.3014355003833771,
      "learning_rate": 0.0001564864,
      "loss": 1.8652,
      "step": 6800
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.2774125635623932,
      "learning_rate": 0.0001561664,
      "loss": 1.7681,
      "step": 6850
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.2675333619117737,
      "learning_rate": 0.0001558464,
      "loss": 1.7792,
      "step": 6900
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.27330613136291504,
      "learning_rate": 0.00015552640000000002,
      "loss": 1.7978,
      "step": 6950
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.26358771324157715,
      "learning_rate": 0.00015520640000000002,
      "loss": 1.8222,
      "step": 7000
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.26059964299201965,
      "learning_rate": 0.00015488640000000002,
      "loss": 1.7869,
      "step": 7050
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.30577173829078674,
      "learning_rate": 0.0001545664,
      "loss": 1.849,
      "step": 7100
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.30626314878463745,
      "learning_rate": 0.0001542464,
      "loss": 1.8108,
      "step": 7150
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.2973378896713257,
      "learning_rate": 0.0001539264,
      "loss": 1.8116,
      "step": 7200
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.3716229498386383,
      "learning_rate": 0.0001536064,
      "loss": 1.7597,
      "step": 7250
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.30360785126686096,
      "learning_rate": 0.0001532864,
      "loss": 1.7641,
      "step": 7300
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.2970120310783386,
      "learning_rate": 0.00015296639999999999,
      "loss": 1.8322,
      "step": 7350
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.27460917830467224,
      "learning_rate": 0.00015264640000000002,
      "loss": 1.8087,
      "step": 7400
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.2530566453933716,
      "learning_rate": 0.0001523264,
      "loss": 1.8866,
      "step": 7450
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.31163159012794495,
      "learning_rate": 0.00015200640000000002,
      "loss": 1.7859,
      "step": 7500
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.34323790669441223,
      "learning_rate": 0.0001516864,
      "loss": 1.7915,
      "step": 7550
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.29573407769203186,
      "learning_rate": 0.0001513664,
      "loss": 1.8359,
      "step": 7600
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.34260186553001404,
      "learning_rate": 0.0001510464,
      "loss": 1.8379,
      "step": 7650
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.3503241539001465,
      "learning_rate": 0.0001507264,
      "loss": 1.846,
      "step": 7700
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.27132636308670044,
      "learning_rate": 0.0001504064,
      "loss": 1.8001,
      "step": 7750
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.25370821356773376,
      "learning_rate": 0.00015008640000000001,
      "loss": 1.78,
      "step": 7800
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.30215972661972046,
      "learning_rate": 0.00014976640000000002,
      "loss": 1.8012,
      "step": 7850
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.308514803647995,
      "learning_rate": 0.00014944640000000002,
      "loss": 1.8363,
      "step": 7900
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.25889623165130615,
      "learning_rate": 0.0001491264,
      "loss": 1.7745,
      "step": 7950
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.3080611526966095,
      "learning_rate": 0.00014880640000000003,
      "loss": 1.8482,
      "step": 8000
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.26211145520210266,
      "learning_rate": 0.0001484864,
      "loss": 1.7241,
      "step": 8050
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.3694957494735718,
      "learning_rate": 0.0001481664,
      "loss": 1.7982,
      "step": 8100
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.34076568484306335,
      "learning_rate": 0.0001478464,
      "loss": 1.7949,
      "step": 8150
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.3562433123588562,
      "learning_rate": 0.0001475264,
      "loss": 1.7901,
      "step": 8200
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.3152335286140442,
      "learning_rate": 0.00014720640000000001,
      "loss": 1.8073,
      "step": 8250
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.334293395280838,
      "learning_rate": 0.0001468864,
      "loss": 1.8332,
      "step": 8300
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.27143773436546326,
      "learning_rate": 0.00014656640000000002,
      "loss": 1.8128,
      "step": 8350
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.2765320837497711,
      "learning_rate": 0.0001462464,
      "loss": 1.8192,
      "step": 8400
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.2917439043521881,
      "learning_rate": 0.0001459264,
      "loss": 1.8259,
      "step": 8450
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.3194022476673126,
      "learning_rate": 0.0001456064,
      "loss": 1.8454,
      "step": 8500
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.332554429769516,
      "learning_rate": 0.0001452864,
      "loss": 1.8045,
      "step": 8550
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.27806246280670166,
      "learning_rate": 0.0001449664,
      "loss": 1.8214,
      "step": 8600
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.31298819184303284,
      "learning_rate": 0.0001446464,
      "loss": 1.7839,
      "step": 8650
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.32246994972229004,
      "learning_rate": 0.00014432640000000001,
      "loss": 1.8888,
      "step": 8700
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.3120400607585907,
      "learning_rate": 0.00014400640000000002,
      "loss": 1.8005,
      "step": 8750
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.2538500130176544,
      "learning_rate": 0.0001436864,
      "loss": 1.7933,
      "step": 8800
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.3082687556743622,
      "learning_rate": 0.00014336640000000002,
      "loss": 1.7973,
      "step": 8850
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.24862803518772125,
      "learning_rate": 0.0001430464,
      "loss": 1.8687,
      "step": 8900
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.27072393894195557,
      "learning_rate": 0.0001427264,
      "loss": 1.8045,
      "step": 8950
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.3131619393825531,
      "learning_rate": 0.0001424064,
      "loss": 1.8325,
      "step": 9000
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.2755843698978424,
      "learning_rate": 0.0001420864,
      "loss": 1.8361,
      "step": 9050
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.26074033975601196,
      "learning_rate": 0.0001417664,
      "loss": 1.8223,
      "step": 9100
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.2987450659275055,
      "learning_rate": 0.0001414464,
      "loss": 1.8233,
      "step": 9150
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.2676022946834564,
      "learning_rate": 0.00014112640000000002,
      "loss": 1.7899,
      "step": 9200
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.3194308280944824,
      "learning_rate": 0.0001408064,
      "loss": 1.8006,
      "step": 9250
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.28804025053977966,
      "learning_rate": 0.0001404864,
      "loss": 1.7787,
      "step": 9300
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.2800513803958893,
      "learning_rate": 0.0001401664,
      "loss": 1.8288,
      "step": 9350
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.31906333565711975,
      "learning_rate": 0.0001398464,
      "loss": 1.8121,
      "step": 9400
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.2769741714000702,
      "learning_rate": 0.0001395264,
      "loss": 1.8102,
      "step": 9450
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.32433146238327026,
      "learning_rate": 0.0001392064,
      "loss": 1.8119,
      "step": 9500
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.29477477073669434,
      "learning_rate": 0.0001388864,
      "loss": 1.7932,
      "step": 9550
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.27205348014831543,
      "learning_rate": 0.00013856640000000002,
      "loss": 1.7691,
      "step": 9600
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.3259357810020447,
      "learning_rate": 0.0001382464,
      "loss": 1.8043,
      "step": 9650
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.3409823775291443,
      "learning_rate": 0.00013792640000000002,
      "loss": 1.7942,
      "step": 9700
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.3474277853965759,
      "learning_rate": 0.0001376064,
      "loss": 1.7983,
      "step": 9750
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.3174933195114136,
      "learning_rate": 0.00013728640000000003,
      "loss": 1.8478,
      "step": 9800
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.2981214225292206,
      "learning_rate": 0.0001369664,
      "loss": 1.8018,
      "step": 9850
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.3299664258956909,
      "learning_rate": 0.0001366464,
      "loss": 1.7735,
      "step": 9900
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.3366376459598541,
      "learning_rate": 0.0001363264,
      "loss": 1.8066,
      "step": 9950
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.3451743721961975,
      "learning_rate": 0.0001360064,
      "loss": 1.8484,
      "step": 10000
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.294643759727478,
      "learning_rate": 0.00013568640000000002,
      "loss": 1.8032,
      "step": 10050
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.31768307089805603,
      "learning_rate": 0.0001353664,
      "loss": 1.8271,
      "step": 10100
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.27884989976882935,
      "learning_rate": 0.00013504640000000002,
      "loss": 1.7964,
      "step": 10150
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.31621870398521423,
      "learning_rate": 0.0001347264,
      "loss": 1.8225,
      "step": 10200
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.28990641236305237,
      "learning_rate": 0.0001344064,
      "loss": 1.8449,
      "step": 10250
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.2555449903011322,
      "learning_rate": 0.0001340864,
      "loss": 1.8398,
      "step": 10300
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.3257658779621124,
      "learning_rate": 0.0001337664,
      "loss": 1.8418,
      "step": 10350
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.29917022585868835,
      "learning_rate": 0.0001334464,
      "loss": 1.772,
      "step": 10400
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.30550241470336914,
      "learning_rate": 0.0001331264,
      "loss": 1.7723,
      "step": 10450
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.27072978019714355,
      "learning_rate": 0.0001328064,
      "loss": 1.7866,
      "step": 10500
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.3018016517162323,
      "learning_rate": 0.00013248640000000002,
      "loss": 1.7577,
      "step": 10550
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.2927757203578949,
      "learning_rate": 0.0001321664,
      "loss": 1.8168,
      "step": 10600
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.32940131425857544,
      "learning_rate": 0.00013184640000000003,
      "loss": 1.8017,
      "step": 10650
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.28822630643844604,
      "learning_rate": 0.0001315264,
      "loss": 1.8574,
      "step": 10700
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.3004099428653717,
      "learning_rate": 0.0001312064,
      "loss": 1.7829,
      "step": 10750
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.29190298914909363,
      "learning_rate": 0.0001308864,
      "loss": 1.8069,
      "step": 10800
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.32675185799598694,
      "learning_rate": 0.0001305664,
      "loss": 1.8193,
      "step": 10850
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.3367694318294525,
      "learning_rate": 0.00013024640000000001,
      "loss": 1.8337,
      "step": 10900
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.29300248622894287,
      "learning_rate": 0.00012992640000000002,
      "loss": 1.7949,
      "step": 10950
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.28062576055526733,
      "learning_rate": 0.00012960640000000002,
      "loss": 1.7784,
      "step": 11000
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.27039653062820435,
      "learning_rate": 0.0001292864,
      "loss": 1.8165,
      "step": 11050
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.31435999274253845,
      "learning_rate": 0.0001289664,
      "loss": 1.8273,
      "step": 11100
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.24683386087417603,
      "learning_rate": 0.0001286464,
      "loss": 1.8563,
      "step": 11150
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.28034746646881104,
      "learning_rate": 0.0001283264,
      "loss": 1.8257,
      "step": 11200
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.30476638674736023,
      "learning_rate": 0.0001280064,
      "loss": 1.7994,
      "step": 11250
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.37459731101989746,
      "learning_rate": 0.0001276864,
      "loss": 1.8115,
      "step": 11300
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.29105085134506226,
      "learning_rate": 0.0001273664,
      "loss": 1.8262,
      "step": 11350
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.3519231677055359,
      "learning_rate": 0.00012704640000000002,
      "loss": 1.8065,
      "step": 11400
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.2831331789493561,
      "learning_rate": 0.0001267264,
      "loss": 1.7967,
      "step": 11450
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.28576231002807617,
      "learning_rate": 0.00012640640000000002,
      "loss": 1.7852,
      "step": 11500
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.29377561807632446,
      "learning_rate": 0.0001260864,
      "loss": 1.8039,
      "step": 11550
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.3249170184135437,
      "learning_rate": 0.0001257664,
      "loss": 1.8376,
      "step": 11600
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.2797921597957611,
      "learning_rate": 0.0001254464,
      "loss": 1.8379,
      "step": 11650
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.29124006628990173,
      "learning_rate": 0.0001251264,
      "loss": 1.7959,
      "step": 11700
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.31400400400161743,
      "learning_rate": 0.0001248064,
      "loss": 1.8088,
      "step": 11750
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.35230010747909546,
      "learning_rate": 0.00012448640000000001,
      "loss": 1.7771,
      "step": 11800
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.3169030249118805,
      "learning_rate": 0.00012416640000000002,
      "loss": 1.8587,
      "step": 11850
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.2890899181365967,
      "learning_rate": 0.0001238464,
      "loss": 1.7578,
      "step": 11900
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.314360648393631,
      "learning_rate": 0.0001235264,
      "loss": 1.7943,
      "step": 11950
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.28951844573020935,
      "learning_rate": 0.0001232064,
      "loss": 1.7578,
      "step": 12000
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.27244874835014343,
      "learning_rate": 0.0001228864,
      "loss": 1.7768,
      "step": 12050
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.31204548478126526,
      "learning_rate": 0.0001225664,
      "loss": 1.8205,
      "step": 12100
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.33536067605018616,
      "learning_rate": 0.0001222464,
      "loss": 1.8399,
      "step": 12150
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.29325708746910095,
      "learning_rate": 0.0001219264,
      "loss": 1.7709,
      "step": 12200
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.2970702052116394,
      "learning_rate": 0.00012160640000000002,
      "loss": 1.7763,
      "step": 12250
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.3955056369304657,
      "learning_rate": 0.0001212864,
      "loss": 1.743,
      "step": 12300
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.2503276467323303,
      "learning_rate": 0.00012096640000000001,
      "loss": 1.8576,
      "step": 12350
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.3415337800979614,
      "learning_rate": 0.0001206464,
      "loss": 1.7968,
      "step": 12400
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.30179736018180847,
      "learning_rate": 0.0001203264,
      "loss": 1.7888,
      "step": 12450
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2818034589290619,
      "learning_rate": 0.0001200064,
      "loss": 1.8363,
      "step": 12500
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.2879684567451477,
      "learning_rate": 0.00011968639999999999,
      "loss": 1.7929,
      "step": 12550
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.3270112872123718,
      "learning_rate": 0.00011936640000000001,
      "loss": 1.7976,
      "step": 12600
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.2589770257472992,
      "learning_rate": 0.0001190464,
      "loss": 1.8046,
      "step": 12650
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.41373905539512634,
      "learning_rate": 0.00011872640000000002,
      "loss": 1.7715,
      "step": 12700
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.2927563190460205,
      "learning_rate": 0.0001184064,
      "loss": 1.8156,
      "step": 12750
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.29135850071907043,
      "learning_rate": 0.0001180864,
      "loss": 1.7703,
      "step": 12800
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.314430832862854,
      "learning_rate": 0.00011776640000000001,
      "loss": 1.7614,
      "step": 12850
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.24082955718040466,
      "learning_rate": 0.0001174464,
      "loss": 1.7752,
      "step": 12900
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.3145913779735565,
      "learning_rate": 0.00011712640000000002,
      "loss": 1.7635,
      "step": 12950
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.31780532002449036,
      "learning_rate": 0.00011680640000000001,
      "loss": 1.7293,
      "step": 13000
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.29352590441703796,
      "learning_rate": 0.0001164864,
      "loss": 1.8477,
      "step": 13050
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.2987584173679352,
      "learning_rate": 0.00011616640000000001,
      "loss": 1.7929,
      "step": 13100
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.30407941341400146,
      "learning_rate": 0.0001158464,
      "loss": 1.8392,
      "step": 13150
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.2880842983722687,
      "learning_rate": 0.0001155264,
      "loss": 1.8292,
      "step": 13200
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.37827134132385254,
      "learning_rate": 0.00011520640000000001,
      "loss": 1.7814,
      "step": 13250
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.3150538504123688,
      "learning_rate": 0.00011488640000000001,
      "loss": 1.782,
      "step": 13300
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.36706846952438354,
      "learning_rate": 0.0001145664,
      "loss": 1.7887,
      "step": 13350
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.28253042697906494,
      "learning_rate": 0.0001142464,
      "loss": 1.8124,
      "step": 13400
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.345808207988739,
      "learning_rate": 0.00011392640000000001,
      "loss": 1.7007,
      "step": 13450
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.30850550532341003,
      "learning_rate": 0.0001136064,
      "loss": 1.8396,
      "step": 13500
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.3248752951622009,
      "learning_rate": 0.00011328640000000001,
      "loss": 1.7768,
      "step": 13550
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.3168941140174866,
      "learning_rate": 0.0001129664,
      "loss": 1.7815,
      "step": 13600
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.34806933999061584,
      "learning_rate": 0.00011264639999999999,
      "loss": 1.7883,
      "step": 13650
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.27895644307136536,
      "learning_rate": 0.00011232640000000001,
      "loss": 1.8061,
      "step": 13700
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.3246729075908661,
      "learning_rate": 0.0001120064,
      "loss": 1.823,
      "step": 13750
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.3679395914077759,
      "learning_rate": 0.00011168640000000002,
      "loss": 1.7706,
      "step": 13800
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.31492188572883606,
      "learning_rate": 0.0001113664,
      "loss": 1.7977,
      "step": 13850
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.3071358799934387,
      "learning_rate": 0.0001110464,
      "loss": 1.796,
      "step": 13900
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.3529023230075836,
      "learning_rate": 0.00011072640000000001,
      "loss": 1.7541,
      "step": 13950
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3050280511379242,
      "learning_rate": 0.0001104064,
      "loss": 1.7954,
      "step": 14000
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.36059826612472534,
      "learning_rate": 0.00011008640000000002,
      "loss": 1.7896,
      "step": 14050
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.3180069625377655,
      "learning_rate": 0.0001097664,
      "loss": 1.8134,
      "step": 14100
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.3157206177711487,
      "learning_rate": 0.00010944640000000001,
      "loss": 1.8061,
      "step": 14150
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.27530306577682495,
      "learning_rate": 0.00010912640000000001,
      "loss": 1.8025,
      "step": 14200
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.2781720757484436,
      "learning_rate": 0.0001088064,
      "loss": 1.7721,
      "step": 14250
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.2526057958602905,
      "learning_rate": 0.0001084864,
      "loss": 1.8148,
      "step": 14300
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.31747886538505554,
      "learning_rate": 0.0001081664,
      "loss": 1.7905,
      "step": 14350
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.31165629625320435,
      "learning_rate": 0.00010784640000000001,
      "loss": 1.793,
      "step": 14400
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.34854039549827576,
      "learning_rate": 0.0001075264,
      "loss": 1.7995,
      "step": 14450
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.2954410910606384,
      "learning_rate": 0.00010720639999999999,
      "loss": 1.8004,
      "step": 14500
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.33089306950569153,
      "learning_rate": 0.00010688640000000001,
      "loss": 1.8044,
      "step": 14550
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.2879883348941803,
      "learning_rate": 0.0001065664,
      "loss": 1.7868,
      "step": 14600
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.2600494921207428,
      "learning_rate": 0.00010624640000000001,
      "loss": 1.7964,
      "step": 14650
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.3095603585243225,
      "learning_rate": 0.0001059264,
      "loss": 1.7753,
      "step": 14700
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.3326737582683563,
      "learning_rate": 0.00010560639999999999,
      "loss": 1.8252,
      "step": 14750
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.3192763328552246,
      "learning_rate": 0.00010528640000000001,
      "loss": 1.8155,
      "step": 14800
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.32251599431037903,
      "learning_rate": 0.0001049664,
      "loss": 1.8234,
      "step": 14850
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.2956213355064392,
      "learning_rate": 0.00010464640000000002,
      "loss": 1.8003,
      "step": 14900
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.3625930845737457,
      "learning_rate": 0.0001043264,
      "loss": 1.8441,
      "step": 14950
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.4161251187324524,
      "learning_rate": 0.00010400640000000002,
      "loss": 1.7648,
      "step": 15000
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.2885575294494629,
      "learning_rate": 0.00010368640000000001,
      "loss": 1.7952,
      "step": 15050
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.36311864852905273,
      "learning_rate": 0.0001033664,
      "loss": 1.8122,
      "step": 15100
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.3825657367706299,
      "learning_rate": 0.0001030464,
      "loss": 1.8211,
      "step": 15150
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.3407253324985504,
      "learning_rate": 0.0001027264,
      "loss": 1.8116,
      "step": 15200
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.35368379950523376,
      "learning_rate": 0.00010240640000000001,
      "loss": 1.796,
      "step": 15250
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.2984375059604645,
      "learning_rate": 0.0001020864,
      "loss": 1.7901,
      "step": 15300
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.30663615465164185,
      "learning_rate": 0.00010176639999999999,
      "loss": 1.8306,
      "step": 15350
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.37548866868019104,
      "learning_rate": 0.0001014464,
      "loss": 1.7597,
      "step": 15400
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.35007041692733765,
      "learning_rate": 0.0001011264,
      "loss": 1.7608,
      "step": 15450
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.2862440049648285,
      "learning_rate": 0.00010080640000000001,
      "loss": 1.8247,
      "step": 15500
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.29289448261260986,
      "learning_rate": 0.0001004864,
      "loss": 1.798,
      "step": 15550
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.31164684891700745,
      "learning_rate": 0.00010016640000000002,
      "loss": 1.8345,
      "step": 15600
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.2742388844490051,
      "learning_rate": 9.984640000000001e-05,
      "loss": 1.8021,
      "step": 15650
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.3491654396057129,
      "learning_rate": 9.952640000000001e-05,
      "loss": 1.7976,
      "step": 15700
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.35776761174201965,
      "learning_rate": 9.92064e-05,
      "loss": 1.7741,
      "step": 15750
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.3581370413303375,
      "learning_rate": 9.88864e-05,
      "loss": 1.815,
      "step": 15800
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.344675749540329,
      "learning_rate": 9.85664e-05,
      "loss": 1.8268,
      "step": 15850
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.35795703530311584,
      "learning_rate": 9.824640000000001e-05,
      "loss": 1.797,
      "step": 15900
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.3095141649246216,
      "learning_rate": 9.792640000000001e-05,
      "loss": 1.7697,
      "step": 15950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.371002733707428,
      "learning_rate": 9.760640000000001e-05,
      "loss": 1.7243,
      "step": 16000
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.3013852834701538,
      "learning_rate": 9.72864e-05,
      "loss": 1.7855,
      "step": 16050
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.31773579120635986,
      "learning_rate": 9.696640000000001e-05,
      "loss": 1.7428,
      "step": 16100
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.35356980562210083,
      "learning_rate": 9.664640000000001e-05,
      "loss": 1.7971,
      "step": 16150
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.34513768553733826,
      "learning_rate": 9.63264e-05,
      "loss": 1.8241,
      "step": 16200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.32046517729759216,
      "learning_rate": 9.60064e-05,
      "loss": 1.7599,
      "step": 16250
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.3197764456272125,
      "learning_rate": 9.56864e-05,
      "loss": 1.7858,
      "step": 16300
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.34404948353767395,
      "learning_rate": 9.53664e-05,
      "loss": 1.8486,
      "step": 16350
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.3207720220088959,
      "learning_rate": 9.50464e-05,
      "loss": 1.7948,
      "step": 16400
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.30601975321769714,
      "learning_rate": 9.47264e-05,
      "loss": 1.8186,
      "step": 16450
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.3348638117313385,
      "learning_rate": 9.44064e-05,
      "loss": 1.7718,
      "step": 16500
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.32532015442848206,
      "learning_rate": 9.408640000000001e-05,
      "loss": 1.7925,
      "step": 16550
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.3824702799320221,
      "learning_rate": 9.376640000000001e-05,
      "loss": 1.6892,
      "step": 16600
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.3220434784889221,
      "learning_rate": 9.34464e-05,
      "loss": 1.7408,
      "step": 16650
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.34193456172943115,
      "learning_rate": 9.31264e-05,
      "loss": 1.806,
      "step": 16700
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.2994717061519623,
      "learning_rate": 9.28064e-05,
      "loss": 1.8099,
      "step": 16750
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.31595179438591003,
      "learning_rate": 9.248640000000001e-05,
      "loss": 1.7994,
      "step": 16800
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.3110333979129791,
      "learning_rate": 9.216640000000001e-05,
      "loss": 1.8416,
      "step": 16850
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.2766802906990051,
      "learning_rate": 9.18464e-05,
      "loss": 1.8035,
      "step": 16900
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.37053361535072327,
      "learning_rate": 9.15264e-05,
      "loss": 1.793,
      "step": 16950
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.3232746124267578,
      "learning_rate": 9.120640000000001e-05,
      "loss": 1.8264,
      "step": 17000
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.35226932168006897,
      "learning_rate": 9.088640000000001e-05,
      "loss": 1.8735,
      "step": 17050
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.36875924468040466,
      "learning_rate": 9.05664e-05,
      "loss": 1.7793,
      "step": 17100
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.3653600811958313,
      "learning_rate": 9.02464e-05,
      "loss": 1.7677,
      "step": 17150
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.42528238892555237,
      "learning_rate": 8.99264e-05,
      "loss": 1.7347,
      "step": 17200
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.3457956910133362,
      "learning_rate": 8.96064e-05,
      "loss": 1.8051,
      "step": 17250
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.37105703353881836,
      "learning_rate": 8.92864e-05,
      "loss": 1.78,
      "step": 17300
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.29743263125419617,
      "learning_rate": 8.89664e-05,
      "loss": 1.7661,
      "step": 17350
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.34402772784233093,
      "learning_rate": 8.86464e-05,
      "loss": 1.8036,
      "step": 17400
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.3587418794631958,
      "learning_rate": 8.832640000000001e-05,
      "loss": 1.8062,
      "step": 17450
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.3308715224266052,
      "learning_rate": 8.80064e-05,
      "loss": 1.7874,
      "step": 17500
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.27991265058517456,
      "learning_rate": 8.76864e-05,
      "loss": 1.7986,
      "step": 17550
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.33189719915390015,
      "learning_rate": 8.73664e-05,
      "loss": 1.7747,
      "step": 17600
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.31355783343315125,
      "learning_rate": 8.704640000000001e-05,
      "loss": 1.7628,
      "step": 17650
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.3443429470062256,
      "learning_rate": 8.672640000000001e-05,
      "loss": 1.7647,
      "step": 17700
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.31539881229400635,
      "learning_rate": 8.640640000000001e-05,
      "loss": 1.8096,
      "step": 17750
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.30709850788116455,
      "learning_rate": 8.60864e-05,
      "loss": 1.7608,
      "step": 17800
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.3362567722797394,
      "learning_rate": 8.57664e-05,
      "loss": 1.8349,
      "step": 17850
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.28187549114227295,
      "learning_rate": 8.544640000000001e-05,
      "loss": 1.7962,
      "step": 17900
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.33343493938446045,
      "learning_rate": 8.512640000000001e-05,
      "loss": 1.8582,
      "step": 17950
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.33989208936691284,
      "learning_rate": 8.48064e-05,
      "loss": 1.7824,
      "step": 18000
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.3448905944824219,
      "learning_rate": 8.44864e-05,
      "loss": 1.774,
      "step": 18050
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.27701520919799805,
      "learning_rate": 8.41664e-05,
      "loss": 1.8066,
      "step": 18100
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.2932681739330292,
      "learning_rate": 8.38464e-05,
      "loss": 1.8177,
      "step": 18150
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.3665323853492737,
      "learning_rate": 8.35264e-05,
      "loss": 1.8234,
      "step": 18200
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.29406389594078064,
      "learning_rate": 8.32064e-05,
      "loss": 1.7754,
      "step": 18250
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.3370537757873535,
      "learning_rate": 8.28864e-05,
      "loss": 1.7953,
      "step": 18300
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.2772781252861023,
      "learning_rate": 8.25664e-05,
      "loss": 1.7766,
      "step": 18350
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.3195562958717346,
      "learning_rate": 8.22464e-05,
      "loss": 1.7739,
      "step": 18400
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.24571257829666138,
      "learning_rate": 8.19264e-05,
      "loss": 1.739,
      "step": 18450
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.3511078655719757,
      "learning_rate": 8.16064e-05,
      "loss": 1.8423,
      "step": 18500
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.3916415274143219,
      "learning_rate": 8.128640000000001e-05,
      "loss": 1.7937,
      "step": 18550
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.3125644326210022,
      "learning_rate": 8.096640000000001e-05,
      "loss": 1.8029,
      "step": 18600
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.3280797302722931,
      "learning_rate": 8.06464e-05,
      "loss": 1.7867,
      "step": 18650
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.35390353202819824,
      "learning_rate": 8.03264e-05,
      "loss": 1.8163,
      "step": 18700
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3234773874282837,
      "learning_rate": 8.000640000000001e-05,
      "loss": 1.7897,
      "step": 18750
    },
    {
      "epoch": 3.008,
      "grad_norm": 0.32369789481163025,
      "learning_rate": 7.968640000000001e-05,
      "loss": 1.8225,
      "step": 18800
    },
    {
      "epoch": 3.016,
      "grad_norm": 0.334394246339798,
      "learning_rate": 7.936640000000001e-05,
      "loss": 1.7548,
      "step": 18850
    },
    {
      "epoch": 3.024,
      "grad_norm": 0.3191431164741516,
      "learning_rate": 7.90464e-05,
      "loss": 1.7973,
      "step": 18900
    },
    {
      "epoch": 3.032,
      "grad_norm": 0.2756010890007019,
      "learning_rate": 7.87264e-05,
      "loss": 1.7506,
      "step": 18950
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.37364187836647034,
      "learning_rate": 7.840640000000001e-05,
      "loss": 1.7419,
      "step": 19000
    },
    {
      "epoch": 3.048,
      "grad_norm": 0.23565062880516052,
      "learning_rate": 7.80864e-05,
      "loss": 1.7706,
      "step": 19050
    },
    {
      "epoch": 3.056,
      "grad_norm": 0.4503406882286072,
      "learning_rate": 7.77664e-05,
      "loss": 1.8451,
      "step": 19100
    },
    {
      "epoch": 3.064,
      "grad_norm": 0.3297906816005707,
      "learning_rate": 7.74464e-05,
      "loss": 1.7781,
      "step": 19150
    },
    {
      "epoch": 3.072,
      "grad_norm": 0.3288411796092987,
      "learning_rate": 7.71264e-05,
      "loss": 1.8172,
      "step": 19200
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.29893800616264343,
      "learning_rate": 7.68064e-05,
      "loss": 1.8205,
      "step": 19250
    },
    {
      "epoch": 3.088,
      "grad_norm": 0.34084218740463257,
      "learning_rate": 7.64864e-05,
      "loss": 1.8163,
      "step": 19300
    },
    {
      "epoch": 3.096,
      "grad_norm": 0.30721694231033325,
      "learning_rate": 7.61664e-05,
      "loss": 1.7497,
      "step": 19350
    },
    {
      "epoch": 3.104,
      "grad_norm": 0.31607499718666077,
      "learning_rate": 7.58464e-05,
      "loss": 1.7442,
      "step": 19400
    },
    {
      "epoch": 3.112,
      "grad_norm": 0.3101887106895447,
      "learning_rate": 7.552640000000001e-05,
      "loss": 1.8099,
      "step": 19450
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.3093995451927185,
      "learning_rate": 7.52064e-05,
      "loss": 1.8098,
      "step": 19500
    },
    {
      "epoch": 3.128,
      "grad_norm": 0.3416893482208252,
      "learning_rate": 7.48864e-05,
      "loss": 1.7538,
      "step": 19550
    },
    {
      "epoch": 3.136,
      "grad_norm": 0.3635457754135132,
      "learning_rate": 7.45664e-05,
      "loss": 1.7926,
      "step": 19600
    },
    {
      "epoch": 3.144,
      "grad_norm": 0.33342814445495605,
      "learning_rate": 7.424640000000001e-05,
      "loss": 1.7944,
      "step": 19650
    },
    {
      "epoch": 3.152,
      "grad_norm": 0.2941996455192566,
      "learning_rate": 7.392640000000001e-05,
      "loss": 1.8125,
      "step": 19700
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.4546204209327698,
      "learning_rate": 7.360640000000001e-05,
      "loss": 1.736,
      "step": 19750
    },
    {
      "epoch": 3.168,
      "grad_norm": 0.3597896099090576,
      "learning_rate": 7.32864e-05,
      "loss": 1.7546,
      "step": 19800
    },
    {
      "epoch": 3.176,
      "grad_norm": 0.29647353291511536,
      "learning_rate": 7.29664e-05,
      "loss": 1.8358,
      "step": 19850
    },
    {
      "epoch": 3.184,
      "grad_norm": 0.3916056752204895,
      "learning_rate": 7.264640000000001e-05,
      "loss": 1.7406,
      "step": 19900
    },
    {
      "epoch": 3.192,
      "grad_norm": 0.3499005138874054,
      "learning_rate": 7.23264e-05,
      "loss": 1.7667,
      "step": 19950
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.3352212905883789,
      "learning_rate": 7.20064e-05,
      "loss": 1.7614,
      "step": 20000
    },
    {
      "epoch": 3.208,
      "grad_norm": 0.3401332497596741,
      "learning_rate": 7.168639999999999e-05,
      "loss": 1.7276,
      "step": 20050
    },
    {
      "epoch": 3.216,
      "grad_norm": 0.3196640908718109,
      "learning_rate": 7.13664e-05,
      "loss": 1.7734,
      "step": 20100
    },
    {
      "epoch": 3.224,
      "grad_norm": 0.33133602142333984,
      "learning_rate": 7.10464e-05,
      "loss": 1.7756,
      "step": 20150
    },
    {
      "epoch": 3.232,
      "grad_norm": 0.3419625759124756,
      "learning_rate": 7.07264e-05,
      "loss": 1.7049,
      "step": 20200
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.34748390316963196,
      "learning_rate": 7.04064e-05,
      "loss": 1.7975,
      "step": 20250
    },
    {
      "epoch": 3.248,
      "grad_norm": 0.3441010117530823,
      "learning_rate": 7.008640000000001e-05,
      "loss": 1.8161,
      "step": 20300
    },
    {
      "epoch": 3.2560000000000002,
      "grad_norm": 0.3483249545097351,
      "learning_rate": 6.97664e-05,
      "loss": 1.7934,
      "step": 20350
    },
    {
      "epoch": 3.2640000000000002,
      "grad_norm": 0.372915118932724,
      "learning_rate": 6.94464e-05,
      "loss": 1.8061,
      "step": 20400
    },
    {
      "epoch": 3.2720000000000002,
      "grad_norm": 0.352291464805603,
      "learning_rate": 6.91264e-05,
      "loss": 1.7498,
      "step": 20450
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.3879712224006653,
      "learning_rate": 6.88064e-05,
      "loss": 1.7908,
      "step": 20500
    },
    {
      "epoch": 3.288,
      "grad_norm": 0.2898061275482178,
      "learning_rate": 6.848640000000001e-05,
      "loss": 1.7868,
      "step": 20550
    },
    {
      "epoch": 3.296,
      "grad_norm": 0.3702293634414673,
      "learning_rate": 6.816640000000001e-05,
      "loss": 1.7808,
      "step": 20600
    },
    {
      "epoch": 3.304,
      "grad_norm": 0.33638080954551697,
      "learning_rate": 6.78464e-05,
      "loss": 1.8542,
      "step": 20650
    },
    {
      "epoch": 3.312,
      "grad_norm": 0.3287894129753113,
      "learning_rate": 6.75264e-05,
      "loss": 1.7577,
      "step": 20700
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.3358563482761383,
      "learning_rate": 6.720640000000001e-05,
      "loss": 1.7611,
      "step": 20750
    },
    {
      "epoch": 3.328,
      "grad_norm": 0.3670136332511902,
      "learning_rate": 6.688640000000001e-05,
      "loss": 1.7995,
      "step": 20800
    },
    {
      "epoch": 3.336,
      "grad_norm": 0.371186226606369,
      "learning_rate": 6.65664e-05,
      "loss": 1.7518,
      "step": 20850
    },
    {
      "epoch": 3.344,
      "grad_norm": 0.37587034702301025,
      "learning_rate": 6.62464e-05,
      "loss": 1.8174,
      "step": 20900
    },
    {
      "epoch": 3.352,
      "grad_norm": 0.38298869132995605,
      "learning_rate": 6.592639999999999e-05,
      "loss": 1.8219,
      "step": 20950
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.38465577363967896,
      "learning_rate": 6.56064e-05,
      "loss": 1.7515,
      "step": 21000
    },
    {
      "epoch": 3.368,
      "grad_norm": 0.42367270588874817,
      "learning_rate": 6.52864e-05,
      "loss": 1.7839,
      "step": 21050
    },
    {
      "epoch": 3.376,
      "grad_norm": 0.35238248109817505,
      "learning_rate": 6.49664e-05,
      "loss": 1.8251,
      "step": 21100
    },
    {
      "epoch": 3.384,
      "grad_norm": 0.3610348701477051,
      "learning_rate": 6.46464e-05,
      "loss": 1.7889,
      "step": 21150
    },
    {
      "epoch": 3.392,
      "grad_norm": 0.40106597542762756,
      "learning_rate": 6.43264e-05,
      "loss": 1.8361,
      "step": 21200
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.40080130100250244,
      "learning_rate": 6.40064e-05,
      "loss": 1.8259,
      "step": 21250
    },
    {
      "epoch": 3.408,
      "grad_norm": 0.3655446469783783,
      "learning_rate": 6.36864e-05,
      "loss": 1.7922,
      "step": 21300
    },
    {
      "epoch": 3.416,
      "grad_norm": 0.39443933963775635,
      "learning_rate": 6.33664e-05,
      "loss": 1.8008,
      "step": 21350
    },
    {
      "epoch": 3.424,
      "grad_norm": 0.32999882102012634,
      "learning_rate": 6.30464e-05,
      "loss": 1.8455,
      "step": 21400
    },
    {
      "epoch": 3.432,
      "grad_norm": 0.339986652135849,
      "learning_rate": 6.272640000000001e-05,
      "loss": 1.8225,
      "step": 21450
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.33147284388542175,
      "learning_rate": 6.24064e-05,
      "loss": 1.8016,
      "step": 21500
    },
    {
      "epoch": 3.448,
      "grad_norm": 0.34627699851989746,
      "learning_rate": 6.20864e-05,
      "loss": 1.7753,
      "step": 21550
    },
    {
      "epoch": 3.456,
      "grad_norm": 0.4162883162498474,
      "learning_rate": 6.17664e-05,
      "loss": 1.7623,
      "step": 21600
    },
    {
      "epoch": 3.464,
      "grad_norm": 0.3195498585700989,
      "learning_rate": 6.144640000000001e-05,
      "loss": 1.8076,
      "step": 21650
    },
    {
      "epoch": 3.472,
      "grad_norm": 0.40945157408714294,
      "learning_rate": 6.112640000000001e-05,
      "loss": 1.7464,
      "step": 21700
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.36359718441963196,
      "learning_rate": 6.080640000000001e-05,
      "loss": 1.83,
      "step": 21750
    },
    {
      "epoch": 3.488,
      "grad_norm": 0.3445376753807068,
      "learning_rate": 6.04864e-05,
      "loss": 1.7604,
      "step": 21800
    },
    {
      "epoch": 3.496,
      "grad_norm": 0.40266191959381104,
      "learning_rate": 6.01664e-05,
      "loss": 1.7561,
      "step": 21850
    },
    {
      "epoch": 3.504,
      "grad_norm": 0.4400382936000824,
      "learning_rate": 5.9846400000000004e-05,
      "loss": 1.8106,
      "step": 21900
    },
    {
      "epoch": 3.512,
      "grad_norm": 0.34646448493003845,
      "learning_rate": 5.9526400000000007e-05,
      "loss": 1.7691,
      "step": 21950
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.37332379817962646,
      "learning_rate": 5.920640000000001e-05,
      "loss": 1.7783,
      "step": 22000
    },
    {
      "epoch": 3.528,
      "grad_norm": 0.3412889838218689,
      "learning_rate": 5.8886400000000006e-05,
      "loss": 1.751,
      "step": 22050
    },
    {
      "epoch": 3.536,
      "grad_norm": 0.3133670687675476,
      "learning_rate": 5.85664e-05,
      "loss": 1.7746,
      "step": 22100
    },
    {
      "epoch": 3.544,
      "grad_norm": 0.34252241253852844,
      "learning_rate": 5.82464e-05,
      "loss": 1.7786,
      "step": 22150
    },
    {
      "epoch": 3.552,
      "grad_norm": 0.3336527347564697,
      "learning_rate": 5.79264e-05,
      "loss": 1.7773,
      "step": 22200
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.3434160351753235,
      "learning_rate": 5.7606400000000005e-05,
      "loss": 1.7768,
      "step": 22250
    },
    {
      "epoch": 3.568,
      "grad_norm": 0.33099329471588135,
      "learning_rate": 5.728640000000001e-05,
      "loss": 1.756,
      "step": 22300
    },
    {
      "epoch": 3.576,
      "grad_norm": 0.3144955039024353,
      "learning_rate": 5.69664e-05,
      "loss": 1.7769,
      "step": 22350
    },
    {
      "epoch": 3.584,
      "grad_norm": 0.33575767278671265,
      "learning_rate": 5.66464e-05,
      "loss": 1.7553,
      "step": 22400
    },
    {
      "epoch": 3.592,
      "grad_norm": 0.333182692527771,
      "learning_rate": 5.63264e-05,
      "loss": 1.7973,
      "step": 22450
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.4020291864871979,
      "learning_rate": 5.6006400000000006e-05,
      "loss": 1.7692,
      "step": 22500
    },
    {
      "epoch": 3.608,
      "grad_norm": 0.3770510256290436,
      "learning_rate": 5.56864e-05,
      "loss": 1.8075,
      "step": 22550
    },
    {
      "epoch": 3.616,
      "grad_norm": 0.35143694281578064,
      "learning_rate": 5.5366400000000006e-05,
      "loss": 1.7452,
      "step": 22600
    },
    {
      "epoch": 3.624,
      "grad_norm": 0.3453674912452698,
      "learning_rate": 5.5046399999999995e-05,
      "loss": 1.7764,
      "step": 22650
    },
    {
      "epoch": 3.632,
      "grad_norm": 0.3259034752845764,
      "learning_rate": 5.47264e-05,
      "loss": 1.7953,
      "step": 22700
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.31791236996650696,
      "learning_rate": 5.44064e-05,
      "loss": 1.7591,
      "step": 22750
    },
    {
      "epoch": 3.648,
      "grad_norm": 0.34524697065353394,
      "learning_rate": 5.4086400000000004e-05,
      "loss": 1.8349,
      "step": 22800
    },
    {
      "epoch": 3.656,
      "grad_norm": 0.3433571457862854,
      "learning_rate": 5.376640000000001e-05,
      "loss": 1.7738,
      "step": 22850
    },
    {
      "epoch": 3.664,
      "grad_norm": 0.3498654365539551,
      "learning_rate": 5.344640000000001e-05,
      "loss": 1.7584,
      "step": 22900
    },
    {
      "epoch": 3.672,
      "grad_norm": 0.33706584572792053,
      "learning_rate": 5.31264e-05,
      "loss": 1.7956,
      "step": 22950
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.3862564265727997,
      "learning_rate": 5.28064e-05,
      "loss": 1.8105,
      "step": 23000
    },
    {
      "epoch": 3.6879999999999997,
      "grad_norm": 0.2929794490337372,
      "learning_rate": 5.24864e-05,
      "loss": 1.8053,
      "step": 23050
    },
    {
      "epoch": 3.6959999999999997,
      "grad_norm": 0.34740403294563293,
      "learning_rate": 5.21664e-05,
      "loss": 1.7688,
      "step": 23100
    },
    {
      "epoch": 3.7039999999999997,
      "grad_norm": 0.37553709745407104,
      "learning_rate": 5.1846400000000006e-05,
      "loss": 1.7805,
      "step": 23150
    },
    {
      "epoch": 3.7119999999999997,
      "grad_norm": 0.3301248550415039,
      "learning_rate": 5.152640000000001e-05,
      "loss": 1.7791,
      "step": 23200
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.353434294462204,
      "learning_rate": 5.12064e-05,
      "loss": 1.7871,
      "step": 23250
    },
    {
      "epoch": 3.7279999999999998,
      "grad_norm": 0.3647899031639099,
      "learning_rate": 5.08864e-05,
      "loss": 1.7953,
      "step": 23300
    },
    {
      "epoch": 3.7359999999999998,
      "grad_norm": 0.3937394618988037,
      "learning_rate": 5.0566400000000004e-05,
      "loss": 1.7878,
      "step": 23350
    },
    {
      "epoch": 3.7439999999999998,
      "grad_norm": 0.4136916399002075,
      "learning_rate": 5.024640000000001e-05,
      "loss": 1.7918,
      "step": 23400
    },
    {
      "epoch": 3.752,
      "grad_norm": 0.33837559819221497,
      "learning_rate": 4.9926400000000004e-05,
      "loss": 1.7874,
      "step": 23450
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.3775004744529724,
      "learning_rate": 4.96064e-05,
      "loss": 1.7572,
      "step": 23500
    },
    {
      "epoch": 3.768,
      "grad_norm": 0.32903870940208435,
      "learning_rate": 4.92864e-05,
      "loss": 1.7973,
      "step": 23550
    },
    {
      "epoch": 3.776,
      "grad_norm": 0.32524994015693665,
      "learning_rate": 4.89664e-05,
      "loss": 1.76,
      "step": 23600
    },
    {
      "epoch": 3.784,
      "grad_norm": 0.3396924138069153,
      "learning_rate": 4.86464e-05,
      "loss": 1.7622,
      "step": 23650
    },
    {
      "epoch": 3.792,
      "grad_norm": 0.33558350801467896,
      "learning_rate": 4.8326400000000005e-05,
      "loss": 1.7935,
      "step": 23700
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.35449105501174927,
      "learning_rate": 4.80064e-05,
      "loss": 1.7914,
      "step": 23750
    },
    {
      "epoch": 3.808,
      "grad_norm": 0.38088658452033997,
      "learning_rate": 4.7686400000000005e-05,
      "loss": 1.8044,
      "step": 23800
    },
    {
      "epoch": 3.816,
      "grad_norm": 0.34715554118156433,
      "learning_rate": 4.73664e-05,
      "loss": 1.8041,
      "step": 23850
    },
    {
      "epoch": 3.824,
      "grad_norm": 0.3357008397579193,
      "learning_rate": 4.7046400000000004e-05,
      "loss": 1.7743,
      "step": 23900
    },
    {
      "epoch": 3.832,
      "grad_norm": 0.3476456105709076,
      "learning_rate": 4.67264e-05,
      "loss": 1.7942,
      "step": 23950
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.40032958984375,
      "learning_rate": 4.64064e-05,
      "loss": 1.7812,
      "step": 24000
    },
    {
      "epoch": 3.848,
      "grad_norm": 0.4584224820137024,
      "learning_rate": 4.60864e-05,
      "loss": 1.7828,
      "step": 24050
    },
    {
      "epoch": 3.856,
      "grad_norm": 0.36509135365486145,
      "learning_rate": 4.57664e-05,
      "loss": 1.8561,
      "step": 24100
    },
    {
      "epoch": 3.864,
      "grad_norm": 0.3768604099750519,
      "learning_rate": 4.54464e-05,
      "loss": 1.747,
      "step": 24150
    },
    {
      "epoch": 3.872,
      "grad_norm": 0.33387473225593567,
      "learning_rate": 4.51264e-05,
      "loss": 1.7888,
      "step": 24200
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.42474493384361267,
      "learning_rate": 4.4806400000000005e-05,
      "loss": 1.7953,
      "step": 24250
    },
    {
      "epoch": 3.888,
      "grad_norm": 0.32747218012809753,
      "learning_rate": 4.44864e-05,
      "loss": 1.7754,
      "step": 24300
    },
    {
      "epoch": 3.896,
      "grad_norm": 0.33698540925979614,
      "learning_rate": 4.4166400000000005e-05,
      "loss": 1.7842,
      "step": 24350
    },
    {
      "epoch": 3.904,
      "grad_norm": 0.3150107264518738,
      "learning_rate": 4.38464e-05,
      "loss": 1.7924,
      "step": 24400
    },
    {
      "epoch": 3.912,
      "grad_norm": 0.3566305339336395,
      "learning_rate": 4.35264e-05,
      "loss": 1.7225,
      "step": 24450
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.359702467918396,
      "learning_rate": 4.32064e-05,
      "loss": 1.7486,
      "step": 24500
    },
    {
      "epoch": 3.928,
      "grad_norm": 0.3212030529975891,
      "learning_rate": 4.28864e-05,
      "loss": 1.8189,
      "step": 24550
    },
    {
      "epoch": 3.936,
      "grad_norm": 0.33205726742744446,
      "learning_rate": 4.25664e-05,
      "loss": 1.771,
      "step": 24600
    },
    {
      "epoch": 3.944,
      "grad_norm": 0.410678505897522,
      "learning_rate": 4.22464e-05,
      "loss": 1.7245,
      "step": 24650
    },
    {
      "epoch": 3.952,
      "grad_norm": 0.37232521176338196,
      "learning_rate": 4.1926400000000006e-05,
      "loss": 1.7976,
      "step": 24700
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.330106645822525,
      "learning_rate": 4.16064e-05,
      "loss": 1.7764,
      "step": 24750
    },
    {
      "epoch": 3.968,
      "grad_norm": 0.4791395366191864,
      "learning_rate": 4.1286400000000005e-05,
      "loss": 1.7919,
      "step": 24800
    },
    {
      "epoch": 3.976,
      "grad_norm": 0.39126652479171753,
      "learning_rate": 4.09664e-05,
      "loss": 1.7621,
      "step": 24850
    },
    {
      "epoch": 3.984,
      "grad_norm": 0.30385512113571167,
      "learning_rate": 4.0646400000000004e-05,
      "loss": 1.8223,
      "step": 24900
    },
    {
      "epoch": 3.992,
      "grad_norm": 0.36614662408828735,
      "learning_rate": 4.03264e-05,
      "loss": 1.8039,
      "step": 24950
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.37707796692848206,
      "learning_rate": 4.00064e-05,
      "loss": 1.7338,
      "step": 25000
    },
    {
      "epoch": 4.008,
      "grad_norm": 0.307839572429657,
      "learning_rate": 3.96864e-05,
      "loss": 1.7286,
      "step": 25050
    },
    {
      "epoch": 4.016,
      "grad_norm": 0.3820750117301941,
      "learning_rate": 3.93664e-05,
      "loss": 1.7852,
      "step": 25100
    },
    {
      "epoch": 4.024,
      "grad_norm": 0.3520828187465668,
      "learning_rate": 3.90464e-05,
      "loss": 1.759,
      "step": 25150
    },
    {
      "epoch": 4.032,
      "grad_norm": 0.3292810618877411,
      "learning_rate": 3.87264e-05,
      "loss": 1.8134,
      "step": 25200
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.33804836869239807,
      "learning_rate": 3.8406400000000006e-05,
      "loss": 1.7776,
      "step": 25250
    },
    {
      "epoch": 4.048,
      "grad_norm": 0.33659547567367554,
      "learning_rate": 3.80864e-05,
      "loss": 1.7992,
      "step": 25300
    },
    {
      "epoch": 4.056,
      "grad_norm": 0.3197844326496124,
      "learning_rate": 3.7766400000000005e-05,
      "loss": 1.8044,
      "step": 25350
    },
    {
      "epoch": 4.064,
      "grad_norm": 0.3287131190299988,
      "learning_rate": 3.74464e-05,
      "loss": 1.7303,
      "step": 25400
    },
    {
      "epoch": 4.072,
      "grad_norm": 0.35101279616355896,
      "learning_rate": 3.71264e-05,
      "loss": 1.8076,
      "step": 25450
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.3460434377193451,
      "learning_rate": 3.68064e-05,
      "loss": 1.797,
      "step": 25500
    },
    {
      "epoch": 4.088,
      "grad_norm": 0.3610341250896454,
      "learning_rate": 3.6486400000000004e-05,
      "loss": 1.8185,
      "step": 25550
    },
    {
      "epoch": 4.096,
      "grad_norm": 0.44661492109298706,
      "learning_rate": 3.61664e-05,
      "loss": 1.8066,
      "step": 25600
    },
    {
      "epoch": 4.104,
      "grad_norm": 0.4161267578601837,
      "learning_rate": 3.58464e-05,
      "loss": 1.7543,
      "step": 25650
    },
    {
      "epoch": 4.112,
      "grad_norm": 0.3697561025619507,
      "learning_rate": 3.5526400000000006e-05,
      "loss": 1.7785,
      "step": 25700
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.36283132433891296,
      "learning_rate": 3.52064e-05,
      "loss": 1.7426,
      "step": 25750
    },
    {
      "epoch": 4.128,
      "grad_norm": 0.3429301381111145,
      "learning_rate": 3.4886400000000005e-05,
      "loss": 1.7584,
      "step": 25800
    },
    {
      "epoch": 4.136,
      "grad_norm": 0.3967260718345642,
      "learning_rate": 3.45664e-05,
      "loss": 1.7619,
      "step": 25850
    },
    {
      "epoch": 4.144,
      "grad_norm": 0.3594251275062561,
      "learning_rate": 3.42464e-05,
      "loss": 1.7624,
      "step": 25900
    },
    {
      "epoch": 4.152,
      "grad_norm": 0.3628654479980469,
      "learning_rate": 3.39264e-05,
      "loss": 1.7288,
      "step": 25950
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.3278958201408386,
      "learning_rate": 3.36064e-05,
      "loss": 1.7481,
      "step": 26000
    },
    {
      "epoch": 4.168,
      "grad_norm": 0.2943950593471527,
      "learning_rate": 3.32864e-05,
      "loss": 1.7446,
      "step": 26050
    },
    {
      "epoch": 4.176,
      "grad_norm": 0.3733558654785156,
      "learning_rate": 3.2966400000000003e-05,
      "loss": 1.7147,
      "step": 26100
    },
    {
      "epoch": 4.184,
      "grad_norm": 0.33419913053512573,
      "learning_rate": 3.26464e-05,
      "loss": 1.7863,
      "step": 26150
    },
    {
      "epoch": 4.192,
      "grad_norm": 0.3495301604270935,
      "learning_rate": 3.23264e-05,
      "loss": 1.7288,
      "step": 26200
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.35487884283065796,
      "learning_rate": 3.2006400000000006e-05,
      "loss": 1.8071,
      "step": 26250
    },
    {
      "epoch": 4.208,
      "grad_norm": 0.46727174520492554,
      "learning_rate": 3.16864e-05,
      "loss": 1.785,
      "step": 26300
    },
    {
      "epoch": 4.216,
      "grad_norm": 0.3399762809276581,
      "learning_rate": 3.13664e-05,
      "loss": 1.7899,
      "step": 26350
    },
    {
      "epoch": 4.224,
      "grad_norm": 0.39413803815841675,
      "learning_rate": 3.10464e-05,
      "loss": 1.7696,
      "step": 26400
    },
    {
      "epoch": 4.232,
      "grad_norm": 0.34527307748794556,
      "learning_rate": 3.07264e-05,
      "loss": 1.7621,
      "step": 26450
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.36198750138282776,
      "learning_rate": 3.04064e-05,
      "loss": 1.841,
      "step": 26500
    },
    {
      "epoch": 4.248,
      "grad_norm": 0.387592077255249,
      "learning_rate": 3.0086400000000004e-05,
      "loss": 1.764,
      "step": 26550
    },
    {
      "epoch": 4.256,
      "grad_norm": 0.3413552939891815,
      "learning_rate": 2.97664e-05,
      "loss": 1.7611,
      "step": 26600
    },
    {
      "epoch": 4.264,
      "grad_norm": 0.32657870650291443,
      "learning_rate": 2.9446400000000003e-05,
      "loss": 1.8234,
      "step": 26650
    },
    {
      "epoch": 4.272,
      "grad_norm": 0.29406628012657166,
      "learning_rate": 2.9126400000000003e-05,
      "loss": 1.8216,
      "step": 26700
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.3980964720249176,
      "learning_rate": 2.88064e-05,
      "loss": 1.7613,
      "step": 26750
    },
    {
      "epoch": 4.288,
      "grad_norm": 0.33942899107933044,
      "learning_rate": 2.8486400000000002e-05,
      "loss": 1.7697,
      "step": 26800
    },
    {
      "epoch": 4.296,
      "grad_norm": 0.5253591537475586,
      "learning_rate": 2.8166400000000005e-05,
      "loss": 1.7829,
      "step": 26850
    },
    {
      "epoch": 4.304,
      "grad_norm": 0.33507323265075684,
      "learning_rate": 2.78464e-05,
      "loss": 1.8026,
      "step": 26900
    },
    {
      "epoch": 4.312,
      "grad_norm": 0.39511847496032715,
      "learning_rate": 2.75264e-05,
      "loss": 1.7755,
      "step": 26950
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.3709181249141693,
      "learning_rate": 2.7206399999999998e-05,
      "loss": 1.7416,
      "step": 27000
    },
    {
      "epoch": 4.328,
      "grad_norm": 0.3570409119129181,
      "learning_rate": 2.68864e-05,
      "loss": 1.7648,
      "step": 27050
    },
    {
      "epoch": 4.336,
      "grad_norm": 0.347901314496994,
      "learning_rate": 2.6566400000000004e-05,
      "loss": 1.7707,
      "step": 27100
    },
    {
      "epoch": 4.344,
      "grad_norm": 0.34879177808761597,
      "learning_rate": 2.62464e-05,
      "loss": 1.7537,
      "step": 27150
    },
    {
      "epoch": 4.352,
      "grad_norm": 0.35995593667030334,
      "learning_rate": 2.59264e-05,
      "loss": 1.7737,
      "step": 27200
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.31048277020454407,
      "learning_rate": 2.5606400000000003e-05,
      "loss": 1.7882,
      "step": 27250
    },
    {
      "epoch": 4.368,
      "grad_norm": 0.35742127895355225,
      "learning_rate": 2.52864e-05,
      "loss": 1.8157,
      "step": 27300
    },
    {
      "epoch": 4.376,
      "grad_norm": 0.37318018078804016,
      "learning_rate": 2.4966400000000002e-05,
      "loss": 1.7983,
      "step": 27350
    },
    {
      "epoch": 4.384,
      "grad_norm": 0.3348500728607178,
      "learning_rate": 2.4646400000000002e-05,
      "loss": 1.7535,
      "step": 27400
    },
    {
      "epoch": 4.392,
      "grad_norm": 0.4005623459815979,
      "learning_rate": 2.43264e-05,
      "loss": 1.8018,
      "step": 27450
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.3361831605434418,
      "learning_rate": 2.40064e-05,
      "loss": 1.7531,
      "step": 27500
    },
    {
      "epoch": 4.408,
      "grad_norm": 0.3378064036369324,
      "learning_rate": 2.36864e-05,
      "loss": 1.7755,
      "step": 27550
    },
    {
      "epoch": 4.416,
      "grad_norm": 0.3564450740814209,
      "learning_rate": 2.3366400000000004e-05,
      "loss": 1.7388,
      "step": 27600
    },
    {
      "epoch": 4.424,
      "grad_norm": 0.37079137563705444,
      "learning_rate": 2.30464e-05,
      "loss": 1.7911,
      "step": 27650
    },
    {
      "epoch": 4.432,
      "grad_norm": 0.30840957164764404,
      "learning_rate": 2.27264e-05,
      "loss": 1.7518,
      "step": 27700
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.34627753496170044,
      "learning_rate": 2.2406400000000003e-05,
      "loss": 1.7988,
      "step": 27750
    },
    {
      "epoch": 4.448,
      "grad_norm": 0.3376955986022949,
      "learning_rate": 2.2086400000000003e-05,
      "loss": 1.7684,
      "step": 27800
    },
    {
      "epoch": 4.456,
      "grad_norm": 0.4043881297111511,
      "learning_rate": 2.1766400000000002e-05,
      "loss": 1.7915,
      "step": 27850
    },
    {
      "epoch": 4.464,
      "grad_norm": 0.36291855573654175,
      "learning_rate": 2.14464e-05,
      "loss": 1.7844,
      "step": 27900
    },
    {
      "epoch": 4.4719999999999995,
      "grad_norm": 0.41820207238197327,
      "learning_rate": 2.11264e-05,
      "loss": 1.8366,
      "step": 27950
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.3431607782840729,
      "learning_rate": 2.08064e-05,
      "loss": 1.8399,
      "step": 28000
    },
    {
      "epoch": 4.4879999999999995,
      "grad_norm": 0.33342039585113525,
      "learning_rate": 2.04864e-05,
      "loss": 1.7673,
      "step": 28050
    },
    {
      "epoch": 4.496,
      "grad_norm": 0.37526920437812805,
      "learning_rate": 2.01664e-05,
      "loss": 1.7653,
      "step": 28100
    },
    {
      "epoch": 4.504,
      "grad_norm": 0.3496679365634918,
      "learning_rate": 1.98464e-05,
      "loss": 1.7774,
      "step": 28150
    },
    {
      "epoch": 4.5120000000000005,
      "grad_norm": 0.31793248653411865,
      "learning_rate": 1.95264e-05,
      "loss": 1.7473,
      "step": 28200
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.34402066469192505,
      "learning_rate": 1.9206400000000003e-05,
      "loss": 1.8067,
      "step": 28250
    },
    {
      "epoch": 4.5280000000000005,
      "grad_norm": 0.3293251395225525,
      "learning_rate": 1.8886400000000003e-05,
      "loss": 1.7585,
      "step": 28300
    },
    {
      "epoch": 4.536,
      "grad_norm": 0.3394536077976227,
      "learning_rate": 1.85664e-05,
      "loss": 1.7904,
      "step": 28350
    },
    {
      "epoch": 4.5440000000000005,
      "grad_norm": 0.3745424151420593,
      "learning_rate": 1.82464e-05,
      "loss": 1.8221,
      "step": 28400
    },
    {
      "epoch": 4.552,
      "grad_norm": 0.34417232871055603,
      "learning_rate": 1.7926400000000002e-05,
      "loss": 1.7075,
      "step": 28450
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.3616280257701874,
      "learning_rate": 1.76064e-05,
      "loss": 1.7767,
      "step": 28500
    },
    {
      "epoch": 4.568,
      "grad_norm": 0.3858494460582733,
      "learning_rate": 1.72864e-05,
      "loss": 1.7858,
      "step": 28550
    },
    {
      "epoch": 4.576,
      "grad_norm": 0.38520801067352295,
      "learning_rate": 1.69664e-05,
      "loss": 1.7698,
      "step": 28600
    },
    {
      "epoch": 4.584,
      "grad_norm": 0.37992238998413086,
      "learning_rate": 1.66464e-05,
      "loss": 1.7953,
      "step": 28650
    },
    {
      "epoch": 4.592,
      "grad_norm": 0.4197562336921692,
      "learning_rate": 1.63264e-05,
      "loss": 1.7749,
      "step": 28700
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.3196513056755066,
      "learning_rate": 1.6006400000000003e-05,
      "loss": 1.731,
      "step": 28750
    },
    {
      "epoch": 4.608,
      "grad_norm": 0.30092713236808777,
      "learning_rate": 1.56864e-05,
      "loss": 1.7597,
      "step": 28800
    },
    {
      "epoch": 4.616,
      "grad_norm": 0.3140275776386261,
      "learning_rate": 1.53664e-05,
      "loss": 1.7883,
      "step": 28850
    },
    {
      "epoch": 4.624,
      "grad_norm": 0.43212130665779114,
      "learning_rate": 1.5046399999999999e-05,
      "loss": 1.7953,
      "step": 28900
    },
    {
      "epoch": 4.632,
      "grad_norm": 0.37236565351486206,
      "learning_rate": 1.4726400000000002e-05,
      "loss": 1.7317,
      "step": 28950
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.3751303553581238,
      "learning_rate": 1.44064e-05,
      "loss": 1.7983,
      "step": 29000
    },
    {
      "epoch": 4.648,
      "grad_norm": 0.33851921558380127,
      "learning_rate": 1.40864e-05,
      "loss": 1.7717,
      "step": 29050
    },
    {
      "epoch": 4.656,
      "grad_norm": 0.40958452224731445,
      "learning_rate": 1.3766400000000001e-05,
      "loss": 1.7406,
      "step": 29100
    },
    {
      "epoch": 4.664,
      "grad_norm": 0.34354281425476074,
      "learning_rate": 1.34464e-05,
      "loss": 1.7444,
      "step": 29150
    },
    {
      "epoch": 4.672,
      "grad_norm": 0.38554099202156067,
      "learning_rate": 1.31264e-05,
      "loss": 1.6605,
      "step": 29200
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.3774331212043762,
      "learning_rate": 1.2806400000000002e-05,
      "loss": 1.7562,
      "step": 29250
    },
    {
      "epoch": 4.688,
      "grad_norm": 0.3769165277481079,
      "learning_rate": 1.2486400000000001e-05,
      "loss": 1.7608,
      "step": 29300
    },
    {
      "epoch": 4.696,
      "grad_norm": 0.3777897357940674,
      "learning_rate": 1.21664e-05,
      "loss": 1.7836,
      "step": 29350
    },
    {
      "epoch": 4.704,
      "grad_norm": 0.3792779743671417,
      "learning_rate": 1.18464e-05,
      "loss": 1.7695,
      "step": 29400
    },
    {
      "epoch": 4.712,
      "grad_norm": 0.3706614673137665,
      "learning_rate": 1.15264e-05,
      "loss": 1.7704,
      "step": 29450
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.40595120191574097,
      "learning_rate": 1.12064e-05,
      "loss": 1.7326,
      "step": 29500
    },
    {
      "epoch": 4.728,
      "grad_norm": 0.376392126083374,
      "learning_rate": 1.0886400000000001e-05,
      "loss": 1.8214,
      "step": 29550
    },
    {
      "epoch": 4.736,
      "grad_norm": 0.3720906674861908,
      "learning_rate": 1.05664e-05,
      "loss": 1.7835,
      "step": 29600
    },
    {
      "epoch": 4.744,
      "grad_norm": 0.3293039798736572,
      "learning_rate": 1.02464e-05,
      "loss": 1.8135,
      "step": 29650
    },
    {
      "epoch": 4.752,
      "grad_norm": 0.3792802095413208,
      "learning_rate": 9.9264e-06,
      "loss": 1.8319,
      "step": 29700
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.3624827265739441,
      "learning_rate": 9.6064e-06,
      "loss": 1.7776,
      "step": 29750
    },
    {
      "epoch": 4.768,
      "grad_norm": 0.400577574968338,
      "learning_rate": 9.286400000000001e-06,
      "loss": 1.8147,
      "step": 29800
    },
    {
      "epoch": 4.776,
      "grad_norm": 0.38335004448890686,
      "learning_rate": 8.9664e-06,
      "loss": 1.7541,
      "step": 29850
    },
    {
      "epoch": 4.784,
      "grad_norm": 0.3141995668411255,
      "learning_rate": 8.6464e-06,
      "loss": 1.7885,
      "step": 29900
    },
    {
      "epoch": 4.792,
      "grad_norm": 0.36927515268325806,
      "learning_rate": 8.3264e-06,
      "loss": 1.8262,
      "step": 29950
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.4995729327201843,
      "learning_rate": 8.0064e-06,
      "loss": 1.795,
      "step": 30000
    },
    {
      "epoch": 4.808,
      "grad_norm": 0.3838842809200287,
      "learning_rate": 7.6864e-06,
      "loss": 1.8192,
      "step": 30050
    },
    {
      "epoch": 4.816,
      "grad_norm": 0.31308117508888245,
      "learning_rate": 7.3663999999999995e-06,
      "loss": 1.7719,
      "step": 30100
    },
    {
      "epoch": 4.824,
      "grad_norm": 0.3578863739967346,
      "learning_rate": 7.0464e-06,
      "loss": 1.8012,
      "step": 30150
    },
    {
      "epoch": 4.832,
      "grad_norm": 0.42608651518821716,
      "learning_rate": 6.7264000000000005e-06,
      "loss": 1.7963,
      "step": 30200
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.38177192211151123,
      "learning_rate": 6.4064e-06,
      "loss": 1.7854,
      "step": 30250
    },
    {
      "epoch": 4.848,
      "grad_norm": 0.44101279973983765,
      "learning_rate": 6.086400000000001e-06,
      "loss": 1.7972,
      "step": 30300
    },
    {
      "epoch": 4.856,
      "grad_norm": 0.28488969802856445,
      "learning_rate": 5.7664e-06,
      "loss": 1.7818,
      "step": 30350
    },
    {
      "epoch": 4.864,
      "grad_norm": 0.3220667541027069,
      "learning_rate": 5.4464e-06,
      "loss": 1.7795,
      "step": 30400
    },
    {
      "epoch": 4.872,
      "grad_norm": 0.32140931487083435,
      "learning_rate": 5.1264e-06,
      "loss": 1.6977,
      "step": 30450
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.3828713595867157,
      "learning_rate": 4.8064e-06,
      "loss": 1.8077,
      "step": 30500
    },
    {
      "epoch": 4.888,
      "grad_norm": 0.44122114777565,
      "learning_rate": 4.4864e-06,
      "loss": 1.7852,
      "step": 30550
    },
    {
      "epoch": 4.896,
      "grad_norm": 0.40101534128189087,
      "learning_rate": 4.1664000000000005e-06,
      "loss": 1.7413,
      "step": 30600
    },
    {
      "epoch": 4.904,
      "grad_norm": 0.3211788833141327,
      "learning_rate": 3.8464e-06,
      "loss": 1.7321,
      "step": 30650
    },
    {
      "epoch": 4.912,
      "grad_norm": 0.35853439569473267,
      "learning_rate": 3.5264e-06,
      "loss": 1.8047,
      "step": 30700
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.3562188744544983,
      "learning_rate": 3.2064000000000003e-06,
      "loss": 1.7454,
      "step": 30750
    },
    {
      "epoch": 4.928,
      "grad_norm": 0.4092903435230255,
      "learning_rate": 2.8864e-06,
      "loss": 1.7899,
      "step": 30800
    },
    {
      "epoch": 4.936,
      "grad_norm": 0.3786206841468811,
      "learning_rate": 2.5664e-06,
      "loss": 1.7637,
      "step": 30850
    },
    {
      "epoch": 4.944,
      "grad_norm": 0.323476105928421,
      "learning_rate": 2.2464e-06,
      "loss": 1.7529,
      "step": 30900
    },
    {
      "epoch": 4.952,
      "grad_norm": 0.3540307581424713,
      "learning_rate": 1.9264e-06,
      "loss": 1.763,
      "step": 30950
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.32512491941452026,
      "learning_rate": 1.6064e-06,
      "loss": 1.7974,
      "step": 31000
    },
    {
      "epoch": 4.968,
      "grad_norm": 0.4440614879131317,
      "learning_rate": 1.2864e-06,
      "loss": 1.7841,
      "step": 31050
    },
    {
      "epoch": 4.976,
      "grad_norm": 0.4558616876602173,
      "learning_rate": 9.664000000000002e-07,
      "loss": 1.7243,
      "step": 31100
    },
    {
      "epoch": 4.984,
      "grad_norm": 0.3253656029701233,
      "learning_rate": 6.464000000000001e-07,
      "loss": 1.7492,
      "step": 31150
    },
    {
      "epoch": 4.992,
      "grad_norm": 0.40668901801109314,
      "learning_rate": 3.264e-07,
      "loss": 1.7982,
      "step": 31200
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.3963775932788849,
      "learning_rate": 6.4e-09,
      "loss": 1.7415,
      "step": 31250
    }
  ],
  "logging_steps": 50,
  "max_steps": 31250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.984263209217229e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
