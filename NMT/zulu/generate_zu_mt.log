nohup: ignoring input
/home/mwei/NMT_projects/MAenv/lib/python3.13/site-packages/peft/tuners/lora/bnb.py:93: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.
  warnings.warn(
--- 1. Loading base model and LoRA adapter ---
Loading LoRA adapter from: ./zu-25k-finetune/checkpoint-7815
--- Merging LoRA adapter into the base model ---
--- 2. Loading source test file: ./test_data/flores200_en.txt ---
--- 3. Generating translations ---
  0%|          | 0/64 [00:00<?, ?it/s]/home/mwei/NMT_projects/MAenv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
  2%|▏         | 1/64 [00:03<03:13,  3.07s/it]  3%|▎         | 2/64 [00:05<02:41,  2.61s/it]  5%|▍         | 3/64 [00:06<02:08,  2.11s/it]  6%|▋         | 4/64 [00:08<02:02,  2.04s/it]  8%|▊         | 5/64 [00:11<02:05,  2.13s/it]  9%|▉         | 6/64 [00:12<01:52,  1.93s/it] 11%|█         | 7/64 [00:14<01:54,  2.02s/it] 12%|█▎        | 8/64 [00:16<01:49,  1.95s/it] 14%|█▍        | 9/64 [00:18<01:45,  1.92s/it] 16%|█▌        | 10/64 [00:20<01:38,  1.82s/it] 17%|█▋        | 11/64 [00:22<01:48,  2.05s/it] 19%|█▉        | 12/64 [00:24<01:41,  1.96s/it] 20%|██        | 13/64 [00:27<01:52,  2.21s/it] 22%|██▏       | 14/64 [00:28<01:37,  1.95s/it] 23%|██▎       | 15/64 [00:30<01:35,  1.94s/it] 25%|██▌       | 16/64 [00:32<01:40,  2.09s/it] 27%|██▋       | 17/64 [00:34<01:36,  2.04s/it] 28%|██▊       | 18/64 [00:37<01:43,  2.26s/it] 30%|██▉       | 19/64 [00:39<01:35,  2.11s/it] 31%|███▏      | 20/64 [00:40<01:24,  1.91s/it] 33%|███▎      | 21/64 [00:42<01:18,  1.82s/it] 34%|███▍      | 22/64 [00:45<01:29,  2.13s/it] 36%|███▌      | 23/64 [00:46<01:22,  2.01s/it] 38%|███▊      | 24/64 [00:50<01:44,  2.60s/it] 39%|███▉      | 25/64 [00:53<01:35,  2.46s/it] 41%|████      | 26/64 [00:55<01:30,  2.39s/it] 42%|████▏     | 27/64 [00:57<01:25,  2.30s/it] 44%|████▍     | 28/64 [00:59<01:17,  2.16s/it] 45%|████▌     | 29/64 [01:01<01:11,  2.05s/it] 47%|████▋     | 30/64 [01:03<01:15,  2.22s/it] 48%|████▊     | 31/64 [01:05<01:14,  2.24s/it] 50%|█████     | 32/64 [01:07<01:08,  2.13s/it] 52%|█████▏    | 33/64 [01:09<01:01,  1.97s/it] 53%|█████▎    | 34/64 [01:11<00:57,  1.92s/it] 55%|█████▍    | 35/64 [01:14<01:07,  2.32s/it] 56%|█████▋    | 36/64 [01:16<01:02,  2.24s/it] 58%|█████▊    | 37/64 [01:18<00:56,  2.08s/it] 59%|█████▉    | 38/64 [01:19<00:50,  1.95s/it] 61%|██████    | 39/64 [01:21<00:49,  1.98s/it] 62%|██████▎   | 40/64 [01:23<00:44,  1.87s/it] 64%|██████▍   | 41/64 [01:24<00:38,  1.66s/it] 66%|██████▌   | 42/64 [01:26<00:34,  1.57s/it] 67%|██████▋   | 43/64 [01:27<00:35,  1.67s/it] 69%|██████▉   | 44/64 [01:29<00:34,  1.74s/it] 70%|███████   | 45/64 [01:31<00:34,  1.80s/it] 72%|███████▏  | 46/64 [01:33<00:32,  1.80s/it] 73%|███████▎  | 47/64 [01:35<00:30,  1.79s/it] 75%|███████▌  | 48/64 [01:36<00:27,  1.72s/it] 77%|███████▋  | 49/64 [01:38<00:24,  1.64s/it] 78%|███████▊  | 50/64 [01:40<00:23,  1.64s/it] 80%|███████▉  | 51/64 [01:41<00:21,  1.69s/it] 81%|████████▏ | 52/64 [01:43<00:20,  1.69s/it] 83%|████████▎ | 53/64 [01:45<00:19,  1.82s/it] 84%|████████▍ | 54/64 [01:47<00:17,  1.77s/it] 86%|████████▌ | 55/64 [01:49<00:16,  1.80s/it] 88%|████████▊ | 56/64 [01:50<00:13,  1.68s/it] 89%|████████▉ | 57/64 [01:52<00:11,  1.66s/it] 91%|█████████ | 58/64 [01:53<00:09,  1.62s/it] 92%|█████████▏| 59/64 [01:55<00:08,  1.66s/it] 94%|█████████▍| 60/64 [01:57<00:07,  1.84s/it] 95%|█████████▌| 61/64 [01:59<00:05,  1.84s/it] 97%|█████████▋| 62/64 [02:01<00:03,  1.77s/it] 98%|█████████▊| 63/64 [02:02<00:01,  1.76s/it]100%|██████████| 64/64 [02:04<00:00,  1.60s/it]100%|██████████| 64/64 [02:04<00:00,  1.94s/it]

--- 4. Calculating metrics ---
BLEU Score: 13.41
chrF++ Score: 52.37

--- 5. Machine Translation (MT) predictions successfully saved to: ./inflection/zulu_large_MT.txt ---

COMET not installed. Skipping. Install with: pip install unbabel-comet
