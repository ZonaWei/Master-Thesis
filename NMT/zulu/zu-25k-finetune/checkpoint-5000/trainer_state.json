{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.19904,
  "eval_steps": 5000,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032,
      "grad_norm": 0.3410780727863312,
      "learning_rate": 0.00019874600127959053,
      "loss": 3.465,
      "step": 50
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.32998716831207275,
      "learning_rate": 0.00019746641074856047,
      "loss": 2.9329,
      "step": 100
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.27936792373657227,
      "learning_rate": 0.00019618682021753042,
      "loss": 2.7959,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.3373732268810272,
      "learning_rate": 0.00019490722968650034,
      "loss": 2.7763,
      "step": 200
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3131316900253296,
      "learning_rate": 0.00019362763915547026,
      "loss": 2.6996,
      "step": 250
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.36049848794937134,
      "learning_rate": 0.00019234804862444018,
      "loss": 2.7322,
      "step": 300
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.2877313792705536,
      "learning_rate": 0.00019106845809341012,
      "loss": 2.7606,
      "step": 350
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.3393981456756592,
      "learning_rate": 0.00018978886756238007,
      "loss": 2.7545,
      "step": 400
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.35380682349205017,
      "learning_rate": 0.00018850927703134996,
      "loss": 2.7253,
      "step": 450
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.36578869819641113,
      "learning_rate": 0.0001872296865003199,
      "loss": 2.8138,
      "step": 500
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.3273063600063324,
      "learning_rate": 0.00018595009596928983,
      "loss": 2.7146,
      "step": 550
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.31683167815208435,
      "learning_rate": 0.00018467050543825977,
      "loss": 2.666,
      "step": 600
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.33186984062194824,
      "learning_rate": 0.0001833909149072297,
      "loss": 2.7524,
      "step": 650
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.3262530565261841,
      "learning_rate": 0.0001821113243761996,
      "loss": 2.7268,
      "step": 700
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3084923326969147,
      "learning_rate": 0.00018083173384516956,
      "loss": 2.7062,
      "step": 750
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.33649933338165283,
      "learning_rate": 0.00017955214331413948,
      "loss": 2.7148,
      "step": 800
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.2890840768814087,
      "learning_rate": 0.00017827255278310942,
      "loss": 2.7817,
      "step": 850
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.33760732412338257,
      "learning_rate": 0.00017699296225207934,
      "loss": 2.7796,
      "step": 900
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.28520405292510986,
      "learning_rate": 0.00017571337172104926,
      "loss": 2.7084,
      "step": 950
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3413291275501251,
      "learning_rate": 0.0001744337811900192,
      "loss": 2.726,
      "step": 1000
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.32036060094833374,
      "learning_rate": 0.00017315419065898913,
      "loss": 2.6639,
      "step": 1050
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.3035920560359955,
      "learning_rate": 0.00017187460012795907,
      "loss": 2.7091,
      "step": 1100
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.3141402006149292,
      "learning_rate": 0.000170595009596929,
      "loss": 2.7092,
      "step": 1150
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.31484150886535645,
      "learning_rate": 0.0001693154190658989,
      "loss": 2.7014,
      "step": 1200
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.31437885761260986,
      "learning_rate": 0.00016803582853486886,
      "loss": 2.6938,
      "step": 1250
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.27689415216445923,
      "learning_rate": 0.00016675623800383878,
      "loss": 2.7385,
      "step": 1300
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.3537401854991913,
      "learning_rate": 0.0001654766474728087,
      "loss": 2.8366,
      "step": 1350
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.3028022348880768,
      "learning_rate": 0.00016419705694177864,
      "loss": 2.7417,
      "step": 1400
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.3027086555957794,
      "learning_rate": 0.00016291746641074856,
      "loss": 2.7258,
      "step": 1450
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3054271340370178,
      "learning_rate": 0.0001616378758797185,
      "loss": 2.73,
      "step": 1500
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.29700493812561035,
      "learning_rate": 0.00016035828534868843,
      "loss": 2.7798,
      "step": 1550
    },
    {
      "epoch": 1.02368,
      "grad_norm": 0.32518208026885986,
      "learning_rate": 0.00015907869481765835,
      "loss": 2.651,
      "step": 1600
    },
    {
      "epoch": 1.05568,
      "grad_norm": 0.28582581877708435,
      "learning_rate": 0.0001577991042866283,
      "loss": 2.7399,
      "step": 1650
    },
    {
      "epoch": 1.08768,
      "grad_norm": 0.30652520060539246,
      "learning_rate": 0.00015651951375559821,
      "loss": 2.662,
      "step": 1700
    },
    {
      "epoch": 1.11968,
      "grad_norm": 0.330824613571167,
      "learning_rate": 0.00015523992322456816,
      "loss": 2.6871,
      "step": 1750
    },
    {
      "epoch": 1.15168,
      "grad_norm": 0.40537789463996887,
      "learning_rate": 0.00015396033269353808,
      "loss": 2.6598,
      "step": 1800
    },
    {
      "epoch": 1.18368,
      "grad_norm": 0.3265346884727478,
      "learning_rate": 0.000152680742162508,
      "loss": 2.6398,
      "step": 1850
    },
    {
      "epoch": 1.21568,
      "grad_norm": 0.300487756729126,
      "learning_rate": 0.00015140115163147795,
      "loss": 2.6798,
      "step": 1900
    },
    {
      "epoch": 1.24768,
      "grad_norm": 0.33103615045547485,
      "learning_rate": 0.00015012156110044786,
      "loss": 2.7533,
      "step": 1950
    },
    {
      "epoch": 1.27968,
      "grad_norm": 0.35764026641845703,
      "learning_rate": 0.0001488419705694178,
      "loss": 2.6363,
      "step": 2000
    },
    {
      "epoch": 1.31168,
      "grad_norm": 0.34897106885910034,
      "learning_rate": 0.0001475623800383877,
      "loss": 2.6931,
      "step": 2050
    },
    {
      "epoch": 1.34368,
      "grad_norm": 0.3818601965904236,
      "learning_rate": 0.00014628278950735765,
      "loss": 2.7126,
      "step": 2100
    },
    {
      "epoch": 1.37568,
      "grad_norm": 0.3603038787841797,
      "learning_rate": 0.0001450031989763276,
      "loss": 2.6257,
      "step": 2150
    },
    {
      "epoch": 1.40768,
      "grad_norm": 0.29404571652412415,
      "learning_rate": 0.00014372360844529752,
      "loss": 2.6476,
      "step": 2200
    },
    {
      "epoch": 1.43968,
      "grad_norm": 0.3022482097148895,
      "learning_rate": 0.00014244401791426743,
      "loss": 2.6815,
      "step": 2250
    },
    {
      "epoch": 1.47168,
      "grad_norm": 0.35029473900794983,
      "learning_rate": 0.00014116442738323735,
      "loss": 2.6927,
      "step": 2300
    },
    {
      "epoch": 1.5036800000000001,
      "grad_norm": 0.3157918453216553,
      "learning_rate": 0.0001398848368522073,
      "loss": 2.8378,
      "step": 2350
    },
    {
      "epoch": 1.5356800000000002,
      "grad_norm": 0.39454612135887146,
      "learning_rate": 0.00013860524632117725,
      "loss": 2.7157,
      "step": 2400
    },
    {
      "epoch": 1.56768,
      "grad_norm": 0.32988807559013367,
      "learning_rate": 0.00013732565579014717,
      "loss": 2.7955,
      "step": 2450
    },
    {
      "epoch": 1.59968,
      "grad_norm": 0.3852485716342926,
      "learning_rate": 0.00013604606525911708,
      "loss": 2.6804,
      "step": 2500
    },
    {
      "epoch": 1.63168,
      "grad_norm": 0.47138673067092896,
      "learning_rate": 0.000134766474728087,
      "loss": 2.7498,
      "step": 2550
    },
    {
      "epoch": 1.66368,
      "grad_norm": 0.34403684735298157,
      "learning_rate": 0.00013348688419705695,
      "loss": 2.6978,
      "step": 2600
    },
    {
      "epoch": 1.6956799999999999,
      "grad_norm": 0.38165420293807983,
      "learning_rate": 0.0001322072936660269,
      "loss": 2.7476,
      "step": 2650
    },
    {
      "epoch": 1.7276799999999999,
      "grad_norm": 0.38020625710487366,
      "learning_rate": 0.00013092770313499682,
      "loss": 2.7258,
      "step": 2700
    },
    {
      "epoch": 1.75968,
      "grad_norm": 0.3719028830528259,
      "learning_rate": 0.00012964811260396674,
      "loss": 2.7409,
      "step": 2750
    },
    {
      "epoch": 1.79168,
      "grad_norm": 0.32403406500816345,
      "learning_rate": 0.00012836852207293665,
      "loss": 2.701,
      "step": 2800
    },
    {
      "epoch": 1.82368,
      "grad_norm": 0.3562627136707306,
      "learning_rate": 0.0001270889315419066,
      "loss": 2.7102,
      "step": 2850
    },
    {
      "epoch": 1.85568,
      "grad_norm": 0.33457398414611816,
      "learning_rate": 0.00012580934101087655,
      "loss": 2.7041,
      "step": 2900
    },
    {
      "epoch": 1.88768,
      "grad_norm": 0.33127307891845703,
      "learning_rate": 0.00012452975047984644,
      "loss": 2.74,
      "step": 2950
    },
    {
      "epoch": 1.91968,
      "grad_norm": 0.36532631516456604,
      "learning_rate": 0.00012325015994881639,
      "loss": 2.7566,
      "step": 3000
    },
    {
      "epoch": 1.95168,
      "grad_norm": 0.4302850663661957,
      "learning_rate": 0.0001219705694177863,
      "loss": 2.7996,
      "step": 3050
    },
    {
      "epoch": 1.98368,
      "grad_norm": 0.3560482859611511,
      "learning_rate": 0.00012069097888675625,
      "loss": 2.7085,
      "step": 3100
    },
    {
      "epoch": 2.01536,
      "grad_norm": 0.4099937975406647,
      "learning_rate": 0.00011941138835572618,
      "loss": 2.6269,
      "step": 3150
    },
    {
      "epoch": 2.04736,
      "grad_norm": 0.4196159541606903,
      "learning_rate": 0.0001181317978246961,
      "loss": 2.6683,
      "step": 3200
    },
    {
      "epoch": 2.07936,
      "grad_norm": 0.352337509393692,
      "learning_rate": 0.00011685220729366604,
      "loss": 2.6267,
      "step": 3250
    },
    {
      "epoch": 2.11136,
      "grad_norm": 0.3963507115840912,
      "learning_rate": 0.00011557261676263596,
      "loss": 2.7544,
      "step": 3300
    },
    {
      "epoch": 2.14336,
      "grad_norm": 0.38373857736587524,
      "learning_rate": 0.00011429302623160589,
      "loss": 2.6862,
      "step": 3350
    },
    {
      "epoch": 2.17536,
      "grad_norm": 0.36501461267471313,
      "learning_rate": 0.00011301343570057583,
      "loss": 2.6554,
      "step": 3400
    },
    {
      "epoch": 2.20736,
      "grad_norm": 0.40349844098091125,
      "learning_rate": 0.00011173384516954575,
      "loss": 2.7033,
      "step": 3450
    },
    {
      "epoch": 2.23936,
      "grad_norm": 0.37415844202041626,
      "learning_rate": 0.00011045425463851569,
      "loss": 2.723,
      "step": 3500
    },
    {
      "epoch": 2.27136,
      "grad_norm": 0.4034935235977173,
      "learning_rate": 0.0001091746641074856,
      "loss": 2.6442,
      "step": 3550
    },
    {
      "epoch": 2.30336,
      "grad_norm": 0.370340496301651,
      "learning_rate": 0.00010789507357645554,
      "loss": 2.6364,
      "step": 3600
    },
    {
      "epoch": 2.33536,
      "grad_norm": 0.3914045989513397,
      "learning_rate": 0.00010661548304542549,
      "loss": 2.7088,
      "step": 3650
    },
    {
      "epoch": 2.36736,
      "grad_norm": 0.42731890082359314,
      "learning_rate": 0.00010533589251439539,
      "loss": 2.6807,
      "step": 3700
    },
    {
      "epoch": 2.39936,
      "grad_norm": 0.37237289547920227,
      "learning_rate": 0.00010405630198336534,
      "loss": 2.7903,
      "step": 3750
    },
    {
      "epoch": 2.43136,
      "grad_norm": 0.39754438400268555,
      "learning_rate": 0.00010277671145233526,
      "loss": 2.6691,
      "step": 3800
    },
    {
      "epoch": 2.4633599999999998,
      "grad_norm": 0.3897267282009125,
      "learning_rate": 0.00010149712092130519,
      "loss": 2.7234,
      "step": 3850
    },
    {
      "epoch": 2.49536,
      "grad_norm": 0.3740396201610565,
      "learning_rate": 0.00010021753039027512,
      "loss": 2.7161,
      "step": 3900
    },
    {
      "epoch": 2.52736,
      "grad_norm": 0.5007175803184509,
      "learning_rate": 9.893793985924504e-05,
      "loss": 2.7962,
      "step": 3950
    },
    {
      "epoch": 2.55936,
      "grad_norm": 0.39458388090133667,
      "learning_rate": 9.765834932821497e-05,
      "loss": 2.611,
      "step": 4000
    },
    {
      "epoch": 2.59136,
      "grad_norm": 0.38346433639526367,
      "learning_rate": 9.637875879718491e-05,
      "loss": 2.725,
      "step": 4050
    },
    {
      "epoch": 2.62336,
      "grad_norm": 0.42750468850135803,
      "learning_rate": 9.509916826615484e-05,
      "loss": 2.6684,
      "step": 4100
    },
    {
      "epoch": 2.65536,
      "grad_norm": 0.33360233902931213,
      "learning_rate": 9.381957773512476e-05,
      "loss": 2.6275,
      "step": 4150
    },
    {
      "epoch": 2.68736,
      "grad_norm": 0.41004738211631775,
      "learning_rate": 9.253998720409469e-05,
      "loss": 2.6938,
      "step": 4200
    },
    {
      "epoch": 2.71936,
      "grad_norm": 0.3379938006401062,
      "learning_rate": 9.126039667306462e-05,
      "loss": 2.6838,
      "step": 4250
    },
    {
      "epoch": 2.75136,
      "grad_norm": 0.3432033956050873,
      "learning_rate": 8.998080614203456e-05,
      "loss": 2.5757,
      "step": 4300
    },
    {
      "epoch": 2.78336,
      "grad_norm": 0.37371936440467834,
      "learning_rate": 8.870121561100449e-05,
      "loss": 2.7223,
      "step": 4350
    },
    {
      "epoch": 2.81536,
      "grad_norm": 0.3587186336517334,
      "learning_rate": 8.742162507997441e-05,
      "loss": 2.6239,
      "step": 4400
    },
    {
      "epoch": 2.84736,
      "grad_norm": 0.3911079168319702,
      "learning_rate": 8.614203454894434e-05,
      "loss": 2.7252,
      "step": 4450
    },
    {
      "epoch": 2.87936,
      "grad_norm": 0.37351691722869873,
      "learning_rate": 8.486244401791426e-05,
      "loss": 2.6077,
      "step": 4500
    },
    {
      "epoch": 2.91136,
      "grad_norm": 0.406730592250824,
      "learning_rate": 8.358285348688421e-05,
      "loss": 2.7162,
      "step": 4550
    },
    {
      "epoch": 2.94336,
      "grad_norm": 0.4688709080219269,
      "learning_rate": 8.230326295585413e-05,
      "loss": 2.7726,
      "step": 4600
    },
    {
      "epoch": 2.9753600000000002,
      "grad_norm": 0.39735400676727295,
      "learning_rate": 8.102367242482406e-05,
      "loss": 2.6269,
      "step": 4650
    },
    {
      "epoch": 3.00704,
      "grad_norm": 0.4272473156452179,
      "learning_rate": 7.974408189379399e-05,
      "loss": 2.7655,
      "step": 4700
    },
    {
      "epoch": 3.03904,
      "grad_norm": 0.43111342191696167,
      "learning_rate": 7.846449136276391e-05,
      "loss": 2.6275,
      "step": 4750
    },
    {
      "epoch": 3.07104,
      "grad_norm": 0.3877999782562256,
      "learning_rate": 7.718490083173386e-05,
      "loss": 2.6524,
      "step": 4800
    },
    {
      "epoch": 3.10304,
      "grad_norm": 0.4424433410167694,
      "learning_rate": 7.590531030070378e-05,
      "loss": 2.751,
      "step": 4850
    },
    {
      "epoch": 3.13504,
      "grad_norm": 0.42772966623306274,
      "learning_rate": 7.462571976967371e-05,
      "loss": 2.6346,
      "step": 4900
    },
    {
      "epoch": 3.16704,
      "grad_norm": 0.4436522126197815,
      "learning_rate": 7.334612923864363e-05,
      "loss": 2.6784,
      "step": 4950
    },
    {
      "epoch": 3.19904,
      "grad_norm": 0.3783988058567047,
      "learning_rate": 7.206653870761356e-05,
      "loss": 2.6606,
      "step": 5000
    }
  ],
  "logging_steps": 50,
  "max_steps": 7815,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3527374688747520.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
