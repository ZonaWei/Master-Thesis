{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 5000,
  "global_step": 3910,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.064,
      "grad_norm": 0.11147937178611755,
      "learning_rate": 0.00019749360613810743,
      "loss": 2.2747,
      "step": 50
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.09579777717590332,
      "learning_rate": 0.00019493606138107418,
      "loss": 2.0366,
      "step": 100
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.10549144446849823,
      "learning_rate": 0.00019237851662404093,
      "loss": 1.9883,
      "step": 150
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.10340750217437744,
      "learning_rate": 0.00018982097186700768,
      "loss": 1.9367,
      "step": 200
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09563589841127396,
      "learning_rate": 0.00018726342710997444,
      "loss": 1.934,
      "step": 250
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.10339606553316116,
      "learning_rate": 0.0001847058823529412,
      "loss": 1.9496,
      "step": 300
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.11089428514242172,
      "learning_rate": 0.00018214833759590794,
      "loss": 1.9536,
      "step": 350
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.10590318590402603,
      "learning_rate": 0.0001795907928388747,
      "loss": 1.932,
      "step": 400
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.11454106867313385,
      "learning_rate": 0.00017703324808184142,
      "loss": 1.9389,
      "step": 450
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.10395358502864838,
      "learning_rate": 0.00017447570332480817,
      "loss": 1.9297,
      "step": 500
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.10216931253671646,
      "learning_rate": 0.00017191815856777492,
      "loss": 1.9361,
      "step": 550
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.10325930267572403,
      "learning_rate": 0.00016936061381074167,
      "loss": 1.9327,
      "step": 600
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.11217602342367172,
      "learning_rate": 0.00016680306905370843,
      "loss": 1.9153,
      "step": 650
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.0992496982216835,
      "learning_rate": 0.00016424552429667518,
      "loss": 1.9326,
      "step": 700
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.10708844661712646,
      "learning_rate": 0.00016168797953964193,
      "loss": 1.9089,
      "step": 750
    },
    {
      "epoch": 1.02304,
      "grad_norm": 0.11126124858856201,
      "learning_rate": 0.00015913043478260868,
      "loss": 1.9213,
      "step": 800
    },
    {
      "epoch": 1.08704,
      "grad_norm": 0.11248264461755753,
      "learning_rate": 0.00015657289002557543,
      "loss": 1.9331,
      "step": 850
    },
    {
      "epoch": 1.15104,
      "grad_norm": 0.10524193942546844,
      "learning_rate": 0.00015401534526854219,
      "loss": 1.9478,
      "step": 900
    },
    {
      "epoch": 1.2150400000000001,
      "grad_norm": 0.10624212771654129,
      "learning_rate": 0.00015145780051150894,
      "loss": 1.9341,
      "step": 950
    },
    {
      "epoch": 1.27904,
      "grad_norm": 0.12183979153633118,
      "learning_rate": 0.0001489002557544757,
      "loss": 1.9315,
      "step": 1000
    },
    {
      "epoch": 1.34304,
      "grad_norm": 0.11192169040441513,
      "learning_rate": 0.00014634271099744244,
      "loss": 1.9395,
      "step": 1050
    },
    {
      "epoch": 1.40704,
      "grad_norm": 0.11286350339651108,
      "learning_rate": 0.00014378516624040922,
      "loss": 1.8939,
      "step": 1100
    },
    {
      "epoch": 1.47104,
      "grad_norm": 0.12576356530189514,
      "learning_rate": 0.00014122762148337597,
      "loss": 1.8957,
      "step": 1150
    },
    {
      "epoch": 1.53504,
      "grad_norm": 0.11415431648492813,
      "learning_rate": 0.00013867007672634273,
      "loss": 1.9206,
      "step": 1200
    },
    {
      "epoch": 1.59904,
      "grad_norm": 0.11422053724527359,
      "learning_rate": 0.00013611253196930948,
      "loss": 1.933,
      "step": 1250
    },
    {
      "epoch": 1.66304,
      "grad_norm": 0.11538390815258026,
      "learning_rate": 0.00013355498721227623,
      "loss": 1.9205,
      "step": 1300
    },
    {
      "epoch": 1.7270400000000001,
      "grad_norm": 0.11808259785175323,
      "learning_rate": 0.00013099744245524298,
      "loss": 1.9044,
      "step": 1350
    },
    {
      "epoch": 1.79104,
      "grad_norm": 0.11699411273002625,
      "learning_rate": 0.00012843989769820973,
      "loss": 1.89,
      "step": 1400
    },
    {
      "epoch": 1.85504,
      "grad_norm": 0.10763859748840332,
      "learning_rate": 0.0001258823529411765,
      "loss": 1.9029,
      "step": 1450
    },
    {
      "epoch": 1.9190399999999999,
      "grad_norm": 0.11511848866939545,
      "learning_rate": 0.00012332480818414324,
      "loss": 1.8624,
      "step": 1500
    },
    {
      "epoch": 1.98304,
      "grad_norm": 0.11520296335220337,
      "learning_rate": 0.00012076726342710998,
      "loss": 1.9131,
      "step": 1550
    },
    {
      "epoch": 2.04608,
      "grad_norm": 0.11477696895599365,
      "learning_rate": 0.00011820971867007673,
      "loss": 1.9124,
      "step": 1600
    },
    {
      "epoch": 2.11008,
      "grad_norm": 0.12557050585746765,
      "learning_rate": 0.00011565217391304348,
      "loss": 1.886,
      "step": 1650
    },
    {
      "epoch": 2.17408,
      "grad_norm": 0.12938077747821808,
      "learning_rate": 0.00011309462915601023,
      "loss": 1.9093,
      "step": 1700
    },
    {
      "epoch": 2.23808,
      "grad_norm": 0.11614618450403214,
      "learning_rate": 0.00011053708439897699,
      "loss": 1.9119,
      "step": 1750
    },
    {
      "epoch": 2.30208,
      "grad_norm": 0.11582084745168686,
      "learning_rate": 0.00010797953964194374,
      "loss": 1.9043,
      "step": 1800
    },
    {
      "epoch": 2.36608,
      "grad_norm": 0.1222582757472992,
      "learning_rate": 0.00010542199488491049,
      "loss": 1.9358,
      "step": 1850
    },
    {
      "epoch": 2.4300800000000002,
      "grad_norm": 0.12679463624954224,
      "learning_rate": 0.00010286445012787724,
      "loss": 1.892,
      "step": 1900
    },
    {
      "epoch": 2.49408,
      "grad_norm": 0.12930460274219513,
      "learning_rate": 0.000100306905370844,
      "loss": 1.9068,
      "step": 1950
    },
    {
      "epoch": 2.55808,
      "grad_norm": 0.12777620553970337,
      "learning_rate": 9.774936061381075e-05,
      "loss": 1.9099,
      "step": 2000
    },
    {
      "epoch": 2.62208,
      "grad_norm": 0.12199345976114273,
      "learning_rate": 9.51918158567775e-05,
      "loss": 1.8884,
      "step": 2050
    },
    {
      "epoch": 2.68608,
      "grad_norm": 0.1314815878868103,
      "learning_rate": 9.263427109974425e-05,
      "loss": 1.9214,
      "step": 2100
    },
    {
      "epoch": 2.75008,
      "grad_norm": 0.12914583086967468,
      "learning_rate": 9.0076726342711e-05,
      "loss": 1.915,
      "step": 2150
    },
    {
      "epoch": 2.81408,
      "grad_norm": 0.12203297764062881,
      "learning_rate": 8.751918158567776e-05,
      "loss": 1.9181,
      "step": 2200
    },
    {
      "epoch": 2.8780799999999997,
      "grad_norm": 0.13253894448280334,
      "learning_rate": 8.496163682864451e-05,
      "loss": 1.9148,
      "step": 2250
    },
    {
      "epoch": 2.94208,
      "grad_norm": 0.13240289688110352,
      "learning_rate": 8.240409207161126e-05,
      "loss": 1.9033,
      "step": 2300
    },
    {
      "epoch": 3.00512,
      "grad_norm": 0.12856219708919525,
      "learning_rate": 7.984654731457801e-05,
      "loss": 1.8879,
      "step": 2350
    },
    {
      "epoch": 3.06912,
      "grad_norm": 0.15234827995300293,
      "learning_rate": 7.728900255754476e-05,
      "loss": 1.8938,
      "step": 2400
    },
    {
      "epoch": 3.13312,
      "grad_norm": 0.11678475141525269,
      "learning_rate": 7.473145780051152e-05,
      "loss": 1.9044,
      "step": 2450
    },
    {
      "epoch": 3.19712,
      "grad_norm": 0.12016316503286362,
      "learning_rate": 7.217391304347827e-05,
      "loss": 1.8941,
      "step": 2500
    },
    {
      "epoch": 3.26112,
      "grad_norm": 0.12837930023670197,
      "learning_rate": 6.9616368286445e-05,
      "loss": 1.912,
      "step": 2550
    },
    {
      "epoch": 3.32512,
      "grad_norm": 0.13073424994945526,
      "learning_rate": 6.705882352941176e-05,
      "loss": 1.9191,
      "step": 2600
    },
    {
      "epoch": 3.38912,
      "grad_norm": 0.13363850116729736,
      "learning_rate": 6.450127877237851e-05,
      "loss": 1.9,
      "step": 2650
    },
    {
      "epoch": 3.45312,
      "grad_norm": 0.12842918932437897,
      "learning_rate": 6.194373401534526e-05,
      "loss": 1.884,
      "step": 2700
    },
    {
      "epoch": 3.5171200000000002,
      "grad_norm": 0.12973719835281372,
      "learning_rate": 5.938618925831202e-05,
      "loss": 1.91,
      "step": 2750
    },
    {
      "epoch": 3.58112,
      "grad_norm": 0.1234329491853714,
      "learning_rate": 5.6828644501278774e-05,
      "loss": 1.9054,
      "step": 2800
    },
    {
      "epoch": 3.64512,
      "grad_norm": 0.1422797441482544,
      "learning_rate": 5.4271099744245526e-05,
      "loss": 1.913,
      "step": 2850
    },
    {
      "epoch": 3.70912,
      "grad_norm": 0.12516307830810547,
      "learning_rate": 5.171355498721228e-05,
      "loss": 1.8997,
      "step": 2900
    },
    {
      "epoch": 3.77312,
      "grad_norm": 0.12699398398399353,
      "learning_rate": 4.915601023017903e-05,
      "loss": 1.8953,
      "step": 2950
    },
    {
      "epoch": 3.83712,
      "grad_norm": 0.14474402368068695,
      "learning_rate": 4.659846547314578e-05,
      "loss": 1.9276,
      "step": 3000
    },
    {
      "epoch": 3.90112,
      "grad_norm": 0.12335899472236633,
      "learning_rate": 4.4040920716112535e-05,
      "loss": 1.9115,
      "step": 3050
    },
    {
      "epoch": 3.9651199999999998,
      "grad_norm": 0.1324973702430725,
      "learning_rate": 4.148337595907929e-05,
      "loss": 1.8789,
      "step": 3100
    },
    {
      "epoch": 4.02816,
      "grad_norm": 0.12726855278015137,
      "learning_rate": 3.892583120204604e-05,
      "loss": 1.8975,
      "step": 3150
    },
    {
      "epoch": 4.09216,
      "grad_norm": 0.13179267942905426,
      "learning_rate": 3.636828644501279e-05,
      "loss": 1.9122,
      "step": 3200
    },
    {
      "epoch": 4.15616,
      "grad_norm": 0.1316443234682083,
      "learning_rate": 3.3810741687979543e-05,
      "loss": 1.9173,
      "step": 3250
    },
    {
      "epoch": 4.22016,
      "grad_norm": 0.13629257678985596,
      "learning_rate": 3.1253196930946296e-05,
      "loss": 1.8815,
      "step": 3300
    },
    {
      "epoch": 4.28416,
      "grad_norm": 0.13065479695796967,
      "learning_rate": 2.8695652173913044e-05,
      "loss": 1.9008,
      "step": 3350
    },
    {
      "epoch": 4.34816,
      "grad_norm": 0.13813945651054382,
      "learning_rate": 2.6138107416879796e-05,
      "loss": 1.9018,
      "step": 3400
    },
    {
      "epoch": 4.41216,
      "grad_norm": 0.12809692323207855,
      "learning_rate": 2.358056265984655e-05,
      "loss": 1.8849,
      "step": 3450
    },
    {
      "epoch": 4.47616,
      "grad_norm": 0.13017593324184418,
      "learning_rate": 2.10230179028133e-05,
      "loss": 1.9112,
      "step": 3500
    },
    {
      "epoch": 4.54016,
      "grad_norm": 0.13299432396888733,
      "learning_rate": 1.8465473145780053e-05,
      "loss": 1.8676,
      "step": 3550
    },
    {
      "epoch": 4.60416,
      "grad_norm": 0.12070100009441376,
      "learning_rate": 1.5907928388746805e-05,
      "loss": 1.903,
      "step": 3600
    },
    {
      "epoch": 4.66816,
      "grad_norm": 0.13396945595741272,
      "learning_rate": 1.3350383631713556e-05,
      "loss": 1.9051,
      "step": 3650
    },
    {
      "epoch": 4.73216,
      "grad_norm": 0.13650798797607422,
      "learning_rate": 1.0792838874680308e-05,
      "loss": 1.9188,
      "step": 3700
    },
    {
      "epoch": 4.79616,
      "grad_norm": 0.1356525719165802,
      "learning_rate": 8.23529411764706e-06,
      "loss": 1.9032,
      "step": 3750
    },
    {
      "epoch": 4.8601600000000005,
      "grad_norm": 0.1406508833169937,
      "learning_rate": 5.677749360613811e-06,
      "loss": 1.8861,
      "step": 3800
    },
    {
      "epoch": 4.92416,
      "grad_norm": 0.12612749636173248,
      "learning_rate": 3.120204603580563e-06,
      "loss": 1.899,
      "step": 3850
    },
    {
      "epoch": 4.98816,
      "grad_norm": 0.1387844681739807,
      "learning_rate": 5.626598465473146e-07,
      "loss": 1.8735,
      "step": 3900
    }
  ],
  "logging_steps": 50,
  "max_steps": 3910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.630251949011763e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
