{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 5000,
  "global_step": 31250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 0.22342045605182648,
      "learning_rate": 0.0001996864,
      "loss": 2.5323,
      "step": 50
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.26832738518714905,
      "learning_rate": 0.00019936640000000003,
      "loss": 2.3158,
      "step": 100
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.44410279393196106,
      "learning_rate": 0.0001990464,
      "loss": 2.2135,
      "step": 150
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.31851693987846375,
      "learning_rate": 0.0001987264,
      "loss": 2.2211,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.290513813495636,
      "learning_rate": 0.0001984064,
      "loss": 2.2004,
      "step": 250
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.29753178358078003,
      "learning_rate": 0.00019808640000000001,
      "loss": 2.1971,
      "step": 300
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.2809513807296753,
      "learning_rate": 0.00019776640000000002,
      "loss": 2.1759,
      "step": 350
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.2588876485824585,
      "learning_rate": 0.00019744640000000002,
      "loss": 2.2019,
      "step": 400
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.2634355425834656,
      "learning_rate": 0.0001971264,
      "loss": 2.131,
      "step": 450
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.29230567812919617,
      "learning_rate": 0.0001968064,
      "loss": 2.1115,
      "step": 500
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.31353870034217834,
      "learning_rate": 0.0001964864,
      "loss": 2.1435,
      "step": 550
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.2982780635356903,
      "learning_rate": 0.0001961664,
      "loss": 2.2053,
      "step": 600
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.2835768759250641,
      "learning_rate": 0.0001958464,
      "loss": 2.1518,
      "step": 650
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.3492989242076874,
      "learning_rate": 0.00019552639999999999,
      "loss": 2.2019,
      "step": 700
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3002175986766815,
      "learning_rate": 0.00019520640000000002,
      "loss": 2.1574,
      "step": 750
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.2540690004825592,
      "learning_rate": 0.0001948864,
      "loss": 2.1735,
      "step": 800
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.3994276225566864,
      "learning_rate": 0.00019456640000000002,
      "loss": 2.1164,
      "step": 850
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.26519209146499634,
      "learning_rate": 0.0001942464,
      "loss": 2.2249,
      "step": 900
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.2822549641132355,
      "learning_rate": 0.00019392640000000003,
      "loss": 2.1813,
      "step": 950
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.27309882640838623,
      "learning_rate": 0.0001936064,
      "loss": 2.151,
      "step": 1000
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.32716915011405945,
      "learning_rate": 0.0001932864,
      "loss": 2.1927,
      "step": 1050
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.2877933084964752,
      "learning_rate": 0.0001929664,
      "loss": 2.1836,
      "step": 1100
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.26641854643821716,
      "learning_rate": 0.0001926464,
      "loss": 2.1696,
      "step": 1150
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.341478168964386,
      "learning_rate": 0.00019232640000000002,
      "loss": 2.1744,
      "step": 1200
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.24213559925556183,
      "learning_rate": 0.00019200640000000002,
      "loss": 2.185,
      "step": 1250
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.28359782695770264,
      "learning_rate": 0.0001916864,
      "loss": 2.1773,
      "step": 1300
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.2859967350959778,
      "learning_rate": 0.00019136640000000003,
      "loss": 2.1954,
      "step": 1350
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.28929415345191956,
      "learning_rate": 0.0001910464,
      "loss": 2.2029,
      "step": 1400
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.29819610714912415,
      "learning_rate": 0.0001907264,
      "loss": 2.1269,
      "step": 1450
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.267450213432312,
      "learning_rate": 0.0001904064,
      "loss": 2.1836,
      "step": 1500
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.30772164463996887,
      "learning_rate": 0.0001900864,
      "loss": 2.203,
      "step": 1550
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.24890822172164917,
      "learning_rate": 0.0001897664,
      "loss": 2.1579,
      "step": 1600
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.27074214816093445,
      "learning_rate": 0.0001894464,
      "loss": 2.1307,
      "step": 1650
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.316410094499588,
      "learning_rate": 0.00018912640000000002,
      "loss": 2.2282,
      "step": 1700
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.34959203004837036,
      "learning_rate": 0.0001888064,
      "loss": 2.1674,
      "step": 1750
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.29725566506385803,
      "learning_rate": 0.00018848640000000003,
      "loss": 2.1618,
      "step": 1800
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.2961842715740204,
      "learning_rate": 0.0001881664,
      "loss": 2.1654,
      "step": 1850
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.2669754922389984,
      "learning_rate": 0.0001878464,
      "loss": 2.1988,
      "step": 1900
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.30666789412498474,
      "learning_rate": 0.0001875264,
      "loss": 2.1692,
      "step": 1950
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.25937315821647644,
      "learning_rate": 0.0001872064,
      "loss": 2.1087,
      "step": 2000
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.3033800721168518,
      "learning_rate": 0.00018688640000000001,
      "loss": 2.1513,
      "step": 2050
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.27394720911979675,
      "learning_rate": 0.00018656640000000002,
      "loss": 2.2042,
      "step": 2100
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.2705451250076294,
      "learning_rate": 0.0001862464,
      "loss": 2.1572,
      "step": 2150
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.31367120146751404,
      "learning_rate": 0.00018592640000000002,
      "loss": 2.2609,
      "step": 2200
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.299331933259964,
      "learning_rate": 0.0001856064,
      "loss": 2.1496,
      "step": 2250
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.27058735489845276,
      "learning_rate": 0.00018528640000000003,
      "loss": 2.1684,
      "step": 2300
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.33465057611465454,
      "learning_rate": 0.0001849664,
      "loss": 2.1718,
      "step": 2350
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.276947557926178,
      "learning_rate": 0.0001846464,
      "loss": 2.1436,
      "step": 2400
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.28616753220558167,
      "learning_rate": 0.0001843264,
      "loss": 2.1594,
      "step": 2450
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3158637285232544,
      "learning_rate": 0.00018400640000000001,
      "loss": 2.1548,
      "step": 2500
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.31244924664497375,
      "learning_rate": 0.00018368640000000002,
      "loss": 2.1912,
      "step": 2550
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.2536545991897583,
      "learning_rate": 0.0001833664,
      "loss": 2.1475,
      "step": 2600
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.29921939969062805,
      "learning_rate": 0.00018304640000000002,
      "loss": 2.1857,
      "step": 2650
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.2896721065044403,
      "learning_rate": 0.0001827264,
      "loss": 2.2071,
      "step": 2700
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3173871636390686,
      "learning_rate": 0.0001824064,
      "loss": 2.1445,
      "step": 2750
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.3368052840232849,
      "learning_rate": 0.0001820864,
      "loss": 2.1519,
      "step": 2800
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.2593226134777069,
      "learning_rate": 0.0001817664,
      "loss": 2.2023,
      "step": 2850
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.2404656708240509,
      "learning_rate": 0.0001814464,
      "loss": 2.1461,
      "step": 2900
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.2736555337905884,
      "learning_rate": 0.00018112640000000001,
      "loss": 2.1685,
      "step": 2950
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3125213384628296,
      "learning_rate": 0.0001808064,
      "loss": 2.1924,
      "step": 3000
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.32459551095962524,
      "learning_rate": 0.00018048640000000002,
      "loss": 2.1978,
      "step": 3050
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.26782384514808655,
      "learning_rate": 0.0001801664,
      "loss": 2.1802,
      "step": 3100
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.2711884081363678,
      "learning_rate": 0.00017984640000000003,
      "loss": 2.2099,
      "step": 3150
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.2741006314754486,
      "learning_rate": 0.0001795264,
      "loss": 2.1265,
      "step": 3200
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.32124245166778564,
      "learning_rate": 0.0001792064,
      "loss": 2.1619,
      "step": 3250
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.2435016930103302,
      "learning_rate": 0.0001788864,
      "loss": 2.1101,
      "step": 3300
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.2862839996814728,
      "learning_rate": 0.0001785664,
      "loss": 2.1761,
      "step": 3350
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.3418269455432892,
      "learning_rate": 0.00017824640000000002,
      "loss": 2.15,
      "step": 3400
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.2985434830188751,
      "learning_rate": 0.0001779264,
      "loss": 2.1598,
      "step": 3450
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2573705315589905,
      "learning_rate": 0.00017760640000000002,
      "loss": 2.1402,
      "step": 3500
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.2894502282142639,
      "learning_rate": 0.0001772864,
      "loss": 2.1667,
      "step": 3550
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.27920031547546387,
      "learning_rate": 0.0001769664,
      "loss": 2.1244,
      "step": 3600
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.2680422365665436,
      "learning_rate": 0.0001766464,
      "loss": 2.1345,
      "step": 3650
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.27714160084724426,
      "learning_rate": 0.0001763264,
      "loss": 2.2587,
      "step": 3700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.27190402150154114,
      "learning_rate": 0.0001760064,
      "loss": 2.2226,
      "step": 3750
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.2551979124546051,
      "learning_rate": 0.0001756864,
      "loss": 2.1317,
      "step": 3800
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.26535600423812866,
      "learning_rate": 0.0001753664,
      "loss": 2.2152,
      "step": 3850
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.2791357934474945,
      "learning_rate": 0.00017504640000000002,
      "loss": 2.1721,
      "step": 3900
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.30252522230148315,
      "learning_rate": 0.0001747264,
      "loss": 2.1696,
      "step": 3950
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.22992847859859467,
      "learning_rate": 0.00017440640000000002,
      "loss": 2.1968,
      "step": 4000
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.25437605381011963,
      "learning_rate": 0.0001740864,
      "loss": 2.1715,
      "step": 4050
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.27308276295661926,
      "learning_rate": 0.00017376640000000003,
      "loss": 2.028,
      "step": 4100
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.2660285532474518,
      "learning_rate": 0.0001734464,
      "loss": 2.1585,
      "step": 4150
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.2726149260997772,
      "learning_rate": 0.0001731264,
      "loss": 2.1834,
      "step": 4200
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.2741108238697052,
      "learning_rate": 0.0001728064,
      "loss": 2.1728,
      "step": 4250
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.2791237235069275,
      "learning_rate": 0.00017248640000000002,
      "loss": 2.1496,
      "step": 4300
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.27508804202079773,
      "learning_rate": 0.00017216640000000002,
      "loss": 2.1732,
      "step": 4350
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.3043767213821411,
      "learning_rate": 0.0001718464,
      "loss": 2.1923,
      "step": 4400
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.25830984115600586,
      "learning_rate": 0.0001715264,
      "loss": 2.1162,
      "step": 4450
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.27559694647789,
      "learning_rate": 0.0001712064,
      "loss": 2.1705,
      "step": 4500
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.24032434821128845,
      "learning_rate": 0.0001708864,
      "loss": 2.151,
      "step": 4550
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.24617081880569458,
      "learning_rate": 0.0001705664,
      "loss": 2.1611,
      "step": 4600
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.27578723430633545,
      "learning_rate": 0.0001702464,
      "loss": 2.1164,
      "step": 4650
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.3093271255493164,
      "learning_rate": 0.0001699264,
      "loss": 2.1529,
      "step": 4700
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3081338405609131,
      "learning_rate": 0.00016960640000000002,
      "loss": 2.1247,
      "step": 4750
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.2969409227371216,
      "learning_rate": 0.0001692864,
      "loss": 2.1632,
      "step": 4800
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.28913548588752747,
      "learning_rate": 0.00016896640000000002,
      "loss": 2.1813,
      "step": 4850
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.26167619228363037,
      "learning_rate": 0.0001686464,
      "loss": 2.2091,
      "step": 4900
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.2594471871852875,
      "learning_rate": 0.00016832640000000003,
      "loss": 2.0936,
      "step": 4950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2659921646118164,
      "learning_rate": 0.0001680064,
      "loss": 2.1262,
      "step": 5000
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.25506260991096497,
      "learning_rate": 0.0001676864,
      "loss": 2.1561,
      "step": 5050
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.23441319167613983,
      "learning_rate": 0.0001673664,
      "loss": 2.1422,
      "step": 5100
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.2625035345554352,
      "learning_rate": 0.00016704640000000001,
      "loss": 2.126,
      "step": 5150
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.33828291296958923,
      "learning_rate": 0.00016672640000000002,
      "loss": 2.1777,
      "step": 5200
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.2646392583847046,
      "learning_rate": 0.00016640640000000002,
      "loss": 2.1761,
      "step": 5250
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.30095401406288147,
      "learning_rate": 0.0001660864,
      "loss": 2.1771,
      "step": 5300
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.3170646131038666,
      "learning_rate": 0.0001657664,
      "loss": 2.1835,
      "step": 5350
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.27139148116111755,
      "learning_rate": 0.0001654464,
      "loss": 2.1882,
      "step": 5400
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.24615788459777832,
      "learning_rate": 0.0001651264,
      "loss": 2.1833,
      "step": 5450
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.26342737674713135,
      "learning_rate": 0.0001648064,
      "loss": 2.1603,
      "step": 5500
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.2922862768173218,
      "learning_rate": 0.0001644864,
      "loss": 2.1948,
      "step": 5550
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.27575480937957764,
      "learning_rate": 0.00016416640000000001,
      "loss": 2.1891,
      "step": 5600
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.3011765778064728,
      "learning_rate": 0.0001638464,
      "loss": 2.2087,
      "step": 5650
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.2896926999092102,
      "learning_rate": 0.00016352640000000002,
      "loss": 2.1567,
      "step": 5700
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.2923579812049866,
      "learning_rate": 0.0001632064,
      "loss": 2.126,
      "step": 5750
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.29801544547080994,
      "learning_rate": 0.00016288640000000003,
      "loss": 2.1135,
      "step": 5800
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.28398194909095764,
      "learning_rate": 0.0001625664,
      "loss": 2.1958,
      "step": 5850
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.27701127529144287,
      "learning_rate": 0.0001622464,
      "loss": 2.1139,
      "step": 5900
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.25434571504592896,
      "learning_rate": 0.0001619264,
      "loss": 2.1799,
      "step": 5950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2715506851673126,
      "learning_rate": 0.0001616064,
      "loss": 2.13,
      "step": 6000
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.28190234303474426,
      "learning_rate": 0.00016128640000000001,
      "loss": 2.1686,
      "step": 6050
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.35604918003082275,
      "learning_rate": 0.00016096640000000002,
      "loss": 2.1579,
      "step": 6100
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.23643574118614197,
      "learning_rate": 0.0001606464,
      "loss": 2.1445,
      "step": 6150
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.2938578128814697,
      "learning_rate": 0.0001603264,
      "loss": 2.1832,
      "step": 6200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.25854748487472534,
      "learning_rate": 0.0001600064,
      "loss": 2.1205,
      "step": 6250
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.26243850588798523,
      "learning_rate": 0.0001596864,
      "loss": 2.1371,
      "step": 6300
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.2937067449092865,
      "learning_rate": 0.0001593664,
      "loss": 2.137,
      "step": 6350
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.3800131380558014,
      "learning_rate": 0.0001590464,
      "loss": 2.2293,
      "step": 6400
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.30620527267456055,
      "learning_rate": 0.0001587264,
      "loss": 2.1353,
      "step": 6450
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.30665338039398193,
      "learning_rate": 0.0001584064,
      "loss": 2.1336,
      "step": 6500
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.3273150324821472,
      "learning_rate": 0.00015808640000000002,
      "loss": 2.165,
      "step": 6550
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.3071894645690918,
      "learning_rate": 0.0001577664,
      "loss": 2.1771,
      "step": 6600
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.2784873843193054,
      "learning_rate": 0.00015744640000000002,
      "loss": 2.1141,
      "step": 6650
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.3032359480857849,
      "learning_rate": 0.0001571264,
      "loss": 2.1588,
      "step": 6700
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.31613582372665405,
      "learning_rate": 0.0001568064,
      "loss": 2.1882,
      "step": 6750
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.2758912742137909,
      "learning_rate": 0.0001564864,
      "loss": 2.1406,
      "step": 6800
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.2835202217102051,
      "learning_rate": 0.0001561664,
      "loss": 2.1377,
      "step": 6850
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.2937420606613159,
      "learning_rate": 0.0001558464,
      "loss": 2.2092,
      "step": 6900
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.27823492884635925,
      "learning_rate": 0.00015552640000000002,
      "loss": 2.2025,
      "step": 6950
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.28877171874046326,
      "learning_rate": 0.00015520640000000002,
      "loss": 2.2047,
      "step": 7000
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.28430235385894775,
      "learning_rate": 0.00015488640000000002,
      "loss": 2.2302,
      "step": 7050
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.2918946444988251,
      "learning_rate": 0.0001545664,
      "loss": 2.0871,
      "step": 7100
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.29429781436920166,
      "learning_rate": 0.0001542464,
      "loss": 2.1707,
      "step": 7150
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.26245468854904175,
      "learning_rate": 0.0001539264,
      "loss": 2.1485,
      "step": 7200
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.28363046050071716,
      "learning_rate": 0.0001536064,
      "loss": 2.1114,
      "step": 7250
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.2844071686267853,
      "learning_rate": 0.0001532864,
      "loss": 2.1341,
      "step": 7300
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.28347164392471313,
      "learning_rate": 0.00015296639999999999,
      "loss": 2.1518,
      "step": 7350
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.2651500999927521,
      "learning_rate": 0.00015264640000000002,
      "loss": 2.1664,
      "step": 7400
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.25834500789642334,
      "learning_rate": 0.0001523264,
      "loss": 2.1032,
      "step": 7450
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.2899426221847534,
      "learning_rate": 0.00015200640000000002,
      "loss": 2.2108,
      "step": 7500
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.3050593137741089,
      "learning_rate": 0.0001516864,
      "loss": 2.1394,
      "step": 7550
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.29862597584724426,
      "learning_rate": 0.0001513664,
      "loss": 2.1313,
      "step": 7600
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.2699107527732849,
      "learning_rate": 0.0001510464,
      "loss": 2.1219,
      "step": 7650
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.30178993940353394,
      "learning_rate": 0.0001507264,
      "loss": 2.1107,
      "step": 7700
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.3182710111141205,
      "learning_rate": 0.0001504064,
      "loss": 2.1102,
      "step": 7750
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.2737072706222534,
      "learning_rate": 0.00015008640000000001,
      "loss": 2.1144,
      "step": 7800
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.2709621489048004,
      "learning_rate": 0.00014976640000000002,
      "loss": 2.1788,
      "step": 7850
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.307539701461792,
      "learning_rate": 0.00014944640000000002,
      "loss": 2.1623,
      "step": 7900
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.2900056540966034,
      "learning_rate": 0.0001491264,
      "loss": 2.0883,
      "step": 7950
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.33849307894706726,
      "learning_rate": 0.00014880640000000003,
      "loss": 2.1411,
      "step": 8000
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.3245646357536316,
      "learning_rate": 0.0001484864,
      "loss": 2.1029,
      "step": 8050
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.33846765756607056,
      "learning_rate": 0.0001481664,
      "loss": 2.1499,
      "step": 8100
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.32160452008247375,
      "learning_rate": 0.0001478464,
      "loss": 2.0917,
      "step": 8150
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.3026050925254822,
      "learning_rate": 0.0001475264,
      "loss": 2.1482,
      "step": 8200
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.2864041328430176,
      "learning_rate": 0.00014720640000000001,
      "loss": 2.181,
      "step": 8250
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.276187539100647,
      "learning_rate": 0.0001468864,
      "loss": 2.1379,
      "step": 8300
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.2922895550727844,
      "learning_rate": 0.00014656640000000002,
      "loss": 2.195,
      "step": 8350
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.24524147808551788,
      "learning_rate": 0.0001462464,
      "loss": 2.1411,
      "step": 8400
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.29120156168937683,
      "learning_rate": 0.0001459264,
      "loss": 2.0782,
      "step": 8450
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.25571662187576294,
      "learning_rate": 0.0001456064,
      "loss": 2.0958,
      "step": 8500
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.2937825918197632,
      "learning_rate": 0.0001452864,
      "loss": 2.0775,
      "step": 8550
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.3243781328201294,
      "learning_rate": 0.0001449664,
      "loss": 2.1319,
      "step": 8600
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.28071966767311096,
      "learning_rate": 0.0001446464,
      "loss": 2.1293,
      "step": 8650
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.29247376322746277,
      "learning_rate": 0.00014432640000000001,
      "loss": 2.1455,
      "step": 8700
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.3218124210834503,
      "learning_rate": 0.00014400640000000002,
      "loss": 2.1254,
      "step": 8750
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.3315124809741974,
      "learning_rate": 0.0001436864,
      "loss": 2.1777,
      "step": 8800
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.29886677861213684,
      "learning_rate": 0.00014336640000000002,
      "loss": 2.1158,
      "step": 8850
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.2827821969985962,
      "learning_rate": 0.0001430464,
      "loss": 2.1352,
      "step": 8900
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.2759505808353424,
      "learning_rate": 0.0001427264,
      "loss": 2.0934,
      "step": 8950
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.28651225566864014,
      "learning_rate": 0.0001424064,
      "loss": 2.1459,
      "step": 9000
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.3463030755519867,
      "learning_rate": 0.0001420864,
      "loss": 2.1222,
      "step": 9050
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.2956671118736267,
      "learning_rate": 0.0001417664,
      "loss": 2.0954,
      "step": 9100
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.2836800813674927,
      "learning_rate": 0.0001414464,
      "loss": 2.2441,
      "step": 9150
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.34490880370140076,
      "learning_rate": 0.00014112640000000002,
      "loss": 2.1887,
      "step": 9200
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.2705356180667877,
      "learning_rate": 0.0001408064,
      "loss": 2.1189,
      "step": 9250
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.25754764676094055,
      "learning_rate": 0.0001404864,
      "loss": 2.1781,
      "step": 9300
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.29734545946121216,
      "learning_rate": 0.0001401664,
      "loss": 2.1393,
      "step": 9350
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.3104797899723053,
      "learning_rate": 0.0001398464,
      "loss": 2.1313,
      "step": 9400
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.35952478647232056,
      "learning_rate": 0.0001395264,
      "loss": 2.1564,
      "step": 9450
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.3398975431919098,
      "learning_rate": 0.0001392064,
      "loss": 2.1631,
      "step": 9500
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.29062971472740173,
      "learning_rate": 0.0001388864,
      "loss": 2.1442,
      "step": 9550
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.32172128558158875,
      "learning_rate": 0.00013856640000000002,
      "loss": 2.1804,
      "step": 9600
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.28814300894737244,
      "learning_rate": 0.0001382464,
      "loss": 2.1646,
      "step": 9650
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.3174609839916229,
      "learning_rate": 0.00013792640000000002,
      "loss": 2.1386,
      "step": 9700
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.2753920257091522,
      "learning_rate": 0.0001376064,
      "loss": 2.1233,
      "step": 9750
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.36433637142181396,
      "learning_rate": 0.00013728640000000003,
      "loss": 2.0778,
      "step": 9800
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.34372425079345703,
      "learning_rate": 0.0001369664,
      "loss": 2.1616,
      "step": 9850
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.32494449615478516,
      "learning_rate": 0.0001366464,
      "loss": 2.1636,
      "step": 9900
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.3606272339820862,
      "learning_rate": 0.0001363264,
      "loss": 2.1458,
      "step": 9950
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2711452543735504,
      "learning_rate": 0.0001360064,
      "loss": 2.1065,
      "step": 10000
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.27246731519699097,
      "learning_rate": 0.00013568640000000002,
      "loss": 2.1507,
      "step": 10050
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.35562026500701904,
      "learning_rate": 0.0001353664,
      "loss": 2.1385,
      "step": 10100
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.25381627678871155,
      "learning_rate": 0.00013504640000000002,
      "loss": 2.1762,
      "step": 10150
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.2581089437007904,
      "learning_rate": 0.0001347264,
      "loss": 2.1338,
      "step": 10200
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.31895676255226135,
      "learning_rate": 0.0001344064,
      "loss": 2.1293,
      "step": 10250
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.30687540769577026,
      "learning_rate": 0.0001340864,
      "loss": 2.1609,
      "step": 10300
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.27734506130218506,
      "learning_rate": 0.0001337664,
      "loss": 2.1726,
      "step": 10350
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.32890239357948303,
      "learning_rate": 0.0001334464,
      "loss": 2.1145,
      "step": 10400
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.28114134073257446,
      "learning_rate": 0.0001331264,
      "loss": 2.1069,
      "step": 10450
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.3058178424835205,
      "learning_rate": 0.0001328064,
      "loss": 2.1436,
      "step": 10500
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.3204050362110138,
      "learning_rate": 0.00013248640000000002,
      "loss": 2.1646,
      "step": 10550
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.30516448616981506,
      "learning_rate": 0.0001321664,
      "loss": 2.178,
      "step": 10600
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.2434246689081192,
      "learning_rate": 0.00013184640000000003,
      "loss": 2.194,
      "step": 10650
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.2788180708885193,
      "learning_rate": 0.0001315264,
      "loss": 2.172,
      "step": 10700
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.28848105669021606,
      "learning_rate": 0.0001312064,
      "loss": 2.1273,
      "step": 10750
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.2907389998435974,
      "learning_rate": 0.0001308864,
      "loss": 2.1587,
      "step": 10800
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.33800211548805237,
      "learning_rate": 0.0001305664,
      "loss": 2.1419,
      "step": 10850
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.28375107049942017,
      "learning_rate": 0.00013024640000000001,
      "loss": 2.1525,
      "step": 10900
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.30025023221969604,
      "learning_rate": 0.00012992640000000002,
      "loss": 2.1185,
      "step": 10950
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.3451016843318939,
      "learning_rate": 0.00012960640000000002,
      "loss": 2.1641,
      "step": 11000
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.34726572036743164,
      "learning_rate": 0.0001292864,
      "loss": 2.0956,
      "step": 11050
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.2783952057361603,
      "learning_rate": 0.0001289664,
      "loss": 2.1283,
      "step": 11100
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.2971976101398468,
      "learning_rate": 0.0001286464,
      "loss": 2.1397,
      "step": 11150
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.2539474070072174,
      "learning_rate": 0.0001283264,
      "loss": 2.0977,
      "step": 11200
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2839888632297516,
      "learning_rate": 0.0001280064,
      "loss": 2.1333,
      "step": 11250
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.28041961789131165,
      "learning_rate": 0.0001276864,
      "loss": 2.1637,
      "step": 11300
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.2874488830566406,
      "learning_rate": 0.0001273664,
      "loss": 2.0995,
      "step": 11350
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.2915460467338562,
      "learning_rate": 0.00012704640000000002,
      "loss": 2.1447,
      "step": 11400
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.28375813364982605,
      "learning_rate": 0.0001267264,
      "loss": 2.1599,
      "step": 11450
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.3145386576652527,
      "learning_rate": 0.00012640640000000002,
      "loss": 2.1347,
      "step": 11500
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.3390218913555145,
      "learning_rate": 0.0001260864,
      "loss": 2.1449,
      "step": 11550
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.3121265769004822,
      "learning_rate": 0.0001257664,
      "loss": 2.1587,
      "step": 11600
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.28285443782806396,
      "learning_rate": 0.0001254464,
      "loss": 2.1875,
      "step": 11650
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.3443599045276642,
      "learning_rate": 0.0001251264,
      "loss": 2.1316,
      "step": 11700
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.27607694268226624,
      "learning_rate": 0.0001248064,
      "loss": 2.1092,
      "step": 11750
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.25877845287323,
      "learning_rate": 0.00012448640000000001,
      "loss": 2.1402,
      "step": 11800
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.30644890666007996,
      "learning_rate": 0.00012416640000000002,
      "loss": 2.1618,
      "step": 11850
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.3086867034435272,
      "learning_rate": 0.0001238464,
      "loss": 2.1399,
      "step": 11900
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.29110297560691833,
      "learning_rate": 0.0001235264,
      "loss": 2.1577,
      "step": 11950
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.3069535791873932,
      "learning_rate": 0.0001232064,
      "loss": 2.081,
      "step": 12000
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.30682238936424255,
      "learning_rate": 0.0001228864,
      "loss": 2.172,
      "step": 12050
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.30773046612739563,
      "learning_rate": 0.0001225664,
      "loss": 2.1798,
      "step": 12100
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.34666672348976135,
      "learning_rate": 0.0001222464,
      "loss": 2.1362,
      "step": 12150
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.7000110149383545,
      "learning_rate": 0.0001219264,
      "loss": 2.1894,
      "step": 12200
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.34230056405067444,
      "learning_rate": 0.00012160640000000002,
      "loss": 2.1974,
      "step": 12250
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.49764925241470337,
      "learning_rate": 0.0001212864,
      "loss": 2.1103,
      "step": 12300
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.28101247549057007,
      "learning_rate": 0.00012096640000000001,
      "loss": 2.2193,
      "step": 12350
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.28413745760917664,
      "learning_rate": 0.0001206464,
      "loss": 2.0987,
      "step": 12400
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.30299124121665955,
      "learning_rate": 0.0001203264,
      "loss": 2.1253,
      "step": 12450
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.3032952845096588,
      "learning_rate": 0.0001200064,
      "loss": 2.1438,
      "step": 12500
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.29727885127067566,
      "learning_rate": 0.00011968639999999999,
      "loss": 2.1117,
      "step": 12550
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.2970718741416931,
      "learning_rate": 0.00011936640000000001,
      "loss": 2.0796,
      "step": 12600
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.31434160470962524,
      "learning_rate": 0.0001190464,
      "loss": 2.1288,
      "step": 12650
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.3292873799800873,
      "learning_rate": 0.00011872640000000002,
      "loss": 2.195,
      "step": 12700
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.29573458433151245,
      "learning_rate": 0.0001184064,
      "loss": 2.083,
      "step": 12750
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.27630650997161865,
      "learning_rate": 0.0001180864,
      "loss": 2.1235,
      "step": 12800
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.3112276494503021,
      "learning_rate": 0.00011776640000000001,
      "loss": 2.0908,
      "step": 12850
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.2864954471588135,
      "learning_rate": 0.0001174464,
      "loss": 2.1099,
      "step": 12900
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.2906849682331085,
      "learning_rate": 0.00011712640000000002,
      "loss": 2.0931,
      "step": 12950
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.26448655128479004,
      "learning_rate": 0.00011680640000000001,
      "loss": 2.1079,
      "step": 13000
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.2807212471961975,
      "learning_rate": 0.0001164864,
      "loss": 2.1289,
      "step": 13050
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.28122368454933167,
      "learning_rate": 0.00011616640000000001,
      "loss": 2.1126,
      "step": 13100
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.29804757237434387,
      "learning_rate": 0.0001158464,
      "loss": 2.1202,
      "step": 13150
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.2931637167930603,
      "learning_rate": 0.0001155264,
      "loss": 2.1657,
      "step": 13200
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.28333789110183716,
      "learning_rate": 0.00011520640000000001,
      "loss": 2.1226,
      "step": 13250
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.2796957194805145,
      "learning_rate": 0.00011488640000000001,
      "loss": 2.1542,
      "step": 13300
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.26752999424934387,
      "learning_rate": 0.0001145664,
      "loss": 2.1665,
      "step": 13350
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.3182758688926697,
      "learning_rate": 0.0001142464,
      "loss": 2.0732,
      "step": 13400
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.37791624665260315,
      "learning_rate": 0.00011392640000000001,
      "loss": 2.1352,
      "step": 13450
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.29808375239372253,
      "learning_rate": 0.0001136064,
      "loss": 2.1406,
      "step": 13500
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.25471431016921997,
      "learning_rate": 0.00011328640000000001,
      "loss": 2.1406,
      "step": 13550
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.30587658286094666,
      "learning_rate": 0.0001129664,
      "loss": 2.1726,
      "step": 13600
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.2993007302284241,
      "learning_rate": 0.00011264639999999999,
      "loss": 2.0772,
      "step": 13650
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.3134128451347351,
      "learning_rate": 0.00011232640000000001,
      "loss": 2.1323,
      "step": 13700
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.38202059268951416,
      "learning_rate": 0.0001120064,
      "loss": 2.154,
      "step": 13750
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.3236802816390991,
      "learning_rate": 0.00011168640000000002,
      "loss": 2.1337,
      "step": 13800
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.35332372784614563,
      "learning_rate": 0.0001113664,
      "loss": 2.1391,
      "step": 13850
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.3298048973083496,
      "learning_rate": 0.0001110464,
      "loss": 2.1496,
      "step": 13900
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.35807958245277405,
      "learning_rate": 0.00011072640000000001,
      "loss": 2.091,
      "step": 13950
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.334471195936203,
      "learning_rate": 0.0001104064,
      "loss": 2.1206,
      "step": 14000
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.27737244963645935,
      "learning_rate": 0.00011008640000000002,
      "loss": 2.1378,
      "step": 14050
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.31282755732536316,
      "learning_rate": 0.0001097664,
      "loss": 2.1282,
      "step": 14100
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.3207365572452545,
      "learning_rate": 0.00010944640000000001,
      "loss": 2.1129,
      "step": 14150
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.29714781045913696,
      "learning_rate": 0.00010912640000000001,
      "loss": 2.1144,
      "step": 14200
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.2750338613986969,
      "learning_rate": 0.0001088064,
      "loss": 2.1317,
      "step": 14250
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.32142022252082825,
      "learning_rate": 0.0001084864,
      "loss": 2.1131,
      "step": 14300
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.3303419351577759,
      "learning_rate": 0.0001081664,
      "loss": 2.1232,
      "step": 14350
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.27069318294525146,
      "learning_rate": 0.00010784640000000001,
      "loss": 2.0868,
      "step": 14400
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.3073786497116089,
      "learning_rate": 0.0001075264,
      "loss": 2.1344,
      "step": 14450
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.37379324436187744,
      "learning_rate": 0.00010720639999999999,
      "loss": 2.1617,
      "step": 14500
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.28837454319000244,
      "learning_rate": 0.00010688640000000001,
      "loss": 2.1568,
      "step": 14550
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.3299601972103119,
      "learning_rate": 0.0001065664,
      "loss": 2.1203,
      "step": 14600
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.2930365800857544,
      "learning_rate": 0.00010624640000000001,
      "loss": 2.1536,
      "step": 14650
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.31811559200286865,
      "learning_rate": 0.0001059264,
      "loss": 2.1618,
      "step": 14700
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.2700025141239166,
      "learning_rate": 0.00010560639999999999,
      "loss": 2.1145,
      "step": 14750
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.35185831785202026,
      "learning_rate": 0.00010528640000000001,
      "loss": 2.1549,
      "step": 14800
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.34411299228668213,
      "learning_rate": 0.0001049664,
      "loss": 2.18,
      "step": 14850
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.29161912202835083,
      "learning_rate": 0.00010464640000000002,
      "loss": 2.1713,
      "step": 14900
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.356901615858078,
      "learning_rate": 0.0001043264,
      "loss": 2.1978,
      "step": 14950
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.29208090901374817,
      "learning_rate": 0.00010400640000000002,
      "loss": 2.1218,
      "step": 15000
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.3197191059589386,
      "learning_rate": 0.00010368640000000001,
      "loss": 2.126,
      "step": 15050
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.34034672379493713,
      "learning_rate": 0.0001033664,
      "loss": 2.1686,
      "step": 15100
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.28230080008506775,
      "learning_rate": 0.0001030464,
      "loss": 2.0682,
      "step": 15150
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.36495378613471985,
      "learning_rate": 0.0001027264,
      "loss": 2.1228,
      "step": 15200
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.32544761896133423,
      "learning_rate": 0.00010240640000000001,
      "loss": 2.0973,
      "step": 15250
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.34878721833229065,
      "learning_rate": 0.0001020864,
      "loss": 2.1224,
      "step": 15300
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.3089902997016907,
      "learning_rate": 0.00010176639999999999,
      "loss": 2.1522,
      "step": 15350
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.3191989064216614,
      "learning_rate": 0.0001014464,
      "loss": 2.1086,
      "step": 15400
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.28495052456855774,
      "learning_rate": 0.0001011264,
      "loss": 2.1645,
      "step": 15450
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.3371294438838959,
      "learning_rate": 0.00010080640000000001,
      "loss": 2.1245,
      "step": 15500
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.3395225703716278,
      "learning_rate": 0.0001004864,
      "loss": 2.171,
      "step": 15550
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.3529559075832367,
      "learning_rate": 0.00010016640000000002,
      "loss": 2.1107,
      "step": 15600
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.34189969301223755,
      "learning_rate": 9.984640000000001e-05,
      "loss": 2.0718,
      "step": 15650
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.3343883454799652,
      "learning_rate": 9.952640000000001e-05,
      "loss": 2.1238,
      "step": 15700
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.32315242290496826,
      "learning_rate": 9.92064e-05,
      "loss": 2.106,
      "step": 15750
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.33942949771881104,
      "learning_rate": 9.88864e-05,
      "loss": 2.0871,
      "step": 15800
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.33271652460098267,
      "learning_rate": 9.85664e-05,
      "loss": 2.2445,
      "step": 15850
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.2697279155254364,
      "learning_rate": 9.824640000000001e-05,
      "loss": 2.1214,
      "step": 15900
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.3292543590068817,
      "learning_rate": 9.792640000000001e-05,
      "loss": 2.0964,
      "step": 15950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.291631281375885,
      "learning_rate": 9.760640000000001e-05,
      "loss": 2.1358,
      "step": 16000
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.33726924657821655,
      "learning_rate": 9.72864e-05,
      "loss": 2.2014,
      "step": 16050
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.26096221804618835,
      "learning_rate": 9.696640000000001e-05,
      "loss": 2.1362,
      "step": 16100
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.2757740914821625,
      "learning_rate": 9.664640000000001e-05,
      "loss": 2.0496,
      "step": 16150
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.3265877664089203,
      "learning_rate": 9.63264e-05,
      "loss": 2.1199,
      "step": 16200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3454741835594177,
      "learning_rate": 9.60064e-05,
      "loss": 2.2058,
      "step": 16250
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.33077558875083923,
      "learning_rate": 9.56864e-05,
      "loss": 2.1565,
      "step": 16300
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.3171279728412628,
      "learning_rate": 9.53664e-05,
      "loss": 2.1429,
      "step": 16350
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.30793794989585876,
      "learning_rate": 9.50464e-05,
      "loss": 2.0962,
      "step": 16400
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.3127615749835968,
      "learning_rate": 9.47264e-05,
      "loss": 2.0922,
      "step": 16450
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.3395426571369171,
      "learning_rate": 9.44064e-05,
      "loss": 2.1276,
      "step": 16500
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.3178265690803528,
      "learning_rate": 9.408640000000001e-05,
      "loss": 2.1566,
      "step": 16550
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.3073139786720276,
      "learning_rate": 9.376640000000001e-05,
      "loss": 2.1172,
      "step": 16600
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.38834092020988464,
      "learning_rate": 9.34464e-05,
      "loss": 2.0349,
      "step": 16650
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.3538602888584137,
      "learning_rate": 9.31264e-05,
      "loss": 2.099,
      "step": 16700
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.31228917837142944,
      "learning_rate": 9.28064e-05,
      "loss": 2.1258,
      "step": 16750
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.2783753573894501,
      "learning_rate": 9.248640000000001e-05,
      "loss": 2.1166,
      "step": 16800
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.26494982838630676,
      "learning_rate": 9.216640000000001e-05,
      "loss": 2.145,
      "step": 16850
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.3068816065788269,
      "learning_rate": 9.18464e-05,
      "loss": 2.1628,
      "step": 16900
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.2984355390071869,
      "learning_rate": 9.15264e-05,
      "loss": 2.1865,
      "step": 16950
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.3179747462272644,
      "learning_rate": 9.120640000000001e-05,
      "loss": 2.1561,
      "step": 17000
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.2892109155654907,
      "learning_rate": 9.088640000000001e-05,
      "loss": 2.1639,
      "step": 17050
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.34126752614974976,
      "learning_rate": 9.05664e-05,
      "loss": 2.1662,
      "step": 17100
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.3487970530986786,
      "learning_rate": 9.02464e-05,
      "loss": 2.1306,
      "step": 17150
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.327499121427536,
      "learning_rate": 8.99264e-05,
      "loss": 2.1926,
      "step": 17200
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.30717024207115173,
      "learning_rate": 8.96064e-05,
      "loss": 2.1539,
      "step": 17250
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.3995973765850067,
      "learning_rate": 8.92864e-05,
      "loss": 2.1039,
      "step": 17300
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.2972348928451538,
      "learning_rate": 8.89664e-05,
      "loss": 2.1383,
      "step": 17350
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.28387391567230225,
      "learning_rate": 8.86464e-05,
      "loss": 2.1342,
      "step": 17400
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.3097488582134247,
      "learning_rate": 8.832640000000001e-05,
      "loss": 2.1053,
      "step": 17450
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.2903100252151489,
      "learning_rate": 8.80064e-05,
      "loss": 2.1024,
      "step": 17500
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.3051838278770447,
      "learning_rate": 8.76864e-05,
      "loss": 2.1129,
      "step": 17550
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.3442156910896301,
      "learning_rate": 8.73664e-05,
      "loss": 2.084,
      "step": 17600
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.3058243989944458,
      "learning_rate": 8.704640000000001e-05,
      "loss": 2.1348,
      "step": 17650
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.3176199793815613,
      "learning_rate": 8.672640000000001e-05,
      "loss": 2.1027,
      "step": 17700
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.3548816740512848,
      "learning_rate": 8.640640000000001e-05,
      "loss": 2.1789,
      "step": 17750
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.29946139454841614,
      "learning_rate": 8.60864e-05,
      "loss": 2.1729,
      "step": 17800
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.3008052110671997,
      "learning_rate": 8.57664e-05,
      "loss": 2.1414,
      "step": 17850
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.3568324148654938,
      "learning_rate": 8.544640000000001e-05,
      "loss": 2.103,
      "step": 17900
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.2995741665363312,
      "learning_rate": 8.512640000000001e-05,
      "loss": 2.1801,
      "step": 17950
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.31824439764022827,
      "learning_rate": 8.48064e-05,
      "loss": 2.1021,
      "step": 18000
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.2844395339488983,
      "learning_rate": 8.44864e-05,
      "loss": 2.1859,
      "step": 18050
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.3127942383289337,
      "learning_rate": 8.41664e-05,
      "loss": 2.1041,
      "step": 18100
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.3019586503505707,
      "learning_rate": 8.38464e-05,
      "loss": 2.1522,
      "step": 18150
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.3211114704608917,
      "learning_rate": 8.35264e-05,
      "loss": 2.1197,
      "step": 18200
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.3410241901874542,
      "learning_rate": 8.32064e-05,
      "loss": 2.1665,
      "step": 18250
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.27680760622024536,
      "learning_rate": 8.28864e-05,
      "loss": 2.1548,
      "step": 18300
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.3135809004306793,
      "learning_rate": 8.25664e-05,
      "loss": 2.1747,
      "step": 18350
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.3894297480583191,
      "learning_rate": 8.22464e-05,
      "loss": 2.1425,
      "step": 18400
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.41103029251098633,
      "learning_rate": 8.19264e-05,
      "loss": 2.0876,
      "step": 18450
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.3623810410499573,
      "learning_rate": 8.16064e-05,
      "loss": 2.1238,
      "step": 18500
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.34660905599594116,
      "learning_rate": 8.128640000000001e-05,
      "loss": 2.0703,
      "step": 18550
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.3582782745361328,
      "learning_rate": 8.096640000000001e-05,
      "loss": 2.0824,
      "step": 18600
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.34762099385261536,
      "learning_rate": 8.06464e-05,
      "loss": 2.1122,
      "step": 18650
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.3317382335662842,
      "learning_rate": 8.03264e-05,
      "loss": 2.1078,
      "step": 18700
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.31477487087249756,
      "learning_rate": 8.000640000000001e-05,
      "loss": 2.1353,
      "step": 18750
    },
    {
      "epoch": 3.008,
      "grad_norm": 0.32929834723472595,
      "learning_rate": 7.968640000000001e-05,
      "loss": 2.1162,
      "step": 18800
    },
    {
      "epoch": 3.016,
      "grad_norm": 0.35894647240638733,
      "learning_rate": 7.936640000000001e-05,
      "loss": 2.1304,
      "step": 18850
    },
    {
      "epoch": 3.024,
      "grad_norm": 0.36441218852996826,
      "learning_rate": 7.90464e-05,
      "loss": 2.1624,
      "step": 18900
    },
    {
      "epoch": 3.032,
      "grad_norm": 0.31230854988098145,
      "learning_rate": 7.87264e-05,
      "loss": 2.1761,
      "step": 18950
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.2827311158180237,
      "learning_rate": 7.840640000000001e-05,
      "loss": 2.1551,
      "step": 19000
    },
    {
      "epoch": 3.048,
      "grad_norm": 0.36455270648002625,
      "learning_rate": 7.80864e-05,
      "loss": 2.1654,
      "step": 19050
    },
    {
      "epoch": 3.056,
      "grad_norm": 0.38474878668785095,
      "learning_rate": 7.77664e-05,
      "loss": 2.1406,
      "step": 19100
    },
    {
      "epoch": 3.064,
      "grad_norm": 0.4300770163536072,
      "learning_rate": 7.74464e-05,
      "loss": 2.0931,
      "step": 19150
    },
    {
      "epoch": 3.072,
      "grad_norm": 0.3919259309768677,
      "learning_rate": 7.71264e-05,
      "loss": 2.112,
      "step": 19200
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.3162398338317871,
      "learning_rate": 7.68064e-05,
      "loss": 2.1254,
      "step": 19250
    },
    {
      "epoch": 3.088,
      "grad_norm": 0.32476720213890076,
      "learning_rate": 7.64864e-05,
      "loss": 2.1152,
      "step": 19300
    },
    {
      "epoch": 3.096,
      "grad_norm": 0.33676064014434814,
      "learning_rate": 7.61664e-05,
      "loss": 2.0885,
      "step": 19350
    },
    {
      "epoch": 3.104,
      "grad_norm": 0.3363529145717621,
      "learning_rate": 7.58464e-05,
      "loss": 2.1095,
      "step": 19400
    },
    {
      "epoch": 3.112,
      "grad_norm": 0.2959112823009491,
      "learning_rate": 7.552640000000001e-05,
      "loss": 2.0726,
      "step": 19450
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.3117867708206177,
      "learning_rate": 7.52064e-05,
      "loss": 2.2094,
      "step": 19500
    },
    {
      "epoch": 3.128,
      "grad_norm": 0.35729432106018066,
      "learning_rate": 7.48864e-05,
      "loss": 2.1415,
      "step": 19550
    },
    {
      "epoch": 3.136,
      "grad_norm": 0.3241913616657257,
      "learning_rate": 7.45664e-05,
      "loss": 2.0729,
      "step": 19600
    },
    {
      "epoch": 3.144,
      "grad_norm": 0.2913626432418823,
      "learning_rate": 7.424640000000001e-05,
      "loss": 2.0623,
      "step": 19650
    },
    {
      "epoch": 3.152,
      "grad_norm": 0.3378257155418396,
      "learning_rate": 7.392640000000001e-05,
      "loss": 2.1297,
      "step": 19700
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.3723754286766052,
      "learning_rate": 7.360640000000001e-05,
      "loss": 2.1608,
      "step": 19750
    },
    {
      "epoch": 3.168,
      "grad_norm": 0.2885906994342804,
      "learning_rate": 7.32864e-05,
      "loss": 2.1231,
      "step": 19800
    },
    {
      "epoch": 3.176,
      "grad_norm": 0.289768785238266,
      "learning_rate": 7.29664e-05,
      "loss": 2.1006,
      "step": 19850
    },
    {
      "epoch": 3.184,
      "grad_norm": 0.35355985164642334,
      "learning_rate": 7.264640000000001e-05,
      "loss": 2.0887,
      "step": 19900
    },
    {
      "epoch": 3.192,
      "grad_norm": 0.3173597455024719,
      "learning_rate": 7.23264e-05,
      "loss": 2.0942,
      "step": 19950
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.31238850951194763,
      "learning_rate": 7.20064e-05,
      "loss": 2.1472,
      "step": 20000
    },
    {
      "epoch": 3.208,
      "grad_norm": 0.30691957473754883,
      "learning_rate": 7.168639999999999e-05,
      "loss": 2.1156,
      "step": 20050
    },
    {
      "epoch": 3.216,
      "grad_norm": 0.35300105810165405,
      "learning_rate": 7.13664e-05,
      "loss": 2.1336,
      "step": 20100
    },
    {
      "epoch": 3.224,
      "grad_norm": 0.3551730215549469,
      "learning_rate": 7.10464e-05,
      "loss": 2.1597,
      "step": 20150
    },
    {
      "epoch": 3.232,
      "grad_norm": 0.38700637221336365,
      "learning_rate": 7.07264e-05,
      "loss": 2.0752,
      "step": 20200
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.38214507699012756,
      "learning_rate": 7.04064e-05,
      "loss": 2.1054,
      "step": 20250
    },
    {
      "epoch": 3.248,
      "grad_norm": 0.3125569522380829,
      "learning_rate": 7.008640000000001e-05,
      "loss": 2.1563,
      "step": 20300
    },
    {
      "epoch": 3.2560000000000002,
      "grad_norm": 0.29667550325393677,
      "learning_rate": 6.97664e-05,
      "loss": 2.1515,
      "step": 20350
    },
    {
      "epoch": 3.2640000000000002,
      "grad_norm": 0.33412644267082214,
      "learning_rate": 6.94464e-05,
      "loss": 2.097,
      "step": 20400
    },
    {
      "epoch": 3.2720000000000002,
      "grad_norm": 0.3687650263309479,
      "learning_rate": 6.91264e-05,
      "loss": 2.1247,
      "step": 20450
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.37321895360946655,
      "learning_rate": 6.88064e-05,
      "loss": 2.0625,
      "step": 20500
    },
    {
      "epoch": 3.288,
      "grad_norm": 0.3711153268814087,
      "learning_rate": 6.848640000000001e-05,
      "loss": 2.0641,
      "step": 20550
    },
    {
      "epoch": 3.296,
      "grad_norm": 0.32201820611953735,
      "learning_rate": 6.816640000000001e-05,
      "loss": 2.1017,
      "step": 20600
    },
    {
      "epoch": 3.304,
      "grad_norm": 0.32258936762809753,
      "learning_rate": 6.78464e-05,
      "loss": 2.126,
      "step": 20650
    },
    {
      "epoch": 3.312,
      "grad_norm": 0.35693973302841187,
      "learning_rate": 6.75264e-05,
      "loss": 2.0465,
      "step": 20700
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.3312217891216278,
      "learning_rate": 6.720640000000001e-05,
      "loss": 2.0946,
      "step": 20750
    },
    {
      "epoch": 3.328,
      "grad_norm": 0.36673420667648315,
      "learning_rate": 6.688640000000001e-05,
      "loss": 2.1173,
      "step": 20800
    },
    {
      "epoch": 3.336,
      "grad_norm": 0.3139725625514984,
      "learning_rate": 6.65664e-05,
      "loss": 2.0753,
      "step": 20850
    },
    {
      "epoch": 3.344,
      "grad_norm": 0.3640793561935425,
      "learning_rate": 6.62464e-05,
      "loss": 2.1226,
      "step": 20900
    },
    {
      "epoch": 3.352,
      "grad_norm": 0.3013513386249542,
      "learning_rate": 6.592639999999999e-05,
      "loss": 2.0815,
      "step": 20950
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.33212608098983765,
      "learning_rate": 6.56064e-05,
      "loss": 2.0952,
      "step": 21000
    },
    {
      "epoch": 3.368,
      "grad_norm": 0.36222782731056213,
      "learning_rate": 6.52864e-05,
      "loss": 2.1694,
      "step": 21050
    },
    {
      "epoch": 3.376,
      "grad_norm": 0.34172481298446655,
      "learning_rate": 6.49664e-05,
      "loss": 2.1129,
      "step": 21100
    },
    {
      "epoch": 3.384,
      "grad_norm": 0.3255768120288849,
      "learning_rate": 6.46464e-05,
      "loss": 2.1091,
      "step": 21150
    },
    {
      "epoch": 3.392,
      "grad_norm": 0.3739502429962158,
      "learning_rate": 6.43264e-05,
      "loss": 2.1387,
      "step": 21200
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.3170757591724396,
      "learning_rate": 6.40064e-05,
      "loss": 2.0686,
      "step": 21250
    },
    {
      "epoch": 3.408,
      "grad_norm": 0.311769038438797,
      "learning_rate": 6.36864e-05,
      "loss": 2.1134,
      "step": 21300
    },
    {
      "epoch": 3.416,
      "grad_norm": 0.36419206857681274,
      "learning_rate": 6.33664e-05,
      "loss": 2.1241,
      "step": 21350
    },
    {
      "epoch": 3.424,
      "grad_norm": 0.28921258449554443,
      "learning_rate": 6.30464e-05,
      "loss": 2.136,
      "step": 21400
    },
    {
      "epoch": 3.432,
      "grad_norm": 0.3758513331413269,
      "learning_rate": 6.272640000000001e-05,
      "loss": 2.0944,
      "step": 21450
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.38624849915504456,
      "learning_rate": 6.24064e-05,
      "loss": 2.1264,
      "step": 21500
    },
    {
      "epoch": 3.448,
      "grad_norm": 0.37966710329055786,
      "learning_rate": 6.20864e-05,
      "loss": 2.1372,
      "step": 21550
    },
    {
      "epoch": 3.456,
      "grad_norm": 0.35489508509635925,
      "learning_rate": 6.17664e-05,
      "loss": 2.1007,
      "step": 21600
    },
    {
      "epoch": 3.464,
      "grad_norm": 0.27806586027145386,
      "learning_rate": 6.144640000000001e-05,
      "loss": 2.1754,
      "step": 21650
    },
    {
      "epoch": 3.472,
      "grad_norm": 0.3509363830089569,
      "learning_rate": 6.112640000000001e-05,
      "loss": 2.1345,
      "step": 21700
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.28656327724456787,
      "learning_rate": 6.080640000000001e-05,
      "loss": 2.1292,
      "step": 21750
    },
    {
      "epoch": 3.488,
      "grad_norm": 0.37356993556022644,
      "learning_rate": 6.04864e-05,
      "loss": 2.22,
      "step": 21800
    },
    {
      "epoch": 3.496,
      "grad_norm": 0.3294558525085449,
      "learning_rate": 6.01664e-05,
      "loss": 2.1409,
      "step": 21850
    },
    {
      "epoch": 3.504,
      "grad_norm": 0.32928574085235596,
      "learning_rate": 5.9846400000000004e-05,
      "loss": 2.1081,
      "step": 21900
    },
    {
      "epoch": 3.512,
      "grad_norm": 0.35255154967308044,
      "learning_rate": 5.9526400000000007e-05,
      "loss": 2.1039,
      "step": 21950
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.3211163282394409,
      "learning_rate": 5.920640000000001e-05,
      "loss": 2.1255,
      "step": 22000
    },
    {
      "epoch": 3.528,
      "grad_norm": 0.39248332381248474,
      "learning_rate": 5.8886400000000006e-05,
      "loss": 2.1811,
      "step": 22050
    },
    {
      "epoch": 3.536,
      "grad_norm": 0.30976516008377075,
      "learning_rate": 5.85664e-05,
      "loss": 2.0828,
      "step": 22100
    },
    {
      "epoch": 3.544,
      "grad_norm": 0.2995283007621765,
      "learning_rate": 5.82464e-05,
      "loss": 2.0435,
      "step": 22150
    },
    {
      "epoch": 3.552,
      "grad_norm": 0.32222649455070496,
      "learning_rate": 5.79264e-05,
      "loss": 2.1069,
      "step": 22200
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.3762241303920746,
      "learning_rate": 5.7606400000000005e-05,
      "loss": 2.0921,
      "step": 22250
    },
    {
      "epoch": 3.568,
      "grad_norm": 0.39476823806762695,
      "learning_rate": 5.728640000000001e-05,
      "loss": 2.1076,
      "step": 22300
    },
    {
      "epoch": 3.576,
      "grad_norm": 0.3681609332561493,
      "learning_rate": 5.69664e-05,
      "loss": 2.189,
      "step": 22350
    },
    {
      "epoch": 3.584,
      "grad_norm": 0.333228200674057,
      "learning_rate": 5.66464e-05,
      "loss": 2.1553,
      "step": 22400
    },
    {
      "epoch": 3.592,
      "grad_norm": 0.34703442454338074,
      "learning_rate": 5.63264e-05,
      "loss": 2.0655,
      "step": 22450
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.3082595765590668,
      "learning_rate": 5.6006400000000006e-05,
      "loss": 2.1278,
      "step": 22500
    },
    {
      "epoch": 3.608,
      "grad_norm": 0.3431362807750702,
      "learning_rate": 5.56864e-05,
      "loss": 2.1649,
      "step": 22550
    },
    {
      "epoch": 3.616,
      "grad_norm": 0.38812026381492615,
      "learning_rate": 5.5366400000000006e-05,
      "loss": 2.1777,
      "step": 22600
    },
    {
      "epoch": 3.624,
      "grad_norm": 0.300021231174469,
      "learning_rate": 5.5046399999999995e-05,
      "loss": 2.1518,
      "step": 22650
    },
    {
      "epoch": 3.632,
      "grad_norm": 0.4108889102935791,
      "learning_rate": 5.47264e-05,
      "loss": 2.0472,
      "step": 22700
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.391031950712204,
      "learning_rate": 5.44064e-05,
      "loss": 2.1483,
      "step": 22750
    },
    {
      "epoch": 3.648,
      "grad_norm": 0.3096005618572235,
      "learning_rate": 5.4086400000000004e-05,
      "loss": 2.1026,
      "step": 22800
    },
    {
      "epoch": 3.656,
      "grad_norm": 0.37031251192092896,
      "learning_rate": 5.376640000000001e-05,
      "loss": 2.1733,
      "step": 22850
    },
    {
      "epoch": 3.664,
      "grad_norm": 0.3563629984855652,
      "learning_rate": 5.344640000000001e-05,
      "loss": 2.1162,
      "step": 22900
    },
    {
      "epoch": 3.672,
      "grad_norm": 0.29584142565727234,
      "learning_rate": 5.31264e-05,
      "loss": 2.0948,
      "step": 22950
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.3562059700489044,
      "learning_rate": 5.28064e-05,
      "loss": 2.0748,
      "step": 23000
    },
    {
      "epoch": 3.6879999999999997,
      "grad_norm": 0.36740919947624207,
      "learning_rate": 5.24864e-05,
      "loss": 2.1361,
      "step": 23050
    },
    {
      "epoch": 3.6959999999999997,
      "grad_norm": 0.3872576057910919,
      "learning_rate": 5.21664e-05,
      "loss": 2.1568,
      "step": 23100
    },
    {
      "epoch": 3.7039999999999997,
      "grad_norm": 0.3758851885795593,
      "learning_rate": 5.1846400000000006e-05,
      "loss": 2.1727,
      "step": 23150
    },
    {
      "epoch": 3.7119999999999997,
      "grad_norm": 0.30621641874313354,
      "learning_rate": 5.152640000000001e-05,
      "loss": 2.059,
      "step": 23200
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.34018582105636597,
      "learning_rate": 5.12064e-05,
      "loss": 2.1076,
      "step": 23250
    },
    {
      "epoch": 3.7279999999999998,
      "grad_norm": 0.3858242928981781,
      "learning_rate": 5.08864e-05,
      "loss": 2.1406,
      "step": 23300
    },
    {
      "epoch": 3.7359999999999998,
      "grad_norm": 0.37132295966148376,
      "learning_rate": 5.0566400000000004e-05,
      "loss": 2.0823,
      "step": 23350
    },
    {
      "epoch": 3.7439999999999998,
      "grad_norm": 0.3180895745754242,
      "learning_rate": 5.024640000000001e-05,
      "loss": 2.1601,
      "step": 23400
    },
    {
      "epoch": 3.752,
      "grad_norm": 0.35220131278038025,
      "learning_rate": 4.9926400000000004e-05,
      "loss": 2.0851,
      "step": 23450
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.3164518475532532,
      "learning_rate": 4.96064e-05,
      "loss": 2.1072,
      "step": 23500
    },
    {
      "epoch": 3.768,
      "grad_norm": 0.3144841492176056,
      "learning_rate": 4.92864e-05,
      "loss": 2.0871,
      "step": 23550
    },
    {
      "epoch": 3.776,
      "grad_norm": 0.35232746601104736,
      "learning_rate": 4.89664e-05,
      "loss": 2.124,
      "step": 23600
    },
    {
      "epoch": 3.784,
      "grad_norm": 0.34443438053131104,
      "learning_rate": 4.86464e-05,
      "loss": 2.1106,
      "step": 23650
    },
    {
      "epoch": 3.792,
      "grad_norm": 0.3549395501613617,
      "learning_rate": 4.8326400000000005e-05,
      "loss": 2.1147,
      "step": 23700
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.35637524724006653,
      "learning_rate": 4.80064e-05,
      "loss": 2.1171,
      "step": 23750
    },
    {
      "epoch": 3.808,
      "grad_norm": 0.2988679111003876,
      "learning_rate": 4.7686400000000005e-05,
      "loss": 2.0812,
      "step": 23800
    },
    {
      "epoch": 3.816,
      "grad_norm": 0.29388266801834106,
      "learning_rate": 4.73664e-05,
      "loss": 2.1478,
      "step": 23850
    },
    {
      "epoch": 3.824,
      "grad_norm": 0.36915427446365356,
      "learning_rate": 4.7046400000000004e-05,
      "loss": 2.1278,
      "step": 23900
    },
    {
      "epoch": 3.832,
      "grad_norm": 0.34271082282066345,
      "learning_rate": 4.67264e-05,
      "loss": 2.1191,
      "step": 23950
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.4292522370815277,
      "learning_rate": 4.64064e-05,
      "loss": 2.0911,
      "step": 24000
    },
    {
      "epoch": 3.848,
      "grad_norm": 0.3992026448249817,
      "learning_rate": 4.60864e-05,
      "loss": 2.1195,
      "step": 24050
    },
    {
      "epoch": 3.856,
      "grad_norm": 0.37357354164123535,
      "learning_rate": 4.57664e-05,
      "loss": 2.0873,
      "step": 24100
    },
    {
      "epoch": 3.864,
      "grad_norm": 0.33434057235717773,
      "learning_rate": 4.54464e-05,
      "loss": 2.085,
      "step": 24150
    },
    {
      "epoch": 3.872,
      "grad_norm": 0.34277185797691345,
      "learning_rate": 4.51264e-05,
      "loss": 2.1522,
      "step": 24200
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.34137922525405884,
      "learning_rate": 4.4806400000000005e-05,
      "loss": 2.1475,
      "step": 24250
    },
    {
      "epoch": 3.888,
      "grad_norm": 0.34299951791763306,
      "learning_rate": 4.44864e-05,
      "loss": 2.1692,
      "step": 24300
    },
    {
      "epoch": 3.896,
      "grad_norm": 0.3647526800632477,
      "learning_rate": 4.4166400000000005e-05,
      "loss": 2.1002,
      "step": 24350
    },
    {
      "epoch": 3.904,
      "grad_norm": 0.3469060957431793,
      "learning_rate": 4.38464e-05,
      "loss": 2.0768,
      "step": 24400
    },
    {
      "epoch": 3.912,
      "grad_norm": 0.4041559398174286,
      "learning_rate": 4.35264e-05,
      "loss": 2.1572,
      "step": 24450
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.2973061501979828,
      "learning_rate": 4.32064e-05,
      "loss": 2.1303,
      "step": 24500
    },
    {
      "epoch": 3.928,
      "grad_norm": 0.3786763548851013,
      "learning_rate": 4.28864e-05,
      "loss": 2.1334,
      "step": 24550
    },
    {
      "epoch": 3.936,
      "grad_norm": 0.3552823066711426,
      "learning_rate": 4.25664e-05,
      "loss": 2.1283,
      "step": 24600
    },
    {
      "epoch": 3.944,
      "grad_norm": 0.3780064880847931,
      "learning_rate": 4.22464e-05,
      "loss": 2.101,
      "step": 24650
    },
    {
      "epoch": 3.952,
      "grad_norm": 0.33696725964546204,
      "learning_rate": 4.1926400000000006e-05,
      "loss": 2.0747,
      "step": 24700
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.35583198070526123,
      "learning_rate": 4.16064e-05,
      "loss": 2.1556,
      "step": 24750
    },
    {
      "epoch": 3.968,
      "grad_norm": 0.3416758179664612,
      "learning_rate": 4.1286400000000005e-05,
      "loss": 2.082,
      "step": 24800
    },
    {
      "epoch": 3.976,
      "grad_norm": 0.3584218919277191,
      "learning_rate": 4.09664e-05,
      "loss": 2.169,
      "step": 24850
    },
    {
      "epoch": 3.984,
      "grad_norm": 0.32742518186569214,
      "learning_rate": 4.0646400000000004e-05,
      "loss": 2.1688,
      "step": 24900
    },
    {
      "epoch": 3.992,
      "grad_norm": 0.2981492578983307,
      "learning_rate": 4.03264e-05,
      "loss": 2.147,
      "step": 24950
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3533321022987366,
      "learning_rate": 4.00064e-05,
      "loss": 2.0964,
      "step": 25000
    },
    {
      "epoch": 4.008,
      "grad_norm": 0.3651697039604187,
      "learning_rate": 3.96864e-05,
      "loss": 2.1642,
      "step": 25050
    },
    {
      "epoch": 4.016,
      "grad_norm": 0.37237676978111267,
      "learning_rate": 3.93664e-05,
      "loss": 2.1291,
      "step": 25100
    },
    {
      "epoch": 4.024,
      "grad_norm": 0.3405747413635254,
      "learning_rate": 3.90464e-05,
      "loss": 2.1547,
      "step": 25150
    },
    {
      "epoch": 4.032,
      "grad_norm": 0.2957647144794464,
      "learning_rate": 3.87264e-05,
      "loss": 2.0669,
      "step": 25200
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.4112109839916229,
      "learning_rate": 3.8406400000000006e-05,
      "loss": 2.0852,
      "step": 25250
    },
    {
      "epoch": 4.048,
      "grad_norm": 0.34234103560447693,
      "learning_rate": 3.80864e-05,
      "loss": 2.0773,
      "step": 25300
    },
    {
      "epoch": 4.056,
      "grad_norm": 0.39870110154151917,
      "learning_rate": 3.7766400000000005e-05,
      "loss": 2.0121,
      "step": 25350
    },
    {
      "epoch": 4.064,
      "grad_norm": 0.36921486258506775,
      "learning_rate": 3.74464e-05,
      "loss": 2.112,
      "step": 25400
    },
    {
      "epoch": 4.072,
      "grad_norm": 0.32540783286094666,
      "learning_rate": 3.71264e-05,
      "loss": 2.0506,
      "step": 25450
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.3222948908805847,
      "learning_rate": 3.68064e-05,
      "loss": 2.1097,
      "step": 25500
    },
    {
      "epoch": 4.088,
      "grad_norm": 0.30675145983695984,
      "learning_rate": 3.6486400000000004e-05,
      "loss": 2.0854,
      "step": 25550
    },
    {
      "epoch": 4.096,
      "grad_norm": 0.35517415404319763,
      "learning_rate": 3.61664e-05,
      "loss": 2.1374,
      "step": 25600
    },
    {
      "epoch": 4.104,
      "grad_norm": 0.3600480258464813,
      "learning_rate": 3.58464e-05,
      "loss": 2.1038,
      "step": 25650
    },
    {
      "epoch": 4.112,
      "grad_norm": 0.36297574639320374,
      "learning_rate": 3.5526400000000006e-05,
      "loss": 2.098,
      "step": 25700
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.33576175570487976,
      "learning_rate": 3.52064e-05,
      "loss": 2.1505,
      "step": 25750
    },
    {
      "epoch": 4.128,
      "grad_norm": 0.3324037790298462,
      "learning_rate": 3.4886400000000005e-05,
      "loss": 2.0543,
      "step": 25800
    },
    {
      "epoch": 4.136,
      "grad_norm": 0.40480393171310425,
      "learning_rate": 3.45664e-05,
      "loss": 2.1794,
      "step": 25850
    },
    {
      "epoch": 4.144,
      "grad_norm": 0.3582831621170044,
      "learning_rate": 3.42464e-05,
      "loss": 2.0784,
      "step": 25900
    },
    {
      "epoch": 4.152,
      "grad_norm": 0.36537742614746094,
      "learning_rate": 3.39264e-05,
      "loss": 2.0884,
      "step": 25950
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.3642977476119995,
      "learning_rate": 3.36064e-05,
      "loss": 2.1069,
      "step": 26000
    },
    {
      "epoch": 4.168,
      "grad_norm": 0.31055405735969543,
      "learning_rate": 3.32864e-05,
      "loss": 2.1357,
      "step": 26050
    },
    {
      "epoch": 4.176,
      "grad_norm": 0.3728657066822052,
      "learning_rate": 3.2966400000000003e-05,
      "loss": 2.0998,
      "step": 26100
    },
    {
      "epoch": 4.184,
      "grad_norm": 0.3222571611404419,
      "learning_rate": 3.26464e-05,
      "loss": 2.0627,
      "step": 26150
    },
    {
      "epoch": 4.192,
      "grad_norm": 0.3467704653739929,
      "learning_rate": 3.23264e-05,
      "loss": 2.0656,
      "step": 26200
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.36452820897102356,
      "learning_rate": 3.2006400000000006e-05,
      "loss": 2.1205,
      "step": 26250
    },
    {
      "epoch": 4.208,
      "grad_norm": 0.43832361698150635,
      "learning_rate": 3.16864e-05,
      "loss": 2.0759,
      "step": 26300
    },
    {
      "epoch": 4.216,
      "grad_norm": 0.34963253140449524,
      "learning_rate": 3.13664e-05,
      "loss": 2.1213,
      "step": 26350
    },
    {
      "epoch": 4.224,
      "grad_norm": 0.3388318717479706,
      "learning_rate": 3.10464e-05,
      "loss": 2.1414,
      "step": 26400
    },
    {
      "epoch": 4.232,
      "grad_norm": 0.35933640599250793,
      "learning_rate": 3.07264e-05,
      "loss": 2.1671,
      "step": 26450
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.3568635880947113,
      "learning_rate": 3.04064e-05,
      "loss": 2.1454,
      "step": 26500
    },
    {
      "epoch": 4.248,
      "grad_norm": 0.3871075510978699,
      "learning_rate": 3.0086400000000004e-05,
      "loss": 2.0752,
      "step": 26550
    },
    {
      "epoch": 4.256,
      "grad_norm": 0.3331790864467621,
      "learning_rate": 2.97664e-05,
      "loss": 2.1043,
      "step": 26600
    },
    {
      "epoch": 4.264,
      "grad_norm": 0.34866800904273987,
      "learning_rate": 2.9446400000000003e-05,
      "loss": 2.1261,
      "step": 26650
    },
    {
      "epoch": 4.272,
      "grad_norm": 0.31683287024497986,
      "learning_rate": 2.9126400000000003e-05,
      "loss": 2.0891,
      "step": 26700
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.341696560382843,
      "learning_rate": 2.88064e-05,
      "loss": 2.0728,
      "step": 26750
    },
    {
      "epoch": 4.288,
      "grad_norm": 0.3310927748680115,
      "learning_rate": 2.8486400000000002e-05,
      "loss": 2.0821,
      "step": 26800
    },
    {
      "epoch": 4.296,
      "grad_norm": 0.36527886986732483,
      "learning_rate": 2.8166400000000005e-05,
      "loss": 2.1456,
      "step": 26850
    },
    {
      "epoch": 4.304,
      "grad_norm": 0.3494385778903961,
      "learning_rate": 2.78464e-05,
      "loss": 2.1357,
      "step": 26900
    },
    {
      "epoch": 4.312,
      "grad_norm": 0.3722367286682129,
      "learning_rate": 2.75264e-05,
      "loss": 2.0368,
      "step": 26950
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.3201543688774109,
      "learning_rate": 2.7206399999999998e-05,
      "loss": 2.1096,
      "step": 27000
    },
    {
      "epoch": 4.328,
      "grad_norm": 0.3664453625679016,
      "learning_rate": 2.68864e-05,
      "loss": 2.1007,
      "step": 27050
    },
    {
      "epoch": 4.336,
      "grad_norm": 0.39936181902885437,
      "learning_rate": 2.6566400000000004e-05,
      "loss": 2.0659,
      "step": 27100
    },
    {
      "epoch": 4.344,
      "grad_norm": 0.421580046415329,
      "learning_rate": 2.62464e-05,
      "loss": 2.0913,
      "step": 27150
    },
    {
      "epoch": 4.352,
      "grad_norm": 0.3190249502658844,
      "learning_rate": 2.59264e-05,
      "loss": 2.0936,
      "step": 27200
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.3758394420146942,
      "learning_rate": 2.5606400000000003e-05,
      "loss": 2.1969,
      "step": 27250
    },
    {
      "epoch": 4.368,
      "grad_norm": 0.4007728695869446,
      "learning_rate": 2.52864e-05,
      "loss": 2.1075,
      "step": 27300
    },
    {
      "epoch": 4.376,
      "grad_norm": 0.33914926648139954,
      "learning_rate": 2.4966400000000002e-05,
      "loss": 2.1103,
      "step": 27350
    },
    {
      "epoch": 4.384,
      "grad_norm": 0.31810781359672546,
      "learning_rate": 2.4646400000000002e-05,
      "loss": 2.1324,
      "step": 27400
    },
    {
      "epoch": 4.392,
      "grad_norm": 0.32775408029556274,
      "learning_rate": 2.43264e-05,
      "loss": 2.076,
      "step": 27450
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.2961556613445282,
      "learning_rate": 2.40064e-05,
      "loss": 2.1139,
      "step": 27500
    },
    {
      "epoch": 4.408,
      "grad_norm": 0.33984801173210144,
      "learning_rate": 2.36864e-05,
      "loss": 2.1208,
      "step": 27550
    },
    {
      "epoch": 4.416,
      "grad_norm": 0.31989455223083496,
      "learning_rate": 2.3366400000000004e-05,
      "loss": 2.1046,
      "step": 27600
    },
    {
      "epoch": 4.424,
      "grad_norm": 0.31199583411216736,
      "learning_rate": 2.30464e-05,
      "loss": 2.0854,
      "step": 27650
    },
    {
      "epoch": 4.432,
      "grad_norm": 0.35379210114479065,
      "learning_rate": 2.27264e-05,
      "loss": 2.1259,
      "step": 27700
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.37481677532196045,
      "learning_rate": 2.2406400000000003e-05,
      "loss": 2.1883,
      "step": 27750
    },
    {
      "epoch": 4.448,
      "grad_norm": 0.37020671367645264,
      "learning_rate": 2.2086400000000003e-05,
      "loss": 2.114,
      "step": 27800
    },
    {
      "epoch": 4.456,
      "grad_norm": 0.40641844272613525,
      "learning_rate": 2.1766400000000002e-05,
      "loss": 2.1137,
      "step": 27850
    },
    {
      "epoch": 4.464,
      "grad_norm": 0.3713107705116272,
      "learning_rate": 2.14464e-05,
      "loss": 2.1827,
      "step": 27900
    },
    {
      "epoch": 4.4719999999999995,
      "grad_norm": 0.3319115936756134,
      "learning_rate": 2.11264e-05,
      "loss": 2.163,
      "step": 27950
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.2848144471645355,
      "learning_rate": 2.08064e-05,
      "loss": 2.1481,
      "step": 28000
    },
    {
      "epoch": 4.4879999999999995,
      "grad_norm": 0.38930544257164,
      "learning_rate": 2.04864e-05,
      "loss": 2.0962,
      "step": 28050
    },
    {
      "epoch": 4.496,
      "grad_norm": 0.33255112171173096,
      "learning_rate": 2.01664e-05,
      "loss": 2.1327,
      "step": 28100
    },
    {
      "epoch": 4.504,
      "grad_norm": 0.40963253378868103,
      "learning_rate": 1.98464e-05,
      "loss": 2.116,
      "step": 28150
    },
    {
      "epoch": 4.5120000000000005,
      "grad_norm": 0.367242693901062,
      "learning_rate": 1.95264e-05,
      "loss": 2.099,
      "step": 28200
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.36231449246406555,
      "learning_rate": 1.9206400000000003e-05,
      "loss": 2.0618,
      "step": 28250
    },
    {
      "epoch": 4.5280000000000005,
      "grad_norm": 0.3478696048259735,
      "learning_rate": 1.8886400000000003e-05,
      "loss": 2.0951,
      "step": 28300
    },
    {
      "epoch": 4.536,
      "grad_norm": 0.31797194480895996,
      "learning_rate": 1.85664e-05,
      "loss": 2.0377,
      "step": 28350
    },
    {
      "epoch": 4.5440000000000005,
      "grad_norm": 0.32695382833480835,
      "learning_rate": 1.82464e-05,
      "loss": 2.0858,
      "step": 28400
    },
    {
      "epoch": 4.552,
      "grad_norm": 0.378344863653183,
      "learning_rate": 1.7926400000000002e-05,
      "loss": 2.0881,
      "step": 28450
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.3201870024204254,
      "learning_rate": 1.76064e-05,
      "loss": 2.0718,
      "step": 28500
    },
    {
      "epoch": 4.568,
      "grad_norm": 0.2992672920227051,
      "learning_rate": 1.72864e-05,
      "loss": 2.0777,
      "step": 28550
    },
    {
      "epoch": 4.576,
      "grad_norm": 0.3475164771080017,
      "learning_rate": 1.69664e-05,
      "loss": 2.082,
      "step": 28600
    },
    {
      "epoch": 4.584,
      "grad_norm": 0.33392268419265747,
      "learning_rate": 1.66464e-05,
      "loss": 2.1405,
      "step": 28650
    },
    {
      "epoch": 4.592,
      "grad_norm": 0.3282417356967926,
      "learning_rate": 1.63264e-05,
      "loss": 2.122,
      "step": 28700
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.3442521095275879,
      "learning_rate": 1.6006400000000003e-05,
      "loss": 2.1908,
      "step": 28750
    },
    {
      "epoch": 4.608,
      "grad_norm": 0.34779295325279236,
      "learning_rate": 1.56864e-05,
      "loss": 2.0856,
      "step": 28800
    },
    {
      "epoch": 4.616,
      "grad_norm": 0.3520480692386627,
      "learning_rate": 1.53664e-05,
      "loss": 2.0521,
      "step": 28850
    },
    {
      "epoch": 4.624,
      "grad_norm": 0.35933905839920044,
      "learning_rate": 1.5046399999999999e-05,
      "loss": 2.1269,
      "step": 28900
    },
    {
      "epoch": 4.632,
      "grad_norm": 0.30458906292915344,
      "learning_rate": 1.4726400000000002e-05,
      "loss": 2.0924,
      "step": 28950
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.3312433362007141,
      "learning_rate": 1.44064e-05,
      "loss": 2.1553,
      "step": 29000
    },
    {
      "epoch": 4.648,
      "grad_norm": 0.2978413999080658,
      "learning_rate": 1.40864e-05,
      "loss": 2.121,
      "step": 29050
    },
    {
      "epoch": 4.656,
      "grad_norm": 0.3536282479763031,
      "learning_rate": 1.3766400000000001e-05,
      "loss": 2.0712,
      "step": 29100
    },
    {
      "epoch": 4.664,
      "grad_norm": 0.3655599355697632,
      "learning_rate": 1.34464e-05,
      "loss": 2.1034,
      "step": 29150
    },
    {
      "epoch": 4.672,
      "grad_norm": 0.30747509002685547,
      "learning_rate": 1.31264e-05,
      "loss": 2.0353,
      "step": 29200
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.3555721342563629,
      "learning_rate": 1.2806400000000002e-05,
      "loss": 2.1538,
      "step": 29250
    },
    {
      "epoch": 4.688,
      "grad_norm": 0.3651981055736542,
      "learning_rate": 1.2486400000000001e-05,
      "loss": 2.0623,
      "step": 29300
    },
    {
      "epoch": 4.696,
      "grad_norm": 0.339404433965683,
      "learning_rate": 1.21664e-05,
      "loss": 2.1126,
      "step": 29350
    },
    {
      "epoch": 4.704,
      "grad_norm": 0.32913821935653687,
      "learning_rate": 1.18464e-05,
      "loss": 2.1323,
      "step": 29400
    },
    {
      "epoch": 4.712,
      "grad_norm": 0.36885708570480347,
      "learning_rate": 1.15264e-05,
      "loss": 2.1498,
      "step": 29450
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.4172624349594116,
      "learning_rate": 1.12064e-05,
      "loss": 2.1332,
      "step": 29500
    },
    {
      "epoch": 4.728,
      "grad_norm": 0.32124996185302734,
      "learning_rate": 1.0886400000000001e-05,
      "loss": 2.1133,
      "step": 29550
    },
    {
      "epoch": 4.736,
      "grad_norm": 0.32697173953056335,
      "learning_rate": 1.05664e-05,
      "loss": 2.1105,
      "step": 29600
    },
    {
      "epoch": 4.744,
      "grad_norm": 0.42352983355522156,
      "learning_rate": 1.02464e-05,
      "loss": 2.0878,
      "step": 29650
    },
    {
      "epoch": 4.752,
      "grad_norm": 0.3146445155143738,
      "learning_rate": 9.9264e-06,
      "loss": 2.093,
      "step": 29700
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.386593759059906,
      "learning_rate": 9.6064e-06,
      "loss": 2.1347,
      "step": 29750
    },
    {
      "epoch": 4.768,
      "grad_norm": 0.31444624066352844,
      "learning_rate": 9.286400000000001e-06,
      "loss": 2.1006,
      "step": 29800
    },
    {
      "epoch": 4.776,
      "grad_norm": 0.3693259358406067,
      "learning_rate": 8.9664e-06,
      "loss": 2.0993,
      "step": 29850
    },
    {
      "epoch": 4.784,
      "grad_norm": 0.39481404423713684,
      "learning_rate": 8.6464e-06,
      "loss": 2.1639,
      "step": 29900
    },
    {
      "epoch": 4.792,
      "grad_norm": 0.3296564519405365,
      "learning_rate": 8.3264e-06,
      "loss": 2.1543,
      "step": 29950
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.3568834662437439,
      "learning_rate": 8.0064e-06,
      "loss": 2.1763,
      "step": 30000
    },
    {
      "epoch": 4.808,
      "grad_norm": 0.36340513825416565,
      "learning_rate": 7.6864e-06,
      "loss": 2.1024,
      "step": 30050
    },
    {
      "epoch": 4.816,
      "grad_norm": 0.3527858257293701,
      "learning_rate": 7.3663999999999995e-06,
      "loss": 2.1606,
      "step": 30100
    },
    {
      "epoch": 4.824,
      "grad_norm": 0.3589124381542206,
      "learning_rate": 7.0464e-06,
      "loss": 2.1652,
      "step": 30150
    },
    {
      "epoch": 4.832,
      "grad_norm": 0.3806999921798706,
      "learning_rate": 6.7264000000000005e-06,
      "loss": 2.0819,
      "step": 30200
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.36594855785369873,
      "learning_rate": 6.4064e-06,
      "loss": 2.1269,
      "step": 30250
    },
    {
      "epoch": 4.848,
      "grad_norm": 0.3942403495311737,
      "learning_rate": 6.086400000000001e-06,
      "loss": 2.1398,
      "step": 30300
    },
    {
      "epoch": 4.856,
      "grad_norm": 0.3282756805419922,
      "learning_rate": 5.7664e-06,
      "loss": 2.1065,
      "step": 30350
    },
    {
      "epoch": 4.864,
      "grad_norm": 0.3509730398654938,
      "learning_rate": 5.4464e-06,
      "loss": 2.135,
      "step": 30400
    },
    {
      "epoch": 4.872,
      "grad_norm": 0.3170745074748993,
      "learning_rate": 5.1264e-06,
      "loss": 2.1152,
      "step": 30450
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.4151701331138611,
      "learning_rate": 4.8064e-06,
      "loss": 2.1176,
      "step": 30500
    },
    {
      "epoch": 4.888,
      "grad_norm": 0.3464239239692688,
      "learning_rate": 4.4864e-06,
      "loss": 2.1392,
      "step": 30550
    },
    {
      "epoch": 4.896,
      "grad_norm": 0.31425371766090393,
      "learning_rate": 4.1664000000000005e-06,
      "loss": 2.1429,
      "step": 30600
    },
    {
      "epoch": 4.904,
      "grad_norm": 0.32706788182258606,
      "learning_rate": 3.8464e-06,
      "loss": 2.1066,
      "step": 30650
    },
    {
      "epoch": 4.912,
      "grad_norm": 0.33331719040870667,
      "learning_rate": 3.5264e-06,
      "loss": 2.1625,
      "step": 30700
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.3454757034778595,
      "learning_rate": 3.2064000000000003e-06,
      "loss": 2.1541,
      "step": 30750
    },
    {
      "epoch": 4.928,
      "grad_norm": 0.35256466269493103,
      "learning_rate": 2.8864e-06,
      "loss": 2.1135,
      "step": 30800
    },
    {
      "epoch": 4.936,
      "grad_norm": 0.3651965260505676,
      "learning_rate": 2.5664e-06,
      "loss": 2.1027,
      "step": 30850
    },
    {
      "epoch": 4.944,
      "grad_norm": 0.299015074968338,
      "learning_rate": 2.2464e-06,
      "loss": 2.136,
      "step": 30900
    },
    {
      "epoch": 4.952,
      "grad_norm": 0.3359745144844055,
      "learning_rate": 1.9264e-06,
      "loss": 2.0893,
      "step": 30950
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.3483027219772339,
      "learning_rate": 1.6064e-06,
      "loss": 2.1106,
      "step": 31000
    },
    {
      "epoch": 4.968,
      "grad_norm": 0.3715634346008301,
      "learning_rate": 1.2864e-06,
      "loss": 2.1992,
      "step": 31050
    },
    {
      "epoch": 4.976,
      "grad_norm": 0.37945905327796936,
      "learning_rate": 9.664000000000002e-07,
      "loss": 2.0911,
      "step": 31100
    },
    {
      "epoch": 4.984,
      "grad_norm": 0.35030657052993774,
      "learning_rate": 6.464000000000001e-07,
      "loss": 2.1156,
      "step": 31150
    },
    {
      "epoch": 4.992,
      "grad_norm": 0.3605561852455139,
      "learning_rate": 3.264e-07,
      "loss": 2.1321,
      "step": 31200
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.39620551466941833,
      "learning_rate": 6.4e-09,
      "loss": 2.0973,
      "step": 31250
    }
  ],
  "logging_steps": 50,
  "max_steps": 31250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.62679354290176e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
