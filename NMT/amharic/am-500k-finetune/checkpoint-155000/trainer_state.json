{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.96,
  "eval_steps": 5000,
  "global_step": 155000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 0.28655290603637695,
      "learning_rate": 0.00019993728,
      "loss": 2.4653,
      "step": 50
    },
    {
      "epoch": 0.0032,
      "grad_norm": 0.2715713679790497,
      "learning_rate": 0.00019987328,
      "loss": 2.2623,
      "step": 100
    },
    {
      "epoch": 0.0048,
      "grad_norm": 0.2526845335960388,
      "learning_rate": 0.00019980928,
      "loss": 2.2542,
      "step": 150
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.2782219648361206,
      "learning_rate": 0.00019974528000000003,
      "loss": 2.2277,
      "step": 200
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.3471236228942871,
      "learning_rate": 0.00019968128000000002,
      "loss": 2.2025,
      "step": 250
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.3074416518211365,
      "learning_rate": 0.00019961728000000002,
      "loss": 2.1522,
      "step": 300
    },
    {
      "epoch": 0.0112,
      "grad_norm": 0.44371330738067627,
      "learning_rate": 0.00019955328,
      "loss": 2.1809,
      "step": 350
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.25782039761543274,
      "learning_rate": 0.00019948928,
      "loss": 2.1871,
      "step": 400
    },
    {
      "epoch": 0.0144,
      "grad_norm": 0.2880309224128723,
      "learning_rate": 0.00019942528,
      "loss": 2.1846,
      "step": 450
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.2813336253166199,
      "learning_rate": 0.00019936128,
      "loss": 2.1848,
      "step": 500
    },
    {
      "epoch": 0.0176,
      "grad_norm": 0.2989383637905121,
      "learning_rate": 0.00019929728000000002,
      "loss": 2.1875,
      "step": 550
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.33948853611946106,
      "learning_rate": 0.00019923328000000001,
      "loss": 2.2013,
      "step": 600
    },
    {
      "epoch": 0.0208,
      "grad_norm": 0.30929696559906006,
      "learning_rate": 0.00019916928,
      "loss": 2.1776,
      "step": 650
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.28138527274131775,
      "learning_rate": 0.00019910528,
      "loss": 2.16,
      "step": 700
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.3081750273704529,
      "learning_rate": 0.00019904128000000003,
      "loss": 2.1797,
      "step": 750
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.2832907438278198,
      "learning_rate": 0.00019897728,
      "loss": 2.1809,
      "step": 800
    },
    {
      "epoch": 0.0272,
      "grad_norm": 0.2811259925365448,
      "learning_rate": 0.00019891328,
      "loss": 2.1259,
      "step": 850
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.3448331952095032,
      "learning_rate": 0.00019884928,
      "loss": 2.1714,
      "step": 900
    },
    {
      "epoch": 0.0304,
      "grad_norm": 0.32761120796203613,
      "learning_rate": 0.00019878528,
      "loss": 2.1993,
      "step": 950
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.27665653824806213,
      "learning_rate": 0.00019872128,
      "loss": 2.1364,
      "step": 1000
    },
    {
      "epoch": 0.0336,
      "grad_norm": 0.43602609634399414,
      "learning_rate": 0.00019865728000000003,
      "loss": 2.1369,
      "step": 1050
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.27362480759620667,
      "learning_rate": 0.00019859328000000002,
      "loss": 2.1764,
      "step": 1100
    },
    {
      "epoch": 0.0368,
      "grad_norm": 0.34209346771240234,
      "learning_rate": 0.00019852928000000002,
      "loss": 2.1749,
      "step": 1150
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.2715494632720947,
      "learning_rate": 0.00019846528,
      "loss": 2.2118,
      "step": 1200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2921290397644043,
      "learning_rate": 0.00019840128,
      "loss": 2.1677,
      "step": 1250
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.31781500577926636,
      "learning_rate": 0.00019833728,
      "loss": 2.1835,
      "step": 1300
    },
    {
      "epoch": 0.0432,
      "grad_norm": 0.314397394657135,
      "learning_rate": 0.00019827328,
      "loss": 2.1499,
      "step": 1350
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.2850140631198883,
      "learning_rate": 0.00019820928000000002,
      "loss": 2.1049,
      "step": 1400
    },
    {
      "epoch": 0.0464,
      "grad_norm": 0.2803344130516052,
      "learning_rate": 0.00019814528000000001,
      "loss": 2.1481,
      "step": 1450
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.28352218866348267,
      "learning_rate": 0.00019808128,
      "loss": 2.2354,
      "step": 1500
    },
    {
      "epoch": 0.0496,
      "grad_norm": 0.27710670232772827,
      "learning_rate": 0.00019801728,
      "loss": 2.2206,
      "step": 1550
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.2739223539829254,
      "learning_rate": 0.00019795328000000003,
      "loss": 2.175,
      "step": 1600
    },
    {
      "epoch": 0.0528,
      "grad_norm": 0.3180924654006958,
      "learning_rate": 0.00019788928,
      "loss": 2.1497,
      "step": 1650
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.26862916350364685,
      "learning_rate": 0.00019782528,
      "loss": 2.0782,
      "step": 1700
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.311098575592041,
      "learning_rate": 0.00019776128,
      "loss": 2.1559,
      "step": 1750
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.3153377175331116,
      "learning_rate": 0.00019769728,
      "loss": 2.1732,
      "step": 1800
    },
    {
      "epoch": 0.0592,
      "grad_norm": 0.3148520290851593,
      "learning_rate": 0.00019763328,
      "loss": 2.2149,
      "step": 1850
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.27718475461006165,
      "learning_rate": 0.00019756928000000002,
      "loss": 2.1606,
      "step": 1900
    },
    {
      "epoch": 0.0624,
      "grad_norm": 0.28529301285743713,
      "learning_rate": 0.00019750528000000002,
      "loss": 2.1125,
      "step": 1950
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.2977907955646515,
      "learning_rate": 0.00019744128000000002,
      "loss": 2.1539,
      "step": 2000
    },
    {
      "epoch": 0.0656,
      "grad_norm": 0.3168792128562927,
      "learning_rate": 0.00019737728,
      "loss": 2.2156,
      "step": 2050
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.30355820059776306,
      "learning_rate": 0.00019731328,
      "loss": 2.1651,
      "step": 2100
    },
    {
      "epoch": 0.0688,
      "grad_norm": 0.2855442762374878,
      "learning_rate": 0.00019724928,
      "loss": 2.1763,
      "step": 2150
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.2935347855091095,
      "learning_rate": 0.00019718528,
      "loss": 2.1761,
      "step": 2200
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.28928691148757935,
      "learning_rate": 0.00019712128000000002,
      "loss": 2.1865,
      "step": 2250
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.278240829706192,
      "learning_rate": 0.00019705728,
      "loss": 2.146,
      "step": 2300
    },
    {
      "epoch": 0.0752,
      "grad_norm": 0.3183736205101013,
      "learning_rate": 0.00019699328,
      "loss": 2.1898,
      "step": 2350
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.27116692066192627,
      "learning_rate": 0.00019692928,
      "loss": 2.1785,
      "step": 2400
    },
    {
      "epoch": 0.0784,
      "grad_norm": 0.26451635360717773,
      "learning_rate": 0.00019686528000000003,
      "loss": 2.0892,
      "step": 2450
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.28208982944488525,
      "learning_rate": 0.00019680128,
      "loss": 2.1661,
      "step": 2500
    },
    {
      "epoch": 0.0816,
      "grad_norm": 0.2876914143562317,
      "learning_rate": 0.00019673728,
      "loss": 2.2087,
      "step": 2550
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.27254718542099,
      "learning_rate": 0.00019667328,
      "loss": 2.1556,
      "step": 2600
    },
    {
      "epoch": 0.0848,
      "grad_norm": 0.30132895708084106,
      "learning_rate": 0.00019660928,
      "loss": 2.193,
      "step": 2650
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.3059074580669403,
      "learning_rate": 0.00019654528,
      "loss": 2.1514,
      "step": 2700
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.2741773724555969,
      "learning_rate": 0.00019648128000000002,
      "loss": 2.138,
      "step": 2750
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.25653770565986633,
      "learning_rate": 0.00019641728000000002,
      "loss": 2.1702,
      "step": 2800
    },
    {
      "epoch": 0.0912,
      "grad_norm": 0.2573736011981964,
      "learning_rate": 0.00019635328000000001,
      "loss": 2.1758,
      "step": 2850
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.2607320547103882,
      "learning_rate": 0.00019628928,
      "loss": 2.2062,
      "step": 2900
    },
    {
      "epoch": 0.0944,
      "grad_norm": 0.27351894974708557,
      "learning_rate": 0.00019622528,
      "loss": 2.1089,
      "step": 2950
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.33258533477783203,
      "learning_rate": 0.00019616128,
      "loss": 2.1348,
      "step": 3000
    },
    {
      "epoch": 0.0976,
      "grad_norm": 0.3080061972141266,
      "learning_rate": 0.00019609728,
      "loss": 2.1513,
      "step": 3050
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.23381629586219788,
      "learning_rate": 0.00019603328000000002,
      "loss": 2.1777,
      "step": 3100
    },
    {
      "epoch": 0.1008,
      "grad_norm": 0.23393049836158752,
      "learning_rate": 0.00019596928,
      "loss": 2.127,
      "step": 3150
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.2692231237888336,
      "learning_rate": 0.00019590528,
      "loss": 2.2271,
      "step": 3200
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.3157960772514343,
      "learning_rate": 0.00019584128,
      "loss": 2.1983,
      "step": 3250
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.27666518092155457,
      "learning_rate": 0.00019577728000000003,
      "loss": 2.1449,
      "step": 3300
    },
    {
      "epoch": 0.1072,
      "grad_norm": 0.3250122666358948,
      "learning_rate": 0.00019571328,
      "loss": 2.1278,
      "step": 3350
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.26532983779907227,
      "learning_rate": 0.00019564928,
      "loss": 2.1909,
      "step": 3400
    },
    {
      "epoch": 0.1104,
      "grad_norm": 0.2811051607131958,
      "learning_rate": 0.00019558528,
      "loss": 2.1901,
      "step": 3450
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.3261507749557495,
      "learning_rate": 0.00019552128,
      "loss": 2.1233,
      "step": 3500
    },
    {
      "epoch": 0.1136,
      "grad_norm": 0.25369882583618164,
      "learning_rate": 0.00019545728,
      "loss": 2.2023,
      "step": 3550
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.2768535315990448,
      "learning_rate": 0.00019539328000000002,
      "loss": 2.2717,
      "step": 3600
    },
    {
      "epoch": 0.1168,
      "grad_norm": 0.3081933557987213,
      "learning_rate": 0.00019532928000000002,
      "loss": 2.2073,
      "step": 3650
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.2550888657569885,
      "learning_rate": 0.00019526528000000001,
      "loss": 2.1674,
      "step": 3700
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2661495506763458,
      "learning_rate": 0.00019520128,
      "loss": 2.1564,
      "step": 3750
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.3151762783527374,
      "learning_rate": 0.00019513728,
      "loss": 2.1551,
      "step": 3800
    },
    {
      "epoch": 0.1232,
      "grad_norm": 0.30143067240715027,
      "learning_rate": 0.00019507328,
      "loss": 2.1894,
      "step": 3850
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.2816317677497864,
      "learning_rate": 0.00019500928,
      "loss": 2.1445,
      "step": 3900
    },
    {
      "epoch": 0.1264,
      "grad_norm": 0.3100273609161377,
      "learning_rate": 0.00019494528000000002,
      "loss": 2.198,
      "step": 3950
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.2645518183708191,
      "learning_rate": 0.00019488128,
      "loss": 2.1621,
      "step": 4000
    },
    {
      "epoch": 0.1296,
      "grad_norm": 0.2888793349266052,
      "learning_rate": 0.00019481728,
      "loss": 2.155,
      "step": 4050
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.3087443709373474,
      "learning_rate": 0.00019475328,
      "loss": 2.1697,
      "step": 4100
    },
    {
      "epoch": 0.1328,
      "grad_norm": 0.2839358448982239,
      "learning_rate": 0.00019468928000000003,
      "loss": 2.1102,
      "step": 4150
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.3151463270187378,
      "learning_rate": 0.00019462528,
      "loss": 2.2207,
      "step": 4200
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.2890344560146332,
      "learning_rate": 0.00019456128,
      "loss": 2.168,
      "step": 4250
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.301383376121521,
      "learning_rate": 0.00019449728,
      "loss": 2.1879,
      "step": 4300
    },
    {
      "epoch": 0.1392,
      "grad_norm": 0.3098714053630829,
      "learning_rate": 0.00019443328,
      "loss": 2.2428,
      "step": 4350
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.27440550923347473,
      "learning_rate": 0.00019436928,
      "loss": 2.1561,
      "step": 4400
    },
    {
      "epoch": 0.1424,
      "grad_norm": 0.2506643533706665,
      "learning_rate": 0.00019430528000000002,
      "loss": 2.1631,
      "step": 4450
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.26473504304885864,
      "learning_rate": 0.00019424128000000002,
      "loss": 2.2255,
      "step": 4500
    },
    {
      "epoch": 0.1456,
      "grad_norm": 0.24554428458213806,
      "learning_rate": 0.00019417728000000001,
      "loss": 2.1647,
      "step": 4550
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.2779475748538971,
      "learning_rate": 0.00019411328,
      "loss": 2.1501,
      "step": 4600
    },
    {
      "epoch": 0.1488,
      "grad_norm": 0.2509213984012604,
      "learning_rate": 0.00019404928,
      "loss": 2.1745,
      "step": 4650
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.25618693232536316,
      "learning_rate": 0.00019398528,
      "loss": 2.1347,
      "step": 4700
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.29433920979499817,
      "learning_rate": 0.00019392128,
      "loss": 2.2098,
      "step": 4750
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.2367672175168991,
      "learning_rate": 0.00019385728000000002,
      "loss": 2.163,
      "step": 4800
    },
    {
      "epoch": 0.1552,
      "grad_norm": 0.28328460454940796,
      "learning_rate": 0.00019379328,
      "loss": 2.1867,
      "step": 4850
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.2739259898662567,
      "learning_rate": 0.00019372928,
      "loss": 2.1161,
      "step": 4900
    },
    {
      "epoch": 0.1584,
      "grad_norm": 0.24436341226100922,
      "learning_rate": 0.00019366528,
      "loss": 2.1451,
      "step": 4950
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.26259055733680725,
      "learning_rate": 0.00019360128000000002,
      "loss": 2.196,
      "step": 5000
    },
    {
      "epoch": 0.1616,
      "grad_norm": 0.2885035276412964,
      "learning_rate": 0.00019353728,
      "loss": 2.1196,
      "step": 5050
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.2708752453327179,
      "learning_rate": 0.00019347328,
      "loss": 2.141,
      "step": 5100
    },
    {
      "epoch": 0.1648,
      "grad_norm": 0.25105899572372437,
      "learning_rate": 0.00019340928,
      "loss": 2.1636,
      "step": 5150
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.3124408423900604,
      "learning_rate": 0.00019334528,
      "loss": 2.1462,
      "step": 5200
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.2698918581008911,
      "learning_rate": 0.00019328128,
      "loss": 2.1599,
      "step": 5250
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.2678954303264618,
      "learning_rate": 0.00019321728000000002,
      "loss": 2.111,
      "step": 5300
    },
    {
      "epoch": 0.1712,
      "grad_norm": 0.26915180683135986,
      "learning_rate": 0.00019315328000000002,
      "loss": 2.1481,
      "step": 5350
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.30801135301589966,
      "learning_rate": 0.00019308928,
      "loss": 2.1305,
      "step": 5400
    },
    {
      "epoch": 0.1744,
      "grad_norm": 0.2506173253059387,
      "learning_rate": 0.00019302528,
      "loss": 2.1356,
      "step": 5450
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.2674914300441742,
      "learning_rate": 0.00019296128,
      "loss": 2.0948,
      "step": 5500
    },
    {
      "epoch": 0.1776,
      "grad_norm": 0.25509563088417053,
      "learning_rate": 0.00019289728,
      "loss": 2.1844,
      "step": 5550
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.30089837312698364,
      "learning_rate": 0.00019283328,
      "loss": 2.1517,
      "step": 5600
    },
    {
      "epoch": 0.1808,
      "grad_norm": 0.27111437916755676,
      "learning_rate": 0.00019276928000000002,
      "loss": 2.1426,
      "step": 5650
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.2613980174064636,
      "learning_rate": 0.00019270528,
      "loss": 2.1042,
      "step": 5700
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.24152234196662903,
      "learning_rate": 0.00019264128,
      "loss": 2.1345,
      "step": 5750
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.28621795773506165,
      "learning_rate": 0.00019257728,
      "loss": 2.1972,
      "step": 5800
    },
    {
      "epoch": 0.1872,
      "grad_norm": 0.3087862730026245,
      "learning_rate": 0.00019251328000000002,
      "loss": 2.1176,
      "step": 5850
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.29735106229782104,
      "learning_rate": 0.00019244928,
      "loss": 2.1833,
      "step": 5900
    },
    {
      "epoch": 0.1904,
      "grad_norm": 0.2871825397014618,
      "learning_rate": 0.00019238528,
      "loss": 2.1678,
      "step": 5950
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.24061332643032074,
      "learning_rate": 0.00019232128,
      "loss": 2.1126,
      "step": 6000
    },
    {
      "epoch": 0.1936,
      "grad_norm": 0.27334046363830566,
      "learning_rate": 0.00019225728,
      "loss": 2.1516,
      "step": 6050
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.2627016603946686,
      "learning_rate": 0.00019219328,
      "loss": 2.1488,
      "step": 6100
    },
    {
      "epoch": 0.1968,
      "grad_norm": 0.32974112033843994,
      "learning_rate": 0.00019212928000000002,
      "loss": 2.1376,
      "step": 6150
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.2605276107788086,
      "learning_rate": 0.00019206528000000002,
      "loss": 2.1419,
      "step": 6200
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2452729195356369,
      "learning_rate": 0.00019200128,
      "loss": 2.1425,
      "step": 6250
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.36889639496803284,
      "learning_rate": 0.00019193728,
      "loss": 2.0803,
      "step": 6300
    },
    {
      "epoch": 0.2032,
      "grad_norm": 0.2595408260822296,
      "learning_rate": 0.00019187328,
      "loss": 2.2068,
      "step": 6350
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.2583218216896057,
      "learning_rate": 0.00019180928,
      "loss": 2.2028,
      "step": 6400
    },
    {
      "epoch": 0.2064,
      "grad_norm": 0.25652211904525757,
      "learning_rate": 0.00019174528,
      "loss": 2.2087,
      "step": 6450
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.319548636674881,
      "learning_rate": 0.00019168128000000002,
      "loss": 2.1277,
      "step": 6500
    },
    {
      "epoch": 0.2096,
      "grad_norm": 0.28721705079078674,
      "learning_rate": 0.00019161728,
      "loss": 2.1684,
      "step": 6550
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.2856495678424835,
      "learning_rate": 0.00019155328,
      "loss": 2.1898,
      "step": 6600
    },
    {
      "epoch": 0.2128,
      "grad_norm": 0.2742760479450226,
      "learning_rate": 0.00019148928000000003,
      "loss": 2.1414,
      "step": 6650
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.2859490215778351,
      "learning_rate": 0.00019142528000000002,
      "loss": 2.1917,
      "step": 6700
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.2970024049282074,
      "learning_rate": 0.00019136128,
      "loss": 2.1426,
      "step": 6750
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.21801812946796417,
      "learning_rate": 0.00019129728000000001,
      "loss": 2.1368,
      "step": 6800
    },
    {
      "epoch": 0.2192,
      "grad_norm": 0.2968301475048065,
      "learning_rate": 0.00019123328,
      "loss": 2.1603,
      "step": 6850
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.2421727031469345,
      "learning_rate": 0.00019116928,
      "loss": 2.0805,
      "step": 6900
    },
    {
      "epoch": 0.2224,
      "grad_norm": 0.3143380284309387,
      "learning_rate": 0.00019110528,
      "loss": 2.2288,
      "step": 6950
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.34559166431427,
      "learning_rate": 0.00019104128000000002,
      "loss": 2.1435,
      "step": 7000
    },
    {
      "epoch": 0.2256,
      "grad_norm": 0.26232457160949707,
      "learning_rate": 0.00019097728000000002,
      "loss": 2.1218,
      "step": 7050
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.28067144751548767,
      "learning_rate": 0.00019091328,
      "loss": 2.1658,
      "step": 7100
    },
    {
      "epoch": 0.2288,
      "grad_norm": 0.26727238297462463,
      "learning_rate": 0.00019084928,
      "loss": 2.1404,
      "step": 7150
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.28994107246398926,
      "learning_rate": 0.00019078528,
      "loss": 2.1365,
      "step": 7200
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.2601534426212311,
      "learning_rate": 0.00019072128,
      "loss": 2.1852,
      "step": 7250
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.2830909788608551,
      "learning_rate": 0.00019065728,
      "loss": 2.2273,
      "step": 7300
    },
    {
      "epoch": 0.2352,
      "grad_norm": 0.2947399914264679,
      "learning_rate": 0.00019059328000000002,
      "loss": 2.1811,
      "step": 7350
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.3371879458427429,
      "learning_rate": 0.00019052928,
      "loss": 2.1188,
      "step": 7400
    },
    {
      "epoch": 0.2384,
      "grad_norm": 0.25502097606658936,
      "learning_rate": 0.00019046528,
      "loss": 2.1409,
      "step": 7450
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.24498097598552704,
      "learning_rate": 0.00019040128000000003,
      "loss": 2.181,
      "step": 7500
    },
    {
      "epoch": 0.2416,
      "grad_norm": 0.27804461121559143,
      "learning_rate": 0.00019033728000000002,
      "loss": 2.1886,
      "step": 7550
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.2700079679489136,
      "learning_rate": 0.00019027328,
      "loss": 2.1549,
      "step": 7600
    },
    {
      "epoch": 0.2448,
      "grad_norm": 0.2396552860736847,
      "learning_rate": 0.00019020928000000001,
      "loss": 2.0897,
      "step": 7650
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.28981414437294006,
      "learning_rate": 0.00019014528,
      "loss": 2.1796,
      "step": 7700
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.24378475546836853,
      "learning_rate": 0.00019008128,
      "loss": 2.1689,
      "step": 7750
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.24556680023670197,
      "learning_rate": 0.00019001728,
      "loss": 2.1351,
      "step": 7800
    },
    {
      "epoch": 0.2512,
      "grad_norm": 0.2529773712158203,
      "learning_rate": 0.00018995328000000002,
      "loss": 2.1855,
      "step": 7850
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.24313201010227203,
      "learning_rate": 0.00018988928000000002,
      "loss": 2.1324,
      "step": 7900
    },
    {
      "epoch": 0.2544,
      "grad_norm": 0.25098589062690735,
      "learning_rate": 0.00018982528,
      "loss": 2.1789,
      "step": 7950
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.33645448088645935,
      "learning_rate": 0.00018976128,
      "loss": 2.1943,
      "step": 8000
    },
    {
      "epoch": 0.2576,
      "grad_norm": 0.2718272805213928,
      "learning_rate": 0.00018969728,
      "loss": 2.1627,
      "step": 8050
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.24377970397472382,
      "learning_rate": 0.00018963328,
      "loss": 2.2162,
      "step": 8100
    },
    {
      "epoch": 0.2608,
      "grad_norm": 0.22869586944580078,
      "learning_rate": 0.00018956928,
      "loss": 2.1679,
      "step": 8150
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.29245463013648987,
      "learning_rate": 0.00018950528000000002,
      "loss": 2.1082,
      "step": 8200
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.25921398401260376,
      "learning_rate": 0.00018944128,
      "loss": 2.1198,
      "step": 8250
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.2624872028827667,
      "learning_rate": 0.00018937728,
      "loss": 2.1372,
      "step": 8300
    },
    {
      "epoch": 0.2672,
      "grad_norm": 0.28645437955856323,
      "learning_rate": 0.00018931328000000003,
      "loss": 2.1677,
      "step": 8350
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.2673211991786957,
      "learning_rate": 0.00018924928000000002,
      "loss": 2.1768,
      "step": 8400
    },
    {
      "epoch": 0.2704,
      "grad_norm": 0.3121369183063507,
      "learning_rate": 0.00018918528,
      "loss": 2.1877,
      "step": 8450
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.30888769030570984,
      "learning_rate": 0.00018912128000000001,
      "loss": 2.1352,
      "step": 8500
    },
    {
      "epoch": 0.2736,
      "grad_norm": 0.29032665491104126,
      "learning_rate": 0.00018905728,
      "loss": 2.1058,
      "step": 8550
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.27029019594192505,
      "learning_rate": 0.00018899328,
      "loss": 2.1154,
      "step": 8600
    },
    {
      "epoch": 0.2768,
      "grad_norm": 0.3070162832736969,
      "learning_rate": 0.00018892928,
      "loss": 2.1216,
      "step": 8650
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.28885841369628906,
      "learning_rate": 0.00018886528000000002,
      "loss": 2.1101,
      "step": 8700
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2865452170372009,
      "learning_rate": 0.00018880128000000002,
      "loss": 2.2145,
      "step": 8750
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.28566908836364746,
      "learning_rate": 0.00018873728,
      "loss": 2.175,
      "step": 8800
    },
    {
      "epoch": 0.2832,
      "grad_norm": 0.2776755690574646,
      "learning_rate": 0.00018867328,
      "loss": 2.1575,
      "step": 8850
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.24645529687404633,
      "learning_rate": 0.00018860928,
      "loss": 2.1398,
      "step": 8900
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.33519771695137024,
      "learning_rate": 0.00018854528,
      "loss": 2.1279,
      "step": 8950
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.21689724922180176,
      "learning_rate": 0.00018848128,
      "loss": 2.1625,
      "step": 9000
    },
    {
      "epoch": 0.2896,
      "grad_norm": 0.402027428150177,
      "learning_rate": 0.00018841728000000001,
      "loss": 2.1396,
      "step": 9050
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.2811432480812073,
      "learning_rate": 0.00018835328,
      "loss": 2.1491,
      "step": 9100
    },
    {
      "epoch": 0.2928,
      "grad_norm": 0.27193304896354675,
      "learning_rate": 0.00018828928,
      "loss": 2.2044,
      "step": 9150
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.261671781539917,
      "learning_rate": 0.00018822528000000003,
      "loss": 2.1172,
      "step": 9200
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.2714362144470215,
      "learning_rate": 0.00018816128000000002,
      "loss": 2.1011,
      "step": 9250
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.23477624356746674,
      "learning_rate": 0.00018809728,
      "loss": 2.0836,
      "step": 9300
    },
    {
      "epoch": 0.2992,
      "grad_norm": 0.27720963954925537,
      "learning_rate": 0.00018803328,
      "loss": 2.1819,
      "step": 9350
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.32706400752067566,
      "learning_rate": 0.00018796928,
      "loss": 2.1724,
      "step": 9400
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.27881956100463867,
      "learning_rate": 0.00018790528,
      "loss": 2.1305,
      "step": 9450
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.3163300156593323,
      "learning_rate": 0.00018784128,
      "loss": 2.201,
      "step": 9500
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.23653069138526917,
      "learning_rate": 0.00018777728000000002,
      "loss": 2.1783,
      "step": 9550
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.28815922141075134,
      "learning_rate": 0.00018771328000000002,
      "loss": 2.2133,
      "step": 9600
    },
    {
      "epoch": 0.3088,
      "grad_norm": 0.2511928379535675,
      "learning_rate": 0.00018764928,
      "loss": 2.1587,
      "step": 9650
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.29056474566459656,
      "learning_rate": 0.00018758528,
      "loss": 2.1189,
      "step": 9700
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.2552260458469391,
      "learning_rate": 0.00018752128,
      "loss": 2.1579,
      "step": 9750
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.3082362115383148,
      "learning_rate": 0.00018745728,
      "loss": 2.1724,
      "step": 9800
    },
    {
      "epoch": 0.3152,
      "grad_norm": 0.30331042408943176,
      "learning_rate": 0.00018739328,
      "loss": 2.1102,
      "step": 9850
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.3177957534790039,
      "learning_rate": 0.00018732928000000001,
      "loss": 2.152,
      "step": 9900
    },
    {
      "epoch": 0.3184,
      "grad_norm": 0.35119181871414185,
      "learning_rate": 0.00018726528,
      "loss": 2.1967,
      "step": 9950
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.21992909908294678,
      "learning_rate": 0.00018720128,
      "loss": 2.1511,
      "step": 10000
    },
    {
      "epoch": 0.3216,
      "grad_norm": 0.3012927770614624,
      "learning_rate": 0.00018713728000000003,
      "loss": 2.142,
      "step": 10050
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.2690141797065735,
      "learning_rate": 0.00018707328000000002,
      "loss": 2.1218,
      "step": 10100
    },
    {
      "epoch": 0.3248,
      "grad_norm": 0.35602208971977234,
      "learning_rate": 0.00018700928000000002,
      "loss": 2.1234,
      "step": 10150
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.23787464201450348,
      "learning_rate": 0.00018694528,
      "loss": 2.139,
      "step": 10200
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.26187920570373535,
      "learning_rate": 0.00018688128,
      "loss": 2.0916,
      "step": 10250
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.3003993034362793,
      "learning_rate": 0.00018681728,
      "loss": 2.1597,
      "step": 10300
    },
    {
      "epoch": 0.3312,
      "grad_norm": 0.24106615781784058,
      "learning_rate": 0.00018675328,
      "loss": 2.1518,
      "step": 10350
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.2397099733352661,
      "learning_rate": 0.00018668928000000002,
      "loss": 2.1406,
      "step": 10400
    },
    {
      "epoch": 0.3344,
      "grad_norm": 0.29431596398353577,
      "learning_rate": 0.00018662528000000002,
      "loss": 2.1335,
      "step": 10450
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.2442980408668518,
      "learning_rate": 0.00018656128,
      "loss": 2.1615,
      "step": 10500
    },
    {
      "epoch": 0.3376,
      "grad_norm": 0.2536061406135559,
      "learning_rate": 0.00018649728,
      "loss": 2.163,
      "step": 10550
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.3754299283027649,
      "learning_rate": 0.00018643328,
      "loss": 2.1669,
      "step": 10600
    },
    {
      "epoch": 0.3408,
      "grad_norm": 0.26274603605270386,
      "learning_rate": 0.00018636928,
      "loss": 2.1745,
      "step": 10650
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.2540043294429779,
      "learning_rate": 0.00018630528,
      "loss": 2.1775,
      "step": 10700
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.31403276324272156,
      "learning_rate": 0.00018624128000000001,
      "loss": 2.1906,
      "step": 10750
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.28202518820762634,
      "learning_rate": 0.00018617728,
      "loss": 2.1841,
      "step": 10800
    },
    {
      "epoch": 0.3472,
      "grad_norm": 0.28823739290237427,
      "learning_rate": 0.00018611328,
      "loss": 2.146,
      "step": 10850
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.30092287063598633,
      "learning_rate": 0.00018604928000000003,
      "loss": 2.1706,
      "step": 10900
    },
    {
      "epoch": 0.3504,
      "grad_norm": 0.22110597789287567,
      "learning_rate": 0.00018598528000000002,
      "loss": 2.1695,
      "step": 10950
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.2295565903186798,
      "learning_rate": 0.00018592128000000002,
      "loss": 2.1697,
      "step": 11000
    },
    {
      "epoch": 0.3536,
      "grad_norm": 0.2726788818836212,
      "learning_rate": 0.00018585728,
      "loss": 2.097,
      "step": 11050
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.2603890895843506,
      "learning_rate": 0.00018579328,
      "loss": 2.1155,
      "step": 11100
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.24252860248088837,
      "learning_rate": 0.00018572928,
      "loss": 2.1825,
      "step": 11150
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.29051730036735535,
      "learning_rate": 0.00018566528,
      "loss": 2.1463,
      "step": 11200
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.2717691659927368,
      "learning_rate": 0.00018560128000000002,
      "loss": 2.1173,
      "step": 11250
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.2583319842815399,
      "learning_rate": 0.00018553728000000002,
      "loss": 2.1661,
      "step": 11300
    },
    {
      "epoch": 0.3632,
      "grad_norm": 0.2790764570236206,
      "learning_rate": 0.00018547328,
      "loss": 2.2021,
      "step": 11350
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.28401151299476624,
      "learning_rate": 0.00018540928,
      "loss": 2.1313,
      "step": 11400
    },
    {
      "epoch": 0.3664,
      "grad_norm": 0.26559683680534363,
      "learning_rate": 0.00018534528,
      "loss": 2.1654,
      "step": 11450
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.2508864402770996,
      "learning_rate": 0.00018528128,
      "loss": 2.1458,
      "step": 11500
    },
    {
      "epoch": 0.3696,
      "grad_norm": 0.28693777322769165,
      "learning_rate": 0.00018521728,
      "loss": 2.1908,
      "step": 11550
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.3478771448135376,
      "learning_rate": 0.00018515328000000001,
      "loss": 2.0831,
      "step": 11600
    },
    {
      "epoch": 0.3728,
      "grad_norm": 0.3045921325683594,
      "learning_rate": 0.00018508928,
      "loss": 2.1913,
      "step": 11650
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.31711649894714355,
      "learning_rate": 0.00018502528,
      "loss": 2.0952,
      "step": 11700
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.2710410952568054,
      "learning_rate": 0.00018496128000000003,
      "loss": 2.1482,
      "step": 11750
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.2723141610622406,
      "learning_rate": 0.00018489728000000002,
      "loss": 2.2517,
      "step": 11800
    },
    {
      "epoch": 0.3792,
      "grad_norm": 0.31411823630332947,
      "learning_rate": 0.00018483328000000002,
      "loss": 2.0959,
      "step": 11850
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.2253427654504776,
      "learning_rate": 0.00018476928,
      "loss": 2.1475,
      "step": 11900
    },
    {
      "epoch": 0.3824,
      "grad_norm": 0.3126470744609833,
      "learning_rate": 0.00018470528,
      "loss": 2.1991,
      "step": 11950
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.22976312041282654,
      "learning_rate": 0.00018464128,
      "loss": 2.1637,
      "step": 12000
    },
    {
      "epoch": 0.3856,
      "grad_norm": 0.23019950091838837,
      "learning_rate": 0.00018457728,
      "loss": 2.1318,
      "step": 12050
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.2724008858203888,
      "learning_rate": 0.00018451328000000002,
      "loss": 2.1688,
      "step": 12100
    },
    {
      "epoch": 0.3888,
      "grad_norm": 0.2947228252887726,
      "learning_rate": 0.00018444928000000001,
      "loss": 2.1582,
      "step": 12150
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.2634638845920563,
      "learning_rate": 0.00018438528,
      "loss": 2.1153,
      "step": 12200
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.3141883313655853,
      "learning_rate": 0.00018432128,
      "loss": 2.1587,
      "step": 12250
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.28093060851097107,
      "learning_rate": 0.00018425728,
      "loss": 2.0874,
      "step": 12300
    },
    {
      "epoch": 0.3952,
      "grad_norm": 0.28334587812423706,
      "learning_rate": 0.00018419328,
      "loss": 2.164,
      "step": 12350
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.2396937906742096,
      "learning_rate": 0.00018412928,
      "loss": 2.2039,
      "step": 12400
    },
    {
      "epoch": 0.3984,
      "grad_norm": 0.2780134677886963,
      "learning_rate": 0.00018406528,
      "loss": 2.1427,
      "step": 12450
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.2872473895549774,
      "learning_rate": 0.00018400128,
      "loss": 2.1736,
      "step": 12500
    },
    {
      "epoch": 0.4016,
      "grad_norm": 0.27491849660873413,
      "learning_rate": 0.00018393728,
      "loss": 2.082,
      "step": 12550
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.2758353054523468,
      "learning_rate": 0.00018387328000000003,
      "loss": 2.1825,
      "step": 12600
    },
    {
      "epoch": 0.4048,
      "grad_norm": 0.38857465982437134,
      "learning_rate": 0.00018380928000000002,
      "loss": 2.1791,
      "step": 12650
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.2390340119600296,
      "learning_rate": 0.00018374528000000002,
      "loss": 2.0964,
      "step": 12700
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.2502341568470001,
      "learning_rate": 0.00018368128,
      "loss": 2.1496,
      "step": 12750
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.26048433780670166,
      "learning_rate": 0.00018361728,
      "loss": 2.1891,
      "step": 12800
    },
    {
      "epoch": 0.4112,
      "grad_norm": 0.2367028445005417,
      "learning_rate": 0.00018355328,
      "loss": 2.1532,
      "step": 12850
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.2957116663455963,
      "learning_rate": 0.00018348928,
      "loss": 2.1201,
      "step": 12900
    },
    {
      "epoch": 0.4144,
      "grad_norm": 0.3383512794971466,
      "learning_rate": 0.00018342528000000002,
      "loss": 2.1538,
      "step": 12950
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.23603084683418274,
      "learning_rate": 0.00018336128000000001,
      "loss": 2.13,
      "step": 13000
    },
    {
      "epoch": 0.4176,
      "grad_norm": 0.24107420444488525,
      "learning_rate": 0.00018329728,
      "loss": 2.1472,
      "step": 13050
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.26930972933769226,
      "learning_rate": 0.00018323328,
      "loss": 2.1514,
      "step": 13100
    },
    {
      "epoch": 0.4208,
      "grad_norm": 0.3046024441719055,
      "learning_rate": 0.00018316928,
      "loss": 2.1661,
      "step": 13150
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.30479809641838074,
      "learning_rate": 0.00018310528,
      "loss": 2.1653,
      "step": 13200
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.3005683422088623,
      "learning_rate": 0.00018304128,
      "loss": 2.2151,
      "step": 13250
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.2704771161079407,
      "learning_rate": 0.00018297728,
      "loss": 2.1219,
      "step": 13300
    },
    {
      "epoch": 0.4272,
      "grad_norm": 0.2673851251602173,
      "learning_rate": 0.00018291328,
      "loss": 2.1103,
      "step": 13350
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.23048648238182068,
      "learning_rate": 0.00018284928,
      "loss": 2.0946,
      "step": 13400
    },
    {
      "epoch": 0.4304,
      "grad_norm": 0.29736924171447754,
      "learning_rate": 0.00018278528000000003,
      "loss": 2.0434,
      "step": 13450
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.2701839506626129,
      "learning_rate": 0.00018272128000000002,
      "loss": 2.1376,
      "step": 13500
    },
    {
      "epoch": 0.4336,
      "grad_norm": 0.29992324113845825,
      "learning_rate": 0.00018265728000000002,
      "loss": 2.1868,
      "step": 13550
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.3244081437587738,
      "learning_rate": 0.00018259328,
      "loss": 2.09,
      "step": 13600
    },
    {
      "epoch": 0.4368,
      "grad_norm": 0.606082558631897,
      "learning_rate": 0.00018252928,
      "loss": 2.1552,
      "step": 13650
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.261309415102005,
      "learning_rate": 0.00018246528,
      "loss": 2.1578,
      "step": 13700
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.29428139328956604,
      "learning_rate": 0.00018240128,
      "loss": 2.1139,
      "step": 13750
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.28133636713027954,
      "learning_rate": 0.00018233728000000002,
      "loss": 2.1508,
      "step": 13800
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.2170514464378357,
      "learning_rate": 0.00018227328000000001,
      "loss": 2.1446,
      "step": 13850
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.24532979726791382,
      "learning_rate": 0.00018220928,
      "loss": 2.1209,
      "step": 13900
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.2646465003490448,
      "learning_rate": 0.00018214528000000003,
      "loss": 2.1204,
      "step": 13950
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.2750431299209595,
      "learning_rate": 0.00018208128,
      "loss": 2.1943,
      "step": 14000
    },
    {
      "epoch": 0.4496,
      "grad_norm": 0.3003244698047638,
      "learning_rate": 0.00018201728,
      "loss": 2.1205,
      "step": 14050
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.2740812301635742,
      "learning_rate": 0.00018195328000000002,
      "loss": 2.1171,
      "step": 14100
    },
    {
      "epoch": 0.4528,
      "grad_norm": 0.25466012954711914,
      "learning_rate": 0.00018188928,
      "loss": 2.1413,
      "step": 14150
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.24578958749771118,
      "learning_rate": 0.00018182528,
      "loss": 2.1729,
      "step": 14200
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.2785203158855438,
      "learning_rate": 0.00018176128,
      "loss": 2.1505,
      "step": 14250
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.2470686435699463,
      "learning_rate": 0.00018169728000000003,
      "loss": 2.1512,
      "step": 14300
    },
    {
      "epoch": 0.4592,
      "grad_norm": 0.2575704753398895,
      "learning_rate": 0.00018163328000000002,
      "loss": 2.1161,
      "step": 14350
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.2668793201446533,
      "learning_rate": 0.00018156928000000002,
      "loss": 2.2071,
      "step": 14400
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.2800840735435486,
      "learning_rate": 0.00018150528,
      "loss": 2.111,
      "step": 14450
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.2531755566596985,
      "learning_rate": 0.00018144128,
      "loss": 2.1575,
      "step": 14500
    },
    {
      "epoch": 0.4656,
      "grad_norm": 0.2793377637863159,
      "learning_rate": 0.00018137728,
      "loss": 2.0749,
      "step": 14550
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.235723078250885,
      "learning_rate": 0.00018131328,
      "loss": 2.1829,
      "step": 14600
    },
    {
      "epoch": 0.4688,
      "grad_norm": 0.2647944986820221,
      "learning_rate": 0.00018124928000000002,
      "loss": 2.1704,
      "step": 14650
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.26542195677757263,
      "learning_rate": 0.00018118528000000001,
      "loss": 2.157,
      "step": 14700
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.2567635178565979,
      "learning_rate": 0.00018112128,
      "loss": 2.1418,
      "step": 14750
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.25157445669174194,
      "learning_rate": 0.00018105728000000003,
      "loss": 2.1556,
      "step": 14800
    },
    {
      "epoch": 0.4752,
      "grad_norm": 0.2682211697101593,
      "learning_rate": 0.00018099328,
      "loss": 2.1117,
      "step": 14850
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.2273889034986496,
      "learning_rate": 0.00018092928,
      "loss": 2.1418,
      "step": 14900
    },
    {
      "epoch": 0.4784,
      "grad_norm": 0.22683590650558472,
      "learning_rate": 0.00018086528000000002,
      "loss": 2.1418,
      "step": 14950
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.24660873413085938,
      "learning_rate": 0.00018080128,
      "loss": 2.1475,
      "step": 15000
    },
    {
      "epoch": 0.4816,
      "grad_norm": 0.2618013322353363,
      "learning_rate": 0.00018073728,
      "loss": 2.1059,
      "step": 15050
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.22590667009353638,
      "learning_rate": 0.00018067328,
      "loss": 2.1344,
      "step": 15100
    },
    {
      "epoch": 0.4848,
      "grad_norm": 0.23988260328769684,
      "learning_rate": 0.00018060928000000002,
      "loss": 2.1927,
      "step": 15150
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.24592342972755432,
      "learning_rate": 0.00018054528000000002,
      "loss": 2.1948,
      "step": 15200
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.25841084122657776,
      "learning_rate": 0.00018048128000000001,
      "loss": 2.1821,
      "step": 15250
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.2568642795085907,
      "learning_rate": 0.00018041728,
      "loss": 2.1796,
      "step": 15300
    },
    {
      "epoch": 0.4912,
      "grad_norm": 0.26113396883010864,
      "learning_rate": 0.00018035328,
      "loss": 2.106,
      "step": 15350
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.27426981925964355,
      "learning_rate": 0.00018028928,
      "loss": 2.1643,
      "step": 15400
    },
    {
      "epoch": 0.4944,
      "grad_norm": 0.28305840492248535,
      "learning_rate": 0.00018022528,
      "loss": 2.1667,
      "step": 15450
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.29321277141571045,
      "learning_rate": 0.00018016128000000002,
      "loss": 2.0602,
      "step": 15500
    },
    {
      "epoch": 0.4976,
      "grad_norm": 0.2871326506137848,
      "learning_rate": 0.00018009728,
      "loss": 2.0475,
      "step": 15550
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.23566913604736328,
      "learning_rate": 0.00018003328,
      "loss": 2.1429,
      "step": 15600
    },
    {
      "epoch": 0.5008,
      "grad_norm": 0.2685111165046692,
      "learning_rate": 0.00017996928000000003,
      "loss": 2.2043,
      "step": 15650
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.29658856987953186,
      "learning_rate": 0.00017990528,
      "loss": 2.1421,
      "step": 15700
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.3695302903652191,
      "learning_rate": 0.00017984128,
      "loss": 2.1866,
      "step": 15750
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.30448323488235474,
      "learning_rate": 0.00017977728000000002,
      "loss": 2.1505,
      "step": 15800
    },
    {
      "epoch": 0.5072,
      "grad_norm": 0.25149092078208923,
      "learning_rate": 0.00017971328,
      "loss": 2.2139,
      "step": 15850
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.32032737135887146,
      "learning_rate": 0.00017964928,
      "loss": 2.1757,
      "step": 15900
    },
    {
      "epoch": 0.5104,
      "grad_norm": 0.27463826537132263,
      "learning_rate": 0.00017958528,
      "loss": 2.0674,
      "step": 15950
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.26086872816085815,
      "learning_rate": 0.00017952128000000002,
      "loss": 2.0943,
      "step": 16000
    },
    {
      "epoch": 0.5136,
      "grad_norm": 0.2808983325958252,
      "learning_rate": 0.00017945728000000002,
      "loss": 2.1758,
      "step": 16050
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.27461862564086914,
      "learning_rate": 0.00017939328000000001,
      "loss": 2.2218,
      "step": 16100
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.2643459737300873,
      "learning_rate": 0.00017932928,
      "loss": 2.1628,
      "step": 16150
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.3182344138622284,
      "learning_rate": 0.00017926528,
      "loss": 2.1554,
      "step": 16200
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.24798592925071716,
      "learning_rate": 0.00017920128,
      "loss": 2.1849,
      "step": 16250
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.33508771657943726,
      "learning_rate": 0.00017913728,
      "loss": 2.1383,
      "step": 16300
    },
    {
      "epoch": 0.5232,
      "grad_norm": 0.27096179127693176,
      "learning_rate": 0.00017907328000000002,
      "loss": 2.1744,
      "step": 16350
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.3471605181694031,
      "learning_rate": 0.00017900928,
      "loss": 2.1339,
      "step": 16400
    },
    {
      "epoch": 0.5264,
      "grad_norm": 0.27617254853248596,
      "learning_rate": 0.00017894528,
      "loss": 2.114,
      "step": 16450
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.4231910705566406,
      "learning_rate": 0.00017888128000000003,
      "loss": 2.2023,
      "step": 16500
    },
    {
      "epoch": 0.5296,
      "grad_norm": 0.27349090576171875,
      "learning_rate": 0.00017881728,
      "loss": 2.1902,
      "step": 16550
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.24215549230575562,
      "learning_rate": 0.00017875328,
      "loss": 2.0843,
      "step": 16600
    },
    {
      "epoch": 0.5328,
      "grad_norm": 0.31298455595970154,
      "learning_rate": 0.00017868928000000002,
      "loss": 2.1428,
      "step": 16650
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.3252820372581482,
      "learning_rate": 0.00017862528,
      "loss": 2.1509,
      "step": 16700
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.339224636554718,
      "learning_rate": 0.00017856128,
      "loss": 2.1799,
      "step": 16750
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.2562122642993927,
      "learning_rate": 0.00017849728,
      "loss": 2.1604,
      "step": 16800
    },
    {
      "epoch": 0.5392,
      "grad_norm": 0.2563059628009796,
      "learning_rate": 0.00017843328000000002,
      "loss": 2.1639,
      "step": 16850
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.26638951897621155,
      "learning_rate": 0.00017836928000000002,
      "loss": 2.1482,
      "step": 16900
    },
    {
      "epoch": 0.5424,
      "grad_norm": 0.27860721945762634,
      "learning_rate": 0.00017830528000000001,
      "loss": 2.1213,
      "step": 16950
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.2329474538564682,
      "learning_rate": 0.00017824128,
      "loss": 2.2226,
      "step": 17000
    },
    {
      "epoch": 0.5456,
      "grad_norm": 0.21657787263393402,
      "learning_rate": 0.00017817728,
      "loss": 2.1349,
      "step": 17050
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.2860495448112488,
      "learning_rate": 0.00017811328,
      "loss": 2.1061,
      "step": 17100
    },
    {
      "epoch": 0.5488,
      "grad_norm": 0.26166242361068726,
      "learning_rate": 0.00017804928,
      "loss": 2.1892,
      "step": 17150
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.31384313106536865,
      "learning_rate": 0.00017798528000000002,
      "loss": 2.1771,
      "step": 17200
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.31680917739868164,
      "learning_rate": 0.00017792128,
      "loss": 2.1915,
      "step": 17250
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.3019963204860687,
      "learning_rate": 0.00017785728,
      "loss": 2.1712,
      "step": 17300
    },
    {
      "epoch": 0.5552,
      "grad_norm": 0.2398471236228943,
      "learning_rate": 0.00017779328000000003,
      "loss": 2.0946,
      "step": 17350
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.28368616104125977,
      "learning_rate": 0.00017772928,
      "loss": 2.1017,
      "step": 17400
    },
    {
      "epoch": 0.5584,
      "grad_norm": 0.23217599093914032,
      "learning_rate": 0.00017766528,
      "loss": 2.1651,
      "step": 17450
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.24277760088443756,
      "learning_rate": 0.00017760128000000002,
      "loss": 2.1747,
      "step": 17500
    },
    {
      "epoch": 0.5616,
      "grad_norm": 0.2968888282775879,
      "learning_rate": 0.00017753728,
      "loss": 2.1849,
      "step": 17550
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.29198360443115234,
      "learning_rate": 0.00017747328,
      "loss": 2.139,
      "step": 17600
    },
    {
      "epoch": 0.5648,
      "grad_norm": 0.2652333676815033,
      "learning_rate": 0.00017740928,
      "loss": 2.1156,
      "step": 17650
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.23962841928005219,
      "learning_rate": 0.00017734528000000002,
      "loss": 2.1453,
      "step": 17700
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.2919600009918213,
      "learning_rate": 0.00017728128000000002,
      "loss": 2.1745,
      "step": 17750
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.2787650227546692,
      "learning_rate": 0.00017721728000000001,
      "loss": 2.1896,
      "step": 17800
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.31088292598724365,
      "learning_rate": 0.00017715328,
      "loss": 2.1541,
      "step": 17850
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.2684009075164795,
      "learning_rate": 0.00017708928,
      "loss": 2.1977,
      "step": 17900
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.25372767448425293,
      "learning_rate": 0.00017702528,
      "loss": 2.0886,
      "step": 17950
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.274857759475708,
      "learning_rate": 0.00017696128,
      "loss": 2.1248,
      "step": 18000
    },
    {
      "epoch": 0.5776,
      "grad_norm": 0.27887097001075745,
      "learning_rate": 0.00017689728000000002,
      "loss": 2.1555,
      "step": 18050
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.3187732398509979,
      "learning_rate": 0.00017683328,
      "loss": 2.2257,
      "step": 18100
    },
    {
      "epoch": 0.5808,
      "grad_norm": 0.31108328700065613,
      "learning_rate": 0.00017676928,
      "loss": 2.1665,
      "step": 18150
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.2958056628704071,
      "learning_rate": 0.00017670528000000003,
      "loss": 2.1652,
      "step": 18200
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.2509506046772003,
      "learning_rate": 0.00017664128,
      "loss": 2.0726,
      "step": 18250
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.2556023597717285,
      "learning_rate": 0.00017657728,
      "loss": 2.1717,
      "step": 18300
    },
    {
      "epoch": 0.5872,
      "grad_norm": 0.3176337778568268,
      "learning_rate": 0.00017651328000000002,
      "loss": 2.138,
      "step": 18350
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.28230762481689453,
      "learning_rate": 0.00017644928,
      "loss": 2.1551,
      "step": 18400
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.2625851035118103,
      "learning_rate": 0.00017638528,
      "loss": 2.1921,
      "step": 18450
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.2417536824941635,
      "learning_rate": 0.00017632128,
      "loss": 2.1735,
      "step": 18500
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.2754395604133606,
      "learning_rate": 0.00017625728000000002,
      "loss": 2.1381,
      "step": 18550
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.2476757913827896,
      "learning_rate": 0.00017619328000000002,
      "loss": 2.1219,
      "step": 18600
    },
    {
      "epoch": 0.5968,
      "grad_norm": 0.31180500984191895,
      "learning_rate": 0.00017612928,
      "loss": 2.1112,
      "step": 18650
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.29279825091362,
      "learning_rate": 0.00017606528,
      "loss": 2.139,
      "step": 18700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.2625661790370941,
      "learning_rate": 0.00017600128,
      "loss": 2.1793,
      "step": 18750
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.2649514675140381,
      "learning_rate": 0.00017593728,
      "loss": 2.162,
      "step": 18800
    },
    {
      "epoch": 0.6032,
      "grad_norm": 0.3023662567138672,
      "learning_rate": 0.00017587328,
      "loss": 2.1634,
      "step": 18850
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.24465619027614594,
      "learning_rate": 0.00017580928000000002,
      "loss": 2.1604,
      "step": 18900
    },
    {
      "epoch": 0.6064,
      "grad_norm": 0.25707313418388367,
      "learning_rate": 0.00017574528,
      "loss": 2.1756,
      "step": 18950
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.27104783058166504,
      "learning_rate": 0.00017568128,
      "loss": 2.1799,
      "step": 19000
    },
    {
      "epoch": 0.6096,
      "grad_norm": 0.23992910981178284,
      "learning_rate": 0.00017561728000000003,
      "loss": 2.1605,
      "step": 19050
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.24551168084144592,
      "learning_rate": 0.00017555328,
      "loss": 2.1075,
      "step": 19100
    },
    {
      "epoch": 0.6128,
      "grad_norm": 0.2631140351295471,
      "learning_rate": 0.00017548928,
      "loss": 2.0948,
      "step": 19150
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.25642192363739014,
      "learning_rate": 0.00017542528000000001,
      "loss": 2.1649,
      "step": 19200
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.2658209502696991,
      "learning_rate": 0.00017536128,
      "loss": 2.2161,
      "step": 19250
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.2638939917087555,
      "learning_rate": 0.00017529728,
      "loss": 2.1652,
      "step": 19300
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.2837983965873718,
      "learning_rate": 0.00017523328,
      "loss": 2.0949,
      "step": 19350
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.24679037928581238,
      "learning_rate": 0.00017516928000000002,
      "loss": 2.1637,
      "step": 19400
    },
    {
      "epoch": 0.6224,
      "grad_norm": 0.22768932580947876,
      "learning_rate": 0.00017510528000000002,
      "loss": 2.1661,
      "step": 19450
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.2499724179506302,
      "learning_rate": 0.00017504128,
      "loss": 2.1537,
      "step": 19500
    },
    {
      "epoch": 0.6256,
      "grad_norm": 0.3039083778858185,
      "learning_rate": 0.00017497728,
      "loss": 2.1303,
      "step": 19550
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.2564828395843506,
      "learning_rate": 0.00017491328,
      "loss": 2.1058,
      "step": 19600
    },
    {
      "epoch": 0.6288,
      "grad_norm": 0.26404982805252075,
      "learning_rate": 0.00017484928,
      "loss": 2.1397,
      "step": 19650
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.36385056376457214,
      "learning_rate": 0.00017478528,
      "loss": 2.1505,
      "step": 19700
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.23951441049575806,
      "learning_rate": 0.00017472128000000002,
      "loss": 2.1521,
      "step": 19750
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.29749295115470886,
      "learning_rate": 0.00017465728,
      "loss": 2.1372,
      "step": 19800
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.26823803782463074,
      "learning_rate": 0.00017459328,
      "loss": 2.1731,
      "step": 19850
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.2878926694393158,
      "learning_rate": 0.00017452928000000003,
      "loss": 2.1564,
      "step": 19900
    },
    {
      "epoch": 0.6384,
      "grad_norm": 0.32312461733818054,
      "learning_rate": 0.00017446528,
      "loss": 2.0751,
      "step": 19950
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2844591438770294,
      "learning_rate": 0.00017440128,
      "loss": 2.1369,
      "step": 20000
    },
    {
      "epoch": 0.6416,
      "grad_norm": 0.29633858799934387,
      "learning_rate": 0.00017433728000000001,
      "loss": 2.1071,
      "step": 20050
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.2803076207637787,
      "learning_rate": 0.00017427328,
      "loss": 2.1116,
      "step": 20100
    },
    {
      "epoch": 0.6448,
      "grad_norm": 0.30752402544021606,
      "learning_rate": 0.00017420928,
      "loss": 2.1568,
      "step": 20150
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.2955527603626251,
      "learning_rate": 0.00017414528,
      "loss": 2.1367,
      "step": 20200
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.27720749378204346,
      "learning_rate": 0.00017408128000000002,
      "loss": 2.1067,
      "step": 20250
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.31692516803741455,
      "learning_rate": 0.00017401728000000002,
      "loss": 2.2182,
      "step": 20300
    },
    {
      "epoch": 0.6512,
      "grad_norm": 0.2733995318412781,
      "learning_rate": 0.00017395328,
      "loss": 2.1491,
      "step": 20350
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.30252939462661743,
      "learning_rate": 0.00017388928,
      "loss": 2.1806,
      "step": 20400
    },
    {
      "epoch": 0.6544,
      "grad_norm": 0.260277658700943,
      "learning_rate": 0.00017382528,
      "loss": 2.0909,
      "step": 20450
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.2763664126396179,
      "learning_rate": 0.00017376128,
      "loss": 2.1205,
      "step": 20500
    },
    {
      "epoch": 0.6576,
      "grad_norm": 0.3010287582874298,
      "learning_rate": 0.00017369728,
      "loss": 2.1409,
      "step": 20550
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.27745169401168823,
      "learning_rate": 0.00017363328000000002,
      "loss": 2.1626,
      "step": 20600
    },
    {
      "epoch": 0.6608,
      "grad_norm": 0.35454609990119934,
      "learning_rate": 0.00017356928,
      "loss": 2.1474,
      "step": 20650
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.2515799403190613,
      "learning_rate": 0.00017350528,
      "loss": 2.1521,
      "step": 20700
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.3657725155353546,
      "learning_rate": 0.00017344128000000003,
      "loss": 2.1837,
      "step": 20750
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.2801712155342102,
      "learning_rate": 0.00017337728,
      "loss": 2.1538,
      "step": 20800
    },
    {
      "epoch": 0.6672,
      "grad_norm": 0.32217004895210266,
      "learning_rate": 0.00017331328,
      "loss": 2.1321,
      "step": 20850
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.26088830828666687,
      "learning_rate": 0.00017324928000000001,
      "loss": 2.1362,
      "step": 20900
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.23415055871009827,
      "learning_rate": 0.00017318528,
      "loss": 2.1239,
      "step": 20950
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.29772084951400757,
      "learning_rate": 0.00017312128,
      "loss": 2.094,
      "step": 21000
    },
    {
      "epoch": 0.6736,
      "grad_norm": 0.2990715205669403,
      "learning_rate": 0.00017305728,
      "loss": 2.1751,
      "step": 21050
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.34767094254493713,
      "learning_rate": 0.00017299328000000002,
      "loss": 2.1803,
      "step": 21100
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.27495071291923523,
      "learning_rate": 0.00017292928000000002,
      "loss": 2.1158,
      "step": 21150
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.2894381582736969,
      "learning_rate": 0.00017286528,
      "loss": 2.1343,
      "step": 21200
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.27025359869003296,
      "learning_rate": 0.00017280128,
      "loss": 2.1498,
      "step": 21250
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.3318804204463959,
      "learning_rate": 0.00017273728,
      "loss": 2.1443,
      "step": 21300
    },
    {
      "epoch": 0.6832,
      "grad_norm": 0.3824673891067505,
      "learning_rate": 0.00017267328,
      "loss": 2.1253,
      "step": 21350
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.25900861620903015,
      "learning_rate": 0.00017260928000000002,
      "loss": 2.2455,
      "step": 21400
    },
    {
      "epoch": 0.6864,
      "grad_norm": 0.2623404562473297,
      "learning_rate": 0.00017254528000000002,
      "loss": 2.173,
      "step": 21450
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.297936350107193,
      "learning_rate": 0.00017248128,
      "loss": 2.1693,
      "step": 21500
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.2211238145828247,
      "learning_rate": 0.00017241728,
      "loss": 2.0308,
      "step": 21550
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.27409103512763977,
      "learning_rate": 0.00017235328000000003,
      "loss": 2.1369,
      "step": 21600
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.2886769473552704,
      "learning_rate": 0.00017228928,
      "loss": 2.1907,
      "step": 21650
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.31305181980133057,
      "learning_rate": 0.00017222528,
      "loss": 2.1691,
      "step": 21700
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.2880699932575226,
      "learning_rate": 0.00017216128,
      "loss": 2.1697,
      "step": 21750
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.26253190636634827,
      "learning_rate": 0.00017209728,
      "loss": 2.1714,
      "step": 21800
    },
    {
      "epoch": 0.6992,
      "grad_norm": 0.2190925031900406,
      "learning_rate": 0.00017203328,
      "loss": 2.1876,
      "step": 21850
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.2567237317562103,
      "learning_rate": 0.00017196928,
      "loss": 2.1721,
      "step": 21900
    },
    {
      "epoch": 0.7024,
      "grad_norm": 0.315927118062973,
      "learning_rate": 0.00017190528000000002,
      "loss": 2.2079,
      "step": 21950
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.28947094082832336,
      "learning_rate": 0.00017184128000000002,
      "loss": 2.1514,
      "step": 22000
    },
    {
      "epoch": 0.7056,
      "grad_norm": 0.26198965311050415,
      "learning_rate": 0.00017177728,
      "loss": 2.1306,
      "step": 22050
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.27417615056037903,
      "learning_rate": 0.00017171328,
      "loss": 2.1277,
      "step": 22100
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.28006500005722046,
      "learning_rate": 0.00017164928,
      "loss": 2.1679,
      "step": 22150
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.2503058910369873,
      "learning_rate": 0.00017158528,
      "loss": 2.0997,
      "step": 22200
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.26769301295280457,
      "learning_rate": 0.00017152128000000002,
      "loss": 2.1373,
      "step": 22250
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.24515655636787415,
      "learning_rate": 0.00017145728000000001,
      "loss": 2.1594,
      "step": 22300
    },
    {
      "epoch": 0.7152,
      "grad_norm": 0.3827642798423767,
      "learning_rate": 0.00017139328,
      "loss": 2.2,
      "step": 22350
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.35313117504119873,
      "learning_rate": 0.00017132928,
      "loss": 2.1424,
      "step": 22400
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.28727197647094727,
      "learning_rate": 0.00017126528000000003,
      "loss": 2.1386,
      "step": 22450
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.31311967968940735,
      "learning_rate": 0.00017120128,
      "loss": 2.1719,
      "step": 22500
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.2784738838672638,
      "learning_rate": 0.00017113728,
      "loss": 2.1766,
      "step": 22550
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.28266721963882446,
      "learning_rate": 0.00017107328,
      "loss": 2.1872,
      "step": 22600
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.28176596760749817,
      "learning_rate": 0.00017100928,
      "loss": 2.1542,
      "step": 22650
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.2777315080165863,
      "learning_rate": 0.00017094528,
      "loss": 2.1558,
      "step": 22700
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.292664498090744,
      "learning_rate": 0.00017088128,
      "loss": 2.1482,
      "step": 22750
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.2385208159685135,
      "learning_rate": 0.00017081728000000002,
      "loss": 2.1141,
      "step": 22800
    },
    {
      "epoch": 0.7312,
      "grad_norm": 0.2560923397541046,
      "learning_rate": 0.00017075328000000002,
      "loss": 2.1778,
      "step": 22850
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.29675060510635376,
      "learning_rate": 0.00017068928,
      "loss": 2.0995,
      "step": 22900
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.2694939970970154,
      "learning_rate": 0.00017062528,
      "loss": 2.122,
      "step": 22950
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.24810318648815155,
      "learning_rate": 0.00017056128,
      "loss": 2.1924,
      "step": 23000
    },
    {
      "epoch": 0.7376,
      "grad_norm": 0.30772268772125244,
      "learning_rate": 0.00017049728,
      "loss": 2.1838,
      "step": 23050
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.27664095163345337,
      "learning_rate": 0.00017043328000000002,
      "loss": 2.1889,
      "step": 23100
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.2665746510028839,
      "learning_rate": 0.00017036928000000001,
      "loss": 2.1753,
      "step": 23150
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.2826070487499237,
      "learning_rate": 0.00017030528,
      "loss": 2.2029,
      "step": 23200
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.3323623239994049,
      "learning_rate": 0.00017024128,
      "loss": 2.0661,
      "step": 23250
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.33926883339881897,
      "learning_rate": 0.00017017728000000003,
      "loss": 2.1418,
      "step": 23300
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.25648871064186096,
      "learning_rate": 0.00017011328,
      "loss": 2.1241,
      "step": 23350
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.24572421610355377,
      "learning_rate": 0.00017004928,
      "loss": 2.1268,
      "step": 23400
    },
    {
      "epoch": 0.7504,
      "grad_norm": 0.3113921880722046,
      "learning_rate": 0.00016998528,
      "loss": 2.0807,
      "step": 23450
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.3010880649089813,
      "learning_rate": 0.00016992128,
      "loss": 2.1535,
      "step": 23500
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.3083306550979614,
      "learning_rate": 0.00016985728,
      "loss": 2.128,
      "step": 23550
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.281295508146286,
      "learning_rate": 0.00016979328,
      "loss": 2.2203,
      "step": 23600
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.34605327248573303,
      "learning_rate": 0.00016972928000000002,
      "loss": 2.2188,
      "step": 23650
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.2481020987033844,
      "learning_rate": 0.00016966528000000002,
      "loss": 2.1137,
      "step": 23700
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.2616407573223114,
      "learning_rate": 0.00016960128,
      "loss": 2.1537,
      "step": 23750
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.27110403776168823,
      "learning_rate": 0.00016953728,
      "loss": 2.1154,
      "step": 23800
    },
    {
      "epoch": 0.7632,
      "grad_norm": 0.2965042293071747,
      "learning_rate": 0.00016947328,
      "loss": 2.1794,
      "step": 23850
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.2488376498222351,
      "learning_rate": 0.00016940928,
      "loss": 2.1264,
      "step": 23900
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.4046272039413452,
      "learning_rate": 0.00016934528000000002,
      "loss": 2.125,
      "step": 23950
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.2630384862422943,
      "learning_rate": 0.00016928128000000001,
      "loss": 2.0612,
      "step": 24000
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.2815447449684143,
      "learning_rate": 0.00016921728,
      "loss": 2.1577,
      "step": 24050
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.25314679741859436,
      "learning_rate": 0.00016915328,
      "loss": 2.1365,
      "step": 24100
    },
    {
      "epoch": 0.7728,
      "grad_norm": 0.2842964828014374,
      "learning_rate": 0.00016908928000000003,
      "loss": 2.1824,
      "step": 24150
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.2782552242279053,
      "learning_rate": 0.00016902528000000002,
      "loss": 2.1371,
      "step": 24200
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.2702459692955017,
      "learning_rate": 0.00016896128,
      "loss": 2.1952,
      "step": 24250
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.36168795824050903,
      "learning_rate": 0.00016889728,
      "loss": 2.1496,
      "step": 24300
    },
    {
      "epoch": 0.7792,
      "grad_norm": 0.3076241612434387,
      "learning_rate": 0.00016883328,
      "loss": 2.0919,
      "step": 24350
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.3376978933811188,
      "learning_rate": 0.00016876928,
      "loss": 2.1232,
      "step": 24400
    },
    {
      "epoch": 0.7824,
      "grad_norm": 0.2863687574863434,
      "learning_rate": 0.00016870528,
      "loss": 2.1654,
      "step": 24450
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.27074259519577026,
      "learning_rate": 0.00016864128000000002,
      "loss": 2.1187,
      "step": 24500
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.3312731385231018,
      "learning_rate": 0.00016857728000000002,
      "loss": 2.1179,
      "step": 24550
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.27624180912971497,
      "learning_rate": 0.00016851328,
      "loss": 2.1531,
      "step": 24600
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.24320314824581146,
      "learning_rate": 0.00016844928,
      "loss": 2.1325,
      "step": 24650
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.2525066137313843,
      "learning_rate": 0.00016838528,
      "loss": 2.1426,
      "step": 24700
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.24765679240226746,
      "learning_rate": 0.00016832128,
      "loss": 2.1371,
      "step": 24750
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.2871890962123871,
      "learning_rate": 0.00016825728000000002,
      "loss": 2.0652,
      "step": 24800
    },
    {
      "epoch": 0.7952,
      "grad_norm": 0.2504695653915405,
      "learning_rate": 0.00016819328,
      "loss": 2.1319,
      "step": 24850
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.28969132900238037,
      "learning_rate": 0.00016812928,
      "loss": 2.1275,
      "step": 24900
    },
    {
      "epoch": 0.7984,
      "grad_norm": 0.250731885433197,
      "learning_rate": 0.00016806528,
      "loss": 2.1268,
      "step": 24950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2904518246650696,
      "learning_rate": 0.00016800128000000003,
      "loss": 2.1173,
      "step": 25000
    },
    {
      "epoch": 0.8016,
      "grad_norm": 0.2487274557352066,
      "learning_rate": 0.00016793728000000002,
      "loss": 2.1115,
      "step": 25050
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.3135547935962677,
      "learning_rate": 0.00016787328,
      "loss": 2.1005,
      "step": 25100
    },
    {
      "epoch": 0.8048,
      "grad_norm": 0.25021472573280334,
      "learning_rate": 0.00016780928,
      "loss": 2.1041,
      "step": 25150
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.2910267114639282,
      "learning_rate": 0.00016774528,
      "loss": 2.1083,
      "step": 25200
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.3253539502620697,
      "learning_rate": 0.00016768128,
      "loss": 2.1598,
      "step": 25250
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.32664820551872253,
      "learning_rate": 0.00016761728,
      "loss": 2.1112,
      "step": 25300
    },
    {
      "epoch": 0.8112,
      "grad_norm": 0.30555403232574463,
      "learning_rate": 0.00016755328000000002,
      "loss": 2.2111,
      "step": 25350
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.2634319067001343,
      "learning_rate": 0.00016748928000000001,
      "loss": 2.1347,
      "step": 25400
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.26800987124443054,
      "learning_rate": 0.00016742528,
      "loss": 2.1456,
      "step": 25450
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.27943485975265503,
      "learning_rate": 0.00016736128,
      "loss": 2.1435,
      "step": 25500
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.2743333578109741,
      "learning_rate": 0.00016729728,
      "loss": 2.15,
      "step": 25550
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.2562238872051239,
      "learning_rate": 0.00016723328,
      "loss": 2.1268,
      "step": 25600
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.2729760706424713,
      "learning_rate": 0.00016716928000000002,
      "loss": 2.1951,
      "step": 25650
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.2804981768131256,
      "learning_rate": 0.00016710528,
      "loss": 2.2191,
      "step": 25700
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.28192979097366333,
      "learning_rate": 0.00016704128,
      "loss": 2.1312,
      "step": 25750
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.2879529297351837,
      "learning_rate": 0.00016697728,
      "loss": 2.1504,
      "step": 25800
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.42370378971099854,
      "learning_rate": 0.00016691328000000003,
      "loss": 2.1673,
      "step": 25850
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.27636417746543884,
      "learning_rate": 0.00016684928000000002,
      "loss": 2.165,
      "step": 25900
    },
    {
      "epoch": 0.8304,
      "grad_norm": 0.29029300808906555,
      "learning_rate": 0.00016678528,
      "loss": 2.1558,
      "step": 25950
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.24957141280174255,
      "learning_rate": 0.00016672128,
      "loss": 2.185,
      "step": 26000
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.24752652645111084,
      "learning_rate": 0.00016665728,
      "loss": 2.144,
      "step": 26050
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.30335310101509094,
      "learning_rate": 0.00016659328,
      "loss": 2.1568,
      "step": 26100
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.25861215591430664,
      "learning_rate": 0.00016652928,
      "loss": 2.167,
      "step": 26150
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.26823002099990845,
      "learning_rate": 0.00016646528000000002,
      "loss": 2.1693,
      "step": 26200
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.30251115560531616,
      "learning_rate": 0.00016640128000000001,
      "loss": 2.1025,
      "step": 26250
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.22999441623687744,
      "learning_rate": 0.00016633728,
      "loss": 2.1835,
      "step": 26300
    },
    {
      "epoch": 0.8432,
      "grad_norm": 0.28273826837539673,
      "learning_rate": 0.00016627328,
      "loss": 2.14,
      "step": 26350
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.3179306387901306,
      "learning_rate": 0.00016620928,
      "loss": 2.1633,
      "step": 26400
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.24315513670444489,
      "learning_rate": 0.00016614528,
      "loss": 2.1708,
      "step": 26450
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.3183077275753021,
      "learning_rate": 0.00016608128000000002,
      "loss": 2.088,
      "step": 26500
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.28548234701156616,
      "learning_rate": 0.00016601728,
      "loss": 2.1173,
      "step": 26550
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.31080254912376404,
      "learning_rate": 0.00016595328,
      "loss": 2.1397,
      "step": 26600
    },
    {
      "epoch": 0.8528,
      "grad_norm": 0.2537405788898468,
      "learning_rate": 0.00016588928,
      "loss": 2.0918,
      "step": 26650
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.3129647672176361,
      "learning_rate": 0.00016582528000000003,
      "loss": 2.1089,
      "step": 26700
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.29891934990882874,
      "learning_rate": 0.00016576128000000002,
      "loss": 2.1898,
      "step": 26750
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.26079198718070984,
      "learning_rate": 0.00016569728,
      "loss": 2.1509,
      "step": 26800
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.2550455331802368,
      "learning_rate": 0.00016563328,
      "loss": 2.1403,
      "step": 26850
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.2872554659843445,
      "learning_rate": 0.00016556928,
      "loss": 2.0906,
      "step": 26900
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.2600608468055725,
      "learning_rate": 0.00016550528,
      "loss": 2.069,
      "step": 26950
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.3094331920146942,
      "learning_rate": 0.00016544128,
      "loss": 2.1086,
      "step": 27000
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.30158746242523193,
      "learning_rate": 0.00016537728000000002,
      "loss": 2.192,
      "step": 27050
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.2985874116420746,
      "learning_rate": 0.00016531328000000001,
      "loss": 2.1874,
      "step": 27100
    },
    {
      "epoch": 0.8688,
      "grad_norm": 0.24744945764541626,
      "learning_rate": 0.00016524928,
      "loss": 2.1066,
      "step": 27150
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.33463364839553833,
      "learning_rate": 0.00016518528,
      "loss": 2.1072,
      "step": 27200
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.29857513308525085,
      "learning_rate": 0.00016512128,
      "loss": 2.1195,
      "step": 27250
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.36789366602897644,
      "learning_rate": 0.00016505728,
      "loss": 2.1056,
      "step": 27300
    },
    {
      "epoch": 0.8752,
      "grad_norm": 0.3224678337574005,
      "learning_rate": 0.00016499328000000002,
      "loss": 2.2129,
      "step": 27350
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.29464074969291687,
      "learning_rate": 0.00016492928,
      "loss": 2.107,
      "step": 27400
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.5154110193252563,
      "learning_rate": 0.00016486528,
      "loss": 2.1415,
      "step": 27450
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.32055947184562683,
      "learning_rate": 0.00016480128,
      "loss": 2.1322,
      "step": 27500
    },
    {
      "epoch": 0.8816,
      "grad_norm": 0.2872247099876404,
      "learning_rate": 0.00016473728000000002,
      "loss": 2.1568,
      "step": 27550
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.28095048666000366,
      "learning_rate": 0.00016467328000000002,
      "loss": 2.1537,
      "step": 27600
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.2978549897670746,
      "learning_rate": 0.00016460928,
      "loss": 2.1696,
      "step": 27650
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.27867329120635986,
      "learning_rate": 0.00016454528,
      "loss": 2.1805,
      "step": 27700
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.2543591856956482,
      "learning_rate": 0.00016448128,
      "loss": 2.1905,
      "step": 27750
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.2827357053756714,
      "learning_rate": 0.00016441728,
      "loss": 2.1476,
      "step": 27800
    },
    {
      "epoch": 0.8912,
      "grad_norm": 0.2543320953845978,
      "learning_rate": 0.00016435328000000002,
      "loss": 2.1392,
      "step": 27850
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.4125365912914276,
      "learning_rate": 0.00016428928000000002,
      "loss": 2.1889,
      "step": 27900
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.24189789593219757,
      "learning_rate": 0.00016422528,
      "loss": 2.1368,
      "step": 27950
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.3126293122768402,
      "learning_rate": 0.00016416128,
      "loss": 2.175,
      "step": 28000
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.26867377758026123,
      "learning_rate": 0.00016409728,
      "loss": 2.151,
      "step": 28050
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.24803611636161804,
      "learning_rate": 0.00016403328,
      "loss": 2.1331,
      "step": 28100
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.3042135536670685,
      "learning_rate": 0.00016396928,
      "loss": 2.1572,
      "step": 28150
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.2941591143608093,
      "learning_rate": 0.00016390528000000002,
      "loss": 2.1307,
      "step": 28200
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.3068472743034363,
      "learning_rate": 0.00016384128,
      "loss": 2.0926,
      "step": 28250
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.25952908396720886,
      "learning_rate": 0.00016377728,
      "loss": 2.138,
      "step": 28300
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.35053113102912903,
      "learning_rate": 0.00016371328,
      "loss": 2.0789,
      "step": 28350
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.29313376545906067,
      "learning_rate": 0.00016364928000000002,
      "loss": 2.1314,
      "step": 28400
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.32536861300468445,
      "learning_rate": 0.00016358528000000002,
      "loss": 2.2031,
      "step": 28450
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.24377089738845825,
      "learning_rate": 0.00016352128,
      "loss": 2.1572,
      "step": 28500
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.2562209665775299,
      "learning_rate": 0.00016345728,
      "loss": 2.1515,
      "step": 28550
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.2967490553855896,
      "learning_rate": 0.00016339328,
      "loss": 2.1834,
      "step": 28600
    },
    {
      "epoch": 0.9168,
      "grad_norm": 0.3531554341316223,
      "learning_rate": 0.00016332928,
      "loss": 2.0956,
      "step": 28650
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.31699272990226746,
      "learning_rate": 0.00016326528000000002,
      "loss": 2.1068,
      "step": 28700
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.2891892194747925,
      "learning_rate": 0.00016320128000000002,
      "loss": 2.0824,
      "step": 28750
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.2836899757385254,
      "learning_rate": 0.00016313728,
      "loss": 2.1896,
      "step": 28800
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.28830111026763916,
      "learning_rate": 0.00016307328,
      "loss": 2.168,
      "step": 28850
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.26527661085128784,
      "learning_rate": 0.00016300928,
      "loss": 2.1337,
      "step": 28900
    },
    {
      "epoch": 0.9264,
      "grad_norm": 0.25938522815704346,
      "learning_rate": 0.00016294528,
      "loss": 2.0693,
      "step": 28950
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.37327784299850464,
      "learning_rate": 0.00016288128,
      "loss": 2.1515,
      "step": 29000
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.2504086494445801,
      "learning_rate": 0.00016281728000000002,
      "loss": 2.1127,
      "step": 29050
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.31557244062423706,
      "learning_rate": 0.00016275328,
      "loss": 2.1806,
      "step": 29100
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.31108078360557556,
      "learning_rate": 0.00016268928,
      "loss": 2.1464,
      "step": 29150
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.28602418303489685,
      "learning_rate": 0.00016262528,
      "loss": 2.1969,
      "step": 29200
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.33843958377838135,
      "learning_rate": 0.00016256128000000002,
      "loss": 2.1395,
      "step": 29250
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.2870118319988251,
      "learning_rate": 0.00016249728000000002,
      "loss": 2.1388,
      "step": 29300
    },
    {
      "epoch": 0.9392,
      "grad_norm": 0.3014293611049652,
      "learning_rate": 0.00016243328,
      "loss": 2.1685,
      "step": 29350
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.31104183197021484,
      "learning_rate": 0.00016236928,
      "loss": 2.0957,
      "step": 29400
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.28060877323150635,
      "learning_rate": 0.00016230528,
      "loss": 2.1879,
      "step": 29450
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.2772318720817566,
      "learning_rate": 0.00016224128,
      "loss": 2.097,
      "step": 29500
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.2887239158153534,
      "learning_rate": 0.00016217728000000002,
      "loss": 2.1694,
      "step": 29550
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.31222671270370483,
      "learning_rate": 0.00016211328000000002,
      "loss": 2.1061,
      "step": 29600
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.2689902186393738,
      "learning_rate": 0.00016204928,
      "loss": 2.1326,
      "step": 29650
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.27651819586753845,
      "learning_rate": 0.00016198528,
      "loss": 2.1621,
      "step": 29700
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.266981303691864,
      "learning_rate": 0.00016192128,
      "loss": 2.1096,
      "step": 29750
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.32879388332366943,
      "learning_rate": 0.00016185728,
      "loss": 2.1726,
      "step": 29800
    },
    {
      "epoch": 0.9552,
      "grad_norm": 0.3622817099094391,
      "learning_rate": 0.00016179328,
      "loss": 2.1376,
      "step": 29850
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.27641570568084717,
      "learning_rate": 0.00016172928000000002,
      "loss": 2.1583,
      "step": 29900
    },
    {
      "epoch": 0.9584,
      "grad_norm": 0.2724153995513916,
      "learning_rate": 0.00016166528,
      "loss": 2.1447,
      "step": 29950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3019944131374359,
      "learning_rate": 0.00016160128,
      "loss": 2.1234,
      "step": 30000
    },
    {
      "epoch": 0.9616,
      "grad_norm": 0.2884368598461151,
      "learning_rate": 0.00016153728,
      "loss": 2.0811,
      "step": 30050
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.27620211243629456,
      "learning_rate": 0.00016147328000000002,
      "loss": 2.1941,
      "step": 30100
    },
    {
      "epoch": 0.9648,
      "grad_norm": 0.2608657479286194,
      "learning_rate": 0.00016140928000000002,
      "loss": 2.2149,
      "step": 30150
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.2598130404949188,
      "learning_rate": 0.00016134528,
      "loss": 2.1592,
      "step": 30200
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.2672680914402008,
      "learning_rate": 0.00016128128,
      "loss": 2.1141,
      "step": 30250
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.2911691963672638,
      "learning_rate": 0.00016121728,
      "loss": 2.1543,
      "step": 30300
    },
    {
      "epoch": 0.9712,
      "grad_norm": 0.31734541058540344,
      "learning_rate": 0.00016115328,
      "loss": 2.1447,
      "step": 30350
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.3701321482658386,
      "learning_rate": 0.00016108928000000002,
      "loss": 2.1054,
      "step": 30400
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.26592108607292175,
      "learning_rate": 0.00016102528000000002,
      "loss": 2.0937,
      "step": 30450
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.33526208996772766,
      "learning_rate": 0.00016096128,
      "loss": 2.1347,
      "step": 30500
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.27598142623901367,
      "learning_rate": 0.00016089728,
      "loss": 2.1104,
      "step": 30550
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.2668483257293701,
      "learning_rate": 0.00016083328,
      "loss": 2.2038,
      "step": 30600
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.26722630858421326,
      "learning_rate": 0.00016076928,
      "loss": 2.1137,
      "step": 30650
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.27286070585250854,
      "learning_rate": 0.00016070528,
      "loss": 2.118,
      "step": 30700
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.35014769434928894,
      "learning_rate": 0.00016064128000000002,
      "loss": 2.1582,
      "step": 30750
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.30740025639533997,
      "learning_rate": 0.00016057728,
      "loss": 2.1114,
      "step": 30800
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.2663349211215973,
      "learning_rate": 0.00016051328,
      "loss": 2.2018,
      "step": 30850
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.2839909791946411,
      "learning_rate": 0.00016044928,
      "loss": 2.0531,
      "step": 30900
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.2563924789428711,
      "learning_rate": 0.00016038528000000002,
      "loss": 2.1469,
      "step": 30950
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.2750755250453949,
      "learning_rate": 0.00016032128000000002,
      "loss": 2.1578,
      "step": 31000
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.3828398585319519,
      "learning_rate": 0.00016025727999999999,
      "loss": 2.1612,
      "step": 31050
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.3008253276348114,
      "learning_rate": 0.00016019328,
      "loss": 2.1076,
      "step": 31100
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.3164689540863037,
      "learning_rate": 0.00016012928,
      "loss": 2.1695,
      "step": 31150
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.2861156165599823,
      "learning_rate": 0.00016006528,
      "loss": 2.2223,
      "step": 31200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3335442543029785,
      "learning_rate": 0.00016000128000000002,
      "loss": 2.1736,
      "step": 31250
    },
    {
      "epoch": 1.0016,
      "grad_norm": 0.3161354959011078,
      "learning_rate": 0.00015993728000000002,
      "loss": 2.1363,
      "step": 31300
    },
    {
      "epoch": 1.0032,
      "grad_norm": 0.2891444265842438,
      "learning_rate": 0.00015987328,
      "loss": 2.1384,
      "step": 31350
    },
    {
      "epoch": 1.0048,
      "grad_norm": 0.2692623734474182,
      "learning_rate": 0.00015980928,
      "loss": 2.1371,
      "step": 31400
    },
    {
      "epoch": 1.0064,
      "grad_norm": 0.3020114302635193,
      "learning_rate": 0.00015974528,
      "loss": 2.1405,
      "step": 31450
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.2518236041069031,
      "learning_rate": 0.00015968128,
      "loss": 2.1427,
      "step": 31500
    },
    {
      "epoch": 1.0096,
      "grad_norm": 0.32687437534332275,
      "learning_rate": 0.00015961728,
      "loss": 2.1483,
      "step": 31550
    },
    {
      "epoch": 1.0112,
      "grad_norm": 0.2793926000595093,
      "learning_rate": 0.00015955328000000001,
      "loss": 2.0885,
      "step": 31600
    },
    {
      "epoch": 1.0128,
      "grad_norm": 0.28430819511413574,
      "learning_rate": 0.00015948928,
      "loss": 2.1192,
      "step": 31650
    },
    {
      "epoch": 1.0144,
      "grad_norm": 0.30508074164390564,
      "learning_rate": 0.00015942528,
      "loss": 2.2164,
      "step": 31700
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.29122480750083923,
      "learning_rate": 0.00015936128,
      "loss": 2.1664,
      "step": 31750
    },
    {
      "epoch": 1.0176,
      "grad_norm": 0.3411315083503723,
      "learning_rate": 0.00015929728000000002,
      "loss": 2.1018,
      "step": 31800
    },
    {
      "epoch": 1.0192,
      "grad_norm": 0.2828892767429352,
      "learning_rate": 0.00015923328000000002,
      "loss": 2.1336,
      "step": 31850
    },
    {
      "epoch": 1.0208,
      "grad_norm": 0.37089815735816956,
      "learning_rate": 0.00015916927999999999,
      "loss": 2.1681,
      "step": 31900
    },
    {
      "epoch": 1.0224,
      "grad_norm": 0.2437780350446701,
      "learning_rate": 0.00015910528,
      "loss": 2.1409,
      "step": 31950
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.2300546020269394,
      "learning_rate": 0.00015904128,
      "loss": 2.1272,
      "step": 32000
    },
    {
      "epoch": 1.0256,
      "grad_norm": 0.31600648164749146,
      "learning_rate": 0.00015897728,
      "loss": 2.0659,
      "step": 32050
    },
    {
      "epoch": 1.0272,
      "grad_norm": 0.3111324906349182,
      "learning_rate": 0.00015891328000000002,
      "loss": 2.144,
      "step": 32100
    },
    {
      "epoch": 1.0288,
      "grad_norm": 0.3189118504524231,
      "learning_rate": 0.00015884928000000002,
      "loss": 2.1865,
      "step": 32150
    },
    {
      "epoch": 1.0304,
      "grad_norm": 0.2375660538673401,
      "learning_rate": 0.00015878528,
      "loss": 2.1069,
      "step": 32200
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.3180801570415497,
      "learning_rate": 0.00015872128,
      "loss": 2.1298,
      "step": 32250
    },
    {
      "epoch": 1.0336,
      "grad_norm": 0.4056697487831116,
      "learning_rate": 0.00015865728,
      "loss": 2.1424,
      "step": 32300
    },
    {
      "epoch": 1.0352,
      "grad_norm": 0.277280330657959,
      "learning_rate": 0.00015859328,
      "loss": 2.1638,
      "step": 32350
    },
    {
      "epoch": 1.0368,
      "grad_norm": 0.27458304166793823,
      "learning_rate": 0.00015852928,
      "loss": 2.139,
      "step": 32400
    },
    {
      "epoch": 1.0384,
      "grad_norm": 0.3625966012477875,
      "learning_rate": 0.00015846528000000001,
      "loss": 2.105,
      "step": 32450
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.2644991874694824,
      "learning_rate": 0.00015840128,
      "loss": 2.1587,
      "step": 32500
    },
    {
      "epoch": 1.0416,
      "grad_norm": 0.26030203700065613,
      "learning_rate": 0.00015833728,
      "loss": 2.1156,
      "step": 32550
    },
    {
      "epoch": 1.0432,
      "grad_norm": 0.2338113784790039,
      "learning_rate": 0.00015827328,
      "loss": 2.142,
      "step": 32600
    },
    {
      "epoch": 1.0448,
      "grad_norm": 0.26326408982276917,
      "learning_rate": 0.00015820928000000002,
      "loss": 2.0977,
      "step": 32650
    },
    {
      "epoch": 1.0464,
      "grad_norm": 0.3073291778564453,
      "learning_rate": 0.00015814528000000002,
      "loss": 2.1332,
      "step": 32700
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.27183616161346436,
      "learning_rate": 0.00015808127999999999,
      "loss": 2.1251,
      "step": 32750
    },
    {
      "epoch": 1.0496,
      "grad_norm": 0.2904634177684784,
      "learning_rate": 0.00015801728,
      "loss": 2.1455,
      "step": 32800
    },
    {
      "epoch": 1.0512,
      "grad_norm": 0.28696388006210327,
      "learning_rate": 0.00015795328,
      "loss": 2.1138,
      "step": 32850
    },
    {
      "epoch": 1.0528,
      "grad_norm": 0.32318028807640076,
      "learning_rate": 0.00015788928,
      "loss": 2.1608,
      "step": 32900
    },
    {
      "epoch": 1.0544,
      "grad_norm": 0.29825419187545776,
      "learning_rate": 0.00015782528000000002,
      "loss": 2.092,
      "step": 32950
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.27997899055480957,
      "learning_rate": 0.00015776128000000002,
      "loss": 2.0775,
      "step": 33000
    },
    {
      "epoch": 1.0576,
      "grad_norm": 0.27169567346572876,
      "learning_rate": 0.00015769728,
      "loss": 2.1314,
      "step": 33050
    },
    {
      "epoch": 1.0592,
      "grad_norm": 0.2841900587081909,
      "learning_rate": 0.00015763328,
      "loss": 2.1424,
      "step": 33100
    },
    {
      "epoch": 1.0608,
      "grad_norm": 0.2576387822628021,
      "learning_rate": 0.00015756928,
      "loss": 2.1582,
      "step": 33150
    },
    {
      "epoch": 1.0624,
      "grad_norm": 0.2991543412208557,
      "learning_rate": 0.00015750528,
      "loss": 2.1761,
      "step": 33200
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.28772762417793274,
      "learning_rate": 0.00015744128,
      "loss": 2.1408,
      "step": 33250
    },
    {
      "epoch": 1.0656,
      "grad_norm": 0.25570711493492126,
      "learning_rate": 0.00015737728000000001,
      "loss": 2.1631,
      "step": 33300
    },
    {
      "epoch": 1.0672,
      "grad_norm": 0.3322284519672394,
      "learning_rate": 0.00015731328,
      "loss": 2.1577,
      "step": 33350
    },
    {
      "epoch": 1.0688,
      "grad_norm": 0.324577271938324,
      "learning_rate": 0.00015724928,
      "loss": 2.1574,
      "step": 33400
    },
    {
      "epoch": 1.0704,
      "grad_norm": 0.27548038959503174,
      "learning_rate": 0.00015718528,
      "loss": 2.1055,
      "step": 33450
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.5121847987174988,
      "learning_rate": 0.00015712128000000002,
      "loss": 2.1176,
      "step": 33500
    },
    {
      "epoch": 1.0735999999999999,
      "grad_norm": 0.332582026720047,
      "learning_rate": 0.00015705728000000002,
      "loss": 2.1272,
      "step": 33550
    },
    {
      "epoch": 1.0752,
      "grad_norm": 0.3117755949497223,
      "learning_rate": 0.00015699327999999999,
      "loss": 2.0966,
      "step": 33600
    },
    {
      "epoch": 1.0768,
      "grad_norm": 0.31236714124679565,
      "learning_rate": 0.00015692928,
      "loss": 2.1223,
      "step": 33650
    },
    {
      "epoch": 1.0784,
      "grad_norm": 0.28693339228630066,
      "learning_rate": 0.00015686528,
      "loss": 2.0782,
      "step": 33700
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.3332849144935608,
      "learning_rate": 0.00015680128,
      "loss": 2.0745,
      "step": 33750
    },
    {
      "epoch": 1.0816,
      "grad_norm": 0.277788370847702,
      "learning_rate": 0.00015673728000000002,
      "loss": 2.1197,
      "step": 33800
    },
    {
      "epoch": 1.0832,
      "grad_norm": 0.35561466217041016,
      "learning_rate": 0.00015667328000000002,
      "loss": 2.197,
      "step": 33850
    },
    {
      "epoch": 1.0848,
      "grad_norm": 0.2836278975009918,
      "learning_rate": 0.00015660928,
      "loss": 2.1537,
      "step": 33900
    },
    {
      "epoch": 1.0864,
      "grad_norm": 0.26088133454322815,
      "learning_rate": 0.00015654528,
      "loss": 2.1357,
      "step": 33950
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.2868838906288147,
      "learning_rate": 0.00015648128,
      "loss": 2.0634,
      "step": 34000
    },
    {
      "epoch": 1.0896,
      "grad_norm": 0.37373536825180054,
      "learning_rate": 0.00015641728,
      "loss": 2.1736,
      "step": 34050
    },
    {
      "epoch": 1.0912,
      "grad_norm": 0.3253604471683502,
      "learning_rate": 0.00015635328,
      "loss": 2.1257,
      "step": 34100
    },
    {
      "epoch": 1.0928,
      "grad_norm": 0.2464189976453781,
      "learning_rate": 0.00015628928,
      "loss": 2.0911,
      "step": 34150
    },
    {
      "epoch": 1.0944,
      "grad_norm": 0.2903526723384857,
      "learning_rate": 0.00015622528,
      "loss": 2.1182,
      "step": 34200
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.29646575450897217,
      "learning_rate": 0.00015616128,
      "loss": 2.1257,
      "step": 34250
    },
    {
      "epoch": 1.0976,
      "grad_norm": 0.3147910535335541,
      "learning_rate": 0.00015609728,
      "loss": 2.1738,
      "step": 34300
    },
    {
      "epoch": 1.0992,
      "grad_norm": 0.2797727584838867,
      "learning_rate": 0.00015603328000000002,
      "loss": 2.1076,
      "step": 34350
    },
    {
      "epoch": 1.1008,
      "grad_norm": 0.2614886462688446,
      "learning_rate": 0.00015596928000000002,
      "loss": 2.1447,
      "step": 34400
    },
    {
      "epoch": 1.1024,
      "grad_norm": 0.3449094891548157,
      "learning_rate": 0.00015590527999999998,
      "loss": 2.103,
      "step": 34450
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.2481822967529297,
      "learning_rate": 0.00015584128,
      "loss": 2.081,
      "step": 34500
    },
    {
      "epoch": 1.1056,
      "grad_norm": 0.34532731771469116,
      "learning_rate": 0.00015577728,
      "loss": 2.1345,
      "step": 34550
    },
    {
      "epoch": 1.1072,
      "grad_norm": 0.3349280059337616,
      "learning_rate": 0.00015571328,
      "loss": 2.1301,
      "step": 34600
    },
    {
      "epoch": 1.1088,
      "grad_norm": 0.3432938754558563,
      "learning_rate": 0.00015564928000000002,
      "loss": 2.1998,
      "step": 34650
    },
    {
      "epoch": 1.1104,
      "grad_norm": 0.3137187063694,
      "learning_rate": 0.00015558528000000001,
      "loss": 2.1257,
      "step": 34700
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.278746098279953,
      "learning_rate": 0.00015552128,
      "loss": 2.1615,
      "step": 34750
    },
    {
      "epoch": 1.1136,
      "grad_norm": 0.3120001256465912,
      "learning_rate": 0.00015545728,
      "loss": 2.0905,
      "step": 34800
    },
    {
      "epoch": 1.1152,
      "grad_norm": 0.28099626302719116,
      "learning_rate": 0.00015539328,
      "loss": 2.1263,
      "step": 34850
    },
    {
      "epoch": 1.1168,
      "grad_norm": 0.26051607728004456,
      "learning_rate": 0.00015532928,
      "loss": 2.1528,
      "step": 34900
    },
    {
      "epoch": 1.1184,
      "grad_norm": 0.29217293858528137,
      "learning_rate": 0.00015526528,
      "loss": 2.0981,
      "step": 34950
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.283551961183548,
      "learning_rate": 0.00015520128,
      "loss": 2.1425,
      "step": 35000
    },
    {
      "epoch": 1.1216,
      "grad_norm": 0.2813681364059448,
      "learning_rate": 0.00015513728,
      "loss": 2.1664,
      "step": 35050
    },
    {
      "epoch": 1.1232,
      "grad_norm": 0.3024808466434479,
      "learning_rate": 0.00015507328,
      "loss": 2.1747,
      "step": 35100
    },
    {
      "epoch": 1.1248,
      "grad_norm": 0.3022964596748352,
      "learning_rate": 0.00015500928000000003,
      "loss": 2.1819,
      "step": 35150
    },
    {
      "epoch": 1.1264,
      "grad_norm": 0.266450971364975,
      "learning_rate": 0.00015494528000000002,
      "loss": 2.189,
      "step": 35200
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.28932425379753113,
      "learning_rate": 0.00015488128000000002,
      "loss": 2.1869,
      "step": 35250
    },
    {
      "epoch": 1.1296,
      "grad_norm": 0.28194472193717957,
      "learning_rate": 0.00015481728,
      "loss": 2.0923,
      "step": 35300
    },
    {
      "epoch": 1.1312,
      "grad_norm": 0.517292857170105,
      "learning_rate": 0.00015475328,
      "loss": 2.1046,
      "step": 35350
    },
    {
      "epoch": 1.1328,
      "grad_norm": 0.3102184236049652,
      "learning_rate": 0.00015468928,
      "loss": 2.1181,
      "step": 35400
    },
    {
      "epoch": 1.1344,
      "grad_norm": 0.2725142240524292,
      "learning_rate": 0.00015462528,
      "loss": 2.1732,
      "step": 35450
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.2647509276866913,
      "learning_rate": 0.00015456128000000002,
      "loss": 2.1285,
      "step": 35500
    },
    {
      "epoch": 1.1376,
      "grad_norm": 0.2846241891384125,
      "learning_rate": 0.00015449728000000001,
      "loss": 2.0959,
      "step": 35550
    },
    {
      "epoch": 1.1392,
      "grad_norm": 0.2769547700881958,
      "learning_rate": 0.00015443328,
      "loss": 2.0914,
      "step": 35600
    },
    {
      "epoch": 1.1408,
      "grad_norm": 0.3072873651981354,
      "learning_rate": 0.00015436928,
      "loss": 2.1021,
      "step": 35650
    },
    {
      "epoch": 1.1424,
      "grad_norm": 0.2957914173603058,
      "learning_rate": 0.00015430528,
      "loss": 2.1383,
      "step": 35700
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.3449211120605469,
      "learning_rate": 0.00015424128,
      "loss": 2.1393,
      "step": 35750
    },
    {
      "epoch": 1.1456,
      "grad_norm": 0.297891229391098,
      "learning_rate": 0.00015417728,
      "loss": 2.0929,
      "step": 35800
    },
    {
      "epoch": 1.1472,
      "grad_norm": 0.35588300228118896,
      "learning_rate": 0.00015411328,
      "loss": 2.1433,
      "step": 35850
    },
    {
      "epoch": 1.1488,
      "grad_norm": 0.34591594338417053,
      "learning_rate": 0.00015404928,
      "loss": 2.1397,
      "step": 35900
    },
    {
      "epoch": 1.1504,
      "grad_norm": 0.2739017903804779,
      "learning_rate": 0.00015398528,
      "loss": 2.1087,
      "step": 35950
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.29610955715179443,
      "learning_rate": 0.00015392128000000003,
      "loss": 2.1537,
      "step": 36000
    },
    {
      "epoch": 1.1536,
      "grad_norm": 0.2564510107040405,
      "learning_rate": 0.00015385728000000002,
      "loss": 2.1696,
      "step": 36050
    },
    {
      "epoch": 1.1552,
      "grad_norm": 0.2783280611038208,
      "learning_rate": 0.00015379328000000002,
      "loss": 2.1498,
      "step": 36100
    },
    {
      "epoch": 1.1568,
      "grad_norm": 0.27992430329322815,
      "learning_rate": 0.00015372928,
      "loss": 2.1261,
      "step": 36150
    },
    {
      "epoch": 1.1584,
      "grad_norm": 0.3302144706249237,
      "learning_rate": 0.00015366528,
      "loss": 2.1949,
      "step": 36200
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.3257289230823517,
      "learning_rate": 0.00015360128,
      "loss": 2.1366,
      "step": 36250
    },
    {
      "epoch": 1.1616,
      "grad_norm": 0.3235775828361511,
      "learning_rate": 0.00015353728,
      "loss": 2.1266,
      "step": 36300
    },
    {
      "epoch": 1.1632,
      "grad_norm": 0.31682050228118896,
      "learning_rate": 0.00015347328000000002,
      "loss": 2.1023,
      "step": 36350
    },
    {
      "epoch": 1.1648,
      "grad_norm": 0.3417048156261444,
      "learning_rate": 0.00015340928000000001,
      "loss": 2.1653,
      "step": 36400
    },
    {
      "epoch": 1.1663999999999999,
      "grad_norm": 0.29324159026145935,
      "learning_rate": 0.00015334528,
      "loss": 2.1346,
      "step": 36450
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.27376484870910645,
      "learning_rate": 0.00015328128,
      "loss": 2.1371,
      "step": 36500
    },
    {
      "epoch": 1.1696,
      "grad_norm": 0.2816894054412842,
      "learning_rate": 0.00015321728,
      "loss": 2.1235,
      "step": 36550
    },
    {
      "epoch": 1.1712,
      "grad_norm": 0.3411697447299957,
      "learning_rate": 0.00015315328,
      "loss": 2.1542,
      "step": 36600
    },
    {
      "epoch": 1.1728,
      "grad_norm": 0.32456067204475403,
      "learning_rate": 0.00015308928,
      "loss": 2.1554,
      "step": 36650
    },
    {
      "epoch": 1.1743999999999999,
      "grad_norm": 0.3078165650367737,
      "learning_rate": 0.00015302528,
      "loss": 2.1087,
      "step": 36700
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.2990323305130005,
      "learning_rate": 0.00015296128,
      "loss": 2.1139,
      "step": 36750
    },
    {
      "epoch": 1.1776,
      "grad_norm": 0.29655101895332336,
      "learning_rate": 0.00015289728,
      "loss": 2.1462,
      "step": 36800
    },
    {
      "epoch": 1.1792,
      "grad_norm": 0.419757217168808,
      "learning_rate": 0.00015283328000000002,
      "loss": 2.2235,
      "step": 36850
    },
    {
      "epoch": 1.1808,
      "grad_norm": 0.288844496011734,
      "learning_rate": 0.00015276928000000002,
      "loss": 2.1099,
      "step": 36900
    },
    {
      "epoch": 1.1824,
      "grad_norm": 0.318390429019928,
      "learning_rate": 0.00015270528000000002,
      "loss": 2.1115,
      "step": 36950
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.2798117995262146,
      "learning_rate": 0.00015264128,
      "loss": 2.108,
      "step": 37000
    },
    {
      "epoch": 1.1856,
      "grad_norm": 0.30524182319641113,
      "learning_rate": 0.00015257728,
      "loss": 2.1273,
      "step": 37050
    },
    {
      "epoch": 1.1872,
      "grad_norm": 0.27310529351234436,
      "learning_rate": 0.00015251328,
      "loss": 2.1233,
      "step": 37100
    },
    {
      "epoch": 1.1888,
      "grad_norm": 0.2671954929828644,
      "learning_rate": 0.00015244928,
      "loss": 2.1542,
      "step": 37150
    },
    {
      "epoch": 1.1904,
      "grad_norm": 0.29350176453590393,
      "learning_rate": 0.00015238528000000002,
      "loss": 2.1128,
      "step": 37200
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.28127723932266235,
      "learning_rate": 0.00015232128,
      "loss": 2.1668,
      "step": 37250
    },
    {
      "epoch": 1.1936,
      "grad_norm": 0.3065052926540375,
      "learning_rate": 0.00015225728,
      "loss": 2.1125,
      "step": 37300
    },
    {
      "epoch": 1.1952,
      "grad_norm": 0.30378738045692444,
      "learning_rate": 0.00015219328,
      "loss": 2.1234,
      "step": 37350
    },
    {
      "epoch": 1.1968,
      "grad_norm": 0.2848118841648102,
      "learning_rate": 0.00015212928,
      "loss": 2.067,
      "step": 37400
    },
    {
      "epoch": 1.1984,
      "grad_norm": 0.3365015387535095,
      "learning_rate": 0.00015206528,
      "loss": 2.1519,
      "step": 37450
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.3255365788936615,
      "learning_rate": 0.00015200128,
      "loss": 2.0954,
      "step": 37500
    },
    {
      "epoch": 1.2016,
      "grad_norm": 0.2763339579105377,
      "learning_rate": 0.00015193728,
      "loss": 2.09,
      "step": 37550
    },
    {
      "epoch": 1.2032,
      "grad_norm": 0.2987922132015228,
      "learning_rate": 0.00015187328,
      "loss": 2.1266,
      "step": 37600
    },
    {
      "epoch": 1.2048,
      "grad_norm": 0.3103782534599304,
      "learning_rate": 0.00015180928,
      "loss": 2.1358,
      "step": 37650
    },
    {
      "epoch": 1.2064,
      "grad_norm": 0.25868454575538635,
      "learning_rate": 0.00015174528000000002,
      "loss": 2.1442,
      "step": 37700
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.29088425636291504,
      "learning_rate": 0.00015168128000000002,
      "loss": 2.1322,
      "step": 37750
    },
    {
      "epoch": 1.2096,
      "grad_norm": 0.29840001463890076,
      "learning_rate": 0.00015161728000000001,
      "loss": 2.1726,
      "step": 37800
    },
    {
      "epoch": 1.2112,
      "grad_norm": 0.31353461742401123,
      "learning_rate": 0.00015155328,
      "loss": 2.0501,
      "step": 37850
    },
    {
      "epoch": 1.2128,
      "grad_norm": 0.2763891816139221,
      "learning_rate": 0.00015148928,
      "loss": 2.1705,
      "step": 37900
    },
    {
      "epoch": 1.2144,
      "grad_norm": 0.25586244463920593,
      "learning_rate": 0.00015142528,
      "loss": 2.1273,
      "step": 37950
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.2836408019065857,
      "learning_rate": 0.00015136128,
      "loss": 2.1219,
      "step": 38000
    },
    {
      "epoch": 1.2176,
      "grad_norm": 0.30632054805755615,
      "learning_rate": 0.00015129728000000002,
      "loss": 2.1785,
      "step": 38050
    },
    {
      "epoch": 1.2192,
      "grad_norm": 0.31858357787132263,
      "learning_rate": 0.00015123328,
      "loss": 2.1377,
      "step": 38100
    },
    {
      "epoch": 1.2208,
      "grad_norm": 0.3113544285297394,
      "learning_rate": 0.00015116928,
      "loss": 2.1685,
      "step": 38150
    },
    {
      "epoch": 1.2224,
      "grad_norm": 0.391567200422287,
      "learning_rate": 0.00015110528,
      "loss": 2.0762,
      "step": 38200
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.3161377012729645,
      "learning_rate": 0.00015104128000000003,
      "loss": 2.1152,
      "step": 38250
    },
    {
      "epoch": 1.2256,
      "grad_norm": 0.32496124505996704,
      "learning_rate": 0.00015097728,
      "loss": 2.185,
      "step": 38300
    },
    {
      "epoch": 1.2272,
      "grad_norm": 0.26863202452659607,
      "learning_rate": 0.00015091328,
      "loss": 2.1615,
      "step": 38350
    },
    {
      "epoch": 1.2288000000000001,
      "grad_norm": 0.2644115388393402,
      "learning_rate": 0.00015084928,
      "loss": 2.167,
      "step": 38400
    },
    {
      "epoch": 1.2304,
      "grad_norm": 0.31588831543922424,
      "learning_rate": 0.00015078528,
      "loss": 2.124,
      "step": 38450
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.2818906009197235,
      "learning_rate": 0.00015072128,
      "loss": 2.1632,
      "step": 38500
    },
    {
      "epoch": 1.2336,
      "grad_norm": 0.28059741854667664,
      "learning_rate": 0.00015065728000000002,
      "loss": 2.1158,
      "step": 38550
    },
    {
      "epoch": 1.2352,
      "grad_norm": 0.2877863943576813,
      "learning_rate": 0.00015059328000000002,
      "loss": 2.1536,
      "step": 38600
    },
    {
      "epoch": 1.2368000000000001,
      "grad_norm": 0.2885816693305969,
      "learning_rate": 0.00015052928000000001,
      "loss": 2.1938,
      "step": 38650
    },
    {
      "epoch": 1.2384,
      "grad_norm": 0.32558318972587585,
      "learning_rate": 0.00015046528,
      "loss": 2.1987,
      "step": 38700
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.3593250811100006,
      "learning_rate": 0.00015040128,
      "loss": 2.1373,
      "step": 38750
    },
    {
      "epoch": 1.2416,
      "grad_norm": 0.3158346116542816,
      "learning_rate": 0.00015033728,
      "loss": 2.1286,
      "step": 38800
    },
    {
      "epoch": 1.2432,
      "grad_norm": 0.39464205503463745,
      "learning_rate": 0.00015027328,
      "loss": 2.1525,
      "step": 38850
    },
    {
      "epoch": 1.2448,
      "grad_norm": 0.3271976411342621,
      "learning_rate": 0.00015020928000000002,
      "loss": 2.1293,
      "step": 38900
    },
    {
      "epoch": 1.2464,
      "grad_norm": 0.3217070996761322,
      "learning_rate": 0.00015014528,
      "loss": 2.2177,
      "step": 38950
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.33486858010292053,
      "learning_rate": 0.00015008128,
      "loss": 2.095,
      "step": 39000
    },
    {
      "epoch": 1.2496,
      "grad_norm": 0.28698962926864624,
      "learning_rate": 0.00015001728,
      "loss": 2.1716,
      "step": 39050
    },
    {
      "epoch": 1.2511999999999999,
      "grad_norm": 0.49628573656082153,
      "learning_rate": 0.00014995328000000003,
      "loss": 2.1257,
      "step": 39100
    },
    {
      "epoch": 1.2528000000000001,
      "grad_norm": 0.42217814922332764,
      "learning_rate": 0.00014988928,
      "loss": 2.1727,
      "step": 39150
    },
    {
      "epoch": 1.2544,
      "grad_norm": 0.35301774740219116,
      "learning_rate": 0.00014982528,
      "loss": 2.1284,
      "step": 39200
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.29897668957710266,
      "learning_rate": 0.00014976128,
      "loss": 2.0973,
      "step": 39250
    },
    {
      "epoch": 1.2576,
      "grad_norm": 0.3160521388053894,
      "learning_rate": 0.00014969728,
      "loss": 2.1877,
      "step": 39300
    },
    {
      "epoch": 1.2591999999999999,
      "grad_norm": 0.3246307969093323,
      "learning_rate": 0.00014963328,
      "loss": 2.1751,
      "step": 39350
    },
    {
      "epoch": 1.2608,
      "grad_norm": 0.3696345388889313,
      "learning_rate": 0.00014956928000000002,
      "loss": 2.1739,
      "step": 39400
    },
    {
      "epoch": 1.2624,
      "grad_norm": 0.261912077665329,
      "learning_rate": 0.00014950528000000002,
      "loss": 2.1273,
      "step": 39450
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.42405086755752563,
      "learning_rate": 0.00014944128000000001,
      "loss": 2.1965,
      "step": 39500
    },
    {
      "epoch": 1.2656,
      "grad_norm": 0.28239989280700684,
      "learning_rate": 0.00014937728,
      "loss": 2.0888,
      "step": 39550
    },
    {
      "epoch": 1.2671999999999999,
      "grad_norm": 0.2852887213230133,
      "learning_rate": 0.00014931328,
      "loss": 2.156,
      "step": 39600
    },
    {
      "epoch": 1.2688,
      "grad_norm": 0.37141767144203186,
      "learning_rate": 0.00014924928,
      "loss": 2.1778,
      "step": 39650
    },
    {
      "epoch": 1.2704,
      "grad_norm": 0.30742162466049194,
      "learning_rate": 0.00014918528,
      "loss": 2.1905,
      "step": 39700
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.3291913568973541,
      "learning_rate": 0.00014912128000000002,
      "loss": 2.145,
      "step": 39750
    },
    {
      "epoch": 1.2736,
      "grad_norm": 0.2840375602245331,
      "learning_rate": 0.00014905728,
      "loss": 2.165,
      "step": 39800
    },
    {
      "epoch": 1.2752,
      "grad_norm": 0.28826263546943665,
      "learning_rate": 0.00014899328,
      "loss": 2.1065,
      "step": 39850
    },
    {
      "epoch": 1.2768,
      "grad_norm": 0.2909923195838928,
      "learning_rate": 0.00014892928,
      "loss": 2.1133,
      "step": 39900
    },
    {
      "epoch": 1.2784,
      "grad_norm": 0.28357529640197754,
      "learning_rate": 0.00014886528000000002,
      "loss": 2.1505,
      "step": 39950
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.27147871255874634,
      "learning_rate": 0.00014880128,
      "loss": 2.1094,
      "step": 40000
    },
    {
      "epoch": 1.2816,
      "grad_norm": 0.29754921793937683,
      "learning_rate": 0.00014873728,
      "loss": 2.1617,
      "step": 40050
    },
    {
      "epoch": 1.2832,
      "grad_norm": 0.3004283308982849,
      "learning_rate": 0.00014867328,
      "loss": 2.1441,
      "step": 40100
    },
    {
      "epoch": 1.2848,
      "grad_norm": 0.3341992497444153,
      "learning_rate": 0.00014860928,
      "loss": 2.1842,
      "step": 40150
    },
    {
      "epoch": 1.2864,
      "grad_norm": 0.2765160799026489,
      "learning_rate": 0.00014854528,
      "loss": 2.1007,
      "step": 40200
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.31326764822006226,
      "learning_rate": 0.00014848128000000002,
      "loss": 2.1194,
      "step": 40250
    },
    {
      "epoch": 1.2896,
      "grad_norm": 0.27247166633605957,
      "learning_rate": 0.00014841728000000002,
      "loss": 2.1161,
      "step": 40300
    },
    {
      "epoch": 1.2912,
      "grad_norm": 0.2602129876613617,
      "learning_rate": 0.00014835328000000001,
      "loss": 2.1533,
      "step": 40350
    },
    {
      "epoch": 1.2928,
      "grad_norm": 0.3092082142829895,
      "learning_rate": 0.00014828928,
      "loss": 2.1594,
      "step": 40400
    },
    {
      "epoch": 1.2944,
      "grad_norm": 0.3101494014263153,
      "learning_rate": 0.00014822528,
      "loss": 2.1503,
      "step": 40450
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.27611806988716125,
      "learning_rate": 0.00014816128,
      "loss": 2.1211,
      "step": 40500
    },
    {
      "epoch": 1.2976,
      "grad_norm": 0.28436750173568726,
      "learning_rate": 0.00014809728,
      "loss": 2.0837,
      "step": 40550
    },
    {
      "epoch": 1.2992,
      "grad_norm": 0.32212066650390625,
      "learning_rate": 0.00014803328000000002,
      "loss": 2.0735,
      "step": 40600
    },
    {
      "epoch": 1.3008,
      "grad_norm": 0.32825663685798645,
      "learning_rate": 0.00014796928,
      "loss": 2.104,
      "step": 40650
    },
    {
      "epoch": 1.3024,
      "grad_norm": 0.3038906157016754,
      "learning_rate": 0.00014790528,
      "loss": 2.1196,
      "step": 40700
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.2980683445930481,
      "learning_rate": 0.00014784128,
      "loss": 2.1126,
      "step": 40750
    },
    {
      "epoch": 1.3056,
      "grad_norm": 0.3029360771179199,
      "learning_rate": 0.00014777728000000002,
      "loss": 2.1735,
      "step": 40800
    },
    {
      "epoch": 1.3072,
      "grad_norm": 0.2608444392681122,
      "learning_rate": 0.00014771328,
      "loss": 2.1905,
      "step": 40850
    },
    {
      "epoch": 1.3088,
      "grad_norm": 0.309224933385849,
      "learning_rate": 0.00014764928,
      "loss": 2.1161,
      "step": 40900
    },
    {
      "epoch": 1.3104,
      "grad_norm": 0.3141118586063385,
      "learning_rate": 0.00014758528,
      "loss": 2.1373,
      "step": 40950
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.2723250389099121,
      "learning_rate": 0.00014752128,
      "loss": 2.1593,
      "step": 41000
    },
    {
      "epoch": 1.3136,
      "grad_norm": 0.2800060510635376,
      "learning_rate": 0.00014745728,
      "loss": 2.1367,
      "step": 41050
    },
    {
      "epoch": 1.3152,
      "grad_norm": 0.27447429299354553,
      "learning_rate": 0.00014739328000000002,
      "loss": 2.1277,
      "step": 41100
    },
    {
      "epoch": 1.3168,
      "grad_norm": 0.33846908807754517,
      "learning_rate": 0.00014732928000000002,
      "loss": 2.1336,
      "step": 41150
    },
    {
      "epoch": 1.3184,
      "grad_norm": 0.36045417189598083,
      "learning_rate": 0.00014726528,
      "loss": 2.1689,
      "step": 41200
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.2841905355453491,
      "learning_rate": 0.00014720128,
      "loss": 2.1461,
      "step": 41250
    },
    {
      "epoch": 1.3216,
      "grad_norm": 0.31716781854629517,
      "learning_rate": 0.00014713728,
      "loss": 2.0714,
      "step": 41300
    },
    {
      "epoch": 1.3232,
      "grad_norm": 0.3529486656188965,
      "learning_rate": 0.00014707328,
      "loss": 2.096,
      "step": 41350
    },
    {
      "epoch": 1.3248,
      "grad_norm": 0.29887259006500244,
      "learning_rate": 0.00014700928,
      "loss": 2.1575,
      "step": 41400
    },
    {
      "epoch": 1.3264,
      "grad_norm": 0.3904312551021576,
      "learning_rate": 0.00014694528000000002,
      "loss": 2.112,
      "step": 41450
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.31164517998695374,
      "learning_rate": 0.00014688128,
      "loss": 2.1,
      "step": 41500
    },
    {
      "epoch": 1.3296000000000001,
      "grad_norm": 0.2857193946838379,
      "learning_rate": 0.00014681728,
      "loss": 2.1409,
      "step": 41550
    },
    {
      "epoch": 1.3312,
      "grad_norm": 0.2895216643810272,
      "learning_rate": 0.00014675328,
      "loss": 2.1006,
      "step": 41600
    },
    {
      "epoch": 1.3328,
      "grad_norm": 0.33500680327415466,
      "learning_rate": 0.00014668928000000002,
      "loss": 2.1857,
      "step": 41650
    },
    {
      "epoch": 1.3344,
      "grad_norm": 0.3338417410850525,
      "learning_rate": 0.00014662528,
      "loss": 2.0909,
      "step": 41700
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.29399362206459045,
      "learning_rate": 0.00014656128,
      "loss": 2.1133,
      "step": 41750
    },
    {
      "epoch": 1.3376000000000001,
      "grad_norm": 0.3127457797527313,
      "learning_rate": 0.00014649728,
      "loss": 2.1339,
      "step": 41800
    },
    {
      "epoch": 1.3392,
      "grad_norm": 0.27800145745277405,
      "learning_rate": 0.00014643328,
      "loss": 2.1388,
      "step": 41850
    },
    {
      "epoch": 1.3408,
      "grad_norm": 0.24574775993824005,
      "learning_rate": 0.00014636928,
      "loss": 2.1392,
      "step": 41900
    },
    {
      "epoch": 1.3424,
      "grad_norm": 0.3004547357559204,
      "learning_rate": 0.00014630528000000002,
      "loss": 2.1729,
      "step": 41950
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.2697308361530304,
      "learning_rate": 0.00014624128000000002,
      "loss": 2.1934,
      "step": 42000
    },
    {
      "epoch": 1.3456000000000001,
      "grad_norm": 0.2773807942867279,
      "learning_rate": 0.00014617728,
      "loss": 2.1379,
      "step": 42050
    },
    {
      "epoch": 1.3472,
      "grad_norm": 0.31877344846725464,
      "learning_rate": 0.00014611328,
      "loss": 2.1488,
      "step": 42100
    },
    {
      "epoch": 1.3488,
      "grad_norm": 0.36422663927078247,
      "learning_rate": 0.00014604928,
      "loss": 2.0484,
      "step": 42150
    },
    {
      "epoch": 1.3504,
      "grad_norm": 0.3372625410556793,
      "learning_rate": 0.00014598528,
      "loss": 2.1687,
      "step": 42200
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.32219627499580383,
      "learning_rate": 0.00014592128,
      "loss": 2.136,
      "step": 42250
    },
    {
      "epoch": 1.3536000000000001,
      "grad_norm": 0.2925899624824524,
      "learning_rate": 0.00014585728000000002,
      "loss": 2.0846,
      "step": 42300
    },
    {
      "epoch": 1.3552,
      "grad_norm": 0.2845068871974945,
      "learning_rate": 0.00014579328,
      "loss": 2.112,
      "step": 42350
    },
    {
      "epoch": 1.3568,
      "grad_norm": 0.3301543891429901,
      "learning_rate": 0.00014572928,
      "loss": 2.147,
      "step": 42400
    },
    {
      "epoch": 1.3584,
      "grad_norm": 0.2991034686565399,
      "learning_rate": 0.00014566528000000003,
      "loss": 2.1083,
      "step": 42450
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.2643601596355438,
      "learning_rate": 0.00014560128000000002,
      "loss": 2.1855,
      "step": 42500
    },
    {
      "epoch": 1.3616,
      "grad_norm": 0.35432079434394836,
      "learning_rate": 0.00014553728,
      "loss": 2.1584,
      "step": 42550
    },
    {
      "epoch": 1.3632,
      "grad_norm": 0.34218528866767883,
      "learning_rate": 0.00014547328000000001,
      "loss": 2.1299,
      "step": 42600
    },
    {
      "epoch": 1.3648,
      "grad_norm": 0.2806018590927124,
      "learning_rate": 0.00014540928,
      "loss": 2.1747,
      "step": 42650
    },
    {
      "epoch": 1.3664,
      "grad_norm": 0.28029099106788635,
      "learning_rate": 0.00014534528,
      "loss": 2.1436,
      "step": 42700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.3200465142726898,
      "learning_rate": 0.00014528128,
      "loss": 2.1535,
      "step": 42750
    },
    {
      "epoch": 1.3696,
      "grad_norm": 0.31169989705085754,
      "learning_rate": 0.00014521728000000002,
      "loss": 2.1562,
      "step": 42800
    },
    {
      "epoch": 1.3712,
      "grad_norm": 0.30392906069755554,
      "learning_rate": 0.00014515328000000002,
      "loss": 2.0751,
      "step": 42850
    },
    {
      "epoch": 1.3728,
      "grad_norm": 0.30713632702827454,
      "learning_rate": 0.00014508928,
      "loss": 2.1265,
      "step": 42900
    },
    {
      "epoch": 1.3744,
      "grad_norm": 0.33922550082206726,
      "learning_rate": 0.00014502528,
      "loss": 2.1092,
      "step": 42950
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.2787895202636719,
      "learning_rate": 0.00014496128,
      "loss": 2.1405,
      "step": 43000
    },
    {
      "epoch": 1.3776,
      "grad_norm": 0.3638260066509247,
      "learning_rate": 0.00014489728,
      "loss": 2.1498,
      "step": 43050
    },
    {
      "epoch": 1.3792,
      "grad_norm": 0.35126280784606934,
      "learning_rate": 0.00014483328,
      "loss": 2.1022,
      "step": 43100
    },
    {
      "epoch": 1.3808,
      "grad_norm": 0.28632277250289917,
      "learning_rate": 0.00014476928000000002,
      "loss": 2.1051,
      "step": 43150
    },
    {
      "epoch": 1.3824,
      "grad_norm": 0.31187570095062256,
      "learning_rate": 0.00014470528,
      "loss": 2.1031,
      "step": 43200
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.28641554713249207,
      "learning_rate": 0.00014464128,
      "loss": 2.1611,
      "step": 43250
    },
    {
      "epoch": 1.3856,
      "grad_norm": 0.41233453154563904,
      "learning_rate": 0.00014457728000000003,
      "loss": 2.1438,
      "step": 43300
    },
    {
      "epoch": 1.3872,
      "grad_norm": 0.3097049295902252,
      "learning_rate": 0.00014451328000000002,
      "loss": 2.1298,
      "step": 43350
    },
    {
      "epoch": 1.3888,
      "grad_norm": 0.2990837097167969,
      "learning_rate": 0.00014444928,
      "loss": 2.1813,
      "step": 43400
    },
    {
      "epoch": 1.3904,
      "grad_norm": 0.2965202331542969,
      "learning_rate": 0.00014438528000000001,
      "loss": 2.0733,
      "step": 43450
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.3530924320220947,
      "learning_rate": 0.00014432128,
      "loss": 2.1659,
      "step": 43500
    },
    {
      "epoch": 1.3936,
      "grad_norm": 0.2937786281108856,
      "learning_rate": 0.00014425728,
      "loss": 2.1167,
      "step": 43550
    },
    {
      "epoch": 1.3952,
      "grad_norm": 0.3031863272190094,
      "learning_rate": 0.00014419328,
      "loss": 2.0913,
      "step": 43600
    },
    {
      "epoch": 1.3968,
      "grad_norm": 0.3610471785068512,
      "learning_rate": 0.00014412928000000002,
      "loss": 2.1665,
      "step": 43650
    },
    {
      "epoch": 1.3984,
      "grad_norm": 0.35414132475852966,
      "learning_rate": 0.00014406528000000002,
      "loss": 2.1383,
      "step": 43700
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.4675758183002472,
      "learning_rate": 0.00014400128,
      "loss": 2.1056,
      "step": 43750
    },
    {
      "epoch": 1.4016,
      "grad_norm": 0.3065387010574341,
      "learning_rate": 0.00014393728,
      "loss": 2.1127,
      "step": 43800
    },
    {
      "epoch": 1.4032,
      "grad_norm": 0.2995985746383667,
      "learning_rate": 0.00014387328,
      "loss": 2.1494,
      "step": 43850
    },
    {
      "epoch": 1.4048,
      "grad_norm": 0.27333223819732666,
      "learning_rate": 0.00014380928,
      "loss": 2.1721,
      "step": 43900
    },
    {
      "epoch": 1.4064,
      "grad_norm": 0.3480799198150635,
      "learning_rate": 0.00014374528,
      "loss": 2.1286,
      "step": 43950
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.2581237554550171,
      "learning_rate": 0.00014368128000000001,
      "loss": 2.1794,
      "step": 44000
    },
    {
      "epoch": 1.4096,
      "grad_norm": 0.3102916181087494,
      "learning_rate": 0.00014361728,
      "loss": 2.1175,
      "step": 44050
    },
    {
      "epoch": 1.4112,
      "grad_norm": 0.38606956601142883,
      "learning_rate": 0.00014355328,
      "loss": 2.1022,
      "step": 44100
    },
    {
      "epoch": 1.4128,
      "grad_norm": 0.3075343668460846,
      "learning_rate": 0.00014348928000000003,
      "loss": 2.1223,
      "step": 44150
    },
    {
      "epoch": 1.4144,
      "grad_norm": 0.34286409616470337,
      "learning_rate": 0.00014342528000000002,
      "loss": 2.177,
      "step": 44200
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.39074456691741943,
      "learning_rate": 0.00014336128,
      "loss": 2.134,
      "step": 44250
    },
    {
      "epoch": 1.4176,
      "grad_norm": 0.28612372279167175,
      "learning_rate": 0.00014329728,
      "loss": 2.1831,
      "step": 44300
    },
    {
      "epoch": 1.4192,
      "grad_norm": 0.378746896982193,
      "learning_rate": 0.00014323328,
      "loss": 2.1506,
      "step": 44350
    },
    {
      "epoch": 1.4208,
      "grad_norm": 0.3538098633289337,
      "learning_rate": 0.00014316928,
      "loss": 2.1298,
      "step": 44400
    },
    {
      "epoch": 1.4224,
      "grad_norm": 0.2947145700454712,
      "learning_rate": 0.00014310528,
      "loss": 2.0937,
      "step": 44450
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.2881421744823456,
      "learning_rate": 0.00014304128000000002,
      "loss": 2.0557,
      "step": 44500
    },
    {
      "epoch": 1.4256,
      "grad_norm": 0.3052964210510254,
      "learning_rate": 0.00014297728000000002,
      "loss": 2.1113,
      "step": 44550
    },
    {
      "epoch": 1.4272,
      "grad_norm": 0.32849499583244324,
      "learning_rate": 0.00014291328,
      "loss": 2.0777,
      "step": 44600
    },
    {
      "epoch": 1.4288,
      "grad_norm": 0.2987323999404907,
      "learning_rate": 0.00014284928,
      "loss": 2.1507,
      "step": 44650
    },
    {
      "epoch": 1.4304000000000001,
      "grad_norm": 0.315019428730011,
      "learning_rate": 0.00014278528,
      "loss": 2.1624,
      "step": 44700
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.34007373452186584,
      "learning_rate": 0.00014272128,
      "loss": 2.1281,
      "step": 44750
    },
    {
      "epoch": 1.4336,
      "grad_norm": 0.27799105644226074,
      "learning_rate": 0.00014265728,
      "loss": 2.128,
      "step": 44800
    },
    {
      "epoch": 1.4352,
      "grad_norm": 0.32336726784706116,
      "learning_rate": 0.00014259328000000001,
      "loss": 2.1517,
      "step": 44850
    },
    {
      "epoch": 1.4368,
      "grad_norm": 0.2815810739994049,
      "learning_rate": 0.00014252928,
      "loss": 2.1568,
      "step": 44900
    },
    {
      "epoch": 1.4384000000000001,
      "grad_norm": 0.3013598620891571,
      "learning_rate": 0.00014246528,
      "loss": 2.0737,
      "step": 44950
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2953222095966339,
      "learning_rate": 0.00014240128000000003,
      "loss": 2.1929,
      "step": 45000
    },
    {
      "epoch": 1.4416,
      "grad_norm": 0.3015109896659851,
      "learning_rate": 0.00014233728000000002,
      "loss": 2.136,
      "step": 45050
    },
    {
      "epoch": 1.4432,
      "grad_norm": 0.2908667325973511,
      "learning_rate": 0.00014227328,
      "loss": 2.1495,
      "step": 45100
    },
    {
      "epoch": 1.4447999999999999,
      "grad_norm": 0.3317776322364807,
      "learning_rate": 0.00014220928,
      "loss": 2.0809,
      "step": 45150
    },
    {
      "epoch": 1.4464000000000001,
      "grad_norm": 0.3297213613986969,
      "learning_rate": 0.00014214528,
      "loss": 2.1618,
      "step": 45200
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.2627861797809601,
      "learning_rate": 0.00014208128,
      "loss": 2.1517,
      "step": 45250
    },
    {
      "epoch": 1.4496,
      "grad_norm": 0.33094295859336853,
      "learning_rate": 0.00014201728,
      "loss": 2.1721,
      "step": 45300
    },
    {
      "epoch": 1.4512,
      "grad_norm": 0.2967852056026459,
      "learning_rate": 0.00014195328000000002,
      "loss": 2.1397,
      "step": 45350
    },
    {
      "epoch": 1.4527999999999999,
      "grad_norm": 0.35837653279304504,
      "learning_rate": 0.00014188928000000002,
      "loss": 2.1428,
      "step": 45400
    },
    {
      "epoch": 1.4544000000000001,
      "grad_norm": 0.2685561180114746,
      "learning_rate": 0.00014182528,
      "loss": 2.1431,
      "step": 45450
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.3286154270172119,
      "learning_rate": 0.00014176128,
      "loss": 2.1017,
      "step": 45500
    },
    {
      "epoch": 1.4576,
      "grad_norm": 0.3192997872829437,
      "learning_rate": 0.00014169728,
      "loss": 2.1372,
      "step": 45550
    },
    {
      "epoch": 1.4592,
      "grad_norm": 0.3441872000694275,
      "learning_rate": 0.00014163328,
      "loss": 2.1207,
      "step": 45600
    },
    {
      "epoch": 1.4607999999999999,
      "grad_norm": 0.3072570860385895,
      "learning_rate": 0.00014156928,
      "loss": 2.1585,
      "step": 45650
    },
    {
      "epoch": 1.4624,
      "grad_norm": 0.2623631954193115,
      "learning_rate": 0.00014150528000000001,
      "loss": 2.2461,
      "step": 45700
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.28797465562820435,
      "learning_rate": 0.00014144128,
      "loss": 2.1824,
      "step": 45750
    },
    {
      "epoch": 1.4656,
      "grad_norm": 0.3150832951068878,
      "learning_rate": 0.00014137728,
      "loss": 2.1098,
      "step": 45800
    },
    {
      "epoch": 1.4672,
      "grad_norm": 0.2841525971889496,
      "learning_rate": 0.00014131328000000003,
      "loss": 2.1489,
      "step": 45850
    },
    {
      "epoch": 1.4687999999999999,
      "grad_norm": 0.2998042404651642,
      "learning_rate": 0.00014124928000000002,
      "loss": 2.1464,
      "step": 45900
    },
    {
      "epoch": 1.4704,
      "grad_norm": 0.3900544345378876,
      "learning_rate": 0.00014118528,
      "loss": 2.1387,
      "step": 45950
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.35974743962287903,
      "learning_rate": 0.00014112128,
      "loss": 2.1564,
      "step": 46000
    },
    {
      "epoch": 1.4736,
      "grad_norm": 0.3256734013557434,
      "learning_rate": 0.00014105728,
      "loss": 2.0769,
      "step": 46050
    },
    {
      "epoch": 1.4752,
      "grad_norm": 0.29980674386024475,
      "learning_rate": 0.00014099328,
      "loss": 2.1496,
      "step": 46100
    },
    {
      "epoch": 1.4768,
      "grad_norm": 0.2786351442337036,
      "learning_rate": 0.00014092928,
      "loss": 2.1111,
      "step": 46150
    },
    {
      "epoch": 1.4784,
      "grad_norm": 0.33939751982688904,
      "learning_rate": 0.00014086528000000002,
      "loss": 2.041,
      "step": 46200
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.34340381622314453,
      "learning_rate": 0.00014080128000000002,
      "loss": 2.1223,
      "step": 46250
    },
    {
      "epoch": 1.4816,
      "grad_norm": 0.32090237736701965,
      "learning_rate": 0.00014073728,
      "loss": 2.1887,
      "step": 46300
    },
    {
      "epoch": 1.4832,
      "grad_norm": 0.33011528849601746,
      "learning_rate": 0.00014067328,
      "loss": 2.122,
      "step": 46350
    },
    {
      "epoch": 1.4848,
      "grad_norm": 0.2826839089393616,
      "learning_rate": 0.00014060928,
      "loss": 2.0917,
      "step": 46400
    },
    {
      "epoch": 1.4864,
      "grad_norm": 0.39659789204597473,
      "learning_rate": 0.00014054528,
      "loss": 2.1453,
      "step": 46450
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.3100895285606384,
      "learning_rate": 0.00014048128,
      "loss": 2.1156,
      "step": 46500
    },
    {
      "epoch": 1.4896,
      "grad_norm": 0.298744797706604,
      "learning_rate": 0.00014041728000000001,
      "loss": 2.151,
      "step": 46550
    },
    {
      "epoch": 1.4912,
      "grad_norm": 0.2966603636741638,
      "learning_rate": 0.00014035328,
      "loss": 2.0948,
      "step": 46600
    },
    {
      "epoch": 1.4928,
      "grad_norm": 0.28288620710372925,
      "learning_rate": 0.00014028928,
      "loss": 2.1199,
      "step": 46650
    },
    {
      "epoch": 1.4944,
      "grad_norm": 0.3304903209209442,
      "learning_rate": 0.00014022528000000003,
      "loss": 2.1742,
      "step": 46700
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.3656557500362396,
      "learning_rate": 0.00014016128000000002,
      "loss": 2.0883,
      "step": 46750
    },
    {
      "epoch": 1.4976,
      "grad_norm": 0.3440124988555908,
      "learning_rate": 0.00014009728,
      "loss": 2.1556,
      "step": 46800
    },
    {
      "epoch": 1.4992,
      "grad_norm": 0.2938685417175293,
      "learning_rate": 0.00014003328,
      "loss": 2.1046,
      "step": 46850
    },
    {
      "epoch": 1.5008,
      "grad_norm": 0.3310853838920593,
      "learning_rate": 0.00013996928,
      "loss": 2.2375,
      "step": 46900
    },
    {
      "epoch": 1.5024,
      "grad_norm": 0.3407224416732788,
      "learning_rate": 0.00013990528,
      "loss": 2.1702,
      "step": 46950
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.322848379611969,
      "learning_rate": 0.00013984128,
      "loss": 2.0686,
      "step": 47000
    },
    {
      "epoch": 1.5056,
      "grad_norm": 0.3245488405227661,
      "learning_rate": 0.00013977728000000002,
      "loss": 2.1541,
      "step": 47050
    },
    {
      "epoch": 1.5072,
      "grad_norm": 0.2760173976421356,
      "learning_rate": 0.00013971328000000001,
      "loss": 2.053,
      "step": 47100
    },
    {
      "epoch": 1.5088,
      "grad_norm": 0.3429655134677887,
      "learning_rate": 0.00013964928,
      "loss": 2.1625,
      "step": 47150
    },
    {
      "epoch": 1.5104,
      "grad_norm": 0.29318737983703613,
      "learning_rate": 0.00013958528,
      "loss": 2.1079,
      "step": 47200
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.30015602707862854,
      "learning_rate": 0.00013952128,
      "loss": 2.1345,
      "step": 47250
    },
    {
      "epoch": 1.5135999999999998,
      "grad_norm": 0.2933427393436432,
      "learning_rate": 0.00013945728,
      "loss": 2.0933,
      "step": 47300
    },
    {
      "epoch": 1.5152,
      "grad_norm": 0.3172321021556854,
      "learning_rate": 0.00013939328,
      "loss": 2.1396,
      "step": 47350
    },
    {
      "epoch": 1.5168,
      "grad_norm": 0.286892294883728,
      "learning_rate": 0.00013932928,
      "loss": 2.0964,
      "step": 47400
    },
    {
      "epoch": 1.5184,
      "grad_norm": 0.444879412651062,
      "learning_rate": 0.00013926528,
      "loss": 2.1521,
      "step": 47450
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.35312581062316895,
      "learning_rate": 0.00013920128,
      "loss": 2.1293,
      "step": 47500
    },
    {
      "epoch": 1.5215999999999998,
      "grad_norm": 0.30198436975479126,
      "learning_rate": 0.00013913728000000003,
      "loss": 2.164,
      "step": 47550
    },
    {
      "epoch": 1.5232,
      "grad_norm": 0.33909332752227783,
      "learning_rate": 0.00013907328000000002,
      "loss": 2.131,
      "step": 47600
    },
    {
      "epoch": 1.5248,
      "grad_norm": 0.28714004158973694,
      "learning_rate": 0.00013900928,
      "loss": 2.1045,
      "step": 47650
    },
    {
      "epoch": 1.5264,
      "grad_norm": 0.3389745354652405,
      "learning_rate": 0.00013894528,
      "loss": 2.0774,
      "step": 47700
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.3604693114757538,
      "learning_rate": 0.00013888128,
      "loss": 2.0648,
      "step": 47750
    },
    {
      "epoch": 1.5295999999999998,
      "grad_norm": 0.2895526885986328,
      "learning_rate": 0.00013881728,
      "loss": 2.1072,
      "step": 47800
    },
    {
      "epoch": 1.5312000000000001,
      "grad_norm": 0.2975376546382904,
      "learning_rate": 0.00013875328,
      "loss": 2.0778,
      "step": 47850
    },
    {
      "epoch": 1.5328,
      "grad_norm": 0.3299194574356079,
      "learning_rate": 0.00013868928000000002,
      "loss": 2.1153,
      "step": 47900
    },
    {
      "epoch": 1.5344,
      "grad_norm": 0.2938334047794342,
      "learning_rate": 0.00013862528000000001,
      "loss": 2.131,
      "step": 47950
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.34174513816833496,
      "learning_rate": 0.00013856128,
      "loss": 2.1032,
      "step": 48000
    },
    {
      "epoch": 1.5375999999999999,
      "grad_norm": 0.31443384289741516,
      "learning_rate": 0.00013849728,
      "loss": 2.0768,
      "step": 48050
    },
    {
      "epoch": 1.5392000000000001,
      "grad_norm": 0.29441675543785095,
      "learning_rate": 0.00013843328,
      "loss": 2.067,
      "step": 48100
    },
    {
      "epoch": 1.5408,
      "grad_norm": 0.2954612672328949,
      "learning_rate": 0.00013836928,
      "loss": 2.1107,
      "step": 48150
    },
    {
      "epoch": 1.5424,
      "grad_norm": 0.3415878117084503,
      "learning_rate": 0.00013830528,
      "loss": 2.1238,
      "step": 48200
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.4085277318954468,
      "learning_rate": 0.00013824128,
      "loss": 2.1153,
      "step": 48250
    },
    {
      "epoch": 1.5455999999999999,
      "grad_norm": 0.3341555893421173,
      "learning_rate": 0.00013817728,
      "loss": 2.1668,
      "step": 48300
    },
    {
      "epoch": 1.5472000000000001,
      "grad_norm": 0.3160955309867859,
      "learning_rate": 0.00013811328,
      "loss": 2.103,
      "step": 48350
    },
    {
      "epoch": 1.5488,
      "grad_norm": 0.2724376916885376,
      "learning_rate": 0.00013804928000000003,
      "loss": 2.1668,
      "step": 48400
    },
    {
      "epoch": 1.5504,
      "grad_norm": 0.36866146326065063,
      "learning_rate": 0.00013798528000000002,
      "loss": 2.126,
      "step": 48450
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.31449049711227417,
      "learning_rate": 0.00013792128,
      "loss": 2.1147,
      "step": 48500
    },
    {
      "epoch": 1.5535999999999999,
      "grad_norm": 0.3656061589717865,
      "learning_rate": 0.00013785728,
      "loss": 2.1348,
      "step": 48550
    },
    {
      "epoch": 1.5552000000000001,
      "grad_norm": 0.36176177859306335,
      "learning_rate": 0.00013779328,
      "loss": 2.1514,
      "step": 48600
    },
    {
      "epoch": 1.5568,
      "grad_norm": 0.31901445984840393,
      "learning_rate": 0.00013772928,
      "loss": 2.1915,
      "step": 48650
    },
    {
      "epoch": 1.5584,
      "grad_norm": 0.33306261897087097,
      "learning_rate": 0.00013766528,
      "loss": 2.0914,
      "step": 48700
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.30054721236228943,
      "learning_rate": 0.00013760128000000002,
      "loss": 2.1164,
      "step": 48750
    },
    {
      "epoch": 1.5615999999999999,
      "grad_norm": 0.32994258403778076,
      "learning_rate": 0.00013753728000000001,
      "loss": 2.0591,
      "step": 48800
    },
    {
      "epoch": 1.5632000000000001,
      "grad_norm": 0.2776896357536316,
      "learning_rate": 0.00013747328,
      "loss": 2.1898,
      "step": 48850
    },
    {
      "epoch": 1.5648,
      "grad_norm": 0.3040403425693512,
      "learning_rate": 0.00013740928,
      "loss": 2.1783,
      "step": 48900
    },
    {
      "epoch": 1.5664,
      "grad_norm": 0.3257919251918793,
      "learning_rate": 0.00013734528,
      "loss": 2.1434,
      "step": 48950
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.3643554747104645,
      "learning_rate": 0.00013728128,
      "loss": 2.0681,
      "step": 49000
    },
    {
      "epoch": 1.5695999999999999,
      "grad_norm": 0.3334580063819885,
      "learning_rate": 0.00013721728,
      "loss": 2.0997,
      "step": 49050
    },
    {
      "epoch": 1.5712000000000002,
      "grad_norm": 0.3027786314487457,
      "learning_rate": 0.00013715328,
      "loss": 2.1332,
      "step": 49100
    },
    {
      "epoch": 1.5728,
      "grad_norm": 0.31813952326774597,
      "learning_rate": 0.00013708928,
      "loss": 2.0854,
      "step": 49150
    },
    {
      "epoch": 1.5744,
      "grad_norm": 0.3206445574760437,
      "learning_rate": 0.00013702528,
      "loss": 2.1118,
      "step": 49200
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.3219767212867737,
      "learning_rate": 0.00013696128000000003,
      "loss": 2.1357,
      "step": 49250
    },
    {
      "epoch": 1.5776,
      "grad_norm": 0.3217014670372009,
      "learning_rate": 0.00013689728000000002,
      "loss": 2.1084,
      "step": 49300
    },
    {
      "epoch": 1.5792000000000002,
      "grad_norm": 0.34128835797309875,
      "learning_rate": 0.00013683328,
      "loss": 2.1406,
      "step": 49350
    },
    {
      "epoch": 1.5808,
      "grad_norm": 0.2731090486049652,
      "learning_rate": 0.00013676928,
      "loss": 2.0878,
      "step": 49400
    },
    {
      "epoch": 1.5824,
      "grad_norm": 0.36185863614082336,
      "learning_rate": 0.00013670528,
      "loss": 2.1791,
      "step": 49450
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.31517553329467773,
      "learning_rate": 0.00013664128,
      "loss": 2.1211,
      "step": 49500
    },
    {
      "epoch": 1.5856,
      "grad_norm": 0.3584192991256714,
      "learning_rate": 0.00013657728,
      "loss": 2.1454,
      "step": 49550
    },
    {
      "epoch": 1.5872000000000002,
      "grad_norm": 0.31330305337905884,
      "learning_rate": 0.00013651328000000002,
      "loss": 2.0816,
      "step": 49600
    },
    {
      "epoch": 1.5888,
      "grad_norm": 0.34860759973526,
      "learning_rate": 0.00013644928000000001,
      "loss": 2.1671,
      "step": 49650
    },
    {
      "epoch": 1.5904,
      "grad_norm": 0.2879185378551483,
      "learning_rate": 0.00013638528,
      "loss": 2.1703,
      "step": 49700
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.28438833355903625,
      "learning_rate": 0.00013632128,
      "loss": 2.0374,
      "step": 49750
    },
    {
      "epoch": 1.5936,
      "grad_norm": 0.30328527092933655,
      "learning_rate": 0.00013625728,
      "loss": 2.1004,
      "step": 49800
    },
    {
      "epoch": 1.5952,
      "grad_norm": 0.3928380310535431,
      "learning_rate": 0.00013619328,
      "loss": 2.1053,
      "step": 49850
    },
    {
      "epoch": 1.5968,
      "grad_norm": 0.2745087146759033,
      "learning_rate": 0.00013612928000000002,
      "loss": 2.1359,
      "step": 49900
    },
    {
      "epoch": 1.5984,
      "grad_norm": 0.301093190908432,
      "learning_rate": 0.00013606528,
      "loss": 2.1062,
      "step": 49950
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.31819403171539307,
      "learning_rate": 0.00013600128,
      "loss": 2.1285,
      "step": 50000
    },
    {
      "epoch": 1.6016,
      "grad_norm": 0.287418931722641,
      "learning_rate": 0.00013593728,
      "loss": 2.098,
      "step": 50050
    },
    {
      "epoch": 1.6032,
      "grad_norm": 0.26982277631759644,
      "learning_rate": 0.00013587328000000002,
      "loss": 2.0893,
      "step": 50100
    },
    {
      "epoch": 1.6048,
      "grad_norm": 0.25635474920272827,
      "learning_rate": 0.00013580928000000002,
      "loss": 2.1172,
      "step": 50150
    },
    {
      "epoch": 1.6064,
      "grad_norm": 0.3315773606300354,
      "learning_rate": 0.00013574528,
      "loss": 2.1304,
      "step": 50200
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.3289473056793213,
      "learning_rate": 0.00013568128,
      "loss": 2.1708,
      "step": 50250
    },
    {
      "epoch": 1.6096,
      "grad_norm": 0.289767861366272,
      "learning_rate": 0.00013561728,
      "loss": 2.1266,
      "step": 50300
    },
    {
      "epoch": 1.6112,
      "grad_norm": 0.3117978572845459,
      "learning_rate": 0.00013555328,
      "loss": 2.0858,
      "step": 50350
    },
    {
      "epoch": 1.6128,
      "grad_norm": 0.38786157965660095,
      "learning_rate": 0.00013548928,
      "loss": 2.1297,
      "step": 50400
    },
    {
      "epoch": 1.6143999999999998,
      "grad_norm": 0.304659903049469,
      "learning_rate": 0.00013542528000000002,
      "loss": 2.0985,
      "step": 50450
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.3088424503803253,
      "learning_rate": 0.00013536128,
      "loss": 2.1225,
      "step": 50500
    },
    {
      "epoch": 1.6176,
      "grad_norm": 0.29497021436691284,
      "learning_rate": 0.00013529728,
      "loss": 2.1667,
      "step": 50550
    },
    {
      "epoch": 1.6192,
      "grad_norm": 0.31722596287727356,
      "learning_rate": 0.00013523328,
      "loss": 2.1733,
      "step": 50600
    },
    {
      "epoch": 1.6208,
      "grad_norm": 0.3377020061016083,
      "learning_rate": 0.00013516928,
      "loss": 2.1256,
      "step": 50650
    },
    {
      "epoch": 1.6223999999999998,
      "grad_norm": 0.3404598832130432,
      "learning_rate": 0.00013510528,
      "loss": 2.1574,
      "step": 50700
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.2671695053577423,
      "learning_rate": 0.00013504128000000002,
      "loss": 2.0719,
      "step": 50750
    },
    {
      "epoch": 1.6256,
      "grad_norm": 0.32961124181747437,
      "learning_rate": 0.00013497728,
      "loss": 2.1634,
      "step": 50800
    },
    {
      "epoch": 1.6272,
      "grad_norm": 0.2898736298084259,
      "learning_rate": 0.00013491328,
      "loss": 2.0827,
      "step": 50850
    },
    {
      "epoch": 1.6288,
      "grad_norm": 0.3069518208503723,
      "learning_rate": 0.00013484928,
      "loss": 2.1042,
      "step": 50900
    },
    {
      "epoch": 1.6303999999999998,
      "grad_norm": 0.3513086140155792,
      "learning_rate": 0.00013478528000000002,
      "loss": 2.1291,
      "step": 50950
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.3010925352573395,
      "learning_rate": 0.00013472128000000002,
      "loss": 2.0785,
      "step": 51000
    },
    {
      "epoch": 1.6336,
      "grad_norm": 0.3359062969684601,
      "learning_rate": 0.00013465728,
      "loss": 2.1339,
      "step": 51050
    },
    {
      "epoch": 1.6352,
      "grad_norm": 0.301866739988327,
      "learning_rate": 0.00013459328,
      "loss": 2.0804,
      "step": 51100
    },
    {
      "epoch": 1.6368,
      "grad_norm": 0.3057444989681244,
      "learning_rate": 0.00013452928,
      "loss": 2.1717,
      "step": 51150
    },
    {
      "epoch": 1.6383999999999999,
      "grad_norm": 0.3033815622329712,
      "learning_rate": 0.00013446528,
      "loss": 2.0725,
      "step": 51200
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.3184921145439148,
      "learning_rate": 0.00013440128,
      "loss": 2.1162,
      "step": 51250
    },
    {
      "epoch": 1.6416,
      "grad_norm": 0.2934548854827881,
      "learning_rate": 0.00013433728000000002,
      "loss": 2.233,
      "step": 51300
    },
    {
      "epoch": 1.6432,
      "grad_norm": 0.38306954503059387,
      "learning_rate": 0.00013427328,
      "loss": 2.1127,
      "step": 51350
    },
    {
      "epoch": 1.6448,
      "grad_norm": 0.31618326902389526,
      "learning_rate": 0.00013420928,
      "loss": 2.1245,
      "step": 51400
    },
    {
      "epoch": 1.6463999999999999,
      "grad_norm": 0.29251939058303833,
      "learning_rate": 0.00013414528,
      "loss": 2.1462,
      "step": 51450
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.30752095580101013,
      "learning_rate": 0.00013408128,
      "loss": 2.1207,
      "step": 51500
    },
    {
      "epoch": 1.6496,
      "grad_norm": 0.281278133392334,
      "learning_rate": 0.00013401728,
      "loss": 2.1699,
      "step": 51550
    },
    {
      "epoch": 1.6512,
      "grad_norm": 0.31447744369506836,
      "learning_rate": 0.00013395328000000002,
      "loss": 2.0919,
      "step": 51600
    },
    {
      "epoch": 1.6528,
      "grad_norm": 0.3862646222114563,
      "learning_rate": 0.00013388928,
      "loss": 2.1284,
      "step": 51650
    },
    {
      "epoch": 1.6543999999999999,
      "grad_norm": 0.30504703521728516,
      "learning_rate": 0.00013382528,
      "loss": 2.1127,
      "step": 51700
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.4101828932762146,
      "learning_rate": 0.00013376128,
      "loss": 2.1256,
      "step": 51750
    },
    {
      "epoch": 1.6576,
      "grad_norm": 0.275049090385437,
      "learning_rate": 0.00013369728000000002,
      "loss": 2.1464,
      "step": 51800
    },
    {
      "epoch": 1.6592,
      "grad_norm": 0.29809844493865967,
      "learning_rate": 0.00013363328000000002,
      "loss": 2.1398,
      "step": 51850
    },
    {
      "epoch": 1.6608,
      "grad_norm": 0.38606157898902893,
      "learning_rate": 0.00013356928,
      "loss": 2.1109,
      "step": 51900
    },
    {
      "epoch": 1.6623999999999999,
      "grad_norm": 0.31830236315727234,
      "learning_rate": 0.00013350528,
      "loss": 2.097,
      "step": 51950
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.2906947135925293,
      "learning_rate": 0.00013344128,
      "loss": 2.137,
      "step": 52000
    },
    {
      "epoch": 1.6656,
      "grad_norm": 0.3134220838546753,
      "learning_rate": 0.00013337728,
      "loss": 2.0861,
      "step": 52050
    },
    {
      "epoch": 1.6672,
      "grad_norm": 0.4011423885822296,
      "learning_rate": 0.00013331328,
      "loss": 2.0966,
      "step": 52100
    },
    {
      "epoch": 1.6688,
      "grad_norm": 0.30614882707595825,
      "learning_rate": 0.00013324928000000002,
      "loss": 2.135,
      "step": 52150
    },
    {
      "epoch": 1.6703999999999999,
      "grad_norm": 0.34883636236190796,
      "learning_rate": 0.00013318528,
      "loss": 2.1304,
      "step": 52200
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.33654841780662537,
      "learning_rate": 0.00013312128,
      "loss": 2.1422,
      "step": 52250
    },
    {
      "epoch": 1.6736,
      "grad_norm": 0.32169216871261597,
      "learning_rate": 0.00013305728000000003,
      "loss": 2.1118,
      "step": 52300
    },
    {
      "epoch": 1.6752,
      "grad_norm": 0.28633713722229004,
      "learning_rate": 0.00013299328,
      "loss": 2.1129,
      "step": 52350
    },
    {
      "epoch": 1.6768,
      "grad_norm": 0.3072236478328705,
      "learning_rate": 0.00013292928,
      "loss": 2.0982,
      "step": 52400
    },
    {
      "epoch": 1.6784,
      "grad_norm": 0.2816133499145508,
      "learning_rate": 0.00013286528000000002,
      "loss": 2.1267,
      "step": 52450
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.3280744254589081,
      "learning_rate": 0.00013280128,
      "loss": 2.0876,
      "step": 52500
    },
    {
      "epoch": 1.6816,
      "grad_norm": 0.31651806831359863,
      "learning_rate": 0.00013273728,
      "loss": 2.172,
      "step": 52550
    },
    {
      "epoch": 1.6832,
      "grad_norm": 0.2977127432823181,
      "learning_rate": 0.00013267328,
      "loss": 2.1806,
      "step": 52600
    },
    {
      "epoch": 1.6848,
      "grad_norm": 0.2778535485267639,
      "learning_rate": 0.00013260928000000002,
      "loss": 2.1088,
      "step": 52650
    },
    {
      "epoch": 1.6864,
      "grad_norm": 0.3627367913722992,
      "learning_rate": 0.00013254528000000002,
      "loss": 2.1155,
      "step": 52700
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.39450085163116455,
      "learning_rate": 0.00013248128,
      "loss": 2.1818,
      "step": 52750
    },
    {
      "epoch": 1.6896,
      "grad_norm": 0.3807736039161682,
      "learning_rate": 0.00013241728,
      "loss": 2.177,
      "step": 52800
    },
    {
      "epoch": 1.6912,
      "grad_norm": 0.3149797022342682,
      "learning_rate": 0.00013235328,
      "loss": 2.1075,
      "step": 52850
    },
    {
      "epoch": 1.6928,
      "grad_norm": 0.32357528805732727,
      "learning_rate": 0.00013228928,
      "loss": 2.1769,
      "step": 52900
    },
    {
      "epoch": 1.6944,
      "grad_norm": 0.2825033962726593,
      "learning_rate": 0.00013222528,
      "loss": 2.1301,
      "step": 52950
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.2836518883705139,
      "learning_rate": 0.00013216128000000002,
      "loss": 2.1435,
      "step": 53000
    },
    {
      "epoch": 1.6976,
      "grad_norm": 0.27111193537712097,
      "learning_rate": 0.00013209728,
      "loss": 2.1365,
      "step": 53050
    },
    {
      "epoch": 1.6992,
      "grad_norm": 0.3638484477996826,
      "learning_rate": 0.00013203328,
      "loss": 2.1494,
      "step": 53100
    },
    {
      "epoch": 1.7008,
      "grad_norm": 0.3241492807865143,
      "learning_rate": 0.00013196928000000003,
      "loss": 2.1222,
      "step": 53150
    },
    {
      "epoch": 1.7024,
      "grad_norm": 0.34302887320518494,
      "learning_rate": 0.00013190528,
      "loss": 2.1954,
      "step": 53200
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.29730024933815,
      "learning_rate": 0.00013184128,
      "loss": 2.1633,
      "step": 53250
    },
    {
      "epoch": 1.7056,
      "grad_norm": 0.37055402994155884,
      "learning_rate": 0.00013177728000000002,
      "loss": 2.0984,
      "step": 53300
    },
    {
      "epoch": 1.7072,
      "grad_norm": 0.2904384732246399,
      "learning_rate": 0.00013171328,
      "loss": 2.0735,
      "step": 53350
    },
    {
      "epoch": 1.7088,
      "grad_norm": 0.28878313302993774,
      "learning_rate": 0.00013164928,
      "loss": 2.1441,
      "step": 53400
    },
    {
      "epoch": 1.7104,
      "grad_norm": 0.28680419921875,
      "learning_rate": 0.00013158528,
      "loss": 2.087,
      "step": 53450
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.2970413267612457,
      "learning_rate": 0.00013152128000000002,
      "loss": 2.0991,
      "step": 53500
    },
    {
      "epoch": 1.7136,
      "grad_norm": 0.35044676065444946,
      "learning_rate": 0.00013145728000000002,
      "loss": 2.1072,
      "step": 53550
    },
    {
      "epoch": 1.7151999999999998,
      "grad_norm": 0.27557140588760376,
      "learning_rate": 0.00013139327999999999,
      "loss": 2.0939,
      "step": 53600
    },
    {
      "epoch": 1.7168,
      "grad_norm": 0.29318997263908386,
      "learning_rate": 0.00013132928,
      "loss": 2.1448,
      "step": 53650
    },
    {
      "epoch": 1.7184,
      "grad_norm": 0.3280854821205139,
      "learning_rate": 0.00013126528,
      "loss": 2.0953,
      "step": 53700
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.33347287774086,
      "learning_rate": 0.00013120128,
      "loss": 2.13,
      "step": 53750
    },
    {
      "epoch": 1.7216,
      "grad_norm": 0.2699977159500122,
      "learning_rate": 0.00013113728,
      "loss": 2.1543,
      "step": 53800
    },
    {
      "epoch": 1.7231999999999998,
      "grad_norm": 0.40141135454177856,
      "learning_rate": 0.00013107328000000002,
      "loss": 2.084,
      "step": 53850
    },
    {
      "epoch": 1.7248,
      "grad_norm": 0.3256123661994934,
      "learning_rate": 0.00013100928,
      "loss": 2.1096,
      "step": 53900
    },
    {
      "epoch": 1.7264,
      "grad_norm": 0.32656148076057434,
      "learning_rate": 0.00013094528,
      "loss": 2.0796,
      "step": 53950
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.2647194564342499,
      "learning_rate": 0.00013088128000000003,
      "loss": 2.1069,
      "step": 54000
    },
    {
      "epoch": 1.7296,
      "grad_norm": 0.3822295367717743,
      "learning_rate": 0.00013081728,
      "loss": 2.1567,
      "step": 54050
    },
    {
      "epoch": 1.7311999999999999,
      "grad_norm": 0.3511821925640106,
      "learning_rate": 0.00013075328,
      "loss": 2.0927,
      "step": 54100
    },
    {
      "epoch": 1.7328000000000001,
      "grad_norm": 0.3332260549068451,
      "learning_rate": 0.00013068928000000001,
      "loss": 2.1427,
      "step": 54150
    },
    {
      "epoch": 1.7344,
      "grad_norm": 0.27608004212379456,
      "learning_rate": 0.00013062528,
      "loss": 2.1644,
      "step": 54200
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.322035014629364,
      "learning_rate": 0.00013056128,
      "loss": 2.139,
      "step": 54250
    },
    {
      "epoch": 1.7376,
      "grad_norm": 0.34499648213386536,
      "learning_rate": 0.00013049728,
      "loss": 2.1451,
      "step": 54300
    },
    {
      "epoch": 1.7391999999999999,
      "grad_norm": 0.3039892315864563,
      "learning_rate": 0.00013043328000000002,
      "loss": 2.1546,
      "step": 54350
    },
    {
      "epoch": 1.7408000000000001,
      "grad_norm": 0.42298996448516846,
      "learning_rate": 0.00013036928000000002,
      "loss": 2.1501,
      "step": 54400
    },
    {
      "epoch": 1.7424,
      "grad_norm": 0.3387914001941681,
      "learning_rate": 0.00013030527999999999,
      "loss": 2.157,
      "step": 54450
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.3495374023914337,
      "learning_rate": 0.00013024128,
      "loss": 2.1072,
      "step": 54500
    },
    {
      "epoch": 1.7456,
      "grad_norm": 0.2633652687072754,
      "learning_rate": 0.00013017728,
      "loss": 2.1225,
      "step": 54550
    },
    {
      "epoch": 1.7471999999999999,
      "grad_norm": 0.2897481918334961,
      "learning_rate": 0.00013011328,
      "loss": 2.1019,
      "step": 54600
    },
    {
      "epoch": 1.7488000000000001,
      "grad_norm": 0.29040399193763733,
      "learning_rate": 0.00013004928,
      "loss": 2.1568,
      "step": 54650
    },
    {
      "epoch": 1.7504,
      "grad_norm": 0.395600825548172,
      "learning_rate": 0.00012998528000000002,
      "loss": 2.1569,
      "step": 54700
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.3204866349697113,
      "learning_rate": 0.00012992128,
      "loss": 2.103,
      "step": 54750
    },
    {
      "epoch": 1.7536,
      "grad_norm": 0.3172670304775238,
      "learning_rate": 0.00012985728,
      "loss": 2.1538,
      "step": 54800
    },
    {
      "epoch": 1.7551999999999999,
      "grad_norm": 0.34781748056411743,
      "learning_rate": 0.00012979328000000003,
      "loss": 2.1363,
      "step": 54850
    },
    {
      "epoch": 1.7568000000000001,
      "grad_norm": 0.3648439347743988,
      "learning_rate": 0.00012972928,
      "loss": 2.1571,
      "step": 54900
    },
    {
      "epoch": 1.7584,
      "grad_norm": 0.3565584123134613,
      "learning_rate": 0.00012966528,
      "loss": 2.1042,
      "step": 54950
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.30625444650650024,
      "learning_rate": 0.00012960128000000001,
      "loss": 2.0952,
      "step": 55000
    },
    {
      "epoch": 1.7616,
      "grad_norm": 0.34137874841690063,
      "learning_rate": 0.00012953728,
      "loss": 2.0415,
      "step": 55050
    },
    {
      "epoch": 1.7631999999999999,
      "grad_norm": 0.2872922122478485,
      "learning_rate": 0.00012947328,
      "loss": 2.1186,
      "step": 55100
    },
    {
      "epoch": 1.7648000000000001,
      "grad_norm": 0.3382588028907776,
      "learning_rate": 0.00012940928,
      "loss": 2.1517,
      "step": 55150
    },
    {
      "epoch": 1.7664,
      "grad_norm": 0.3843670189380646,
      "learning_rate": 0.00012934528000000002,
      "loss": 2.1662,
      "step": 55200
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.2743210196495056,
      "learning_rate": 0.00012928128000000002,
      "loss": 2.2159,
      "step": 55250
    },
    {
      "epoch": 1.7696,
      "grad_norm": 0.3033866286277771,
      "learning_rate": 0.00012921727999999999,
      "loss": 2.1242,
      "step": 55300
    },
    {
      "epoch": 1.7711999999999999,
      "grad_norm": 0.33410611748695374,
      "learning_rate": 0.00012915328,
      "loss": 2.1902,
      "step": 55350
    },
    {
      "epoch": 1.7728000000000002,
      "grad_norm": 0.2672182023525238,
      "learning_rate": 0.00012908928,
      "loss": 2.1209,
      "step": 55400
    },
    {
      "epoch": 1.7744,
      "grad_norm": 0.3796952962875366,
      "learning_rate": 0.00012902528,
      "loss": 2.1623,
      "step": 55450
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.3012404441833496,
      "learning_rate": 0.00012896128,
      "loss": 2.13,
      "step": 55500
    },
    {
      "epoch": 1.7776,
      "grad_norm": 0.30241167545318604,
      "learning_rate": 0.00012889728000000002,
      "loss": 2.086,
      "step": 55550
    },
    {
      "epoch": 1.7792,
      "grad_norm": 0.3693138659000397,
      "learning_rate": 0.00012883328,
      "loss": 2.0977,
      "step": 55600
    },
    {
      "epoch": 1.7808000000000002,
      "grad_norm": 0.33466288447380066,
      "learning_rate": 0.00012876928,
      "loss": 2.0843,
      "step": 55650
    },
    {
      "epoch": 1.7824,
      "grad_norm": 0.2731321454048157,
      "learning_rate": 0.00012870528000000003,
      "loss": 2.1488,
      "step": 55700
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.3065944314002991,
      "learning_rate": 0.00012864128,
      "loss": 2.1795,
      "step": 55750
    },
    {
      "epoch": 1.7856,
      "grad_norm": 0.3554656207561493,
      "learning_rate": 0.00012857728,
      "loss": 2.114,
      "step": 55800
    },
    {
      "epoch": 1.7872,
      "grad_norm": 0.3239678144454956,
      "learning_rate": 0.00012851328000000001,
      "loss": 2.1534,
      "step": 55850
    },
    {
      "epoch": 1.7888,
      "grad_norm": 0.30410611629486084,
      "learning_rate": 0.00012844928,
      "loss": 2.1692,
      "step": 55900
    },
    {
      "epoch": 1.7904,
      "grad_norm": 0.33023983240127563,
      "learning_rate": 0.00012838528,
      "loss": 2.1491,
      "step": 55950
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.3099502921104431,
      "learning_rate": 0.00012832128,
      "loss": 2.1461,
      "step": 56000
    },
    {
      "epoch": 1.7936,
      "grad_norm": 0.375596284866333,
      "learning_rate": 0.00012825728000000002,
      "loss": 2.1999,
      "step": 56050
    },
    {
      "epoch": 1.7952,
      "grad_norm": 0.2730264961719513,
      "learning_rate": 0.00012819328000000002,
      "loss": 2.1131,
      "step": 56100
    },
    {
      "epoch": 1.7968,
      "grad_norm": 0.31242817640304565,
      "learning_rate": 0.00012812927999999998,
      "loss": 2.095,
      "step": 56150
    },
    {
      "epoch": 1.7984,
      "grad_norm": 0.3145621418952942,
      "learning_rate": 0.00012806528,
      "loss": 2.1571,
      "step": 56200
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.3551170229911804,
      "learning_rate": 0.00012800128,
      "loss": 2.0846,
      "step": 56250
    },
    {
      "epoch": 1.8016,
      "grad_norm": 0.30802178382873535,
      "learning_rate": 0.00012793728,
      "loss": 2.09,
      "step": 56300
    },
    {
      "epoch": 1.8032,
      "grad_norm": 0.30981260538101196,
      "learning_rate": 0.00012787328000000002,
      "loss": 2.0811,
      "step": 56350
    },
    {
      "epoch": 1.8048,
      "grad_norm": 0.32581743597984314,
      "learning_rate": 0.00012780928000000002,
      "loss": 2.1894,
      "step": 56400
    },
    {
      "epoch": 1.8064,
      "grad_norm": 0.34380650520324707,
      "learning_rate": 0.00012774528,
      "loss": 2.2386,
      "step": 56450
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.3266564607620239,
      "learning_rate": 0.00012768128,
      "loss": 2.0876,
      "step": 56500
    },
    {
      "epoch": 1.8096,
      "grad_norm": 0.3185971975326538,
      "learning_rate": 0.00012761728000000003,
      "loss": 2.0949,
      "step": 56550
    },
    {
      "epoch": 1.8112,
      "grad_norm": 0.2771143317222595,
      "learning_rate": 0.00012755328,
      "loss": 2.183,
      "step": 56600
    },
    {
      "epoch": 1.8128,
      "grad_norm": 0.3534756004810333,
      "learning_rate": 0.00012748928,
      "loss": 2.1184,
      "step": 56650
    },
    {
      "epoch": 1.8144,
      "grad_norm": 0.40272989869117737,
      "learning_rate": 0.00012742528,
      "loss": 2.0589,
      "step": 56700
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.3393385708332062,
      "learning_rate": 0.00012736128,
      "loss": 2.1869,
      "step": 56750
    },
    {
      "epoch": 1.8176,
      "grad_norm": 0.30735573172569275,
      "learning_rate": 0.00012729728,
      "loss": 2.1519,
      "step": 56800
    },
    {
      "epoch": 1.8192,
      "grad_norm": 0.44457507133483887,
      "learning_rate": 0.00012723328,
      "loss": 2.0847,
      "step": 56850
    },
    {
      "epoch": 1.8208,
      "grad_norm": 0.2849179208278656,
      "learning_rate": 0.00012716928000000002,
      "loss": 2.1452,
      "step": 56900
    },
    {
      "epoch": 1.8224,
      "grad_norm": 0.3013448119163513,
      "learning_rate": 0.00012710528000000002,
      "loss": 2.1691,
      "step": 56950
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.37903696298599243,
      "learning_rate": 0.00012704127999999998,
      "loss": 2.1166,
      "step": 57000
    },
    {
      "epoch": 1.8256000000000001,
      "grad_norm": 0.3073345422744751,
      "learning_rate": 0.00012697728,
      "loss": 2.0569,
      "step": 57050
    },
    {
      "epoch": 1.8272,
      "grad_norm": 0.34392809867858887,
      "learning_rate": 0.00012691328,
      "loss": 2.1055,
      "step": 57100
    },
    {
      "epoch": 1.8288,
      "grad_norm": 0.2904599905014038,
      "learning_rate": 0.00012684928,
      "loss": 2.1402,
      "step": 57150
    },
    {
      "epoch": 1.8304,
      "grad_norm": 0.36012741923332214,
      "learning_rate": 0.00012678528000000002,
      "loss": 2.1092,
      "step": 57200
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.2974887192249298,
      "learning_rate": 0.00012672128000000001,
      "loss": 2.1837,
      "step": 57250
    },
    {
      "epoch": 1.8336000000000001,
      "grad_norm": 0.30753281712532043,
      "learning_rate": 0.00012665728,
      "loss": 2.1258,
      "step": 57300
    },
    {
      "epoch": 1.8352,
      "grad_norm": 0.3079882264137268,
      "learning_rate": 0.00012659328,
      "loss": 2.1054,
      "step": 57350
    },
    {
      "epoch": 1.8368,
      "grad_norm": 0.31002098321914673,
      "learning_rate": 0.00012652928000000003,
      "loss": 2.074,
      "step": 57400
    },
    {
      "epoch": 1.8384,
      "grad_norm": 0.3434523642063141,
      "learning_rate": 0.00012646528,
      "loss": 2.1326,
      "step": 57450
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.275627464056015,
      "learning_rate": 0.00012640128,
      "loss": 2.1412,
      "step": 57500
    },
    {
      "epoch": 1.8416000000000001,
      "grad_norm": 0.39389488101005554,
      "learning_rate": 0.00012633728,
      "loss": 2.1601,
      "step": 57550
    },
    {
      "epoch": 1.8432,
      "grad_norm": 0.37356624007225037,
      "learning_rate": 0.00012627328,
      "loss": 2.142,
      "step": 57600
    },
    {
      "epoch": 1.8448,
      "grad_norm": 0.31538891792297363,
      "learning_rate": 0.00012620928,
      "loss": 2.1794,
      "step": 57650
    },
    {
      "epoch": 1.8464,
      "grad_norm": 0.336134135723114,
      "learning_rate": 0.00012614528,
      "loss": 2.118,
      "step": 57700
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.31699368357658386,
      "learning_rate": 0.00012608128000000002,
      "loss": 2.1311,
      "step": 57750
    },
    {
      "epoch": 1.8496000000000001,
      "grad_norm": 0.29534584283828735,
      "learning_rate": 0.00012601728000000002,
      "loss": 2.1498,
      "step": 57800
    },
    {
      "epoch": 1.8512,
      "grad_norm": 0.3351236581802368,
      "learning_rate": 0.00012595327999999998,
      "loss": 2.1339,
      "step": 57850
    },
    {
      "epoch": 1.8528,
      "grad_norm": 0.34011971950531006,
      "learning_rate": 0.00012588928,
      "loss": 2.141,
      "step": 57900
    },
    {
      "epoch": 1.8544,
      "grad_norm": 0.32696759700775146,
      "learning_rate": 0.00012582528,
      "loss": 2.1273,
      "step": 57950
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.3255544602870941,
      "learning_rate": 0.00012576128,
      "loss": 2.1611,
      "step": 58000
    },
    {
      "epoch": 1.8576000000000001,
      "grad_norm": 0.30354762077331543,
      "learning_rate": 0.00012569728000000002,
      "loss": 2.1499,
      "step": 58050
    },
    {
      "epoch": 1.8592,
      "grad_norm": 0.27034056186676025,
      "learning_rate": 0.00012563328000000001,
      "loss": 2.1151,
      "step": 58100
    },
    {
      "epoch": 1.8608,
      "grad_norm": 0.33562788367271423,
      "learning_rate": 0.00012556928,
      "loss": 2.1378,
      "step": 58150
    },
    {
      "epoch": 1.8624,
      "grad_norm": 0.34335118532180786,
      "learning_rate": 0.00012550528,
      "loss": 2.1435,
      "step": 58200
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.31149086356163025,
      "learning_rate": 0.00012544128000000003,
      "loss": 2.104,
      "step": 58250
    },
    {
      "epoch": 1.8656000000000001,
      "grad_norm": 0.3154974579811096,
      "learning_rate": 0.00012537728,
      "loss": 2.1287,
      "step": 58300
    },
    {
      "epoch": 1.8672,
      "grad_norm": 0.3461726903915405,
      "learning_rate": 0.00012531328,
      "loss": 2.1397,
      "step": 58350
    },
    {
      "epoch": 1.8688,
      "grad_norm": 0.3215077817440033,
      "learning_rate": 0.00012524928,
      "loss": 2.0786,
      "step": 58400
    },
    {
      "epoch": 1.8704,
      "grad_norm": 0.3197769224643707,
      "learning_rate": 0.00012518528,
      "loss": 2.132,
      "step": 58450
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.3256797790527344,
      "learning_rate": 0.00012512128,
      "loss": 2.1654,
      "step": 58500
    },
    {
      "epoch": 1.8736000000000002,
      "grad_norm": 0.4009295701980591,
      "learning_rate": 0.00012505728,
      "loss": 2.0764,
      "step": 58550
    },
    {
      "epoch": 1.8752,
      "grad_norm": 0.3431631326675415,
      "learning_rate": 0.00012499328000000002,
      "loss": 2.1892,
      "step": 58600
    },
    {
      "epoch": 1.8768,
      "grad_norm": 0.32285699248313904,
      "learning_rate": 0.00012492928000000002,
      "loss": 2.1076,
      "step": 58650
    },
    {
      "epoch": 1.8784,
      "grad_norm": 0.2923203110694885,
      "learning_rate": 0.00012486527999999998,
      "loss": 2.1041,
      "step": 58700
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.2553213834762573,
      "learning_rate": 0.00012480128,
      "loss": 2.1061,
      "step": 58750
    },
    {
      "epoch": 1.8816000000000002,
      "grad_norm": 0.33349609375,
      "learning_rate": 0.00012473728,
      "loss": 2.1233,
      "step": 58800
    },
    {
      "epoch": 1.8832,
      "grad_norm": 0.37435683608055115,
      "learning_rate": 0.00012467328,
      "loss": 2.1416,
      "step": 58850
    },
    {
      "epoch": 1.8848,
      "grad_norm": 0.2750197947025299,
      "learning_rate": 0.00012460928000000002,
      "loss": 2.1349,
      "step": 58900
    },
    {
      "epoch": 1.8864,
      "grad_norm": 0.315462589263916,
      "learning_rate": 0.00012454528000000001,
      "loss": 2.1237,
      "step": 58950
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.2871018946170807,
      "learning_rate": 0.00012448128,
      "loss": 2.106,
      "step": 59000
    },
    {
      "epoch": 1.8896,
      "grad_norm": 0.310967355966568,
      "learning_rate": 0.00012441728,
      "loss": 2.0795,
      "step": 59050
    },
    {
      "epoch": 1.8912,
      "grad_norm": 0.3655382990837097,
      "learning_rate": 0.00012435328000000003,
      "loss": 2.1478,
      "step": 59100
    },
    {
      "epoch": 1.8928,
      "grad_norm": 0.2873401641845703,
      "learning_rate": 0.00012428928,
      "loss": 2.1202,
      "step": 59150
    },
    {
      "epoch": 1.8944,
      "grad_norm": 0.30932021141052246,
      "learning_rate": 0.00012422528,
      "loss": 2.0999,
      "step": 59200
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.32711201906204224,
      "learning_rate": 0.00012416128,
      "loss": 2.1012,
      "step": 59250
    },
    {
      "epoch": 1.8976,
      "grad_norm": 0.3403555154800415,
      "learning_rate": 0.00012409728,
      "loss": 2.1128,
      "step": 59300
    },
    {
      "epoch": 1.8992,
      "grad_norm": 0.2677423357963562,
      "learning_rate": 0.00012403328,
      "loss": 2.1126,
      "step": 59350
    },
    {
      "epoch": 1.9008,
      "grad_norm": 0.32629814743995667,
      "learning_rate": 0.00012396928,
      "loss": 2.0833,
      "step": 59400
    },
    {
      "epoch": 1.9024,
      "grad_norm": 0.3320160210132599,
      "learning_rate": 0.00012390528000000002,
      "loss": 2.1504,
      "step": 59450
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.3656931519508362,
      "learning_rate": 0.00012384128000000002,
      "loss": 2.1009,
      "step": 59500
    },
    {
      "epoch": 1.9056,
      "grad_norm": 0.32672685384750366,
      "learning_rate": 0.00012377727999999998,
      "loss": 2.1389,
      "step": 59550
    },
    {
      "epoch": 1.9072,
      "grad_norm": 0.306317538022995,
      "learning_rate": 0.00012371328,
      "loss": 2.0629,
      "step": 59600
    },
    {
      "epoch": 1.9088,
      "grad_norm": 0.3412538170814514,
      "learning_rate": 0.00012364928,
      "loss": 2.1211,
      "step": 59650
    },
    {
      "epoch": 1.9104,
      "grad_norm": 0.27016448974609375,
      "learning_rate": 0.00012358528,
      "loss": 2.1533,
      "step": 59700
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.3104320168495178,
      "learning_rate": 0.00012352128000000002,
      "loss": 2.1419,
      "step": 59750
    },
    {
      "epoch": 1.9136,
      "grad_norm": 0.2790885865688324,
      "learning_rate": 0.00012345728,
      "loss": 2.1775,
      "step": 59800
    },
    {
      "epoch": 1.9152,
      "grad_norm": 0.3214450776576996,
      "learning_rate": 0.00012339328,
      "loss": 2.1054,
      "step": 59850
    },
    {
      "epoch": 1.9167999999999998,
      "grad_norm": 0.3271760642528534,
      "learning_rate": 0.00012332928,
      "loss": 2.1341,
      "step": 59900
    },
    {
      "epoch": 1.9184,
      "grad_norm": 0.32613298296928406,
      "learning_rate": 0.00012326528000000003,
      "loss": 2.142,
      "step": 59950
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.29162612557411194,
      "learning_rate": 0.00012320128,
      "loss": 2.1294,
      "step": 60000
    },
    {
      "epoch": 1.9216,
      "grad_norm": 0.3345080316066742,
      "learning_rate": 0.00012313728,
      "loss": 2.1426,
      "step": 60050
    },
    {
      "epoch": 1.9232,
      "grad_norm": 0.3191845715045929,
      "learning_rate": 0.00012307328,
      "loss": 2.0508,
      "step": 60100
    },
    {
      "epoch": 1.9247999999999998,
      "grad_norm": 0.2757939100265503,
      "learning_rate": 0.00012300928,
      "loss": 2.1207,
      "step": 60150
    },
    {
      "epoch": 1.9264000000000001,
      "grad_norm": 0.2843894958496094,
      "learning_rate": 0.00012294528,
      "loss": 2.1673,
      "step": 60200
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.3074009120464325,
      "learning_rate": 0.00012288128,
      "loss": 2.1324,
      "step": 60250
    },
    {
      "epoch": 1.9296,
      "grad_norm": 0.32159897685050964,
      "learning_rate": 0.00012281728000000002,
      "loss": 2.148,
      "step": 60300
    },
    {
      "epoch": 1.9312,
      "grad_norm": 0.3364996612071991,
      "learning_rate": 0.00012275328000000001,
      "loss": 2.1413,
      "step": 60350
    },
    {
      "epoch": 1.9327999999999999,
      "grad_norm": 0.4119650423526764,
      "learning_rate": 0.00012268927999999998,
      "loss": 2.1525,
      "step": 60400
    },
    {
      "epoch": 1.9344000000000001,
      "grad_norm": 0.2969486117362976,
      "learning_rate": 0.00012262528,
      "loss": 2.0933,
      "step": 60450
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.36319831013679504,
      "learning_rate": 0.00012256128,
      "loss": 2.1438,
      "step": 60500
    },
    {
      "epoch": 1.9376,
      "grad_norm": 0.295644074678421,
      "learning_rate": 0.00012249728,
      "loss": 2.0942,
      "step": 60550
    },
    {
      "epoch": 1.9392,
      "grad_norm": 0.3214031457901001,
      "learning_rate": 0.00012243328000000002,
      "loss": 2.0795,
      "step": 60600
    },
    {
      "epoch": 1.9407999999999999,
      "grad_norm": 0.2993942201137543,
      "learning_rate": 0.00012236928,
      "loss": 2.1428,
      "step": 60650
    },
    {
      "epoch": 1.9424000000000001,
      "grad_norm": 0.27775129675865173,
      "learning_rate": 0.00012230528,
      "loss": 2.1294,
      "step": 60700
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.27036771178245544,
      "learning_rate": 0.00012224128,
      "loss": 2.1673,
      "step": 60750
    },
    {
      "epoch": 1.9456,
      "grad_norm": 0.27950429916381836,
      "learning_rate": 0.00012217728000000003,
      "loss": 2.1027,
      "step": 60800
    },
    {
      "epoch": 1.9472,
      "grad_norm": 0.3214508593082428,
      "learning_rate": 0.00012211328,
      "loss": 2.1427,
      "step": 60850
    },
    {
      "epoch": 1.9487999999999999,
      "grad_norm": 0.3312002420425415,
      "learning_rate": 0.00012204928,
      "loss": 2.1818,
      "step": 60900
    },
    {
      "epoch": 1.9504000000000001,
      "grad_norm": 0.30996596813201904,
      "learning_rate": 0.00012198528,
      "loss": 2.1808,
      "step": 60950
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.3069358766078949,
      "learning_rate": 0.00012192128,
      "loss": 2.1501,
      "step": 61000
    },
    {
      "epoch": 1.9536,
      "grad_norm": 0.31975841522216797,
      "learning_rate": 0.00012185728,
      "loss": 2.1291,
      "step": 61050
    },
    {
      "epoch": 1.9552,
      "grad_norm": 0.3339456021785736,
      "learning_rate": 0.00012179328000000001,
      "loss": 2.1252,
      "step": 61100
    },
    {
      "epoch": 1.9567999999999999,
      "grad_norm": 0.27734068036079407,
      "learning_rate": 0.00012172928,
      "loss": 2.147,
      "step": 61150
    },
    {
      "epoch": 1.9584000000000001,
      "grad_norm": 0.3013468384742737,
      "learning_rate": 0.00012166528000000001,
      "loss": 2.1362,
      "step": 61200
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.34689438343048096,
      "learning_rate": 0.00012160128,
      "loss": 2.111,
      "step": 61250
    },
    {
      "epoch": 1.9616,
      "grad_norm": 0.2701736092567444,
      "learning_rate": 0.00012153727999999999,
      "loss": 2.1064,
      "step": 61300
    },
    {
      "epoch": 1.9632,
      "grad_norm": 0.30203723907470703,
      "learning_rate": 0.00012147328,
      "loss": 2.1235,
      "step": 61350
    },
    {
      "epoch": 1.9647999999999999,
      "grad_norm": 0.28537702560424805,
      "learning_rate": 0.00012140928000000001,
      "loss": 2.0743,
      "step": 61400
    },
    {
      "epoch": 1.9664000000000001,
      "grad_norm": 0.34725257754325867,
      "learning_rate": 0.00012134528,
      "loss": 2.1345,
      "step": 61450
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.3380078077316284,
      "learning_rate": 0.00012128128000000001,
      "loss": 2.0683,
      "step": 61500
    },
    {
      "epoch": 1.9696,
      "grad_norm": 0.35165247321128845,
      "learning_rate": 0.00012121728000000001,
      "loss": 2.1244,
      "step": 61550
    },
    {
      "epoch": 1.9712,
      "grad_norm": 0.3248206675052643,
      "learning_rate": 0.00012115328000000002,
      "loss": 2.1303,
      "step": 61600
    },
    {
      "epoch": 1.9727999999999999,
      "grad_norm": 0.3176381587982178,
      "learning_rate": 0.00012108928000000001,
      "loss": 2.102,
      "step": 61650
    },
    {
      "epoch": 1.9744000000000002,
      "grad_norm": 0.40684086084365845,
      "learning_rate": 0.00012102528,
      "loss": 2.0884,
      "step": 61700
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.2790667712688446,
      "learning_rate": 0.00012096128,
      "loss": 2.1047,
      "step": 61750
    },
    {
      "epoch": 1.9776,
      "grad_norm": 0.3063766658306122,
      "learning_rate": 0.00012089728,
      "loss": 2.1032,
      "step": 61800
    },
    {
      "epoch": 1.9792,
      "grad_norm": 0.3409214913845062,
      "learning_rate": 0.00012083328,
      "loss": 2.1753,
      "step": 61850
    },
    {
      "epoch": 1.9808,
      "grad_norm": 0.3644590973854065,
      "learning_rate": 0.00012076928,
      "loss": 2.118,
      "step": 61900
    },
    {
      "epoch": 1.9824000000000002,
      "grad_norm": 0.32251250743865967,
      "learning_rate": 0.00012070528000000001,
      "loss": 2.1252,
      "step": 61950
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.40868785977363586,
      "learning_rate": 0.00012064128000000002,
      "loss": 2.1016,
      "step": 62000
    },
    {
      "epoch": 1.9856,
      "grad_norm": 0.31438425183296204,
      "learning_rate": 0.00012057728000000001,
      "loss": 2.1943,
      "step": 62050
    },
    {
      "epoch": 1.9872,
      "grad_norm": 0.3171665072441101,
      "learning_rate": 0.00012051328,
      "loss": 2.1541,
      "step": 62100
    },
    {
      "epoch": 1.9888,
      "grad_norm": 0.3506659269332886,
      "learning_rate": 0.00012044928,
      "loss": 2.0692,
      "step": 62150
    },
    {
      "epoch": 1.9904,
      "grad_norm": 0.30332300066947937,
      "learning_rate": 0.00012038528,
      "loss": 2.1025,
      "step": 62200
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.3743964433670044,
      "learning_rate": 0.00012032128000000001,
      "loss": 2.1661,
      "step": 62250
    },
    {
      "epoch": 1.9936,
      "grad_norm": 0.31643664836883545,
      "learning_rate": 0.00012025728,
      "loss": 2.1343,
      "step": 62300
    },
    {
      "epoch": 1.9952,
      "grad_norm": 0.4062362611293793,
      "learning_rate": 0.00012019328000000001,
      "loss": 2.1529,
      "step": 62350
    },
    {
      "epoch": 1.9968,
      "grad_norm": 0.34766456484794617,
      "learning_rate": 0.00012012928000000001,
      "loss": 2.0979,
      "step": 62400
    },
    {
      "epoch": 1.9984,
      "grad_norm": 0.31081053614616394,
      "learning_rate": 0.00012006528000000002,
      "loss": 2.0661,
      "step": 62450
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.32532182335853577,
      "learning_rate": 0.00012000128000000001,
      "loss": 2.15,
      "step": 62500
    },
    {
      "epoch": 2.0016,
      "grad_norm": 0.3369724750518799,
      "learning_rate": 0.00011993727999999999,
      "loss": 2.0824,
      "step": 62550
    },
    {
      "epoch": 2.0032,
      "grad_norm": 0.31964820623397827,
      "learning_rate": 0.00011987328,
      "loss": 2.1437,
      "step": 62600
    },
    {
      "epoch": 2.0048,
      "grad_norm": 0.2970789968967438,
      "learning_rate": 0.00011980928,
      "loss": 2.0884,
      "step": 62650
    },
    {
      "epoch": 2.0064,
      "grad_norm": 0.3509054481983185,
      "learning_rate": 0.00011974528,
      "loss": 2.1362,
      "step": 62700
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.25292688608169556,
      "learning_rate": 0.00011968128,
      "loss": 2.1047,
      "step": 62750
    },
    {
      "epoch": 2.0096,
      "grad_norm": 0.33521080017089844,
      "learning_rate": 0.00011961728000000001,
      "loss": 2.1063,
      "step": 62800
    },
    {
      "epoch": 2.0112,
      "grad_norm": 0.3347892761230469,
      "learning_rate": 0.00011955328000000002,
      "loss": 2.1049,
      "step": 62850
    },
    {
      "epoch": 2.0128,
      "grad_norm": 0.3567257821559906,
      "learning_rate": 0.00011948928000000001,
      "loss": 2.15,
      "step": 62900
    },
    {
      "epoch": 2.0144,
      "grad_norm": 0.3440536558628082,
      "learning_rate": 0.00011942528,
      "loss": 2.1887,
      "step": 62950
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.4572509527206421,
      "learning_rate": 0.00011936128,
      "loss": 2.1398,
      "step": 63000
    },
    {
      "epoch": 2.0176,
      "grad_norm": 0.32747527956962585,
      "learning_rate": 0.00011929728,
      "loss": 2.1115,
      "step": 63050
    },
    {
      "epoch": 2.0192,
      "grad_norm": 0.43358010053634644,
      "learning_rate": 0.00011923328000000001,
      "loss": 2.1972,
      "step": 63100
    },
    {
      "epoch": 2.0208,
      "grad_norm": 0.3159695267677307,
      "learning_rate": 0.00011916928,
      "loss": 2.1754,
      "step": 63150
    },
    {
      "epoch": 2.0224,
      "grad_norm": 0.41757893562316895,
      "learning_rate": 0.00011910528000000001,
      "loss": 2.2237,
      "step": 63200
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.3413655757904053,
      "learning_rate": 0.00011904128000000001,
      "loss": 2.1024,
      "step": 63250
    },
    {
      "epoch": 2.0256,
      "grad_norm": 0.32224711775779724,
      "learning_rate": 0.00011897728000000002,
      "loss": 2.105,
      "step": 63300
    },
    {
      "epoch": 2.0272,
      "grad_norm": 0.34206998348236084,
      "learning_rate": 0.00011891328000000001,
      "loss": 2.056,
      "step": 63350
    },
    {
      "epoch": 2.0288,
      "grad_norm": 0.32109585404396057,
      "learning_rate": 0.00011884927999999999,
      "loss": 2.1288,
      "step": 63400
    },
    {
      "epoch": 2.0304,
      "grad_norm": 0.2945791780948639,
      "learning_rate": 0.00011878528,
      "loss": 2.0907,
      "step": 63450
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.2877524197101593,
      "learning_rate": 0.00011872128,
      "loss": 2.0757,
      "step": 63500
    },
    {
      "epoch": 2.0336,
      "grad_norm": 0.37822428345680237,
      "learning_rate": 0.00011865728,
      "loss": 2.0839,
      "step": 63550
    },
    {
      "epoch": 2.0352,
      "grad_norm": 0.30519261956214905,
      "learning_rate": 0.00011859328,
      "loss": 2.067,
      "step": 63600
    },
    {
      "epoch": 2.0368,
      "grad_norm": 0.2707803249359131,
      "learning_rate": 0.00011852928000000001,
      "loss": 2.1224,
      "step": 63650
    },
    {
      "epoch": 2.0384,
      "grad_norm": 0.3676879405975342,
      "learning_rate": 0.00011846528000000002,
      "loss": 2.1128,
      "step": 63700
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.34575289487838745,
      "learning_rate": 0.00011840128000000001,
      "loss": 2.0744,
      "step": 63750
    },
    {
      "epoch": 2.0416,
      "grad_norm": 0.3024847209453583,
      "learning_rate": 0.00011833728,
      "loss": 2.0863,
      "step": 63800
    },
    {
      "epoch": 2.0432,
      "grad_norm": 0.31222590804100037,
      "learning_rate": 0.00011827328,
      "loss": 2.0981,
      "step": 63850
    },
    {
      "epoch": 2.0448,
      "grad_norm": 0.40553709864616394,
      "learning_rate": 0.00011820928,
      "loss": 2.0981,
      "step": 63900
    },
    {
      "epoch": 2.0464,
      "grad_norm": 0.33564192056655884,
      "learning_rate": 0.00011814528000000001,
      "loss": 2.1004,
      "step": 63950
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.37269437313079834,
      "learning_rate": 0.00011808128,
      "loss": 2.1204,
      "step": 64000
    },
    {
      "epoch": 2.0496,
      "grad_norm": 0.31006327271461487,
      "learning_rate": 0.00011801728000000001,
      "loss": 2.1367,
      "step": 64050
    },
    {
      "epoch": 2.0512,
      "grad_norm": 0.3420180380344391,
      "learning_rate": 0.00011795328,
      "loss": 2.1419,
      "step": 64100
    },
    {
      "epoch": 2.0528,
      "grad_norm": 0.4108862280845642,
      "learning_rate": 0.00011788928000000002,
      "loss": 2.0794,
      "step": 64150
    },
    {
      "epoch": 2.0544,
      "grad_norm": 0.34201177954673767,
      "learning_rate": 0.00011782528000000001,
      "loss": 2.0911,
      "step": 64200
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.3265257179737091,
      "learning_rate": 0.00011776127999999999,
      "loss": 2.1721,
      "step": 64250
    },
    {
      "epoch": 2.0576,
      "grad_norm": 0.35965320467948914,
      "learning_rate": 0.00011769728,
      "loss": 2.142,
      "step": 64300
    },
    {
      "epoch": 2.0592,
      "grad_norm": 0.35818514227867126,
      "learning_rate": 0.00011763328,
      "loss": 2.1595,
      "step": 64350
    },
    {
      "epoch": 2.0608,
      "grad_norm": 0.41794273257255554,
      "learning_rate": 0.00011756928,
      "loss": 2.1399,
      "step": 64400
    },
    {
      "epoch": 2.0624,
      "grad_norm": 0.36538437008857727,
      "learning_rate": 0.00011750528,
      "loss": 2.1501,
      "step": 64450
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.41362839937210083,
      "learning_rate": 0.00011744128000000001,
      "loss": 2.1849,
      "step": 64500
    },
    {
      "epoch": 2.0656,
      "grad_norm": 0.4079562723636627,
      "learning_rate": 0.00011737728000000002,
      "loss": 2.0762,
      "step": 64550
    },
    {
      "epoch": 2.0672,
      "grad_norm": 0.32760998606681824,
      "learning_rate": 0.00011731328000000001,
      "loss": 2.0564,
      "step": 64600
    },
    {
      "epoch": 2.0688,
      "grad_norm": 0.31743624806404114,
      "learning_rate": 0.00011724928,
      "loss": 2.1386,
      "step": 64650
    },
    {
      "epoch": 2.0704,
      "grad_norm": 0.3212684094905853,
      "learning_rate": 0.00011718528,
      "loss": 2.1078,
      "step": 64700
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.27641165256500244,
      "learning_rate": 0.00011712128,
      "loss": 2.0699,
      "step": 64750
    },
    {
      "epoch": 2.0736,
      "grad_norm": 0.2645547091960907,
      "learning_rate": 0.00011705728000000001,
      "loss": 2.084,
      "step": 64800
    },
    {
      "epoch": 2.0752,
      "grad_norm": 0.2616046965122223,
      "learning_rate": 0.00011699328,
      "loss": 2.1588,
      "step": 64850
    },
    {
      "epoch": 2.0768,
      "grad_norm": 0.35789668560028076,
      "learning_rate": 0.00011692928000000001,
      "loss": 2.1692,
      "step": 64900
    },
    {
      "epoch": 2.0784,
      "grad_norm": 0.3196318447589874,
      "learning_rate": 0.00011686528,
      "loss": 2.1262,
      "step": 64950
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.38996440172195435,
      "learning_rate": 0.00011680128000000001,
      "loss": 2.0858,
      "step": 65000
    },
    {
      "epoch": 2.0816,
      "grad_norm": 0.542929470539093,
      "learning_rate": 0.00011673728000000001,
      "loss": 2.0832,
      "step": 65050
    },
    {
      "epoch": 2.0832,
      "grad_norm": 0.36932507157325745,
      "learning_rate": 0.00011667327999999999,
      "loss": 2.1377,
      "step": 65100
    },
    {
      "epoch": 2.0848,
      "grad_norm": 0.35838937759399414,
      "learning_rate": 0.00011660928,
      "loss": 2.1006,
      "step": 65150
    },
    {
      "epoch": 2.0864,
      "grad_norm": 0.32756394147872925,
      "learning_rate": 0.00011654528,
      "loss": 2.1187,
      "step": 65200
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.2913370728492737,
      "learning_rate": 0.00011648128,
      "loss": 2.1387,
      "step": 65250
    },
    {
      "epoch": 2.0896,
      "grad_norm": 0.31960529088974,
      "learning_rate": 0.00011641728000000001,
      "loss": 2.0868,
      "step": 65300
    },
    {
      "epoch": 2.0912,
      "grad_norm": 0.32092607021331787,
      "learning_rate": 0.00011635328000000001,
      "loss": 2.1738,
      "step": 65350
    },
    {
      "epoch": 2.0928,
      "grad_norm": 0.3627048134803772,
      "learning_rate": 0.00011628928000000002,
      "loss": 2.1117,
      "step": 65400
    },
    {
      "epoch": 2.0944,
      "grad_norm": 0.3622969686985016,
      "learning_rate": 0.00011622528000000001,
      "loss": 2.0911,
      "step": 65450
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.30501288175582886,
      "learning_rate": 0.00011616128,
      "loss": 2.1228,
      "step": 65500
    },
    {
      "epoch": 2.0976,
      "grad_norm": 0.357226699590683,
      "learning_rate": 0.00011609728,
      "loss": 2.0709,
      "step": 65550
    },
    {
      "epoch": 2.0992,
      "grad_norm": 0.34973275661468506,
      "learning_rate": 0.00011603328,
      "loss": 2.1578,
      "step": 65600
    },
    {
      "epoch": 2.1008,
      "grad_norm": 0.2838750183582306,
      "learning_rate": 0.00011596928,
      "loss": 2.161,
      "step": 65650
    },
    {
      "epoch": 2.1024,
      "grad_norm": 0.3157832622528076,
      "learning_rate": 0.00011590528,
      "loss": 2.1207,
      "step": 65700
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.33962443470954895,
      "learning_rate": 0.00011584128000000001,
      "loss": 2.1564,
      "step": 65750
    },
    {
      "epoch": 2.1056,
      "grad_norm": 0.3428264856338501,
      "learning_rate": 0.00011577728,
      "loss": 2.1847,
      "step": 65800
    },
    {
      "epoch": 2.1072,
      "grad_norm": 0.4181745648384094,
      "learning_rate": 0.00011571328000000001,
      "loss": 2.0947,
      "step": 65850
    },
    {
      "epoch": 2.1088,
      "grad_norm": 0.28567373752593994,
      "learning_rate": 0.00011564928000000001,
      "loss": 2.1211,
      "step": 65900
    },
    {
      "epoch": 2.1104,
      "grad_norm": 0.3602302074432373,
      "learning_rate": 0.00011558527999999999,
      "loss": 2.1218,
      "step": 65950
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.30405181646347046,
      "learning_rate": 0.00011552128,
      "loss": 2.0614,
      "step": 66000
    },
    {
      "epoch": 2.1136,
      "grad_norm": 0.3667733073234558,
      "learning_rate": 0.00011545728,
      "loss": 2.1076,
      "step": 66050
    },
    {
      "epoch": 2.1152,
      "grad_norm": 0.3030503988265991,
      "learning_rate": 0.00011539328,
      "loss": 2.0859,
      "step": 66100
    },
    {
      "epoch": 2.1168,
      "grad_norm": 0.3169071674346924,
      "learning_rate": 0.00011532928000000001,
      "loss": 2.0853,
      "step": 66150
    },
    {
      "epoch": 2.1184,
      "grad_norm": 0.3760482668876648,
      "learning_rate": 0.00011526528000000001,
      "loss": 2.1059,
      "step": 66200
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.3232399821281433,
      "learning_rate": 0.00011520128000000002,
      "loss": 2.1413,
      "step": 66250
    },
    {
      "epoch": 2.1216,
      "grad_norm": 0.32755574584007263,
      "learning_rate": 0.00011513728000000001,
      "loss": 2.1004,
      "step": 66300
    },
    {
      "epoch": 2.1232,
      "grad_norm": 0.33226433396339417,
      "learning_rate": 0.00011507328,
      "loss": 2.0702,
      "step": 66350
    },
    {
      "epoch": 2.1248,
      "grad_norm": 0.3124821186065674,
      "learning_rate": 0.00011500928,
      "loss": 2.0965,
      "step": 66400
    },
    {
      "epoch": 2.1264,
      "grad_norm": 0.3543786406517029,
      "learning_rate": 0.00011494528,
      "loss": 2.0671,
      "step": 66450
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.4029638171195984,
      "learning_rate": 0.00011488128,
      "loss": 2.1241,
      "step": 66500
    },
    {
      "epoch": 2.1296,
      "grad_norm": 0.31068870425224304,
      "learning_rate": 0.00011481728,
      "loss": 2.2086,
      "step": 66550
    },
    {
      "epoch": 2.1312,
      "grad_norm": 0.3263304531574249,
      "learning_rate": 0.00011475328000000001,
      "loss": 2.1328,
      "step": 66600
    },
    {
      "epoch": 2.1328,
      "grad_norm": 0.33857348561286926,
      "learning_rate": 0.00011468928,
      "loss": 2.1,
      "step": 66650
    },
    {
      "epoch": 2.1344,
      "grad_norm": 0.3326474130153656,
      "learning_rate": 0.00011462528000000001,
      "loss": 2.136,
      "step": 66700
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.3020149767398834,
      "learning_rate": 0.00011456128000000001,
      "loss": 2.0837,
      "step": 66750
    },
    {
      "epoch": 2.1376,
      "grad_norm": 0.3497517704963684,
      "learning_rate": 0.00011449727999999999,
      "loss": 2.1209,
      "step": 66800
    },
    {
      "epoch": 2.1391999999999998,
      "grad_norm": 0.3257761597633362,
      "learning_rate": 0.00011443328,
      "loss": 2.134,
      "step": 66850
    },
    {
      "epoch": 2.1408,
      "grad_norm": 0.4067017734050751,
      "learning_rate": 0.00011436928,
      "loss": 2.1397,
      "step": 66900
    },
    {
      "epoch": 2.1424,
      "grad_norm": 0.3308994770050049,
      "learning_rate": 0.00011430528,
      "loss": 2.1146,
      "step": 66950
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.3420436680316925,
      "learning_rate": 0.00011424128000000001,
      "loss": 2.0662,
      "step": 67000
    },
    {
      "epoch": 2.1456,
      "grad_norm": 0.2987492084503174,
      "learning_rate": 0.00011417728000000001,
      "loss": 2.0918,
      "step": 67050
    },
    {
      "epoch": 2.1471999999999998,
      "grad_norm": 0.3904927968978882,
      "learning_rate": 0.00011411328000000002,
      "loss": 2.0988,
      "step": 67100
    },
    {
      "epoch": 2.1488,
      "grad_norm": 0.3089071810245514,
      "learning_rate": 0.00011404928000000001,
      "loss": 2.1304,
      "step": 67150
    },
    {
      "epoch": 2.1504,
      "grad_norm": 0.31013333797454834,
      "learning_rate": 0.00011398528000000002,
      "loss": 2.0348,
      "step": 67200
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.3691820502281189,
      "learning_rate": 0.00011392128,
      "loss": 2.1531,
      "step": 67250
    },
    {
      "epoch": 2.1536,
      "grad_norm": 0.27960097789764404,
      "learning_rate": 0.00011385728,
      "loss": 2.1107,
      "step": 67300
    },
    {
      "epoch": 2.1552,
      "grad_norm": 0.31893616914749146,
      "learning_rate": 0.00011379328,
      "loss": 2.0688,
      "step": 67350
    },
    {
      "epoch": 2.1568,
      "grad_norm": 0.31580275297164917,
      "learning_rate": 0.00011372928,
      "loss": 2.1072,
      "step": 67400
    },
    {
      "epoch": 2.1584,
      "grad_norm": 0.2950926125049591,
      "learning_rate": 0.00011366528000000001,
      "loss": 2.0939,
      "step": 67450
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.37853360176086426,
      "learning_rate": 0.00011360128,
      "loss": 2.0981,
      "step": 67500
    },
    {
      "epoch": 2.1616,
      "grad_norm": 0.319752037525177,
      "learning_rate": 0.00011353728000000001,
      "loss": 2.068,
      "step": 67550
    },
    {
      "epoch": 2.1632,
      "grad_norm": 0.35549771785736084,
      "learning_rate": 0.00011347328000000001,
      "loss": 2.1009,
      "step": 67600
    },
    {
      "epoch": 2.1648,
      "grad_norm": 0.3418360948562622,
      "learning_rate": 0.00011340927999999999,
      "loss": 2.1664,
      "step": 67650
    },
    {
      "epoch": 2.1664,
      "grad_norm": 0.3450145423412323,
      "learning_rate": 0.00011334528,
      "loss": 2.0945,
      "step": 67700
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.36626026034355164,
      "learning_rate": 0.00011328128,
      "loss": 2.1813,
      "step": 67750
    },
    {
      "epoch": 2.1696,
      "grad_norm": 0.3101671636104584,
      "learning_rate": 0.00011321728,
      "loss": 2.0925,
      "step": 67800
    },
    {
      "epoch": 2.1712,
      "grad_norm": 0.3544289767742157,
      "learning_rate": 0.00011315328000000001,
      "loss": 2.0916,
      "step": 67850
    },
    {
      "epoch": 2.1728,
      "grad_norm": 0.3920469582080841,
      "learning_rate": 0.00011308928000000001,
      "loss": 2.101,
      "step": 67900
    },
    {
      "epoch": 2.1744,
      "grad_norm": 0.32039374113082886,
      "learning_rate": 0.00011302528000000002,
      "loss": 2.1296,
      "step": 67950
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.2884097993373871,
      "learning_rate": 0.00011296128000000001,
      "loss": 2.1149,
      "step": 68000
    },
    {
      "epoch": 2.1776,
      "grad_norm": 0.35842210054397583,
      "learning_rate": 0.00011289728000000002,
      "loss": 2.1818,
      "step": 68050
    },
    {
      "epoch": 2.1792,
      "grad_norm": 0.3153577744960785,
      "learning_rate": 0.00011283328,
      "loss": 2.1514,
      "step": 68100
    },
    {
      "epoch": 2.1808,
      "grad_norm": 0.3472757935523987,
      "learning_rate": 0.00011276928,
      "loss": 2.1698,
      "step": 68150
    },
    {
      "epoch": 2.1824,
      "grad_norm": 0.3433091342449188,
      "learning_rate": 0.00011270528,
      "loss": 2.1246,
      "step": 68200
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.42293137311935425,
      "learning_rate": 0.00011264128,
      "loss": 2.1845,
      "step": 68250
    },
    {
      "epoch": 2.1856,
      "grad_norm": 0.32213377952575684,
      "learning_rate": 0.00011257728000000001,
      "loss": 2.0538,
      "step": 68300
    },
    {
      "epoch": 2.1872,
      "grad_norm": 0.3069731295108795,
      "learning_rate": 0.00011251328,
      "loss": 2.1073,
      "step": 68350
    },
    {
      "epoch": 2.1888,
      "grad_norm": 0.34068742394447327,
      "learning_rate": 0.00011244928000000001,
      "loss": 2.1402,
      "step": 68400
    },
    {
      "epoch": 2.1904,
      "grad_norm": 0.3338016867637634,
      "learning_rate": 0.00011238528000000001,
      "loss": 2.0668,
      "step": 68450
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.3457430601119995,
      "learning_rate": 0.00011232127999999999,
      "loss": 2.0844,
      "step": 68500
    },
    {
      "epoch": 2.1936,
      "grad_norm": 0.43794918060302734,
      "learning_rate": 0.00011225728,
      "loss": 2.103,
      "step": 68550
    },
    {
      "epoch": 2.1952,
      "grad_norm": 0.33730781078338623,
      "learning_rate": 0.00011219328,
      "loss": 2.0837,
      "step": 68600
    },
    {
      "epoch": 2.1968,
      "grad_norm": 0.3562454283237457,
      "learning_rate": 0.00011212928,
      "loss": 2.0967,
      "step": 68650
    },
    {
      "epoch": 2.1984,
      "grad_norm": 0.27446508407592773,
      "learning_rate": 0.00011206528000000001,
      "loss": 2.1309,
      "step": 68700
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.38387331366539,
      "learning_rate": 0.00011200128,
      "loss": 2.061,
      "step": 68750
    },
    {
      "epoch": 2.2016,
      "grad_norm": 0.3102826774120331,
      "learning_rate": 0.00011193728000000002,
      "loss": 2.0879,
      "step": 68800
    },
    {
      "epoch": 2.2032,
      "grad_norm": 0.31720590591430664,
      "learning_rate": 0.00011187328000000001,
      "loss": 2.0861,
      "step": 68850
    },
    {
      "epoch": 2.2048,
      "grad_norm": 0.2828563153743744,
      "learning_rate": 0.00011180928000000002,
      "loss": 2.0742,
      "step": 68900
    },
    {
      "epoch": 2.2064,
      "grad_norm": 0.3496864140033722,
      "learning_rate": 0.00011174528,
      "loss": 2.1291,
      "step": 68950
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.3410758972167969,
      "learning_rate": 0.00011168128,
      "loss": 2.1045,
      "step": 69000
    },
    {
      "epoch": 2.2096,
      "grad_norm": 0.2965221405029297,
      "learning_rate": 0.00011161728,
      "loss": 2.1435,
      "step": 69050
    },
    {
      "epoch": 2.2112,
      "grad_norm": 0.3163028955459595,
      "learning_rate": 0.00011155328,
      "loss": 2.144,
      "step": 69100
    },
    {
      "epoch": 2.2128,
      "grad_norm": 0.2852657735347748,
      "learning_rate": 0.00011148928000000001,
      "loss": 2.1054,
      "step": 69150
    },
    {
      "epoch": 2.2144,
      "grad_norm": 0.29119887948036194,
      "learning_rate": 0.00011142528,
      "loss": 2.0866,
      "step": 69200
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.31175529956817627,
      "learning_rate": 0.00011136128000000001,
      "loss": 2.1598,
      "step": 69250
    },
    {
      "epoch": 2.2176,
      "grad_norm": 0.3434048891067505,
      "learning_rate": 0.00011129728000000002,
      "loss": 2.1347,
      "step": 69300
    },
    {
      "epoch": 2.2192,
      "grad_norm": 0.32519277930259705,
      "learning_rate": 0.00011123327999999999,
      "loss": 2.0748,
      "step": 69350
    },
    {
      "epoch": 2.2208,
      "grad_norm": 0.3103661835193634,
      "learning_rate": 0.00011116928,
      "loss": 2.1656,
      "step": 69400
    },
    {
      "epoch": 2.2224,
      "grad_norm": 0.3261329233646393,
      "learning_rate": 0.00011110528000000001,
      "loss": 2.1598,
      "step": 69450
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.3242088258266449,
      "learning_rate": 0.00011104128,
      "loss": 2.1165,
      "step": 69500
    },
    {
      "epoch": 2.2256,
      "grad_norm": 0.30174723267555237,
      "learning_rate": 0.00011097728000000001,
      "loss": 2.0708,
      "step": 69550
    },
    {
      "epoch": 2.2272,
      "grad_norm": 0.33189377188682556,
      "learning_rate": 0.00011091328,
      "loss": 2.1096,
      "step": 69600
    },
    {
      "epoch": 2.2288,
      "grad_norm": 0.3429643511772156,
      "learning_rate": 0.00011084928000000001,
      "loss": 2.1648,
      "step": 69650
    },
    {
      "epoch": 2.2304,
      "grad_norm": 0.32650041580200195,
      "learning_rate": 0.00011078528000000001,
      "loss": 2.0797,
      "step": 69700
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.3449689745903015,
      "learning_rate": 0.00011072128000000002,
      "loss": 2.2025,
      "step": 69750
    },
    {
      "epoch": 2.2336,
      "grad_norm": 0.3216443657875061,
      "learning_rate": 0.00011065728,
      "loss": 2.1618,
      "step": 69800
    },
    {
      "epoch": 2.2352,
      "grad_norm": 0.30799809098243713,
      "learning_rate": 0.00011059328,
      "loss": 2.1404,
      "step": 69850
    },
    {
      "epoch": 2.2368,
      "grad_norm": 0.36275190114974976,
      "learning_rate": 0.00011052928,
      "loss": 2.165,
      "step": 69900
    },
    {
      "epoch": 2.2384,
      "grad_norm": 0.30561745166778564,
      "learning_rate": 0.00011046528,
      "loss": 2.1113,
      "step": 69950
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3610733449459076,
      "learning_rate": 0.00011040128000000001,
      "loss": 2.1174,
      "step": 70000
    },
    {
      "epoch": 2.2416,
      "grad_norm": 0.3498520851135254,
      "learning_rate": 0.00011033728,
      "loss": 2.1188,
      "step": 70050
    },
    {
      "epoch": 2.2432,
      "grad_norm": 0.33655819296836853,
      "learning_rate": 0.00011027328000000001,
      "loss": 2.153,
      "step": 70100
    },
    {
      "epoch": 2.2448,
      "grad_norm": 0.3634321093559265,
      "learning_rate": 0.00011020928000000002,
      "loss": 2.0477,
      "step": 70150
    },
    {
      "epoch": 2.2464,
      "grad_norm": 0.33540165424346924,
      "learning_rate": 0.00011014527999999999,
      "loss": 2.1343,
      "step": 70200
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.33945292234420776,
      "learning_rate": 0.00011008128,
      "loss": 2.1353,
      "step": 70250
    },
    {
      "epoch": 2.2496,
      "grad_norm": 0.33532893657684326,
      "learning_rate": 0.00011001728,
      "loss": 2.1582,
      "step": 70300
    },
    {
      "epoch": 2.2512,
      "grad_norm": 0.3622693419456482,
      "learning_rate": 0.00010995328,
      "loss": 2.1335,
      "step": 70350
    },
    {
      "epoch": 2.2528,
      "grad_norm": 0.380056232213974,
      "learning_rate": 0.00010988928000000001,
      "loss": 2.1271,
      "step": 70400
    },
    {
      "epoch": 2.2544,
      "grad_norm": 0.4158188998699188,
      "learning_rate": 0.00010982528,
      "loss": 2.1126,
      "step": 70450
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.3904111385345459,
      "learning_rate": 0.00010976128000000001,
      "loss": 2.1138,
      "step": 70500
    },
    {
      "epoch": 2.2576,
      "grad_norm": 0.34885358810424805,
      "learning_rate": 0.00010969728000000001,
      "loss": 2.1155,
      "step": 70550
    },
    {
      "epoch": 2.2592,
      "grad_norm": 0.33684369921684265,
      "learning_rate": 0.00010963328000000002,
      "loss": 2.1116,
      "step": 70600
    },
    {
      "epoch": 2.2608,
      "grad_norm": 0.34535565972328186,
      "learning_rate": 0.00010956928,
      "loss": 2.1021,
      "step": 70650
    },
    {
      "epoch": 2.2624,
      "grad_norm": 0.3241727948188782,
      "learning_rate": 0.00010950528,
      "loss": 2.1562,
      "step": 70700
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.31945911049842834,
      "learning_rate": 0.00010944128,
      "loss": 2.1199,
      "step": 70750
    },
    {
      "epoch": 2.2656,
      "grad_norm": 0.3845265209674835,
      "learning_rate": 0.00010937728,
      "loss": 2.0782,
      "step": 70800
    },
    {
      "epoch": 2.2672,
      "grad_norm": 0.3038465678691864,
      "learning_rate": 0.00010931328000000001,
      "loss": 2.1489,
      "step": 70850
    },
    {
      "epoch": 2.2688,
      "grad_norm": 0.3526685833930969,
      "learning_rate": 0.00010924928,
      "loss": 2.0894,
      "step": 70900
    },
    {
      "epoch": 2.2704,
      "grad_norm": 0.3312751054763794,
      "learning_rate": 0.00010918528000000001,
      "loss": 2.0803,
      "step": 70950
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.315733402967453,
      "learning_rate": 0.00010912128000000002,
      "loss": 2.1174,
      "step": 71000
    },
    {
      "epoch": 2.2736,
      "grad_norm": 0.34661340713500977,
      "learning_rate": 0.00010905727999999999,
      "loss": 2.0786,
      "step": 71050
    },
    {
      "epoch": 2.2752,
      "grad_norm": 0.3192846179008484,
      "learning_rate": 0.00010899328,
      "loss": 2.1391,
      "step": 71100
    },
    {
      "epoch": 2.2768,
      "grad_norm": 0.34840089082717896,
      "learning_rate": 0.00010892928,
      "loss": 2.0904,
      "step": 71150
    },
    {
      "epoch": 2.2784,
      "grad_norm": 0.37428462505340576,
      "learning_rate": 0.00010886528,
      "loss": 2.0468,
      "step": 71200
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.3660809397697449,
      "learning_rate": 0.00010880128000000001,
      "loss": 2.1251,
      "step": 71250
    },
    {
      "epoch": 2.2816,
      "grad_norm": 0.3214553892612457,
      "learning_rate": 0.00010873728,
      "loss": 2.0773,
      "step": 71300
    },
    {
      "epoch": 2.2832,
      "grad_norm": 0.35500189661979675,
      "learning_rate": 0.00010867328000000001,
      "loss": 2.0759,
      "step": 71350
    },
    {
      "epoch": 2.2848,
      "grad_norm": 0.3697586953639984,
      "learning_rate": 0.00010860928000000001,
      "loss": 2.1244,
      "step": 71400
    },
    {
      "epoch": 2.2864,
      "grad_norm": 0.353954941034317,
      "learning_rate": 0.00010854528000000002,
      "loss": 2.1003,
      "step": 71450
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.40276601910591125,
      "learning_rate": 0.00010848128,
      "loss": 2.1939,
      "step": 71500
    },
    {
      "epoch": 2.2896,
      "grad_norm": 0.42808687686920166,
      "learning_rate": 0.00010841728,
      "loss": 2.1087,
      "step": 71550
    },
    {
      "epoch": 2.2912,
      "grad_norm": 0.4504760205745697,
      "learning_rate": 0.00010835328,
      "loss": 2.0748,
      "step": 71600
    },
    {
      "epoch": 2.2928,
      "grad_norm": 0.3290398120880127,
      "learning_rate": 0.00010828928,
      "loss": 2.0775,
      "step": 71650
    },
    {
      "epoch": 2.2944,
      "grad_norm": 0.4007331430912018,
      "learning_rate": 0.00010822528000000001,
      "loss": 2.1599,
      "step": 71700
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.37916725873947144,
      "learning_rate": 0.00010816128,
      "loss": 2.0834,
      "step": 71750
    },
    {
      "epoch": 2.2976,
      "grad_norm": 0.32252126932144165,
      "learning_rate": 0.00010809728000000001,
      "loss": 2.1331,
      "step": 71800
    },
    {
      "epoch": 2.2992,
      "grad_norm": 0.405860960483551,
      "learning_rate": 0.00010803328000000002,
      "loss": 2.1044,
      "step": 71850
    },
    {
      "epoch": 2.3008,
      "grad_norm": 0.3127121329307556,
      "learning_rate": 0.00010796927999999999,
      "loss": 2.1911,
      "step": 71900
    },
    {
      "epoch": 2.3024,
      "grad_norm": 0.3541213274002075,
      "learning_rate": 0.00010790528,
      "loss": 2.06,
      "step": 71950
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.34379205107688904,
      "learning_rate": 0.00010784128,
      "loss": 2.1201,
      "step": 72000
    },
    {
      "epoch": 2.3056,
      "grad_norm": 0.3583928346633911,
      "learning_rate": 0.00010777728,
      "loss": 2.121,
      "step": 72050
    },
    {
      "epoch": 2.3072,
      "grad_norm": 0.36293119192123413,
      "learning_rate": 0.00010771328000000001,
      "loss": 2.1206,
      "step": 72100
    },
    {
      "epoch": 2.3088,
      "grad_norm": 0.35192960500717163,
      "learning_rate": 0.00010764928,
      "loss": 2.1404,
      "step": 72150
    },
    {
      "epoch": 2.3104,
      "grad_norm": 0.3190383315086365,
      "learning_rate": 0.00010758528000000001,
      "loss": 2.1064,
      "step": 72200
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.3148025870323181,
      "learning_rate": 0.00010752128000000001,
      "loss": 2.1301,
      "step": 72250
    },
    {
      "epoch": 2.3136,
      "grad_norm": 0.33587801456451416,
      "learning_rate": 0.00010745728000000002,
      "loss": 2.1381,
      "step": 72300
    },
    {
      "epoch": 2.3152,
      "grad_norm": 0.3832353353500366,
      "learning_rate": 0.00010739328,
      "loss": 2.1589,
      "step": 72350
    },
    {
      "epoch": 2.3168,
      "grad_norm": 0.3061290681362152,
      "learning_rate": 0.00010732928,
      "loss": 2.1573,
      "step": 72400
    },
    {
      "epoch": 2.3184,
      "grad_norm": 0.2811663746833801,
      "learning_rate": 0.00010726528,
      "loss": 2.0978,
      "step": 72450
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.3537755310535431,
      "learning_rate": 0.00010720128,
      "loss": 2.1129,
      "step": 72500
    },
    {
      "epoch": 2.3216,
      "grad_norm": 0.36348846554756165,
      "learning_rate": 0.00010713728000000001,
      "loss": 2.0673,
      "step": 72550
    },
    {
      "epoch": 2.3232,
      "grad_norm": 0.3453485369682312,
      "learning_rate": 0.00010707328000000002,
      "loss": 2.169,
      "step": 72600
    },
    {
      "epoch": 2.3247999999999998,
      "grad_norm": 0.30414748191833496,
      "learning_rate": 0.00010700928000000001,
      "loss": 2.1062,
      "step": 72650
    },
    {
      "epoch": 2.3264,
      "grad_norm": 0.38198551535606384,
      "learning_rate": 0.00010694528000000002,
      "loss": 2.1025,
      "step": 72700
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.288921058177948,
      "learning_rate": 0.00010688128,
      "loss": 2.0786,
      "step": 72750
    },
    {
      "epoch": 2.3296,
      "grad_norm": 0.33891886472702026,
      "learning_rate": 0.00010681728,
      "loss": 2.1304,
      "step": 72800
    },
    {
      "epoch": 2.3312,
      "grad_norm": 0.28448742628097534,
      "learning_rate": 0.00010675328,
      "loss": 2.0927,
      "step": 72850
    },
    {
      "epoch": 2.3327999999999998,
      "grad_norm": 0.37001389265060425,
      "learning_rate": 0.00010668928,
      "loss": 2.0874,
      "step": 72900
    },
    {
      "epoch": 2.3344,
      "grad_norm": 0.30855536460876465,
      "learning_rate": 0.00010662528000000001,
      "loss": 2.0712,
      "step": 72950
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.3256962299346924,
      "learning_rate": 0.00010656128,
      "loss": 2.0647,
      "step": 73000
    },
    {
      "epoch": 2.3376,
      "grad_norm": 0.2895563244819641,
      "learning_rate": 0.00010649728000000001,
      "loss": 2.1331,
      "step": 73050
    },
    {
      "epoch": 2.3392,
      "grad_norm": 0.39242488145828247,
      "learning_rate": 0.00010643328000000001,
      "loss": 2.1571,
      "step": 73100
    },
    {
      "epoch": 2.3407999999999998,
      "grad_norm": 0.35209688544273376,
      "learning_rate": 0.00010636928000000002,
      "loss": 2.0604,
      "step": 73150
    },
    {
      "epoch": 2.3424,
      "grad_norm": 0.36149269342422485,
      "learning_rate": 0.00010630528,
      "loss": 2.1206,
      "step": 73200
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.3283883035182953,
      "learning_rate": 0.00010624128,
      "loss": 2.0911,
      "step": 73250
    },
    {
      "epoch": 2.3456,
      "grad_norm": 0.3944210112094879,
      "learning_rate": 0.00010617728,
      "loss": 2.1139,
      "step": 73300
    },
    {
      "epoch": 2.3472,
      "grad_norm": 0.3539714515209198,
      "learning_rate": 0.00010611328,
      "loss": 2.1626,
      "step": 73350
    },
    {
      "epoch": 2.3487999999999998,
      "grad_norm": 0.3669717013835907,
      "learning_rate": 0.00010604928,
      "loss": 2.0929,
      "step": 73400
    },
    {
      "epoch": 2.3504,
      "grad_norm": 0.35355472564697266,
      "learning_rate": 0.00010598528000000002,
      "loss": 2.1129,
      "step": 73450
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.336101770401001,
      "learning_rate": 0.00010592128000000001,
      "loss": 2.1402,
      "step": 73500
    },
    {
      "epoch": 2.3536,
      "grad_norm": 0.3538232147693634,
      "learning_rate": 0.00010585728000000002,
      "loss": 2.072,
      "step": 73550
    },
    {
      "epoch": 2.3552,
      "grad_norm": 0.348548948764801,
      "learning_rate": 0.00010579328,
      "loss": 2.1504,
      "step": 73600
    },
    {
      "epoch": 2.3568,
      "grad_norm": 0.31371158361434937,
      "learning_rate": 0.00010572928,
      "loss": 2.0944,
      "step": 73650
    },
    {
      "epoch": 2.3584,
      "grad_norm": 0.3531377911567688,
      "learning_rate": 0.00010566528,
      "loss": 2.1055,
      "step": 73700
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.35495179891586304,
      "learning_rate": 0.00010560128,
      "loss": 2.1629,
      "step": 73750
    },
    {
      "epoch": 2.3616,
      "grad_norm": 0.37665554881095886,
      "learning_rate": 0.00010553728000000001,
      "loss": 2.1704,
      "step": 73800
    },
    {
      "epoch": 2.3632,
      "grad_norm": 0.36366188526153564,
      "learning_rate": 0.00010547328,
      "loss": 2.027,
      "step": 73850
    },
    {
      "epoch": 2.3648,
      "grad_norm": 0.3804134726524353,
      "learning_rate": 0.00010540928000000001,
      "loss": 2.1367,
      "step": 73900
    },
    {
      "epoch": 2.3664,
      "grad_norm": 0.3195953965187073,
      "learning_rate": 0.00010534528000000001,
      "loss": 2.1374,
      "step": 73950
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.30386054515838623,
      "learning_rate": 0.00010528128000000002,
      "loss": 2.1505,
      "step": 74000
    },
    {
      "epoch": 2.3696,
      "grad_norm": 0.3253595232963562,
      "learning_rate": 0.00010521728,
      "loss": 2.1414,
      "step": 74050
    },
    {
      "epoch": 2.3712,
      "grad_norm": 0.35215407609939575,
      "learning_rate": 0.00010515328,
      "loss": 2.1133,
      "step": 74100
    },
    {
      "epoch": 2.3728,
      "grad_norm": 0.348285436630249,
      "learning_rate": 0.00010508928,
      "loss": 2.0931,
      "step": 74150
    },
    {
      "epoch": 2.3744,
      "grad_norm": 0.38145557045936584,
      "learning_rate": 0.00010502528,
      "loss": 2.1629,
      "step": 74200
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.3331137001514435,
      "learning_rate": 0.00010496128,
      "loss": 2.0962,
      "step": 74250
    },
    {
      "epoch": 2.3776,
      "grad_norm": 0.31361499428749084,
      "learning_rate": 0.00010489728000000001,
      "loss": 2.1189,
      "step": 74300
    },
    {
      "epoch": 2.3792,
      "grad_norm": 0.3086101710796356,
      "learning_rate": 0.00010483328000000001,
      "loss": 2.0822,
      "step": 74350
    },
    {
      "epoch": 2.3808,
      "grad_norm": 0.35428109765052795,
      "learning_rate": 0.00010476928000000002,
      "loss": 2.0915,
      "step": 74400
    },
    {
      "epoch": 2.3824,
      "grad_norm": 0.34966474771499634,
      "learning_rate": 0.00010470528,
      "loss": 2.1134,
      "step": 74450
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.32314732670783997,
      "learning_rate": 0.00010464128,
      "loss": 2.0583,
      "step": 74500
    },
    {
      "epoch": 2.3856,
      "grad_norm": 0.34905245900154114,
      "learning_rate": 0.00010457728,
      "loss": 2.2053,
      "step": 74550
    },
    {
      "epoch": 2.3872,
      "grad_norm": 0.3509311378002167,
      "learning_rate": 0.00010451328,
      "loss": 2.0752,
      "step": 74600
    },
    {
      "epoch": 2.3888,
      "grad_norm": 0.39170682430267334,
      "learning_rate": 0.00010444928000000001,
      "loss": 2.0919,
      "step": 74650
    },
    {
      "epoch": 2.3904,
      "grad_norm": 0.4533730745315552,
      "learning_rate": 0.00010438528,
      "loss": 2.1352,
      "step": 74700
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.3597274124622345,
      "learning_rate": 0.00010432128000000001,
      "loss": 2.1311,
      "step": 74750
    },
    {
      "epoch": 2.3936,
      "grad_norm": 0.390724241733551,
      "learning_rate": 0.00010425728000000001,
      "loss": 2.0862,
      "step": 74800
    },
    {
      "epoch": 2.3952,
      "grad_norm": 0.33411863446235657,
      "learning_rate": 0.00010419328000000002,
      "loss": 2.1037,
      "step": 74850
    },
    {
      "epoch": 2.3968,
      "grad_norm": 0.28455162048339844,
      "learning_rate": 0.00010412928,
      "loss": 2.1358,
      "step": 74900
    },
    {
      "epoch": 2.3984,
      "grad_norm": 0.34464287757873535,
      "learning_rate": 0.00010406527999999999,
      "loss": 2.0927,
      "step": 74950
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.3011372685432434,
      "learning_rate": 0.00010400128,
      "loss": 2.0956,
      "step": 75000
    },
    {
      "epoch": 2.4016,
      "grad_norm": 0.3320625424385071,
      "learning_rate": 0.00010393728,
      "loss": 2.1361,
      "step": 75050
    },
    {
      "epoch": 2.4032,
      "grad_norm": 0.36962753534317017,
      "learning_rate": 0.00010387328,
      "loss": 2.1626,
      "step": 75100
    },
    {
      "epoch": 2.4048,
      "grad_norm": 0.35113441944122314,
      "learning_rate": 0.00010380928000000001,
      "loss": 2.0956,
      "step": 75150
    },
    {
      "epoch": 2.4064,
      "grad_norm": 0.35199958086013794,
      "learning_rate": 0.00010374528000000001,
      "loss": 2.1228,
      "step": 75200
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.31786659359931946,
      "learning_rate": 0.00010368128000000002,
      "loss": 2.1499,
      "step": 75250
    },
    {
      "epoch": 2.4096,
      "grad_norm": 0.30921459197998047,
      "learning_rate": 0.00010361728,
      "loss": 2.1417,
      "step": 75300
    },
    {
      "epoch": 2.4112,
      "grad_norm": 0.32182157039642334,
      "learning_rate": 0.00010355328,
      "loss": 2.1133,
      "step": 75350
    },
    {
      "epoch": 2.4128,
      "grad_norm": 0.3631383776664734,
      "learning_rate": 0.00010348928,
      "loss": 2.1311,
      "step": 75400
    },
    {
      "epoch": 2.4144,
      "grad_norm": 0.3306390643119812,
      "learning_rate": 0.00010342528,
      "loss": 2.1214,
      "step": 75450
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.37456467747688293,
      "learning_rate": 0.00010336128000000001,
      "loss": 2.0928,
      "step": 75500
    },
    {
      "epoch": 2.4176,
      "grad_norm": 0.3048589825630188,
      "learning_rate": 0.00010329728,
      "loss": 2.1251,
      "step": 75550
    },
    {
      "epoch": 2.4192,
      "grad_norm": 0.3770025670528412,
      "learning_rate": 0.00010323328000000001,
      "loss": 2.1423,
      "step": 75600
    },
    {
      "epoch": 2.4208,
      "grad_norm": 0.3942530155181885,
      "learning_rate": 0.00010316928000000001,
      "loss": 2.1753,
      "step": 75650
    },
    {
      "epoch": 2.4224,
      "grad_norm": 0.39724403619766235,
      "learning_rate": 0.00010310528000000002,
      "loss": 2.0846,
      "step": 75700
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.3221311867237091,
      "learning_rate": 0.00010304128,
      "loss": 2.0725,
      "step": 75750
    },
    {
      "epoch": 2.4256,
      "grad_norm": 0.34656333923339844,
      "learning_rate": 0.00010297727999999999,
      "loss": 2.1343,
      "step": 75800
    },
    {
      "epoch": 2.4272,
      "grad_norm": 0.32082539796829224,
      "learning_rate": 0.00010291328,
      "loss": 2.0838,
      "step": 75850
    },
    {
      "epoch": 2.4288,
      "grad_norm": 0.30894479155540466,
      "learning_rate": 0.00010284928000000001,
      "loss": 2.0869,
      "step": 75900
    },
    {
      "epoch": 2.4304,
      "grad_norm": 0.30473771691322327,
      "learning_rate": 0.00010278528,
      "loss": 2.1423,
      "step": 75950
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.3953992426395416,
      "learning_rate": 0.00010272128000000001,
      "loss": 2.1089,
      "step": 76000
    },
    {
      "epoch": 2.4336,
      "grad_norm": 0.2970808744430542,
      "learning_rate": 0.00010265728000000001,
      "loss": 2.1375,
      "step": 76050
    },
    {
      "epoch": 2.4352,
      "grad_norm": 0.30118775367736816,
      "learning_rate": 0.00010259328000000002,
      "loss": 2.0733,
      "step": 76100
    },
    {
      "epoch": 2.4368,
      "grad_norm": 0.33869895339012146,
      "learning_rate": 0.00010252928,
      "loss": 2.0555,
      "step": 76150
    },
    {
      "epoch": 2.4384,
      "grad_norm": 0.3759264349937439,
      "learning_rate": 0.00010246528,
      "loss": 2.1513,
      "step": 76200
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.3067079782485962,
      "learning_rate": 0.00010240128,
      "loss": 2.2024,
      "step": 76250
    },
    {
      "epoch": 2.4416,
      "grad_norm": 0.35121995210647583,
      "learning_rate": 0.00010233728,
      "loss": 2.1448,
      "step": 76300
    },
    {
      "epoch": 2.4432,
      "grad_norm": 0.3561232388019562,
      "learning_rate": 0.00010227328000000001,
      "loss": 2.0798,
      "step": 76350
    },
    {
      "epoch": 2.4448,
      "grad_norm": 0.34211742877960205,
      "learning_rate": 0.00010220928,
      "loss": 2.1351,
      "step": 76400
    },
    {
      "epoch": 2.4464,
      "grad_norm": 0.4000699818134308,
      "learning_rate": 0.00010214528000000001,
      "loss": 2.0794,
      "step": 76450
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.352340430021286,
      "learning_rate": 0.00010208128,
      "loss": 2.1464,
      "step": 76500
    },
    {
      "epoch": 2.4496,
      "grad_norm": 0.3044602572917938,
      "learning_rate": 0.00010201728000000002,
      "loss": 2.0914,
      "step": 76550
    },
    {
      "epoch": 2.4512,
      "grad_norm": 0.32992833852767944,
      "learning_rate": 0.00010195328,
      "loss": 2.1189,
      "step": 76600
    },
    {
      "epoch": 2.4528,
      "grad_norm": 0.29464060068130493,
      "learning_rate": 0.00010188927999999999,
      "loss": 2.106,
      "step": 76650
    },
    {
      "epoch": 2.4544,
      "grad_norm": 0.3349156677722931,
      "learning_rate": 0.00010182528,
      "loss": 2.1385,
      "step": 76700
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.35747846961021423,
      "learning_rate": 0.00010176128000000001,
      "loss": 2.0682,
      "step": 76750
    },
    {
      "epoch": 2.4576000000000002,
      "grad_norm": 0.3326011300086975,
      "learning_rate": 0.00010169728,
      "loss": 2.103,
      "step": 76800
    },
    {
      "epoch": 2.4592,
      "grad_norm": 0.350240558385849,
      "learning_rate": 0.00010163328000000001,
      "loss": 2.0584,
      "step": 76850
    },
    {
      "epoch": 2.4608,
      "grad_norm": 0.31172919273376465,
      "learning_rate": 0.00010156928000000001,
      "loss": 2.1104,
      "step": 76900
    },
    {
      "epoch": 2.4624,
      "grad_norm": 0.3253932595252991,
      "learning_rate": 0.00010150528000000002,
      "loss": 2.1173,
      "step": 76950
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.3021297752857208,
      "learning_rate": 0.00010144128,
      "loss": 2.14,
      "step": 77000
    },
    {
      "epoch": 2.4656000000000002,
      "grad_norm": 0.3494565188884735,
      "learning_rate": 0.00010137728,
      "loss": 2.1678,
      "step": 77050
    },
    {
      "epoch": 2.4672,
      "grad_norm": 0.27532845735549927,
      "learning_rate": 0.00010131328,
      "loss": 2.1368,
      "step": 77100
    },
    {
      "epoch": 2.4688,
      "grad_norm": 0.35051894187927246,
      "learning_rate": 0.00010124928,
      "loss": 2.11,
      "step": 77150
    },
    {
      "epoch": 2.4704,
      "grad_norm": 0.34231695532798767,
      "learning_rate": 0.00010118528000000001,
      "loss": 2.1079,
      "step": 77200
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.3327648937702179,
      "learning_rate": 0.00010112128,
      "loss": 2.1,
      "step": 77250
    },
    {
      "epoch": 2.4736000000000002,
      "grad_norm": 0.3795531690120697,
      "learning_rate": 0.00010105728000000001,
      "loss": 2.103,
      "step": 77300
    },
    {
      "epoch": 2.4752,
      "grad_norm": 0.3201252818107605,
      "learning_rate": 0.00010099328,
      "loss": 2.0951,
      "step": 77350
    },
    {
      "epoch": 2.4768,
      "grad_norm": 0.31657248735427856,
      "learning_rate": 0.00010092928000000001,
      "loss": 2.119,
      "step": 77400
    },
    {
      "epoch": 2.4784,
      "grad_norm": 0.2983783781528473,
      "learning_rate": 0.00010086528,
      "loss": 2.1422,
      "step": 77450
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.30359208583831787,
      "learning_rate": 0.00010080127999999999,
      "loss": 2.0615,
      "step": 77500
    },
    {
      "epoch": 2.4816,
      "grad_norm": 0.39231574535369873,
      "learning_rate": 0.00010073728,
      "loss": 2.1987,
      "step": 77550
    },
    {
      "epoch": 2.4832,
      "grad_norm": 0.3801898956298828,
      "learning_rate": 0.00010067328000000001,
      "loss": 2.0619,
      "step": 77600
    },
    {
      "epoch": 2.4848,
      "grad_norm": 0.33082905411720276,
      "learning_rate": 0.00010060928,
      "loss": 2.0428,
      "step": 77650
    },
    {
      "epoch": 2.4864,
      "grad_norm": 0.35423484444618225,
      "learning_rate": 0.00010054528000000001,
      "loss": 2.1497,
      "step": 77700
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.3809584379196167,
      "learning_rate": 0.00010048128000000001,
      "loss": 2.1758,
      "step": 77750
    },
    {
      "epoch": 2.4896,
      "grad_norm": 0.35838308930397034,
      "learning_rate": 0.00010041728000000002,
      "loss": 2.1254,
      "step": 77800
    },
    {
      "epoch": 2.4912,
      "grad_norm": 0.4553041458129883,
      "learning_rate": 0.00010035328,
      "loss": 2.1122,
      "step": 77850
    },
    {
      "epoch": 2.4928,
      "grad_norm": 0.41728365421295166,
      "learning_rate": 0.00010028928,
      "loss": 2.0873,
      "step": 77900
    },
    {
      "epoch": 2.4944,
      "grad_norm": 0.3884182274341583,
      "learning_rate": 0.00010022528,
      "loss": 2.1234,
      "step": 77950
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.3734128177165985,
      "learning_rate": 0.00010016128,
      "loss": 2.0624,
      "step": 78000
    },
    {
      "epoch": 2.4976,
      "grad_norm": 0.3354954719543457,
      "learning_rate": 0.00010009728,
      "loss": 2.1086,
      "step": 78050
    },
    {
      "epoch": 2.4992,
      "grad_norm": 0.41407909989356995,
      "learning_rate": 0.00010003328,
      "loss": 2.1325,
      "step": 78100
    },
    {
      "epoch": 2.5008,
      "grad_norm": 0.3551834225654602,
      "learning_rate": 9.996928000000001e-05,
      "loss": 2.0923,
      "step": 78150
    },
    {
      "epoch": 2.5023999999999997,
      "grad_norm": 0.36139851808547974,
      "learning_rate": 9.990528e-05,
      "loss": 2.0795,
      "step": 78200
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.32790234684944153,
      "learning_rate": 9.984128e-05,
      "loss": 2.0798,
      "step": 78250
    },
    {
      "epoch": 2.5056000000000003,
      "grad_norm": 0.450047105550766,
      "learning_rate": 9.977728000000001e-05,
      "loss": 2.1375,
      "step": 78300
    },
    {
      "epoch": 2.5072,
      "grad_norm": 0.36320605874061584,
      "learning_rate": 9.971328e-05,
      "loss": 2.0585,
      "step": 78350
    },
    {
      "epoch": 2.5088,
      "grad_norm": 0.41593021154403687,
      "learning_rate": 9.964928e-05,
      "loss": 2.1341,
      "step": 78400
    },
    {
      "epoch": 2.5103999999999997,
      "grad_norm": 0.357583224773407,
      "learning_rate": 9.958528000000001e-05,
      "loss": 2.2544,
      "step": 78450
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.3534851372241974,
      "learning_rate": 9.952128e-05,
      "loss": 2.0801,
      "step": 78500
    },
    {
      "epoch": 2.5136,
      "grad_norm": 0.322860985994339,
      "learning_rate": 9.945728000000001e-05,
      "loss": 2.136,
      "step": 78550
    },
    {
      "epoch": 2.5152,
      "grad_norm": 0.34948351979255676,
      "learning_rate": 9.939328e-05,
      "loss": 2.045,
      "step": 78600
    },
    {
      "epoch": 2.5168,
      "grad_norm": 0.38163354992866516,
      "learning_rate": 9.932928e-05,
      "loss": 2.0566,
      "step": 78650
    },
    {
      "epoch": 2.5183999999999997,
      "grad_norm": 0.33584272861480713,
      "learning_rate": 9.926528e-05,
      "loss": 2.0998,
      "step": 78700
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.3582956790924072,
      "learning_rate": 9.920128000000001e-05,
      "loss": 2.155,
      "step": 78750
    },
    {
      "epoch": 2.5216,
      "grad_norm": 0.3464528024196625,
      "learning_rate": 9.913728000000002e-05,
      "loss": 2.1015,
      "step": 78800
    },
    {
      "epoch": 2.5232,
      "grad_norm": 0.33216923475265503,
      "learning_rate": 9.907328e-05,
      "loss": 2.1228,
      "step": 78850
    },
    {
      "epoch": 2.5248,
      "grad_norm": 0.3135683238506317,
      "learning_rate": 9.900928e-05,
      "loss": 2.1043,
      "step": 78900
    },
    {
      "epoch": 2.5263999999999998,
      "grad_norm": 0.3445720970630646,
      "learning_rate": 9.894528e-05,
      "loss": 2.1574,
      "step": 78950
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.3568094074726105,
      "learning_rate": 9.888128000000001e-05,
      "loss": 2.1716,
      "step": 79000
    },
    {
      "epoch": 2.5296,
      "grad_norm": 0.36536094546318054,
      "learning_rate": 9.881728e-05,
      "loss": 2.1558,
      "step": 79050
    },
    {
      "epoch": 2.5312,
      "grad_norm": 0.303382933139801,
      "learning_rate": 9.875328e-05,
      "loss": 2.1484,
      "step": 79100
    },
    {
      "epoch": 2.5328,
      "grad_norm": 0.46303221583366394,
      "learning_rate": 9.868928000000001e-05,
      "loss": 2.1337,
      "step": 79150
    },
    {
      "epoch": 2.5343999999999998,
      "grad_norm": 0.3528396785259247,
      "learning_rate": 9.862528e-05,
      "loss": 2.1216,
      "step": 79200
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.4108809232711792,
      "learning_rate": 9.856128e-05,
      "loss": 2.1438,
      "step": 79250
    },
    {
      "epoch": 2.5376,
      "grad_norm": 0.32355234026908875,
      "learning_rate": 9.849728000000001e-05,
      "loss": 2.0991,
      "step": 79300
    },
    {
      "epoch": 2.5392,
      "grad_norm": 0.3519293963909149,
      "learning_rate": 9.843328e-05,
      "loss": 2.1511,
      "step": 79350
    },
    {
      "epoch": 2.5408,
      "grad_norm": 0.3312186598777771,
      "learning_rate": 9.836928000000001e-05,
      "loss": 2.1715,
      "step": 79400
    },
    {
      "epoch": 2.5423999999999998,
      "grad_norm": 0.3218650221824646,
      "learning_rate": 9.830528e-05,
      "loss": 2.1507,
      "step": 79450
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.4324135184288025,
      "learning_rate": 9.824128e-05,
      "loss": 2.1944,
      "step": 79500
    },
    {
      "epoch": 2.5456,
      "grad_norm": 0.3458872437477112,
      "learning_rate": 9.817728000000001e-05,
      "loss": 2.1019,
      "step": 79550
    },
    {
      "epoch": 2.5472,
      "grad_norm": 0.36927589774131775,
      "learning_rate": 9.811328e-05,
      "loss": 2.1583,
      "step": 79600
    },
    {
      "epoch": 2.5488,
      "grad_norm": 0.3438819944858551,
      "learning_rate": 9.804928000000002e-05,
      "loss": 2.0602,
      "step": 79650
    },
    {
      "epoch": 2.5504,
      "grad_norm": 0.3804858922958374,
      "learning_rate": 9.798528e-05,
      "loss": 2.1532,
      "step": 79700
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.29309600591659546,
      "learning_rate": 9.792128e-05,
      "loss": 2.1403,
      "step": 79750
    },
    {
      "epoch": 2.5536,
      "grad_norm": 0.3585508167743683,
      "learning_rate": 9.785728e-05,
      "loss": 2.1279,
      "step": 79800
    },
    {
      "epoch": 2.5552,
      "grad_norm": 0.37176400423049927,
      "learning_rate": 9.779328000000001e-05,
      "loss": 2.1311,
      "step": 79850
    },
    {
      "epoch": 2.5568,
      "grad_norm": 0.2997407019138336,
      "learning_rate": 9.772928e-05,
      "loss": 2.158,
      "step": 79900
    },
    {
      "epoch": 2.5584,
      "grad_norm": 0.3776148855686188,
      "learning_rate": 9.766528e-05,
      "loss": 2.1189,
      "step": 79950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.3121494948863983,
      "learning_rate": 9.760128000000001e-05,
      "loss": 2.0903,
      "step": 80000
    },
    {
      "epoch": 2.5616,
      "grad_norm": 0.34618571400642395,
      "learning_rate": 9.753728e-05,
      "loss": 2.0748,
      "step": 80050
    },
    {
      "epoch": 2.5632,
      "grad_norm": 0.30988645553588867,
      "learning_rate": 9.747328e-05,
      "loss": 2.1063,
      "step": 80100
    },
    {
      "epoch": 2.5648,
      "grad_norm": 0.30991145968437195,
      "learning_rate": 9.740928000000001e-05,
      "loss": 2.123,
      "step": 80150
    },
    {
      "epoch": 2.5664,
      "grad_norm": 0.3376644253730774,
      "learning_rate": 9.734528e-05,
      "loss": 2.1006,
      "step": 80200
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.34363073110580444,
      "learning_rate": 9.728128000000001e-05,
      "loss": 2.0995,
      "step": 80250
    },
    {
      "epoch": 2.5696,
      "grad_norm": 0.3284398913383484,
      "learning_rate": 9.721728e-05,
      "loss": 2.1256,
      "step": 80300
    },
    {
      "epoch": 2.5712,
      "grad_norm": 0.37992069125175476,
      "learning_rate": 9.715328e-05,
      "loss": 2.111,
      "step": 80350
    },
    {
      "epoch": 2.5728,
      "grad_norm": 0.3247569799423218,
      "learning_rate": 9.708928000000001e-05,
      "loss": 2.0685,
      "step": 80400
    },
    {
      "epoch": 2.5744,
      "grad_norm": 0.34559929370880127,
      "learning_rate": 9.702528e-05,
      "loss": 2.0343,
      "step": 80450
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.42828747630119324,
      "learning_rate": 9.696128000000002e-05,
      "loss": 2.1078,
      "step": 80500
    },
    {
      "epoch": 2.5776,
      "grad_norm": 0.35557448863983154,
      "learning_rate": 9.689728e-05,
      "loss": 2.1168,
      "step": 80550
    },
    {
      "epoch": 2.5792,
      "grad_norm": 0.33775073289871216,
      "learning_rate": 9.683328e-05,
      "loss": 2.0863,
      "step": 80600
    },
    {
      "epoch": 2.5808,
      "grad_norm": 0.32776308059692383,
      "learning_rate": 9.676928e-05,
      "loss": 2.1401,
      "step": 80650
    },
    {
      "epoch": 2.5824,
      "grad_norm": 0.3472761809825897,
      "learning_rate": 9.670528000000001e-05,
      "loss": 2.0744,
      "step": 80700
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.3129577934741974,
      "learning_rate": 9.664128e-05,
      "loss": 2.1093,
      "step": 80750
    },
    {
      "epoch": 2.5856,
      "grad_norm": 0.4108150005340576,
      "learning_rate": 9.657728e-05,
      "loss": 2.1272,
      "step": 80800
    },
    {
      "epoch": 2.5872,
      "grad_norm": 0.32335859537124634,
      "learning_rate": 9.651328000000001e-05,
      "loss": 2.1258,
      "step": 80850
    },
    {
      "epoch": 2.5888,
      "grad_norm": 0.3637754023075104,
      "learning_rate": 9.644928e-05,
      "loss": 2.0925,
      "step": 80900
    },
    {
      "epoch": 2.5904,
      "grad_norm": 0.4073047935962677,
      "learning_rate": 9.638528e-05,
      "loss": 2.1088,
      "step": 80950
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.6551039814949036,
      "learning_rate": 9.632128000000001e-05,
      "loss": 2.1535,
      "step": 81000
    },
    {
      "epoch": 2.5936,
      "grad_norm": 0.33409035205841064,
      "learning_rate": 9.625728e-05,
      "loss": 2.1229,
      "step": 81050
    },
    {
      "epoch": 2.5952,
      "grad_norm": 0.32730767130851746,
      "learning_rate": 9.619328000000001e-05,
      "loss": 2.1654,
      "step": 81100
    },
    {
      "epoch": 2.5968,
      "grad_norm": 0.41528213024139404,
      "learning_rate": 9.612927999999999e-05,
      "loss": 2.071,
      "step": 81150
    },
    {
      "epoch": 2.5984,
      "grad_norm": 0.3974761664867401,
      "learning_rate": 9.606528e-05,
      "loss": 2.1113,
      "step": 81200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3435336947441101,
      "learning_rate": 9.600128000000001e-05,
      "loss": 2.1334,
      "step": 81250
    },
    {
      "epoch": 2.6016,
      "grad_norm": 0.32891640067100525,
      "learning_rate": 9.593728e-05,
      "loss": 2.1672,
      "step": 81300
    },
    {
      "epoch": 2.6032,
      "grad_norm": 0.3667038381099701,
      "learning_rate": 9.587328000000001e-05,
      "loss": 2.1709,
      "step": 81350
    },
    {
      "epoch": 2.6048,
      "grad_norm": 0.36786237359046936,
      "learning_rate": 9.580928e-05,
      "loss": 2.1106,
      "step": 81400
    },
    {
      "epoch": 2.6064,
      "grad_norm": 0.36579272150993347,
      "learning_rate": 9.574528e-05,
      "loss": 2.1078,
      "step": 81450
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.3510752022266388,
      "learning_rate": 9.568128e-05,
      "loss": 2.0923,
      "step": 81500
    },
    {
      "epoch": 2.6096,
      "grad_norm": 0.4248960316181183,
      "learning_rate": 9.561728000000001e-05,
      "loss": 2.1715,
      "step": 81550
    },
    {
      "epoch": 2.6112,
      "grad_norm": 0.370967835187912,
      "learning_rate": 9.555328e-05,
      "loss": 2.0742,
      "step": 81600
    },
    {
      "epoch": 2.6128,
      "grad_norm": 0.348442018032074,
      "learning_rate": 9.548928e-05,
      "loss": 2.1186,
      "step": 81650
    },
    {
      "epoch": 2.6144,
      "grad_norm": 0.3339022397994995,
      "learning_rate": 9.542528000000001e-05,
      "loss": 2.1439,
      "step": 81700
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.28540927171707153,
      "learning_rate": 9.536128e-05,
      "loss": 2.1445,
      "step": 81750
    },
    {
      "epoch": 2.6176,
      "grad_norm": 0.3342929184436798,
      "learning_rate": 9.529728e-05,
      "loss": 2.1158,
      "step": 81800
    },
    {
      "epoch": 2.6192,
      "grad_norm": 0.33835870027542114,
      "learning_rate": 9.523328000000001e-05,
      "loss": 2.1293,
      "step": 81850
    },
    {
      "epoch": 2.6208,
      "grad_norm": 0.3280041515827179,
      "learning_rate": 9.516928e-05,
      "loss": 2.1144,
      "step": 81900
    },
    {
      "epoch": 2.6224,
      "grad_norm": 0.4703785181045532,
      "learning_rate": 9.510528000000001e-05,
      "loss": 2.1012,
      "step": 81950
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.33555200695991516,
      "learning_rate": 9.504127999999999e-05,
      "loss": 2.1706,
      "step": 82000
    },
    {
      "epoch": 2.6256,
      "grad_norm": 0.40850841999053955,
      "learning_rate": 9.497728e-05,
      "loss": 2.1204,
      "step": 82050
    },
    {
      "epoch": 2.6272,
      "grad_norm": 0.4038063585758209,
      "learning_rate": 9.491328000000001e-05,
      "loss": 2.0862,
      "step": 82100
    },
    {
      "epoch": 2.6288,
      "grad_norm": 0.4158167243003845,
      "learning_rate": 9.484928e-05,
      "loss": 2.1033,
      "step": 82150
    },
    {
      "epoch": 2.6304,
      "grad_norm": 0.3264291286468506,
      "learning_rate": 9.478528000000001e-05,
      "loss": 2.1284,
      "step": 82200
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.37290629744529724,
      "learning_rate": 9.472128e-05,
      "loss": 2.1307,
      "step": 82250
    },
    {
      "epoch": 2.6336,
      "grad_norm": 0.3107931911945343,
      "learning_rate": 9.465728e-05,
      "loss": 2.1486,
      "step": 82300
    },
    {
      "epoch": 2.6352,
      "grad_norm": 0.303780198097229,
      "learning_rate": 9.459328e-05,
      "loss": 2.1325,
      "step": 82350
    },
    {
      "epoch": 2.6368,
      "grad_norm": 0.39498370885849,
      "learning_rate": 9.452928000000001e-05,
      "loss": 2.0821,
      "step": 82400
    },
    {
      "epoch": 2.6384,
      "grad_norm": 0.33569058775901794,
      "learning_rate": 9.446528e-05,
      "loss": 2.1656,
      "step": 82450
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.37905704975128174,
      "learning_rate": 9.440128e-05,
      "loss": 2.1144,
      "step": 82500
    },
    {
      "epoch": 2.6416,
      "grad_norm": 0.4139246940612793,
      "learning_rate": 9.433728000000001e-05,
      "loss": 2.0979,
      "step": 82550
    },
    {
      "epoch": 2.6432,
      "grad_norm": 0.40197569131851196,
      "learning_rate": 9.427328e-05,
      "loss": 2.1248,
      "step": 82600
    },
    {
      "epoch": 2.6448,
      "grad_norm": 0.36947861313819885,
      "learning_rate": 9.420928e-05,
      "loss": 2.1321,
      "step": 82650
    },
    {
      "epoch": 2.6464,
      "grad_norm": 0.3463435173034668,
      "learning_rate": 9.414528e-05,
      "loss": 2.1138,
      "step": 82700
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.3076523542404175,
      "learning_rate": 9.408128e-05,
      "loss": 2.0964,
      "step": 82750
    },
    {
      "epoch": 2.6496,
      "grad_norm": 0.335632860660553,
      "learning_rate": 9.401728000000001e-05,
      "loss": 2.1487,
      "step": 82800
    },
    {
      "epoch": 2.6512000000000002,
      "grad_norm": 0.40779727697372437,
      "learning_rate": 9.395327999999999e-05,
      "loss": 2.1057,
      "step": 82850
    },
    {
      "epoch": 2.6528,
      "grad_norm": 0.4208988547325134,
      "learning_rate": 9.388928e-05,
      "loss": 2.1357,
      "step": 82900
    },
    {
      "epoch": 2.6544,
      "grad_norm": 0.38824349641799927,
      "learning_rate": 9.382528000000001e-05,
      "loss": 2.146,
      "step": 82950
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.3314732313156128,
      "learning_rate": 9.376128e-05,
      "loss": 2.0931,
      "step": 83000
    },
    {
      "epoch": 2.6576,
      "grad_norm": 0.3755415678024292,
      "learning_rate": 9.369728000000001e-05,
      "loss": 2.1401,
      "step": 83050
    },
    {
      "epoch": 2.6592000000000002,
      "grad_norm": 0.3602408170700073,
      "learning_rate": 9.363328e-05,
      "loss": 2.0763,
      "step": 83100
    },
    {
      "epoch": 2.6608,
      "grad_norm": 0.33734336495399475,
      "learning_rate": 9.356928e-05,
      "loss": 2.0807,
      "step": 83150
    },
    {
      "epoch": 2.6624,
      "grad_norm": 0.3351069986820221,
      "learning_rate": 9.350528000000001e-05,
      "loss": 2.1345,
      "step": 83200
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.3683461844921112,
      "learning_rate": 9.344128000000001e-05,
      "loss": 2.0999,
      "step": 83250
    },
    {
      "epoch": 2.6656,
      "grad_norm": 0.36812204122543335,
      "learning_rate": 9.337728e-05,
      "loss": 2.1307,
      "step": 83300
    },
    {
      "epoch": 2.6672000000000002,
      "grad_norm": 0.34768596291542053,
      "learning_rate": 9.331328e-05,
      "loss": 2.0864,
      "step": 83350
    },
    {
      "epoch": 2.6688,
      "grad_norm": 0.3727881610393524,
      "learning_rate": 9.324928000000001e-05,
      "loss": 2.1839,
      "step": 83400
    },
    {
      "epoch": 2.6704,
      "grad_norm": 0.33956828713417053,
      "learning_rate": 9.318528e-05,
      "loss": 2.0792,
      "step": 83450
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.3528963029384613,
      "learning_rate": 9.312128e-05,
      "loss": 2.1413,
      "step": 83500
    },
    {
      "epoch": 2.6736,
      "grad_norm": 0.424125999212265,
      "learning_rate": 9.305728e-05,
      "loss": 2.1477,
      "step": 83550
    },
    {
      "epoch": 2.6752000000000002,
      "grad_norm": 0.33479636907577515,
      "learning_rate": 9.299328e-05,
      "loss": 2.117,
      "step": 83600
    },
    {
      "epoch": 2.6768,
      "grad_norm": 0.3510435223579407,
      "learning_rate": 9.292928000000001e-05,
      "loss": 2.0746,
      "step": 83650
    },
    {
      "epoch": 2.6784,
      "grad_norm": 0.3632505238056183,
      "learning_rate": 9.286528e-05,
      "loss": 2.0976,
      "step": 83700
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.37932273745536804,
      "learning_rate": 9.280128e-05,
      "loss": 2.1009,
      "step": 83750
    },
    {
      "epoch": 2.6816,
      "grad_norm": 0.38321927189826965,
      "learning_rate": 9.273728000000001e-05,
      "loss": 2.1241,
      "step": 83800
    },
    {
      "epoch": 2.6832000000000003,
      "grad_norm": 0.34724316000938416,
      "learning_rate": 9.267328e-05,
      "loss": 2.1211,
      "step": 83850
    },
    {
      "epoch": 2.6848,
      "grad_norm": 0.3442179262638092,
      "learning_rate": 9.260928000000001e-05,
      "loss": 2.1335,
      "step": 83900
    },
    {
      "epoch": 2.6864,
      "grad_norm": 0.3738689124584198,
      "learning_rate": 9.254528e-05,
      "loss": 2.1486,
      "step": 83950
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.3838266432285309,
      "learning_rate": 9.248128e-05,
      "loss": 2.1455,
      "step": 84000
    },
    {
      "epoch": 2.6896,
      "grad_norm": 0.36940163373947144,
      "learning_rate": 9.241728000000001e-05,
      "loss": 2.1508,
      "step": 84050
    },
    {
      "epoch": 2.6912000000000003,
      "grad_norm": 0.3600650131702423,
      "learning_rate": 9.235328000000001e-05,
      "loss": 2.1948,
      "step": 84100
    },
    {
      "epoch": 2.6928,
      "grad_norm": 0.35239696502685547,
      "learning_rate": 9.228928e-05,
      "loss": 2.1242,
      "step": 84150
    },
    {
      "epoch": 2.6944,
      "grad_norm": 0.31906741857528687,
      "learning_rate": 9.222528e-05,
      "loss": 2.1263,
      "step": 84200
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.34021830558776855,
      "learning_rate": 9.216128e-05,
      "loss": 2.1124,
      "step": 84250
    },
    {
      "epoch": 2.6976,
      "grad_norm": 0.39297473430633545,
      "learning_rate": 9.209728e-05,
      "loss": 2.076,
      "step": 84300
    },
    {
      "epoch": 2.6992000000000003,
      "grad_norm": 0.2987554669380188,
      "learning_rate": 9.203328e-05,
      "loss": 2.2236,
      "step": 84350
    },
    {
      "epoch": 2.7008,
      "grad_norm": 0.4190641939640045,
      "learning_rate": 9.196928e-05,
      "loss": 2.141,
      "step": 84400
    },
    {
      "epoch": 2.7024,
      "grad_norm": 0.3530590832233429,
      "learning_rate": 9.190528e-05,
      "loss": 2.0676,
      "step": 84450
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.3158293664455414,
      "learning_rate": 9.184128000000001e-05,
      "loss": 2.1742,
      "step": 84500
    },
    {
      "epoch": 2.7056,
      "grad_norm": 0.3061654269695282,
      "learning_rate": 9.177728e-05,
      "loss": 2.1447,
      "step": 84550
    },
    {
      "epoch": 2.7072000000000003,
      "grad_norm": 0.32784420251846313,
      "learning_rate": 9.171328e-05,
      "loss": 2.1376,
      "step": 84600
    },
    {
      "epoch": 2.7088,
      "grad_norm": 0.4125453531742096,
      "learning_rate": 9.164928000000001e-05,
      "loss": 2.0499,
      "step": 84650
    },
    {
      "epoch": 2.7104,
      "grad_norm": 0.3350054621696472,
      "learning_rate": 9.158528e-05,
      "loss": 2.1164,
      "step": 84700
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.3326549232006073,
      "learning_rate": 9.152128000000001e-05,
      "loss": 2.109,
      "step": 84750
    },
    {
      "epoch": 2.7136,
      "grad_norm": 0.3854537606239319,
      "learning_rate": 9.145728e-05,
      "loss": 2.1258,
      "step": 84800
    },
    {
      "epoch": 2.7152,
      "grad_norm": 0.350336492061615,
      "learning_rate": 9.139328e-05,
      "loss": 2.1892,
      "step": 84850
    },
    {
      "epoch": 2.7168,
      "grad_norm": 0.37585753202438354,
      "learning_rate": 9.132928000000001e-05,
      "loss": 2.1502,
      "step": 84900
    },
    {
      "epoch": 2.7184,
      "grad_norm": 0.3747108280658722,
      "learning_rate": 9.126528000000001e-05,
      "loss": 2.1454,
      "step": 84950
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.31725233793258667,
      "learning_rate": 9.120128e-05,
      "loss": 2.1327,
      "step": 85000
    },
    {
      "epoch": 2.7216,
      "grad_norm": 0.33986997604370117,
      "learning_rate": 9.113728e-05,
      "loss": 2.1466,
      "step": 85050
    },
    {
      "epoch": 2.7232,
      "grad_norm": 0.357059508562088,
      "learning_rate": 9.107328e-05,
      "loss": 2.1853,
      "step": 85100
    },
    {
      "epoch": 2.7248,
      "grad_norm": 0.3532474637031555,
      "learning_rate": 9.100928e-05,
      "loss": 2.1132,
      "step": 85150
    },
    {
      "epoch": 2.7264,
      "grad_norm": 0.35131344199180603,
      "learning_rate": 9.094528e-05,
      "loss": 2.1189,
      "step": 85200
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.32759013772010803,
      "learning_rate": 9.088128e-05,
      "loss": 2.1595,
      "step": 85250
    },
    {
      "epoch": 2.7296,
      "grad_norm": 0.3557078242301941,
      "learning_rate": 9.081728e-05,
      "loss": 2.1063,
      "step": 85300
    },
    {
      "epoch": 2.7312,
      "grad_norm": 0.4644620418548584,
      "learning_rate": 9.075328000000001e-05,
      "loss": 2.1448,
      "step": 85350
    },
    {
      "epoch": 2.7328,
      "grad_norm": 0.33552587032318115,
      "learning_rate": 9.068928e-05,
      "loss": 2.1595,
      "step": 85400
    },
    {
      "epoch": 2.7344,
      "grad_norm": 0.33624276518821716,
      "learning_rate": 9.062528e-05,
      "loss": 2.0878,
      "step": 85450
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.3703269958496094,
      "learning_rate": 9.056128000000001e-05,
      "loss": 2.1141,
      "step": 85500
    },
    {
      "epoch": 2.7376,
      "grad_norm": 0.33043110370635986,
      "learning_rate": 9.049728e-05,
      "loss": 2.1308,
      "step": 85550
    },
    {
      "epoch": 2.7392,
      "grad_norm": 0.3597247898578644,
      "learning_rate": 9.043328000000001e-05,
      "loss": 2.0605,
      "step": 85600
    },
    {
      "epoch": 2.7408,
      "grad_norm": 0.3965182602405548,
      "learning_rate": 9.036928e-05,
      "loss": 2.0755,
      "step": 85650
    },
    {
      "epoch": 2.7424,
      "grad_norm": 0.37798193097114563,
      "learning_rate": 9.030528e-05,
      "loss": 2.0927,
      "step": 85700
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.3219665288925171,
      "learning_rate": 9.024128000000001e-05,
      "loss": 2.0683,
      "step": 85750
    },
    {
      "epoch": 2.7456,
      "grad_norm": 0.35319241881370544,
      "learning_rate": 9.017728000000001e-05,
      "loss": 2.137,
      "step": 85800
    },
    {
      "epoch": 2.7472,
      "grad_norm": 0.3416491448879242,
      "learning_rate": 9.011328e-05,
      "loss": 2.0832,
      "step": 85850
    },
    {
      "epoch": 2.7488,
      "grad_norm": 0.3494645953178406,
      "learning_rate": 9.004928e-05,
      "loss": 2.0552,
      "step": 85900
    },
    {
      "epoch": 2.7504,
      "grad_norm": 0.41152673959732056,
      "learning_rate": 8.998528e-05,
      "loss": 2.1194,
      "step": 85950
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.37534216046333313,
      "learning_rate": 8.992128e-05,
      "loss": 2.107,
      "step": 86000
    },
    {
      "epoch": 2.7536,
      "grad_norm": 0.3735525906085968,
      "learning_rate": 8.985728e-05,
      "loss": 2.0832,
      "step": 86050
    },
    {
      "epoch": 2.7552,
      "grad_norm": 0.3462046980857849,
      "learning_rate": 8.979328e-05,
      "loss": 2.1023,
      "step": 86100
    },
    {
      "epoch": 2.7568,
      "grad_norm": 0.3313888609409332,
      "learning_rate": 8.972928e-05,
      "loss": 2.0837,
      "step": 86150
    },
    {
      "epoch": 2.7584,
      "grad_norm": 0.3774559795856476,
      "learning_rate": 8.966528000000001e-05,
      "loss": 2.1303,
      "step": 86200
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.388618528842926,
      "learning_rate": 8.960128e-05,
      "loss": 2.1095,
      "step": 86250
    },
    {
      "epoch": 2.7616,
      "grad_norm": 0.3045612871646881,
      "learning_rate": 8.953728e-05,
      "loss": 2.132,
      "step": 86300
    },
    {
      "epoch": 2.7632,
      "grad_norm": 0.3438940942287445,
      "learning_rate": 8.947328000000001e-05,
      "loss": 2.0867,
      "step": 86350
    },
    {
      "epoch": 2.7648,
      "grad_norm": 0.32289940118789673,
      "learning_rate": 8.940928e-05,
      "loss": 2.1545,
      "step": 86400
    },
    {
      "epoch": 2.7664,
      "grad_norm": 0.3080463409423828,
      "learning_rate": 8.934528000000001e-05,
      "loss": 2.0791,
      "step": 86450
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.3476272523403168,
      "learning_rate": 8.928128000000001e-05,
      "loss": 2.1364,
      "step": 86500
    },
    {
      "epoch": 2.7696,
      "grad_norm": 0.35068538784980774,
      "learning_rate": 8.921728e-05,
      "loss": 2.1566,
      "step": 86550
    },
    {
      "epoch": 2.7712,
      "grad_norm": 0.3227042853832245,
      "learning_rate": 8.915328000000001e-05,
      "loss": 2.0991,
      "step": 86600
    },
    {
      "epoch": 2.7728,
      "grad_norm": 0.35081830620765686,
      "learning_rate": 8.908928e-05,
      "loss": 2.0905,
      "step": 86650
    },
    {
      "epoch": 2.7744,
      "grad_norm": 0.3225380778312683,
      "learning_rate": 8.902528e-05,
      "loss": 2.0893,
      "step": 86700
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.30622348189353943,
      "learning_rate": 8.896128e-05,
      "loss": 2.1293,
      "step": 86750
    },
    {
      "epoch": 2.7776,
      "grad_norm": 0.3562294542789459,
      "learning_rate": 8.889728e-05,
      "loss": 2.1297,
      "step": 86800
    },
    {
      "epoch": 2.7792,
      "grad_norm": 0.3711734116077423,
      "learning_rate": 8.883328000000001e-05,
      "loss": 2.141,
      "step": 86850
    },
    {
      "epoch": 2.7808,
      "grad_norm": 0.3235337734222412,
      "learning_rate": 8.876928e-05,
      "loss": 2.0299,
      "step": 86900
    },
    {
      "epoch": 2.7824,
      "grad_norm": 0.4592144191265106,
      "learning_rate": 8.870528e-05,
      "loss": 2.1191,
      "step": 86950
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.3221819996833801,
      "learning_rate": 8.864128e-05,
      "loss": 2.1675,
      "step": 87000
    },
    {
      "epoch": 2.7856,
      "grad_norm": 0.37387850880622864,
      "learning_rate": 8.857728000000001e-05,
      "loss": 2.1596,
      "step": 87050
    },
    {
      "epoch": 2.7872,
      "grad_norm": 0.40193042159080505,
      "learning_rate": 8.851328e-05,
      "loss": 2.1204,
      "step": 87100
    },
    {
      "epoch": 2.7888,
      "grad_norm": 0.3551652729511261,
      "learning_rate": 8.844928e-05,
      "loss": 2.0798,
      "step": 87150
    },
    {
      "epoch": 2.7904,
      "grad_norm": 0.3219614028930664,
      "learning_rate": 8.838528000000001e-05,
      "loss": 2.0987,
      "step": 87200
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.290391206741333,
      "learning_rate": 8.832128e-05,
      "loss": 2.072,
      "step": 87250
    },
    {
      "epoch": 2.7936,
      "grad_norm": 0.34662580490112305,
      "learning_rate": 8.825728000000001e-05,
      "loss": 2.2301,
      "step": 87300
    },
    {
      "epoch": 2.7952,
      "grad_norm": 0.44269612431526184,
      "learning_rate": 8.819328000000001e-05,
      "loss": 2.0992,
      "step": 87350
    },
    {
      "epoch": 2.7968,
      "grad_norm": 0.36785662174224854,
      "learning_rate": 8.812928e-05,
      "loss": 2.04,
      "step": 87400
    },
    {
      "epoch": 2.7984,
      "grad_norm": 0.380389004945755,
      "learning_rate": 8.806528000000001e-05,
      "loss": 2.1725,
      "step": 87450
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.37493789196014404,
      "learning_rate": 8.800128e-05,
      "loss": 2.0622,
      "step": 87500
    },
    {
      "epoch": 2.8016,
      "grad_norm": 0.3671829402446747,
      "learning_rate": 8.793728e-05,
      "loss": 2.1194,
      "step": 87550
    },
    {
      "epoch": 2.8032,
      "grad_norm": 0.3488786518573761,
      "learning_rate": 8.787328e-05,
      "loss": 2.1165,
      "step": 87600
    },
    {
      "epoch": 2.8048,
      "grad_norm": 0.3185146749019623,
      "learning_rate": 8.780928e-05,
      "loss": 2.1299,
      "step": 87650
    },
    {
      "epoch": 2.8064,
      "grad_norm": 0.4183029532432556,
      "learning_rate": 8.774528000000001e-05,
      "loss": 2.0668,
      "step": 87700
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.3291364908218384,
      "learning_rate": 8.768128e-05,
      "loss": 2.093,
      "step": 87750
    },
    {
      "epoch": 2.8096,
      "grad_norm": 0.43492642045021057,
      "learning_rate": 8.761728e-05,
      "loss": 2.0786,
      "step": 87800
    },
    {
      "epoch": 2.8112,
      "grad_norm": 0.3141089975833893,
      "learning_rate": 8.755328e-05,
      "loss": 2.1463,
      "step": 87850
    },
    {
      "epoch": 2.8128,
      "grad_norm": 0.37128517031669617,
      "learning_rate": 8.748928000000001e-05,
      "loss": 2.132,
      "step": 87900
    },
    {
      "epoch": 2.8144,
      "grad_norm": 0.3745684027671814,
      "learning_rate": 8.742528e-05,
      "loss": 2.0999,
      "step": 87950
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.345879465341568,
      "learning_rate": 8.736128e-05,
      "loss": 2.056,
      "step": 88000
    },
    {
      "epoch": 2.8176,
      "grad_norm": 0.3243425786495209,
      "learning_rate": 8.729728000000001e-05,
      "loss": 2.0915,
      "step": 88050
    },
    {
      "epoch": 2.8192,
      "grad_norm": 0.34796828031539917,
      "learning_rate": 8.723328e-05,
      "loss": 2.1075,
      "step": 88100
    },
    {
      "epoch": 2.8208,
      "grad_norm": 0.4245976507663727,
      "learning_rate": 8.716928000000001e-05,
      "loss": 2.1915,
      "step": 88150
    },
    {
      "epoch": 2.8224,
      "grad_norm": 0.36931362748146057,
      "learning_rate": 8.710528e-05,
      "loss": 2.2047,
      "step": 88200
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.37173280119895935,
      "learning_rate": 8.704128e-05,
      "loss": 2.0694,
      "step": 88250
    },
    {
      "epoch": 2.8256,
      "grad_norm": 0.34383177757263184,
      "learning_rate": 8.697728000000001e-05,
      "loss": 2.1597,
      "step": 88300
    },
    {
      "epoch": 2.8272,
      "grad_norm": 0.3536517322063446,
      "learning_rate": 8.691328e-05,
      "loss": 2.1675,
      "step": 88350
    },
    {
      "epoch": 2.8288,
      "grad_norm": 0.33686527609825134,
      "learning_rate": 8.684928e-05,
      "loss": 2.1467,
      "step": 88400
    },
    {
      "epoch": 2.8304,
      "grad_norm": 0.3573840260505676,
      "learning_rate": 8.678528e-05,
      "loss": 2.1101,
      "step": 88450
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.33111271262168884,
      "learning_rate": 8.672128e-05,
      "loss": 2.108,
      "step": 88500
    },
    {
      "epoch": 2.8336,
      "grad_norm": 0.3723478317260742,
      "learning_rate": 8.665728000000001e-05,
      "loss": 2.1175,
      "step": 88550
    },
    {
      "epoch": 2.8352,
      "grad_norm": 0.3214682638645172,
      "learning_rate": 8.659328e-05,
      "loss": 2.1367,
      "step": 88600
    },
    {
      "epoch": 2.8368,
      "grad_norm": 0.3377210795879364,
      "learning_rate": 8.652928e-05,
      "loss": 2.0457,
      "step": 88650
    },
    {
      "epoch": 2.8384,
      "grad_norm": 0.3656444251537323,
      "learning_rate": 8.646528e-05,
      "loss": 2.0338,
      "step": 88700
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.38812586665153503,
      "learning_rate": 8.640128000000001e-05,
      "loss": 2.1165,
      "step": 88750
    },
    {
      "epoch": 2.8416,
      "grad_norm": 0.34488797187805176,
      "learning_rate": 8.633728e-05,
      "loss": 2.1377,
      "step": 88800
    },
    {
      "epoch": 2.8432,
      "grad_norm": 0.38277074694633484,
      "learning_rate": 8.627328e-05,
      "loss": 2.1715,
      "step": 88850
    },
    {
      "epoch": 2.8448,
      "grad_norm": 0.3487139046192169,
      "learning_rate": 8.620928000000001e-05,
      "loss": 2.1596,
      "step": 88900
    },
    {
      "epoch": 2.8464,
      "grad_norm": 0.3406238555908203,
      "learning_rate": 8.614528e-05,
      "loss": 2.0693,
      "step": 88950
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.33977851271629333,
      "learning_rate": 8.608128000000001e-05,
      "loss": 2.1155,
      "step": 89000
    },
    {
      "epoch": 2.8496,
      "grad_norm": 0.3845994472503662,
      "learning_rate": 8.601728e-05,
      "loss": 2.1051,
      "step": 89050
    },
    {
      "epoch": 2.8512,
      "grad_norm": 0.32856735587120056,
      "learning_rate": 8.595328e-05,
      "loss": 2.1369,
      "step": 89100
    },
    {
      "epoch": 2.8528000000000002,
      "grad_norm": 0.34045565128326416,
      "learning_rate": 8.588928000000001e-05,
      "loss": 2.1392,
      "step": 89150
    },
    {
      "epoch": 2.8544,
      "grad_norm": 0.30654141306877136,
      "learning_rate": 8.582528e-05,
      "loss": 2.189,
      "step": 89200
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.3235299289226532,
      "learning_rate": 8.576128e-05,
      "loss": 2.1217,
      "step": 89250
    },
    {
      "epoch": 2.8576,
      "grad_norm": 0.39115655422210693,
      "learning_rate": 8.569728e-05,
      "loss": 2.1584,
      "step": 89300
    },
    {
      "epoch": 2.8592,
      "grad_norm": 0.3458740711212158,
      "learning_rate": 8.563328e-05,
      "loss": 2.1095,
      "step": 89350
    },
    {
      "epoch": 2.8608000000000002,
      "grad_norm": 0.34666550159454346,
      "learning_rate": 8.556928000000001e-05,
      "loss": 2.0852,
      "step": 89400
    },
    {
      "epoch": 2.8624,
      "grad_norm": 0.3248995244503021,
      "learning_rate": 8.550528e-05,
      "loss": 2.0856,
      "step": 89450
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.38721930980682373,
      "learning_rate": 8.544128e-05,
      "loss": 2.0923,
      "step": 89500
    },
    {
      "epoch": 2.8656,
      "grad_norm": 0.368168443441391,
      "learning_rate": 8.537728e-05,
      "loss": 2.0774,
      "step": 89550
    },
    {
      "epoch": 2.8672,
      "grad_norm": 0.39475926756858826,
      "learning_rate": 8.531328000000001e-05,
      "loss": 2.1276,
      "step": 89600
    },
    {
      "epoch": 2.8688000000000002,
      "grad_norm": 0.3702107071876526,
      "learning_rate": 8.524928e-05,
      "loss": 2.1542,
      "step": 89650
    },
    {
      "epoch": 2.8704,
      "grad_norm": 0.3711581826210022,
      "learning_rate": 8.518528e-05,
      "loss": 2.1194,
      "step": 89700
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.35796085000038147,
      "learning_rate": 8.512128e-05,
      "loss": 2.1334,
      "step": 89750
    },
    {
      "epoch": 2.8736,
      "grad_norm": 0.36257824301719666,
      "learning_rate": 8.505728e-05,
      "loss": 2.0798,
      "step": 89800
    },
    {
      "epoch": 2.8752,
      "grad_norm": 0.46512991189956665,
      "learning_rate": 8.499328000000001e-05,
      "loss": 2.1228,
      "step": 89850
    },
    {
      "epoch": 2.8768000000000002,
      "grad_norm": 0.3549841344356537,
      "learning_rate": 8.492928e-05,
      "loss": 2.1559,
      "step": 89900
    },
    {
      "epoch": 2.8784,
      "grad_norm": 0.36731839179992676,
      "learning_rate": 8.486528e-05,
      "loss": 2.1481,
      "step": 89950
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.3217458724975586,
      "learning_rate": 8.480128000000001e-05,
      "loss": 2.0662,
      "step": 90000
    },
    {
      "epoch": 2.8816,
      "grad_norm": 0.3477450907230377,
      "learning_rate": 8.473728e-05,
      "loss": 2.0719,
      "step": 90050
    },
    {
      "epoch": 2.8832,
      "grad_norm": 0.4405675232410431,
      "learning_rate": 8.467328e-05,
      "loss": 2.1298,
      "step": 90100
    },
    {
      "epoch": 2.8848000000000003,
      "grad_norm": 0.4091019630432129,
      "learning_rate": 8.460928000000001e-05,
      "loss": 2.1079,
      "step": 90150
    },
    {
      "epoch": 2.8864,
      "grad_norm": 0.3617631494998932,
      "learning_rate": 8.454528e-05,
      "loss": 2.0952,
      "step": 90200
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.3789329528808594,
      "learning_rate": 8.448128000000001e-05,
      "loss": 2.101,
      "step": 90250
    },
    {
      "epoch": 2.8895999999999997,
      "grad_norm": 0.3068791627883911,
      "learning_rate": 8.441728e-05,
      "loss": 2.1277,
      "step": 90300
    },
    {
      "epoch": 2.8912,
      "grad_norm": 0.33304956555366516,
      "learning_rate": 8.435328e-05,
      "loss": 2.1396,
      "step": 90350
    },
    {
      "epoch": 2.8928000000000003,
      "grad_norm": 0.2882245182991028,
      "learning_rate": 8.428928e-05,
      "loss": 2.123,
      "step": 90400
    },
    {
      "epoch": 2.8944,
      "grad_norm": 0.36187201738357544,
      "learning_rate": 8.422528000000001e-05,
      "loss": 2.1231,
      "step": 90450
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.3147307336330414,
      "learning_rate": 8.416128000000002e-05,
      "loss": 2.1072,
      "step": 90500
    },
    {
      "epoch": 2.8975999999999997,
      "grad_norm": 0.39047884941101074,
      "learning_rate": 8.409728e-05,
      "loss": 2.0627,
      "step": 90550
    },
    {
      "epoch": 2.8992,
      "grad_norm": 0.35914236307144165,
      "learning_rate": 8.403328e-05,
      "loss": 2.0926,
      "step": 90600
    },
    {
      "epoch": 2.9008000000000003,
      "grad_norm": 0.364095002412796,
      "learning_rate": 8.396928e-05,
      "loss": 2.0438,
      "step": 90650
    },
    {
      "epoch": 2.9024,
      "grad_norm": 0.35323214530944824,
      "learning_rate": 8.390528000000001e-05,
      "loss": 2.1237,
      "step": 90700
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.544561505317688,
      "learning_rate": 8.384128e-05,
      "loss": 2.1365,
      "step": 90750
    },
    {
      "epoch": 2.9055999999999997,
      "grad_norm": 0.3562944233417511,
      "learning_rate": 8.377728e-05,
      "loss": 2.1241,
      "step": 90800
    },
    {
      "epoch": 2.9072,
      "grad_norm": 0.3676239550113678,
      "learning_rate": 8.371328000000001e-05,
      "loss": 2.1133,
      "step": 90850
    },
    {
      "epoch": 2.9088000000000003,
      "grad_norm": 0.4142383337020874,
      "learning_rate": 8.364928e-05,
      "loss": 2.1133,
      "step": 90900
    },
    {
      "epoch": 2.9104,
      "grad_norm": 0.3893410861492157,
      "learning_rate": 8.358528e-05,
      "loss": 2.1246,
      "step": 90950
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.38205254077911377,
      "learning_rate": 8.352128000000001e-05,
      "loss": 2.0359,
      "step": 91000
    },
    {
      "epoch": 2.9135999999999997,
      "grad_norm": 0.32722434401512146,
      "learning_rate": 8.345728e-05,
      "loss": 2.0247,
      "step": 91050
    },
    {
      "epoch": 2.9152,
      "grad_norm": 0.34548628330230713,
      "learning_rate": 8.339328000000001e-05,
      "loss": 2.1067,
      "step": 91100
    },
    {
      "epoch": 2.9168,
      "grad_norm": 0.3391098082065582,
      "learning_rate": 8.332928e-05,
      "loss": 2.1386,
      "step": 91150
    },
    {
      "epoch": 2.9184,
      "grad_norm": 0.3136322498321533,
      "learning_rate": 8.326528e-05,
      "loss": 2.0873,
      "step": 91200
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.33547672629356384,
      "learning_rate": 8.320128e-05,
      "loss": 2.1595,
      "step": 91250
    },
    {
      "epoch": 2.9215999999999998,
      "grad_norm": 0.34615203738212585,
      "learning_rate": 8.313728e-05,
      "loss": 2.1163,
      "step": 91300
    },
    {
      "epoch": 2.9232,
      "grad_norm": 0.38837841153144836,
      "learning_rate": 8.307328000000002e-05,
      "loss": 2.1399,
      "step": 91350
    },
    {
      "epoch": 2.9248,
      "grad_norm": 0.34742841124534607,
      "learning_rate": 8.300928e-05,
      "loss": 2.0894,
      "step": 91400
    },
    {
      "epoch": 2.9264,
      "grad_norm": 0.34994587302207947,
      "learning_rate": 8.294528e-05,
      "loss": 2.0478,
      "step": 91450
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.31441405415534973,
      "learning_rate": 8.288128e-05,
      "loss": 2.0924,
      "step": 91500
    },
    {
      "epoch": 2.9295999999999998,
      "grad_norm": 0.3646080195903778,
      "learning_rate": 8.281728000000001e-05,
      "loss": 2.0955,
      "step": 91550
    },
    {
      "epoch": 2.9312,
      "grad_norm": 0.33163022994995117,
      "learning_rate": 8.275328e-05,
      "loss": 2.1402,
      "step": 91600
    },
    {
      "epoch": 2.9328,
      "grad_norm": 0.35996678471565247,
      "learning_rate": 8.268928e-05,
      "loss": 2.1184,
      "step": 91650
    },
    {
      "epoch": 2.9344,
      "grad_norm": 0.33050695061683655,
      "learning_rate": 8.262528000000001e-05,
      "loss": 2.1101,
      "step": 91700
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.3338475227355957,
      "learning_rate": 8.256128e-05,
      "loss": 2.0749,
      "step": 91750
    },
    {
      "epoch": 2.9375999999999998,
      "grad_norm": 0.3552684783935547,
      "learning_rate": 8.249728e-05,
      "loss": 2.1211,
      "step": 91800
    },
    {
      "epoch": 2.9392,
      "grad_norm": 0.3734222948551178,
      "learning_rate": 8.243328000000001e-05,
      "loss": 2.1028,
      "step": 91850
    },
    {
      "epoch": 2.9408,
      "grad_norm": 0.29517582058906555,
      "learning_rate": 8.236928e-05,
      "loss": 2.0793,
      "step": 91900
    },
    {
      "epoch": 2.9424,
      "grad_norm": 0.35808709263801575,
      "learning_rate": 8.230528000000001e-05,
      "loss": 2.1383,
      "step": 91950
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.34572920203208923,
      "learning_rate": 8.224128000000001e-05,
      "loss": 2.1093,
      "step": 92000
    },
    {
      "epoch": 2.9455999999999998,
      "grad_norm": 0.39809030294418335,
      "learning_rate": 8.217728e-05,
      "loss": 2.1183,
      "step": 92050
    },
    {
      "epoch": 2.9472,
      "grad_norm": 0.4075634777545929,
      "learning_rate": 8.211328e-05,
      "loss": 2.0924,
      "step": 92100
    },
    {
      "epoch": 2.9488,
      "grad_norm": 0.3621581792831421,
      "learning_rate": 8.204928e-05,
      "loss": 2.1404,
      "step": 92150
    },
    {
      "epoch": 2.9504,
      "grad_norm": 0.32957008481025696,
      "learning_rate": 8.198528000000001e-05,
      "loss": 2.1281,
      "step": 92200
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.35925841331481934,
      "learning_rate": 8.192128e-05,
      "loss": 2.1838,
      "step": 92250
    },
    {
      "epoch": 2.9536,
      "grad_norm": 0.4071047604084015,
      "learning_rate": 8.185728e-05,
      "loss": 2.1143,
      "step": 92300
    },
    {
      "epoch": 2.9552,
      "grad_norm": 0.3171965479850769,
      "learning_rate": 8.179328e-05,
      "loss": 2.0958,
      "step": 92350
    },
    {
      "epoch": 2.9568,
      "grad_norm": 0.2899591028690338,
      "learning_rate": 8.172928000000001e-05,
      "loss": 2.0869,
      "step": 92400
    },
    {
      "epoch": 2.9584,
      "grad_norm": 0.3447554409503937,
      "learning_rate": 8.166528e-05,
      "loss": 2.0691,
      "step": 92450
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.3652825355529785,
      "learning_rate": 8.160128e-05,
      "loss": 2.145,
      "step": 92500
    },
    {
      "epoch": 2.9616,
      "grad_norm": 0.4153123199939728,
      "learning_rate": 8.153728000000001e-05,
      "loss": 2.1215,
      "step": 92550
    },
    {
      "epoch": 2.9632,
      "grad_norm": 0.29428020119667053,
      "learning_rate": 8.147328e-05,
      "loss": 2.13,
      "step": 92600
    },
    {
      "epoch": 2.9648,
      "grad_norm": 0.3498844504356384,
      "learning_rate": 8.140928e-05,
      "loss": 2.1151,
      "step": 92650
    },
    {
      "epoch": 2.9664,
      "grad_norm": 0.3445679247379303,
      "learning_rate": 8.134528000000001e-05,
      "loss": 2.1338,
      "step": 92700
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.33024096488952637,
      "learning_rate": 8.128128e-05,
      "loss": 2.1438,
      "step": 92750
    },
    {
      "epoch": 2.9696,
      "grad_norm": 0.3348488509654999,
      "learning_rate": 8.121728000000001e-05,
      "loss": 2.1961,
      "step": 92800
    },
    {
      "epoch": 2.9712,
      "grad_norm": 0.3415374755859375,
      "learning_rate": 8.115328e-05,
      "loss": 2.1671,
      "step": 92850
    },
    {
      "epoch": 2.9728,
      "grad_norm": 0.3714553713798523,
      "learning_rate": 8.108928e-05,
      "loss": 2.0206,
      "step": 92900
    },
    {
      "epoch": 2.9744,
      "grad_norm": 0.38347288966178894,
      "learning_rate": 8.102528e-05,
      "loss": 2.1059,
      "step": 92950
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.3281886577606201,
      "learning_rate": 8.096128e-05,
      "loss": 2.1828,
      "step": 93000
    },
    {
      "epoch": 2.9776,
      "grad_norm": 0.3040751516819,
      "learning_rate": 8.089728000000001e-05,
      "loss": 2.1265,
      "step": 93050
    },
    {
      "epoch": 2.9792,
      "grad_norm": 0.348980188369751,
      "learning_rate": 8.083328e-05,
      "loss": 2.1318,
      "step": 93100
    },
    {
      "epoch": 2.9808,
      "grad_norm": 0.353874146938324,
      "learning_rate": 8.076928e-05,
      "loss": 2.1079,
      "step": 93150
    },
    {
      "epoch": 2.9824,
      "grad_norm": 0.37781697511672974,
      "learning_rate": 8.070528e-05,
      "loss": 2.1616,
      "step": 93200
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.3330307900905609,
      "learning_rate": 8.064128000000001e-05,
      "loss": 2.1567,
      "step": 93250
    },
    {
      "epoch": 2.9856,
      "grad_norm": 0.401693195104599,
      "learning_rate": 8.057728e-05,
      "loss": 2.0923,
      "step": 93300
    },
    {
      "epoch": 2.9872,
      "grad_norm": 0.3437458574771881,
      "learning_rate": 8.051328e-05,
      "loss": 2.1419,
      "step": 93350
    },
    {
      "epoch": 2.9888,
      "grad_norm": 0.349607914686203,
      "learning_rate": 8.044928000000001e-05,
      "loss": 2.1697,
      "step": 93400
    },
    {
      "epoch": 2.9904,
      "grad_norm": 0.30450788140296936,
      "learning_rate": 8.038528e-05,
      "loss": 2.1168,
      "step": 93450
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.3478488028049469,
      "learning_rate": 8.032128e-05,
      "loss": 2.1006,
      "step": 93500
    },
    {
      "epoch": 2.9936,
      "grad_norm": 0.35966336727142334,
      "learning_rate": 8.025728000000001e-05,
      "loss": 2.1502,
      "step": 93550
    },
    {
      "epoch": 2.9952,
      "grad_norm": 0.284544438123703,
      "learning_rate": 8.019328e-05,
      "loss": 2.1133,
      "step": 93600
    },
    {
      "epoch": 2.9968,
      "grad_norm": 0.3868176341056824,
      "learning_rate": 8.012928000000001e-05,
      "loss": 2.1483,
      "step": 93650
    },
    {
      "epoch": 2.9984,
      "grad_norm": 0.3086284399032593,
      "learning_rate": 8.006528e-05,
      "loss": 2.0435,
      "step": 93700
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.37540051341056824,
      "learning_rate": 8.000128e-05,
      "loss": 2.066,
      "step": 93750
    },
    {
      "epoch": 3.0016,
      "grad_norm": 0.2925449311733246,
      "learning_rate": 7.993728000000001e-05,
      "loss": 2.1154,
      "step": 93800
    },
    {
      "epoch": 3.0032,
      "grad_norm": 0.35010093450546265,
      "learning_rate": 7.987328e-05,
      "loss": 2.1171,
      "step": 93850
    },
    {
      "epoch": 3.0048,
      "grad_norm": 0.383165568113327,
      "learning_rate": 7.980928000000001e-05,
      "loss": 2.1066,
      "step": 93900
    },
    {
      "epoch": 3.0064,
      "grad_norm": 0.36629408597946167,
      "learning_rate": 7.974528e-05,
      "loss": 2.1374,
      "step": 93950
    },
    {
      "epoch": 3.008,
      "grad_norm": 0.32969018816947937,
      "learning_rate": 7.968128e-05,
      "loss": 2.1162,
      "step": 94000
    },
    {
      "epoch": 3.0096,
      "grad_norm": 0.36069539189338684,
      "learning_rate": 7.961728e-05,
      "loss": 2.0998,
      "step": 94050
    },
    {
      "epoch": 3.0112,
      "grad_norm": 0.39213475584983826,
      "learning_rate": 7.955328000000001e-05,
      "loss": 2.1106,
      "step": 94100
    },
    {
      "epoch": 3.0128,
      "grad_norm": 0.3299957513809204,
      "learning_rate": 7.948928e-05,
      "loss": 2.1072,
      "step": 94150
    },
    {
      "epoch": 3.0144,
      "grad_norm": 0.3346242904663086,
      "learning_rate": 7.942528e-05,
      "loss": 2.0794,
      "step": 94200
    },
    {
      "epoch": 3.016,
      "grad_norm": 0.3184795379638672,
      "learning_rate": 7.936128000000001e-05,
      "loss": 2.0845,
      "step": 94250
    },
    {
      "epoch": 3.0176,
      "grad_norm": 0.3558187782764435,
      "learning_rate": 7.929728e-05,
      "loss": 2.1122,
      "step": 94300
    },
    {
      "epoch": 3.0192,
      "grad_norm": 0.4018990695476532,
      "learning_rate": 7.923328e-05,
      "loss": 2.0997,
      "step": 94350
    },
    {
      "epoch": 3.0208,
      "grad_norm": 0.41603341698646545,
      "learning_rate": 7.916928e-05,
      "loss": 2.0702,
      "step": 94400
    },
    {
      "epoch": 3.0224,
      "grad_norm": 0.40354764461517334,
      "learning_rate": 7.910528e-05,
      "loss": 2.1121,
      "step": 94450
    },
    {
      "epoch": 3.024,
      "grad_norm": 0.3702690899372101,
      "learning_rate": 7.904128000000001e-05,
      "loss": 2.1196,
      "step": 94500
    },
    {
      "epoch": 3.0256,
      "grad_norm": 0.318411648273468,
      "learning_rate": 7.897728e-05,
      "loss": 2.1171,
      "step": 94550
    },
    {
      "epoch": 3.0272,
      "grad_norm": 0.3298581540584564,
      "learning_rate": 7.891328e-05,
      "loss": 2.1631,
      "step": 94600
    },
    {
      "epoch": 3.0288,
      "grad_norm": 0.29439055919647217,
      "learning_rate": 7.884928000000001e-05,
      "loss": 2.0655,
      "step": 94650
    },
    {
      "epoch": 3.0304,
      "grad_norm": 0.39185571670532227,
      "learning_rate": 7.878528e-05,
      "loss": 2.1384,
      "step": 94700
    },
    {
      "epoch": 3.032,
      "grad_norm": 0.2876585125923157,
      "learning_rate": 7.872128000000001e-05,
      "loss": 2.1345,
      "step": 94750
    },
    {
      "epoch": 3.0336,
      "grad_norm": 0.3693190813064575,
      "learning_rate": 7.865728e-05,
      "loss": 2.1209,
      "step": 94800
    },
    {
      "epoch": 3.0352,
      "grad_norm": 0.3764464855194092,
      "learning_rate": 7.859328e-05,
      "loss": 2.1183,
      "step": 94850
    },
    {
      "epoch": 3.0368,
      "grad_norm": 0.32061752676963806,
      "learning_rate": 7.852928e-05,
      "loss": 2.1192,
      "step": 94900
    },
    {
      "epoch": 3.0384,
      "grad_norm": 0.3826505243778229,
      "learning_rate": 7.846528000000001e-05,
      "loss": 2.1197,
      "step": 94950
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.34212812781333923,
      "learning_rate": 7.840128e-05,
      "loss": 2.1494,
      "step": 95000
    },
    {
      "epoch": 3.0416,
      "grad_norm": 0.28893494606018066,
      "learning_rate": 7.833728e-05,
      "loss": 2.1547,
      "step": 95050
    },
    {
      "epoch": 3.0432,
      "grad_norm": 0.30967816710472107,
      "learning_rate": 7.827328000000001e-05,
      "loss": 2.07,
      "step": 95100
    },
    {
      "epoch": 3.0448,
      "grad_norm": 0.33721059560775757,
      "learning_rate": 7.820928e-05,
      "loss": 2.1159,
      "step": 95150
    },
    {
      "epoch": 3.0464,
      "grad_norm": 0.5298234224319458,
      "learning_rate": 7.814528e-05,
      "loss": 2.1248,
      "step": 95200
    },
    {
      "epoch": 3.048,
      "grad_norm": 0.3761591613292694,
      "learning_rate": 7.808128e-05,
      "loss": 2.0703,
      "step": 95250
    },
    {
      "epoch": 3.0496,
      "grad_norm": 0.3265291750431061,
      "learning_rate": 7.801728e-05,
      "loss": 2.1623,
      "step": 95300
    },
    {
      "epoch": 3.0512,
      "grad_norm": 0.4142381250858307,
      "learning_rate": 7.795328000000001e-05,
      "loss": 2.1015,
      "step": 95350
    },
    {
      "epoch": 3.0528,
      "grad_norm": 0.34627267718315125,
      "learning_rate": 7.788928e-05,
      "loss": 2.0211,
      "step": 95400
    },
    {
      "epoch": 3.0544,
      "grad_norm": 0.3528805375099182,
      "learning_rate": 7.782528e-05,
      "loss": 2.1296,
      "step": 95450
    },
    {
      "epoch": 3.056,
      "grad_norm": 0.36972758173942566,
      "learning_rate": 7.776128000000001e-05,
      "loss": 2.0908,
      "step": 95500
    },
    {
      "epoch": 3.0576,
      "grad_norm": 0.3525780439376831,
      "learning_rate": 7.769728e-05,
      "loss": 2.1404,
      "step": 95550
    },
    {
      "epoch": 3.0592,
      "grad_norm": 0.3898692727088928,
      "learning_rate": 7.763328000000001e-05,
      "loss": 2.1006,
      "step": 95600
    },
    {
      "epoch": 3.0608,
      "grad_norm": 0.3822490870952606,
      "learning_rate": 7.756928e-05,
      "loss": 2.1528,
      "step": 95650
    },
    {
      "epoch": 3.0624,
      "grad_norm": 0.36555981636047363,
      "learning_rate": 7.750528e-05,
      "loss": 2.0656,
      "step": 95700
    },
    {
      "epoch": 3.064,
      "grad_norm": 0.34032341837882996,
      "learning_rate": 7.744128e-05,
      "loss": 2.1791,
      "step": 95750
    },
    {
      "epoch": 3.0656,
      "grad_norm": 0.4816814661026001,
      "learning_rate": 7.737728000000001e-05,
      "loss": 2.1548,
      "step": 95800
    },
    {
      "epoch": 3.0672,
      "grad_norm": 0.3843710124492645,
      "learning_rate": 7.731328e-05,
      "loss": 2.1085,
      "step": 95850
    },
    {
      "epoch": 3.0688,
      "grad_norm": 0.34899988770484924,
      "learning_rate": 7.724928e-05,
      "loss": 2.0816,
      "step": 95900
    },
    {
      "epoch": 3.0704,
      "grad_norm": 0.3162800371646881,
      "learning_rate": 7.718528e-05,
      "loss": 2.2007,
      "step": 95950
    },
    {
      "epoch": 3.072,
      "grad_norm": 0.30923935770988464,
      "learning_rate": 7.712128e-05,
      "loss": 2.0966,
      "step": 96000
    },
    {
      "epoch": 3.0736,
      "grad_norm": 0.4700052738189697,
      "learning_rate": 7.705728e-05,
      "loss": 2.0684,
      "step": 96050
    },
    {
      "epoch": 3.0752,
      "grad_norm": 0.3155437111854553,
      "learning_rate": 7.699328e-05,
      "loss": 2.1146,
      "step": 96100
    },
    {
      "epoch": 3.0768,
      "grad_norm": 0.3422563374042511,
      "learning_rate": 7.692928e-05,
      "loss": 2.0802,
      "step": 96150
    },
    {
      "epoch": 3.0784,
      "grad_norm": 0.3548097610473633,
      "learning_rate": 7.686528000000001e-05,
      "loss": 2.0971,
      "step": 96200
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.37279632687568665,
      "learning_rate": 7.680128e-05,
      "loss": 2.1175,
      "step": 96250
    },
    {
      "epoch": 3.0816,
      "grad_norm": 0.39825567603111267,
      "learning_rate": 7.673728e-05,
      "loss": 2.1021,
      "step": 96300
    },
    {
      "epoch": 3.0832,
      "grad_norm": 0.35807719826698303,
      "learning_rate": 7.667328000000001e-05,
      "loss": 2.1066,
      "step": 96350
    },
    {
      "epoch": 3.0848,
      "grad_norm": 0.3493458032608032,
      "learning_rate": 7.660928e-05,
      "loss": 2.1413,
      "step": 96400
    },
    {
      "epoch": 3.0864,
      "grad_norm": 0.4098449945449829,
      "learning_rate": 7.654528000000001e-05,
      "loss": 2.1005,
      "step": 96450
    },
    {
      "epoch": 3.088,
      "grad_norm": 0.3307047486305237,
      "learning_rate": 7.648128e-05,
      "loss": 2.1047,
      "step": 96500
    },
    {
      "epoch": 3.0896,
      "grad_norm": 0.3745502829551697,
      "learning_rate": 7.641728e-05,
      "loss": 2.1091,
      "step": 96550
    },
    {
      "epoch": 3.0912,
      "grad_norm": 0.4326970875263214,
      "learning_rate": 7.635328e-05,
      "loss": 2.1482,
      "step": 96600
    },
    {
      "epoch": 3.0928,
      "grad_norm": 0.33239126205444336,
      "learning_rate": 7.628928000000001e-05,
      "loss": 2.1254,
      "step": 96650
    },
    {
      "epoch": 3.0944,
      "grad_norm": 0.3627835214138031,
      "learning_rate": 7.622528e-05,
      "loss": 2.1121,
      "step": 96700
    },
    {
      "epoch": 3.096,
      "grad_norm": 0.37348029017448425,
      "learning_rate": 7.616128e-05,
      "loss": 2.0681,
      "step": 96750
    },
    {
      "epoch": 3.0976,
      "grad_norm": 0.32956722378730774,
      "learning_rate": 7.609728e-05,
      "loss": 2.1093,
      "step": 96800
    },
    {
      "epoch": 3.0992,
      "grad_norm": 0.3185417056083679,
      "learning_rate": 7.603328e-05,
      "loss": 2.1391,
      "step": 96850
    },
    {
      "epoch": 3.1008,
      "grad_norm": 0.3212350904941559,
      "learning_rate": 7.596928e-05,
      "loss": 2.0692,
      "step": 96900
    },
    {
      "epoch": 3.1024,
      "grad_norm": 0.4246571362018585,
      "learning_rate": 7.590528e-05,
      "loss": 2.0581,
      "step": 96950
    },
    {
      "epoch": 3.104,
      "grad_norm": 0.3762974441051483,
      "learning_rate": 7.584128e-05,
      "loss": 2.1215,
      "step": 97000
    },
    {
      "epoch": 3.1056,
      "grad_norm": 0.3602290451526642,
      "learning_rate": 7.577728000000001e-05,
      "loss": 2.072,
      "step": 97050
    },
    {
      "epoch": 3.1072,
      "grad_norm": 0.3701878488063812,
      "learning_rate": 7.571328e-05,
      "loss": 2.0486,
      "step": 97100
    },
    {
      "epoch": 3.1088,
      "grad_norm": 0.355746865272522,
      "learning_rate": 7.564928e-05,
      "loss": 2.1471,
      "step": 97150
    },
    {
      "epoch": 3.1104,
      "grad_norm": 0.34837520122528076,
      "learning_rate": 7.558528000000001e-05,
      "loss": 2.0988,
      "step": 97200
    },
    {
      "epoch": 3.112,
      "grad_norm": 0.4153044521808624,
      "learning_rate": 7.552128e-05,
      "loss": 2.1481,
      "step": 97250
    },
    {
      "epoch": 3.1136,
      "grad_norm": 0.3588528037071228,
      "learning_rate": 7.545728000000001e-05,
      "loss": 2.1448,
      "step": 97300
    },
    {
      "epoch": 3.1152,
      "grad_norm": 0.3339095115661621,
      "learning_rate": 7.539328e-05,
      "loss": 2.122,
      "step": 97350
    },
    {
      "epoch": 3.1168,
      "grad_norm": 0.356645792722702,
      "learning_rate": 7.532928e-05,
      "loss": 2.0991,
      "step": 97400
    },
    {
      "epoch": 3.1184,
      "grad_norm": 0.35955771803855896,
      "learning_rate": 7.526528000000001e-05,
      "loss": 2.0272,
      "step": 97450
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.3650154173374176,
      "learning_rate": 7.520128e-05,
      "loss": 2.0841,
      "step": 97500
    },
    {
      "epoch": 3.1216,
      "grad_norm": 0.30452269315719604,
      "learning_rate": 7.513728e-05,
      "loss": 2.1348,
      "step": 97550
    },
    {
      "epoch": 3.1232,
      "grad_norm": 0.36924535036087036,
      "learning_rate": 7.507328e-05,
      "loss": 2.084,
      "step": 97600
    },
    {
      "epoch": 3.1248,
      "grad_norm": 0.347890168428421,
      "learning_rate": 7.500928e-05,
      "loss": 2.1046,
      "step": 97650
    },
    {
      "epoch": 3.1264,
      "grad_norm": 0.36577603220939636,
      "learning_rate": 7.494528e-05,
      "loss": 2.0717,
      "step": 97700
    },
    {
      "epoch": 3.128,
      "grad_norm": 0.35451388359069824,
      "learning_rate": 7.488128e-05,
      "loss": 2.0381,
      "step": 97750
    },
    {
      "epoch": 3.1296,
      "grad_norm": 0.3625527620315552,
      "learning_rate": 7.481728e-05,
      "loss": 2.1422,
      "step": 97800
    },
    {
      "epoch": 3.1312,
      "grad_norm": 0.36325162649154663,
      "learning_rate": 7.475328e-05,
      "loss": 2.1769,
      "step": 97850
    },
    {
      "epoch": 3.1328,
      "grad_norm": 0.3945060968399048,
      "learning_rate": 7.468928000000001e-05,
      "loss": 2.1118,
      "step": 97900
    },
    {
      "epoch": 3.1344,
      "grad_norm": 0.4201336205005646,
      "learning_rate": 7.462528e-05,
      "loss": 2.0754,
      "step": 97950
    },
    {
      "epoch": 3.136,
      "grad_norm": 0.3516266644001007,
      "learning_rate": 7.456128e-05,
      "loss": 2.1852,
      "step": 98000
    },
    {
      "epoch": 3.1376,
      "grad_norm": 0.3743450939655304,
      "learning_rate": 7.449728000000001e-05,
      "loss": 2.0428,
      "step": 98050
    },
    {
      "epoch": 3.1391999999999998,
      "grad_norm": 0.350716233253479,
      "learning_rate": 7.443328e-05,
      "loss": 2.1036,
      "step": 98100
    },
    {
      "epoch": 3.1408,
      "grad_norm": 0.3128668963909149,
      "learning_rate": 7.436928000000001e-05,
      "loss": 2.0891,
      "step": 98150
    },
    {
      "epoch": 3.1424,
      "grad_norm": 0.41791465878486633,
      "learning_rate": 7.430528e-05,
      "loss": 2.1258,
      "step": 98200
    },
    {
      "epoch": 3.144,
      "grad_norm": 0.363715261220932,
      "learning_rate": 7.424128e-05,
      "loss": 2.1597,
      "step": 98250
    },
    {
      "epoch": 3.1456,
      "grad_norm": 0.35372158885002136,
      "learning_rate": 7.417728000000001e-05,
      "loss": 2.1112,
      "step": 98300
    },
    {
      "epoch": 3.1471999999999998,
      "grad_norm": 0.3858175575733185,
      "learning_rate": 7.411328e-05,
      "loss": 2.0861,
      "step": 98350
    },
    {
      "epoch": 3.1488,
      "grad_norm": 0.42618271708488464,
      "learning_rate": 7.404928e-05,
      "loss": 2.1026,
      "step": 98400
    },
    {
      "epoch": 3.1504,
      "grad_norm": 0.34607890248298645,
      "learning_rate": 7.398528e-05,
      "loss": 2.0765,
      "step": 98450
    },
    {
      "epoch": 3.152,
      "grad_norm": 0.38905516266822815,
      "learning_rate": 7.392128e-05,
      "loss": 2.1591,
      "step": 98500
    },
    {
      "epoch": 3.1536,
      "grad_norm": 0.3537968099117279,
      "learning_rate": 7.385728e-05,
      "loss": 2.1394,
      "step": 98550
    },
    {
      "epoch": 3.1552,
      "grad_norm": 0.3168184161186218,
      "learning_rate": 7.379328000000001e-05,
      "loss": 2.1361,
      "step": 98600
    },
    {
      "epoch": 3.1568,
      "grad_norm": 0.33134299516677856,
      "learning_rate": 7.372928e-05,
      "loss": 2.1311,
      "step": 98650
    },
    {
      "epoch": 3.1584,
      "grad_norm": 0.3924183249473572,
      "learning_rate": 7.366528e-05,
      "loss": 2.0672,
      "step": 98700
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.4086706340312958,
      "learning_rate": 7.360128000000001e-05,
      "loss": 2.1233,
      "step": 98750
    },
    {
      "epoch": 3.1616,
      "grad_norm": 0.3588297963142395,
      "learning_rate": 7.353728e-05,
      "loss": 2.1372,
      "step": 98800
    },
    {
      "epoch": 3.1632,
      "grad_norm": 0.3440684676170349,
      "learning_rate": 7.347328e-05,
      "loss": 2.0997,
      "step": 98850
    },
    {
      "epoch": 3.1648,
      "grad_norm": 0.36963510513305664,
      "learning_rate": 7.340928000000001e-05,
      "loss": 2.1205,
      "step": 98900
    },
    {
      "epoch": 3.1664,
      "grad_norm": 0.3449981212615967,
      "learning_rate": 7.334528e-05,
      "loss": 2.0339,
      "step": 98950
    },
    {
      "epoch": 3.168,
      "grad_norm": 0.4553089737892151,
      "learning_rate": 7.328128000000001e-05,
      "loss": 2.1393,
      "step": 99000
    },
    {
      "epoch": 3.1696,
      "grad_norm": 0.35867902636528015,
      "learning_rate": 7.321727999999999e-05,
      "loss": 2.0823,
      "step": 99050
    },
    {
      "epoch": 3.1712,
      "grad_norm": 0.4134649932384491,
      "learning_rate": 7.315328e-05,
      "loss": 2.1193,
      "step": 99100
    },
    {
      "epoch": 3.1728,
      "grad_norm": 0.3665478527545929,
      "learning_rate": 7.308928000000001e-05,
      "loss": 2.1474,
      "step": 99150
    },
    {
      "epoch": 3.1744,
      "grad_norm": 0.3856050670146942,
      "learning_rate": 7.302528e-05,
      "loss": 2.1036,
      "step": 99200
    },
    {
      "epoch": 3.176,
      "grad_norm": 0.34949931502342224,
      "learning_rate": 7.296128e-05,
      "loss": 2.117,
      "step": 99250
    },
    {
      "epoch": 3.1776,
      "grad_norm": 0.348237007856369,
      "learning_rate": 7.289728e-05,
      "loss": 2.0982,
      "step": 99300
    },
    {
      "epoch": 3.1792,
      "grad_norm": 0.3836827576160431,
      "learning_rate": 7.283328e-05,
      "loss": 2.1172,
      "step": 99350
    },
    {
      "epoch": 3.1808,
      "grad_norm": 0.34235796332359314,
      "learning_rate": 7.276928e-05,
      "loss": 2.0848,
      "step": 99400
    },
    {
      "epoch": 3.1824,
      "grad_norm": 0.3203551173210144,
      "learning_rate": 7.270528000000001e-05,
      "loss": 2.1611,
      "step": 99450
    },
    {
      "epoch": 3.184,
      "grad_norm": 0.3496438264846802,
      "learning_rate": 7.264128e-05,
      "loss": 2.0575,
      "step": 99500
    },
    {
      "epoch": 3.1856,
      "grad_norm": 0.33702340722084045,
      "learning_rate": 7.257728e-05,
      "loss": 2.1229,
      "step": 99550
    },
    {
      "epoch": 3.1872,
      "grad_norm": 0.4281742572784424,
      "learning_rate": 7.251328000000001e-05,
      "loss": 2.0686,
      "step": 99600
    },
    {
      "epoch": 3.1888,
      "grad_norm": 0.38230571150779724,
      "learning_rate": 7.244928e-05,
      "loss": 2.1468,
      "step": 99650
    },
    {
      "epoch": 3.1904,
      "grad_norm": 0.3632102310657501,
      "learning_rate": 7.238528e-05,
      "loss": 2.0887,
      "step": 99700
    },
    {
      "epoch": 3.192,
      "grad_norm": 0.37298017740249634,
      "learning_rate": 7.232128000000001e-05,
      "loss": 2.0888,
      "step": 99750
    },
    {
      "epoch": 3.1936,
      "grad_norm": 0.3297077417373657,
      "learning_rate": 7.225728e-05,
      "loss": 2.0722,
      "step": 99800
    },
    {
      "epoch": 3.1952,
      "grad_norm": 0.37004193663597107,
      "learning_rate": 7.219328000000001e-05,
      "loss": 2.093,
      "step": 99850
    },
    {
      "epoch": 3.1968,
      "grad_norm": 0.389266699552536,
      "learning_rate": 7.212927999999999e-05,
      "loss": 2.1266,
      "step": 99900
    },
    {
      "epoch": 3.1984,
      "grad_norm": 0.3858962655067444,
      "learning_rate": 7.206528e-05,
      "loss": 2.0334,
      "step": 99950
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.33638831973075867,
      "learning_rate": 7.200128000000001e-05,
      "loss": 2.095,
      "step": 100000
    },
    {
      "epoch": 3.2016,
      "grad_norm": 0.4431211054325104,
      "learning_rate": 7.193728e-05,
      "loss": 2.1222,
      "step": 100050
    },
    {
      "epoch": 3.2032,
      "grad_norm": 0.34413522481918335,
      "learning_rate": 7.187328e-05,
      "loss": 2.1047,
      "step": 100100
    },
    {
      "epoch": 3.2048,
      "grad_norm": 0.3152042031288147,
      "learning_rate": 7.180928e-05,
      "loss": 2.0919,
      "step": 100150
    },
    {
      "epoch": 3.2064,
      "grad_norm": 0.3990526795387268,
      "learning_rate": 7.174528e-05,
      "loss": 2.1268,
      "step": 100200
    },
    {
      "epoch": 3.208,
      "grad_norm": 0.3977445960044861,
      "learning_rate": 7.168128e-05,
      "loss": 2.1387,
      "step": 100250
    },
    {
      "epoch": 3.2096,
      "grad_norm": 0.3637732267379761,
      "learning_rate": 7.161728000000001e-05,
      "loss": 2.1128,
      "step": 100300
    },
    {
      "epoch": 3.2112,
      "grad_norm": 0.3561999201774597,
      "learning_rate": 7.155328e-05,
      "loss": 2.0513,
      "step": 100350
    },
    {
      "epoch": 3.2128,
      "grad_norm": 0.31761303544044495,
      "learning_rate": 7.148928e-05,
      "loss": 2.097,
      "step": 100400
    },
    {
      "epoch": 3.2144,
      "grad_norm": 0.30052080750465393,
      "learning_rate": 7.142528000000001e-05,
      "loss": 2.0596,
      "step": 100450
    },
    {
      "epoch": 3.216,
      "grad_norm": 0.43314021825790405,
      "learning_rate": 7.136128e-05,
      "loss": 2.1131,
      "step": 100500
    },
    {
      "epoch": 3.2176,
      "grad_norm": 0.4315584897994995,
      "learning_rate": 7.129728e-05,
      "loss": 2.0723,
      "step": 100550
    },
    {
      "epoch": 3.2192,
      "grad_norm": 0.35580557584762573,
      "learning_rate": 7.123328e-05,
      "loss": 2.1051,
      "step": 100600
    },
    {
      "epoch": 3.2208,
      "grad_norm": 0.320523202419281,
      "learning_rate": 7.116928e-05,
      "loss": 2.1028,
      "step": 100650
    },
    {
      "epoch": 3.2224,
      "grad_norm": 0.30722227692604065,
      "learning_rate": 7.110528000000001e-05,
      "loss": 2.0381,
      "step": 100700
    },
    {
      "epoch": 3.224,
      "grad_norm": 0.38075312972068787,
      "learning_rate": 7.104128e-05,
      "loss": 2.1408,
      "step": 100750
    },
    {
      "epoch": 3.2256,
      "grad_norm": 0.35689178109169006,
      "learning_rate": 7.097728e-05,
      "loss": 2.1146,
      "step": 100800
    },
    {
      "epoch": 3.2272,
      "grad_norm": 0.35260722041130066,
      "learning_rate": 7.091328000000001e-05,
      "loss": 2.138,
      "step": 100850
    },
    {
      "epoch": 3.2288,
      "grad_norm": 0.3110557496547699,
      "learning_rate": 7.084928e-05,
      "loss": 2.0561,
      "step": 100900
    },
    {
      "epoch": 3.2304,
      "grad_norm": 0.32858774065971375,
      "learning_rate": 7.078528e-05,
      "loss": 2.0901,
      "step": 100950
    },
    {
      "epoch": 3.232,
      "grad_norm": 0.3407805562019348,
      "learning_rate": 7.072128e-05,
      "loss": 2.0641,
      "step": 101000
    },
    {
      "epoch": 3.2336,
      "grad_norm": 0.3708989918231964,
      "learning_rate": 7.065728e-05,
      "loss": 2.0692,
      "step": 101050
    },
    {
      "epoch": 3.2352,
      "grad_norm": 0.2967981696128845,
      "learning_rate": 7.059328000000001e-05,
      "loss": 2.1936,
      "step": 101100
    },
    {
      "epoch": 3.2368,
      "grad_norm": 0.35077694058418274,
      "learning_rate": 7.052928000000001e-05,
      "loss": 2.0955,
      "step": 101150
    },
    {
      "epoch": 3.2384,
      "grad_norm": 0.4050901532173157,
      "learning_rate": 7.046528e-05,
      "loss": 2.0975,
      "step": 101200
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.35024699568748474,
      "learning_rate": 7.040128e-05,
      "loss": 2.1054,
      "step": 101250
    },
    {
      "epoch": 3.2416,
      "grad_norm": 0.4379240870475769,
      "learning_rate": 7.033728000000001e-05,
      "loss": 2.092,
      "step": 101300
    },
    {
      "epoch": 3.2432,
      "grad_norm": 0.37274301052093506,
      "learning_rate": 7.027328e-05,
      "loss": 2.1669,
      "step": 101350
    },
    {
      "epoch": 3.2448,
      "grad_norm": 0.3452720642089844,
      "learning_rate": 7.020928e-05,
      "loss": 2.0993,
      "step": 101400
    },
    {
      "epoch": 3.2464,
      "grad_norm": 0.32698023319244385,
      "learning_rate": 7.014528e-05,
      "loss": 2.1406,
      "step": 101450
    },
    {
      "epoch": 3.248,
      "grad_norm": 0.36451876163482666,
      "learning_rate": 7.008128e-05,
      "loss": 2.0768,
      "step": 101500
    },
    {
      "epoch": 3.2496,
      "grad_norm": 0.3913620412349701,
      "learning_rate": 7.001728000000001e-05,
      "loss": 2.1336,
      "step": 101550
    },
    {
      "epoch": 3.2512,
      "grad_norm": 0.40409019589424133,
      "learning_rate": 6.995328e-05,
      "loss": 2.1119,
      "step": 101600
    },
    {
      "epoch": 3.2528,
      "grad_norm": 0.33987298607826233,
      "learning_rate": 6.988928e-05,
      "loss": 2.0816,
      "step": 101650
    },
    {
      "epoch": 3.2544,
      "grad_norm": 0.5002126693725586,
      "learning_rate": 6.982528000000001e-05,
      "loss": 2.1148,
      "step": 101700
    },
    {
      "epoch": 3.2560000000000002,
      "grad_norm": 0.3614485561847687,
      "learning_rate": 6.976128e-05,
      "loss": 2.0944,
      "step": 101750
    },
    {
      "epoch": 3.2576,
      "grad_norm": 0.38961899280548096,
      "learning_rate": 6.969728e-05,
      "loss": 2.0815,
      "step": 101800
    },
    {
      "epoch": 3.2592,
      "grad_norm": 0.3538266122341156,
      "learning_rate": 6.963328e-05,
      "loss": 2.1839,
      "step": 101850
    },
    {
      "epoch": 3.2608,
      "grad_norm": 0.34846484661102295,
      "learning_rate": 6.956928e-05,
      "loss": 2.1406,
      "step": 101900
    },
    {
      "epoch": 3.2624,
      "grad_norm": 0.3541417419910431,
      "learning_rate": 6.950528000000001e-05,
      "loss": 2.0969,
      "step": 101950
    },
    {
      "epoch": 3.2640000000000002,
      "grad_norm": 0.3442496657371521,
      "learning_rate": 6.944128000000001e-05,
      "loss": 2.2264,
      "step": 102000
    },
    {
      "epoch": 3.2656,
      "grad_norm": 0.34224021434783936,
      "learning_rate": 6.937728e-05,
      "loss": 2.0329,
      "step": 102050
    },
    {
      "epoch": 3.2672,
      "grad_norm": 0.28196483850479126,
      "learning_rate": 6.931328e-05,
      "loss": 2.1203,
      "step": 102100
    },
    {
      "epoch": 3.2688,
      "grad_norm": 0.3914276361465454,
      "learning_rate": 6.924928e-05,
      "loss": 2.1271,
      "step": 102150
    },
    {
      "epoch": 3.2704,
      "grad_norm": 0.37668901681900024,
      "learning_rate": 6.918528e-05,
      "loss": 2.1511,
      "step": 102200
    },
    {
      "epoch": 3.2720000000000002,
      "grad_norm": 0.4185335040092468,
      "learning_rate": 6.912128e-05,
      "loss": 2.1054,
      "step": 102250
    },
    {
      "epoch": 3.2736,
      "grad_norm": 0.38229089975357056,
      "learning_rate": 6.905728e-05,
      "loss": 2.1059,
      "step": 102300
    },
    {
      "epoch": 3.2752,
      "grad_norm": 0.34106162190437317,
      "learning_rate": 6.899328e-05,
      "loss": 2.1037,
      "step": 102350
    },
    {
      "epoch": 3.2768,
      "grad_norm": 0.407265305519104,
      "learning_rate": 6.892928000000001e-05,
      "loss": 2.1213,
      "step": 102400
    },
    {
      "epoch": 3.2784,
      "grad_norm": 0.3589421212673187,
      "learning_rate": 6.886528e-05,
      "loss": 2.1118,
      "step": 102450
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.42949023842811584,
      "learning_rate": 6.880128e-05,
      "loss": 2.0936,
      "step": 102500
    },
    {
      "epoch": 3.2816,
      "grad_norm": 0.3636391758918762,
      "learning_rate": 6.873728000000001e-05,
      "loss": 2.0049,
      "step": 102550
    },
    {
      "epoch": 3.2832,
      "grad_norm": 0.35723182559013367,
      "learning_rate": 6.867328e-05,
      "loss": 2.0951,
      "step": 102600
    },
    {
      "epoch": 3.2848,
      "grad_norm": 0.38312920928001404,
      "learning_rate": 6.860928e-05,
      "loss": 2.079,
      "step": 102650
    },
    {
      "epoch": 3.2864,
      "grad_norm": 0.31881627440452576,
      "learning_rate": 6.854528e-05,
      "loss": 2.101,
      "step": 102700
    },
    {
      "epoch": 3.288,
      "grad_norm": 0.3570898473262787,
      "learning_rate": 6.848128e-05,
      "loss": 2.0872,
      "step": 102750
    },
    {
      "epoch": 3.2896,
      "grad_norm": 0.37336423993110657,
      "learning_rate": 6.841728000000001e-05,
      "loss": 2.098,
      "step": 102800
    },
    {
      "epoch": 3.2912,
      "grad_norm": 0.3750098645687103,
      "learning_rate": 6.835328000000001e-05,
      "loss": 2.0981,
      "step": 102850
    },
    {
      "epoch": 3.2928,
      "grad_norm": 0.44524601101875305,
      "learning_rate": 6.828928e-05,
      "loss": 2.0725,
      "step": 102900
    },
    {
      "epoch": 3.2944,
      "grad_norm": 0.3874322474002838,
      "learning_rate": 6.822528e-05,
      "loss": 2.1316,
      "step": 102950
    },
    {
      "epoch": 3.296,
      "grad_norm": 0.31267493963241577,
      "learning_rate": 6.816128e-05,
      "loss": 2.1105,
      "step": 103000
    },
    {
      "epoch": 3.2976,
      "grad_norm": 0.4961112439632416,
      "learning_rate": 6.809728e-05,
      "loss": 2.0881,
      "step": 103050
    },
    {
      "epoch": 3.2992,
      "grad_norm": 0.39139264822006226,
      "learning_rate": 6.803328e-05,
      "loss": 2.1017,
      "step": 103100
    },
    {
      "epoch": 3.3008,
      "grad_norm": 0.3312153220176697,
      "learning_rate": 6.796928e-05,
      "loss": 2.0834,
      "step": 103150
    },
    {
      "epoch": 3.3024,
      "grad_norm": 0.32914745807647705,
      "learning_rate": 6.790528e-05,
      "loss": 2.1237,
      "step": 103200
    },
    {
      "epoch": 3.304,
      "grad_norm": 0.3738781809806824,
      "learning_rate": 6.784128000000001e-05,
      "loss": 2.0475,
      "step": 103250
    },
    {
      "epoch": 3.3056,
      "grad_norm": 0.4039032459259033,
      "learning_rate": 6.777728e-05,
      "loss": 2.108,
      "step": 103300
    },
    {
      "epoch": 3.3072,
      "grad_norm": 0.3161455988883972,
      "learning_rate": 6.771328e-05,
      "loss": 2.079,
      "step": 103350
    },
    {
      "epoch": 3.3088,
      "grad_norm": 0.3676898181438446,
      "learning_rate": 6.764928000000001e-05,
      "loss": 2.1318,
      "step": 103400
    },
    {
      "epoch": 3.3104,
      "grad_norm": 0.34019654989242554,
      "learning_rate": 6.758528e-05,
      "loss": 2.1713,
      "step": 103450
    },
    {
      "epoch": 3.312,
      "grad_norm": 0.3204851448535919,
      "learning_rate": 6.752128e-05,
      "loss": 2.1142,
      "step": 103500
    },
    {
      "epoch": 3.3136,
      "grad_norm": 0.3759898841381073,
      "learning_rate": 6.745728e-05,
      "loss": 2.0893,
      "step": 103550
    },
    {
      "epoch": 3.3152,
      "grad_norm": 0.41106244921684265,
      "learning_rate": 6.739328e-05,
      "loss": 2.1075,
      "step": 103600
    },
    {
      "epoch": 3.3168,
      "grad_norm": 0.3274896442890167,
      "learning_rate": 6.732928000000001e-05,
      "loss": 2.0964,
      "step": 103650
    },
    {
      "epoch": 3.3184,
      "grad_norm": 0.4537724256515503,
      "learning_rate": 6.726528e-05,
      "loss": 2.0724,
      "step": 103700
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.4305243492126465,
      "learning_rate": 6.720128e-05,
      "loss": 2.0975,
      "step": 103750
    },
    {
      "epoch": 3.3216,
      "grad_norm": 0.37337762117385864,
      "learning_rate": 6.713728e-05,
      "loss": 2.0605,
      "step": 103800
    },
    {
      "epoch": 3.3232,
      "grad_norm": 0.35486677289009094,
      "learning_rate": 6.707328e-05,
      "loss": 2.1356,
      "step": 103850
    },
    {
      "epoch": 3.3247999999999998,
      "grad_norm": 0.32520806789398193,
      "learning_rate": 6.700928e-05,
      "loss": 2.1316,
      "step": 103900
    },
    {
      "epoch": 3.3264,
      "grad_norm": 0.37461191415786743,
      "learning_rate": 6.694528e-05,
      "loss": 2.0587,
      "step": 103950
    },
    {
      "epoch": 3.328,
      "grad_norm": 0.34577763080596924,
      "learning_rate": 6.688128e-05,
      "loss": 2.1038,
      "step": 104000
    },
    {
      "epoch": 3.3296,
      "grad_norm": 0.39359670877456665,
      "learning_rate": 6.681728e-05,
      "loss": 2.0903,
      "step": 104050
    },
    {
      "epoch": 3.3312,
      "grad_norm": 0.40633678436279297,
      "learning_rate": 6.675328000000001e-05,
      "loss": 2.138,
      "step": 104100
    },
    {
      "epoch": 3.3327999999999998,
      "grad_norm": 0.37301599979400635,
      "learning_rate": 6.668928e-05,
      "loss": 2.0946,
      "step": 104150
    },
    {
      "epoch": 3.3344,
      "grad_norm": 0.3712274134159088,
      "learning_rate": 6.662528e-05,
      "loss": 2.0826,
      "step": 104200
    },
    {
      "epoch": 3.336,
      "grad_norm": 0.3372747004032135,
      "learning_rate": 6.656128000000001e-05,
      "loss": 2.0684,
      "step": 104250
    },
    {
      "epoch": 3.3376,
      "grad_norm": 0.379202663898468,
      "learning_rate": 6.649728e-05,
      "loss": 2.1324,
      "step": 104300
    },
    {
      "epoch": 3.3392,
      "grad_norm": 0.38590317964553833,
      "learning_rate": 6.643328e-05,
      "loss": 2.1247,
      "step": 104350
    },
    {
      "epoch": 3.3407999999999998,
      "grad_norm": 0.3560031056404114,
      "learning_rate": 6.636928000000001e-05,
      "loss": 2.1015,
      "step": 104400
    },
    {
      "epoch": 3.3424,
      "grad_norm": 0.4098745584487915,
      "learning_rate": 6.630528e-05,
      "loss": 2.078,
      "step": 104450
    },
    {
      "epoch": 3.344,
      "grad_norm": 0.37011510133743286,
      "learning_rate": 6.624128000000001e-05,
      "loss": 2.0796,
      "step": 104500
    },
    {
      "epoch": 3.3456,
      "grad_norm": 0.3281506597995758,
      "learning_rate": 6.617728e-05,
      "loss": 2.0968,
      "step": 104550
    },
    {
      "epoch": 3.3472,
      "grad_norm": 0.3691026270389557,
      "learning_rate": 6.611328e-05,
      "loss": 2.1435,
      "step": 104600
    },
    {
      "epoch": 3.3487999999999998,
      "grad_norm": 0.4190232455730438,
      "learning_rate": 6.604928e-05,
      "loss": 2.0822,
      "step": 104650
    },
    {
      "epoch": 3.3504,
      "grad_norm": 0.30144935846328735,
      "learning_rate": 6.598528e-05,
      "loss": 2.0842,
      "step": 104700
    },
    {
      "epoch": 3.352,
      "grad_norm": 0.363757848739624,
      "learning_rate": 6.592128000000001e-05,
      "loss": 2.1674,
      "step": 104750
    },
    {
      "epoch": 3.3536,
      "grad_norm": 0.4030962586402893,
      "learning_rate": 6.585728e-05,
      "loss": 2.1153,
      "step": 104800
    },
    {
      "epoch": 3.3552,
      "grad_norm": 0.3833671808242798,
      "learning_rate": 6.579328e-05,
      "loss": 2.123,
      "step": 104850
    },
    {
      "epoch": 3.3568,
      "grad_norm": 0.32452040910720825,
      "learning_rate": 6.572928e-05,
      "loss": 2.0602,
      "step": 104900
    },
    {
      "epoch": 3.3584,
      "grad_norm": 0.3785097002983093,
      "learning_rate": 6.566528000000001e-05,
      "loss": 2.0741,
      "step": 104950
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.36973756551742554,
      "learning_rate": 6.560128e-05,
      "loss": 2.0827,
      "step": 105000
    },
    {
      "epoch": 3.3616,
      "grad_norm": 0.35391756892204285,
      "learning_rate": 6.553728e-05,
      "loss": 2.0657,
      "step": 105050
    },
    {
      "epoch": 3.3632,
      "grad_norm": 0.36012399196624756,
      "learning_rate": 6.547328000000001e-05,
      "loss": 2.0944,
      "step": 105100
    },
    {
      "epoch": 3.3648,
      "grad_norm": 0.35123318433761597,
      "learning_rate": 6.540928e-05,
      "loss": 2.0972,
      "step": 105150
    },
    {
      "epoch": 3.3664,
      "grad_norm": 0.3208789825439453,
      "learning_rate": 6.534528e-05,
      "loss": 2.0936,
      "step": 105200
    },
    {
      "epoch": 3.368,
      "grad_norm": 0.34817928075790405,
      "learning_rate": 6.528128e-05,
      "loss": 2.1035,
      "step": 105250
    },
    {
      "epoch": 3.3696,
      "grad_norm": 0.4724143445491791,
      "learning_rate": 6.521728e-05,
      "loss": 2.0814,
      "step": 105300
    },
    {
      "epoch": 3.3712,
      "grad_norm": 0.3444713056087494,
      "learning_rate": 6.515328000000001e-05,
      "loss": 2.1149,
      "step": 105350
    },
    {
      "epoch": 3.3728,
      "grad_norm": 0.35035720467567444,
      "learning_rate": 6.508928e-05,
      "loss": 2.0904,
      "step": 105400
    },
    {
      "epoch": 3.3744,
      "grad_norm": 0.3517286479473114,
      "learning_rate": 6.502528e-05,
      "loss": 2.1269,
      "step": 105450
    },
    {
      "epoch": 3.376,
      "grad_norm": 0.35422441363334656,
      "learning_rate": 6.496128e-05,
      "loss": 2.0257,
      "step": 105500
    },
    {
      "epoch": 3.3776,
      "grad_norm": 0.539167582988739,
      "learning_rate": 6.489728e-05,
      "loss": 2.1676,
      "step": 105550
    },
    {
      "epoch": 3.3792,
      "grad_norm": 0.3486074209213257,
      "learning_rate": 6.483328000000001e-05,
      "loss": 2.0781,
      "step": 105600
    },
    {
      "epoch": 3.3808,
      "grad_norm": 0.3658713102340698,
      "learning_rate": 6.476928e-05,
      "loss": 2.1082,
      "step": 105650
    },
    {
      "epoch": 3.3824,
      "grad_norm": 0.3753047287464142,
      "learning_rate": 6.470528e-05,
      "loss": 2.0968,
      "step": 105700
    },
    {
      "epoch": 3.384,
      "grad_norm": 0.32584232091903687,
      "learning_rate": 6.464128e-05,
      "loss": 2.0714,
      "step": 105750
    },
    {
      "epoch": 3.3856,
      "grad_norm": 0.3367249071598053,
      "learning_rate": 6.457728000000001e-05,
      "loss": 2.0965,
      "step": 105800
    },
    {
      "epoch": 3.3872,
      "grad_norm": 0.3705499470233917,
      "learning_rate": 6.451328e-05,
      "loss": 2.1441,
      "step": 105850
    },
    {
      "epoch": 3.3888,
      "grad_norm": 0.32592296600341797,
      "learning_rate": 6.444928e-05,
      "loss": 2.1796,
      "step": 105900
    },
    {
      "epoch": 3.3904,
      "grad_norm": 0.37590476870536804,
      "learning_rate": 6.438528000000001e-05,
      "loss": 2.0859,
      "step": 105950
    },
    {
      "epoch": 3.392,
      "grad_norm": 0.33784663677215576,
      "learning_rate": 6.432128e-05,
      "loss": 2.1397,
      "step": 106000
    },
    {
      "epoch": 3.3936,
      "grad_norm": 0.38160377740859985,
      "learning_rate": 6.425728000000001e-05,
      "loss": 2.1517,
      "step": 106050
    },
    {
      "epoch": 3.3952,
      "grad_norm": 0.33206212520599365,
      "learning_rate": 6.419328e-05,
      "loss": 2.1432,
      "step": 106100
    },
    {
      "epoch": 3.3968,
      "grad_norm": 0.38379788398742676,
      "learning_rate": 6.412928e-05,
      "loss": 2.0645,
      "step": 106150
    },
    {
      "epoch": 3.3984,
      "grad_norm": 0.3978121280670166,
      "learning_rate": 6.406528000000001e-05,
      "loss": 2.1138,
      "step": 106200
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.30661147832870483,
      "learning_rate": 6.400128e-05,
      "loss": 2.0623,
      "step": 106250
    },
    {
      "epoch": 3.4016,
      "grad_norm": 0.3154336214065552,
      "learning_rate": 6.393728e-05,
      "loss": 2.0955,
      "step": 106300
    },
    {
      "epoch": 3.4032,
      "grad_norm": 0.34577029943466187,
      "learning_rate": 6.387328e-05,
      "loss": 2.0643,
      "step": 106350
    },
    {
      "epoch": 3.4048,
      "grad_norm": 0.3688819408416748,
      "learning_rate": 6.380928e-05,
      "loss": 2.0539,
      "step": 106400
    },
    {
      "epoch": 3.4064,
      "grad_norm": 0.42818722128868103,
      "learning_rate": 6.374528000000001e-05,
      "loss": 2.0885,
      "step": 106450
    },
    {
      "epoch": 3.408,
      "grad_norm": 0.3532009422779083,
      "learning_rate": 6.368128e-05,
      "loss": 2.1495,
      "step": 106500
    },
    {
      "epoch": 3.4096,
      "grad_norm": 0.33425500988960266,
      "learning_rate": 6.361728e-05,
      "loss": 2.1211,
      "step": 106550
    },
    {
      "epoch": 3.4112,
      "grad_norm": 0.3576560616493225,
      "learning_rate": 6.355328e-05,
      "loss": 2.1322,
      "step": 106600
    },
    {
      "epoch": 3.4128,
      "grad_norm": 0.4114576578140259,
      "learning_rate": 6.348928000000001e-05,
      "loss": 2.1361,
      "step": 106650
    },
    {
      "epoch": 3.4144,
      "grad_norm": 0.3050408959388733,
      "learning_rate": 6.342528e-05,
      "loss": 2.0664,
      "step": 106700
    },
    {
      "epoch": 3.416,
      "grad_norm": 0.34601718187332153,
      "learning_rate": 6.336128e-05,
      "loss": 2.1346,
      "step": 106750
    },
    {
      "epoch": 3.4176,
      "grad_norm": 0.34416183829307556,
      "learning_rate": 6.329728e-05,
      "loss": 2.1044,
      "step": 106800
    },
    {
      "epoch": 3.4192,
      "grad_norm": 0.39985114336013794,
      "learning_rate": 6.323328e-05,
      "loss": 2.114,
      "step": 106850
    },
    {
      "epoch": 3.4208,
      "grad_norm": 0.33661869168281555,
      "learning_rate": 6.316928000000001e-05,
      "loss": 2.0528,
      "step": 106900
    },
    {
      "epoch": 3.4224,
      "grad_norm": 0.37835612893104553,
      "learning_rate": 6.310528e-05,
      "loss": 2.0977,
      "step": 106950
    },
    {
      "epoch": 3.424,
      "grad_norm": 0.31830286979675293,
      "learning_rate": 6.304128e-05,
      "loss": 2.1033,
      "step": 107000
    },
    {
      "epoch": 3.4256,
      "grad_norm": 0.4317390024662018,
      "learning_rate": 6.297728000000001e-05,
      "loss": 2.0798,
      "step": 107050
    },
    {
      "epoch": 3.4272,
      "grad_norm": 0.42667537927627563,
      "learning_rate": 6.291328e-05,
      "loss": 2.1174,
      "step": 107100
    },
    {
      "epoch": 3.4288,
      "grad_norm": 0.3497758209705353,
      "learning_rate": 6.284928e-05,
      "loss": 2.1433,
      "step": 107150
    },
    {
      "epoch": 3.4304,
      "grad_norm": 0.3537491261959076,
      "learning_rate": 6.278528e-05,
      "loss": 2.1251,
      "step": 107200
    },
    {
      "epoch": 3.432,
      "grad_norm": 0.38654303550720215,
      "learning_rate": 6.272128e-05,
      "loss": 2.1167,
      "step": 107250
    },
    {
      "epoch": 3.4336,
      "grad_norm": 0.39624306559562683,
      "learning_rate": 6.265728000000001e-05,
      "loss": 2.153,
      "step": 107300
    },
    {
      "epoch": 3.4352,
      "grad_norm": 0.4268605411052704,
      "learning_rate": 6.259328e-05,
      "loss": 2.1881,
      "step": 107350
    },
    {
      "epoch": 3.4368,
      "grad_norm": 0.3785512447357178,
      "learning_rate": 6.252928e-05,
      "loss": 2.0657,
      "step": 107400
    },
    {
      "epoch": 3.4384,
      "grad_norm": 0.39872193336486816,
      "learning_rate": 6.246528e-05,
      "loss": 2.0914,
      "step": 107450
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.396819144487381,
      "learning_rate": 6.240128000000001e-05,
      "loss": 2.0648,
      "step": 107500
    },
    {
      "epoch": 3.4416,
      "grad_norm": 0.36522865295410156,
      "learning_rate": 6.233728e-05,
      "loss": 2.1374,
      "step": 107550
    },
    {
      "epoch": 3.4432,
      "grad_norm": 0.353283166885376,
      "learning_rate": 6.227328e-05,
      "loss": 2.0669,
      "step": 107600
    },
    {
      "epoch": 3.4448,
      "grad_norm": 0.41091203689575195,
      "learning_rate": 6.220928e-05,
      "loss": 2.0877,
      "step": 107650
    },
    {
      "epoch": 3.4464,
      "grad_norm": 0.3593286871910095,
      "learning_rate": 6.214528e-05,
      "loss": 2.1316,
      "step": 107700
    },
    {
      "epoch": 3.448,
      "grad_norm": 0.31744691729545593,
      "learning_rate": 6.208128000000001e-05,
      "loss": 2.0927,
      "step": 107750
    },
    {
      "epoch": 3.4496,
      "grad_norm": 0.3964313864707947,
      "learning_rate": 6.201728e-05,
      "loss": 2.1,
      "step": 107800
    },
    {
      "epoch": 3.4512,
      "grad_norm": 0.3735367953777313,
      "learning_rate": 6.195328e-05,
      "loss": 2.0439,
      "step": 107850
    },
    {
      "epoch": 3.4528,
      "grad_norm": 0.40390366315841675,
      "learning_rate": 6.188928000000001e-05,
      "loss": 2.0695,
      "step": 107900
    },
    {
      "epoch": 3.4544,
      "grad_norm": 0.3833608329296112,
      "learning_rate": 6.182528e-05,
      "loss": 2.1259,
      "step": 107950
    },
    {
      "epoch": 3.456,
      "grad_norm": 0.3143530488014221,
      "learning_rate": 6.176128e-05,
      "loss": 2.0431,
      "step": 108000
    },
    {
      "epoch": 3.4576000000000002,
      "grad_norm": 0.3751959800720215,
      "learning_rate": 6.169728000000001e-05,
      "loss": 2.1344,
      "step": 108050
    },
    {
      "epoch": 3.4592,
      "grad_norm": 0.3728651702404022,
      "learning_rate": 6.163328e-05,
      "loss": 2.0491,
      "step": 108100
    },
    {
      "epoch": 3.4608,
      "grad_norm": 0.35756319761276245,
      "learning_rate": 6.156928000000001e-05,
      "loss": 2.1229,
      "step": 108150
    },
    {
      "epoch": 3.4624,
      "grad_norm": 0.36449989676475525,
      "learning_rate": 6.150528e-05,
      "loss": 2.1564,
      "step": 108200
    },
    {
      "epoch": 3.464,
      "grad_norm": 0.3706539273262024,
      "learning_rate": 6.144128e-05,
      "loss": 2.1969,
      "step": 108250
    },
    {
      "epoch": 3.4656000000000002,
      "grad_norm": 0.41226842999458313,
      "learning_rate": 6.137728e-05,
      "loss": 2.0628,
      "step": 108300
    },
    {
      "epoch": 3.4672,
      "grad_norm": 0.4225827753543854,
      "learning_rate": 6.131328e-05,
      "loss": 2.1154,
      "step": 108350
    },
    {
      "epoch": 3.4688,
      "grad_norm": 0.3599334955215454,
      "learning_rate": 6.124928e-05,
      "loss": 2.0601,
      "step": 108400
    },
    {
      "epoch": 3.4704,
      "grad_norm": 0.42309731245040894,
      "learning_rate": 6.118528e-05,
      "loss": 2.0916,
      "step": 108450
    },
    {
      "epoch": 3.472,
      "grad_norm": 0.36337023973464966,
      "learning_rate": 6.112128e-05,
      "loss": 2.0982,
      "step": 108500
    },
    {
      "epoch": 3.4736000000000002,
      "grad_norm": 0.4127790927886963,
      "learning_rate": 6.105728e-05,
      "loss": 2.1202,
      "step": 108550
    },
    {
      "epoch": 3.4752,
      "grad_norm": 0.3963589668273926,
      "learning_rate": 6.099328000000001e-05,
      "loss": 2.1241,
      "step": 108600
    },
    {
      "epoch": 3.4768,
      "grad_norm": 0.3680894672870636,
      "learning_rate": 6.092928e-05,
      "loss": 2.0763,
      "step": 108650
    },
    {
      "epoch": 3.4784,
      "grad_norm": 0.3637189269065857,
      "learning_rate": 6.086528e-05,
      "loss": 2.0761,
      "step": 108700
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.32674965262413025,
      "learning_rate": 6.080128e-05,
      "loss": 2.146,
      "step": 108750
    },
    {
      "epoch": 3.4816,
      "grad_norm": 0.35803067684173584,
      "learning_rate": 6.073728000000001e-05,
      "loss": 2.1147,
      "step": 108800
    },
    {
      "epoch": 3.4832,
      "grad_norm": 0.5312442779541016,
      "learning_rate": 6.067328e-05,
      "loss": 2.0855,
      "step": 108850
    },
    {
      "epoch": 3.4848,
      "grad_norm": 0.4353065490722656,
      "learning_rate": 6.060928e-05,
      "loss": 2.0593,
      "step": 108900
    },
    {
      "epoch": 3.4864,
      "grad_norm": 0.41726061701774597,
      "learning_rate": 6.054528e-05,
      "loss": 2.0482,
      "step": 108950
    },
    {
      "epoch": 3.488,
      "grad_norm": 0.3725613057613373,
      "learning_rate": 6.0481280000000005e-05,
      "loss": 2.1215,
      "step": 109000
    },
    {
      "epoch": 3.4896,
      "grad_norm": 0.36993253231048584,
      "learning_rate": 6.041728e-05,
      "loss": 2.1753,
      "step": 109050
    },
    {
      "epoch": 3.4912,
      "grad_norm": 0.3301461637020111,
      "learning_rate": 6.035328e-05,
      "loss": 2.0667,
      "step": 109100
    },
    {
      "epoch": 3.4928,
      "grad_norm": 0.3823416233062744,
      "learning_rate": 6.0289280000000004e-05,
      "loss": 2.1023,
      "step": 109150
    },
    {
      "epoch": 3.4944,
      "grad_norm": 0.3621675372123718,
      "learning_rate": 6.0225280000000006e-05,
      "loss": 2.0898,
      "step": 109200
    },
    {
      "epoch": 3.496,
      "grad_norm": 0.3662758767604828,
      "learning_rate": 6.0161279999999995e-05,
      "loss": 2.1082,
      "step": 109250
    },
    {
      "epoch": 3.4976,
      "grad_norm": 0.3472668528556824,
      "learning_rate": 6.0097280000000003e-05,
      "loss": 2.0856,
      "step": 109300
    },
    {
      "epoch": 3.4992,
      "grad_norm": 0.3792724907398224,
      "learning_rate": 6.0033280000000005e-05,
      "loss": 2.1541,
      "step": 109350
    },
    {
      "epoch": 3.5008,
      "grad_norm": 0.3749316930770874,
      "learning_rate": 5.996928000000001e-05,
      "loss": 2.1344,
      "step": 109400
    },
    {
      "epoch": 3.5023999999999997,
      "grad_norm": 0.3156125247478485,
      "learning_rate": 5.990528000000001e-05,
      "loss": 2.109,
      "step": 109450
    },
    {
      "epoch": 3.504,
      "grad_norm": 0.3446682095527649,
      "learning_rate": 5.984128e-05,
      "loss": 2.0725,
      "step": 109500
    },
    {
      "epoch": 3.5056000000000003,
      "grad_norm": 0.3806222081184387,
      "learning_rate": 5.977728e-05,
      "loss": 2.0556,
      "step": 109550
    },
    {
      "epoch": 3.5072,
      "grad_norm": 0.34629350900650024,
      "learning_rate": 5.971328e-05,
      "loss": 2.1591,
      "step": 109600
    },
    {
      "epoch": 3.5088,
      "grad_norm": 0.4088694751262665,
      "learning_rate": 5.964928000000001e-05,
      "loss": 2.0667,
      "step": 109650
    },
    {
      "epoch": 3.5103999999999997,
      "grad_norm": 0.365780234336853,
      "learning_rate": 5.958528e-05,
      "loss": 2.1338,
      "step": 109700
    },
    {
      "epoch": 3.512,
      "grad_norm": 0.3972839117050171,
      "learning_rate": 5.952128e-05,
      "loss": 2.1531,
      "step": 109750
    },
    {
      "epoch": 3.5136,
      "grad_norm": 0.3555128574371338,
      "learning_rate": 5.945728e-05,
      "loss": 2.1269,
      "step": 109800
    },
    {
      "epoch": 3.5152,
      "grad_norm": 0.47353050112724304,
      "learning_rate": 5.9393280000000005e-05,
      "loss": 2.1798,
      "step": 109850
    },
    {
      "epoch": 3.5168,
      "grad_norm": 0.33181098103523254,
      "learning_rate": 5.932928e-05,
      "loss": 2.0772,
      "step": 109900
    },
    {
      "epoch": 3.5183999999999997,
      "grad_norm": 0.35892343521118164,
      "learning_rate": 5.926528e-05,
      "loss": 2.1761,
      "step": 109950
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.34854647517204285,
      "learning_rate": 5.9201280000000004e-05,
      "loss": 2.0724,
      "step": 110000
    },
    {
      "epoch": 3.5216,
      "grad_norm": 0.6060482263565063,
      "learning_rate": 5.9137280000000006e-05,
      "loss": 2.0976,
      "step": 110050
    },
    {
      "epoch": 3.5232,
      "grad_norm": 0.32739710807800293,
      "learning_rate": 5.9073279999999994e-05,
      "loss": 2.1039,
      "step": 110100
    },
    {
      "epoch": 3.5248,
      "grad_norm": 0.3649860918521881,
      "learning_rate": 5.900928e-05,
      "loss": 2.1083,
      "step": 110150
    },
    {
      "epoch": 3.5263999999999998,
      "grad_norm": 0.3965469300746918,
      "learning_rate": 5.8945280000000005e-05,
      "loss": 2.0547,
      "step": 110200
    },
    {
      "epoch": 3.528,
      "grad_norm": 0.33925649523735046,
      "learning_rate": 5.888128000000001e-05,
      "loss": 2.0913,
      "step": 110250
    },
    {
      "epoch": 3.5296,
      "grad_norm": 0.4230012595653534,
      "learning_rate": 5.881728000000001e-05,
      "loss": 2.1423,
      "step": 110300
    },
    {
      "epoch": 3.5312,
      "grad_norm": 0.43594831228256226,
      "learning_rate": 5.875328e-05,
      "loss": 2.1342,
      "step": 110350
    },
    {
      "epoch": 3.5328,
      "grad_norm": 0.5818246006965637,
      "learning_rate": 5.868928e-05,
      "loss": 2.0969,
      "step": 110400
    },
    {
      "epoch": 3.5343999999999998,
      "grad_norm": 0.3456587791442871,
      "learning_rate": 5.862528000000001e-05,
      "loss": 2.1123,
      "step": 110450
    },
    {
      "epoch": 3.536,
      "grad_norm": 0.3603644073009491,
      "learning_rate": 5.856128000000001e-05,
      "loss": 2.1231,
      "step": 110500
    },
    {
      "epoch": 3.5376,
      "grad_norm": 0.4462457001209259,
      "learning_rate": 5.849728e-05,
      "loss": 2.1753,
      "step": 110550
    },
    {
      "epoch": 3.5392,
      "grad_norm": 0.3699958324432373,
      "learning_rate": 5.843328e-05,
      "loss": 2.1388,
      "step": 110600
    },
    {
      "epoch": 3.5408,
      "grad_norm": 0.389939546585083,
      "learning_rate": 5.836928e-05,
      "loss": 2.0807,
      "step": 110650
    },
    {
      "epoch": 3.5423999999999998,
      "grad_norm": 0.39269891381263733,
      "learning_rate": 5.8305280000000004e-05,
      "loss": 2.0637,
      "step": 110700
    },
    {
      "epoch": 3.544,
      "grad_norm": 0.3912980854511261,
      "learning_rate": 5.824128e-05,
      "loss": 2.0462,
      "step": 110750
    },
    {
      "epoch": 3.5456,
      "grad_norm": 0.37358933687210083,
      "learning_rate": 5.817728e-05,
      "loss": 2.1194,
      "step": 110800
    },
    {
      "epoch": 3.5472,
      "grad_norm": 0.47860369086265564,
      "learning_rate": 5.8113280000000003e-05,
      "loss": 2.0853,
      "step": 110850
    },
    {
      "epoch": 3.5488,
      "grad_norm": 0.37641584873199463,
      "learning_rate": 5.8049280000000005e-05,
      "loss": 2.0604,
      "step": 110900
    },
    {
      "epoch": 3.5504,
      "grad_norm": 0.4006176292896271,
      "learning_rate": 5.798528e-05,
      "loss": 2.1115,
      "step": 110950
    },
    {
      "epoch": 3.552,
      "grad_norm": 0.3619762063026428,
      "learning_rate": 5.792128e-05,
      "loss": 2.1103,
      "step": 111000
    },
    {
      "epoch": 3.5536,
      "grad_norm": 0.4032345414161682,
      "learning_rate": 5.7857280000000005e-05,
      "loss": 2.0656,
      "step": 111050
    },
    {
      "epoch": 3.5552,
      "grad_norm": 0.38701823353767395,
      "learning_rate": 5.7793280000000006e-05,
      "loss": 2.1053,
      "step": 111100
    },
    {
      "epoch": 3.5568,
      "grad_norm": 0.3383016884326935,
      "learning_rate": 5.772928000000001e-05,
      "loss": 2.1078,
      "step": 111150
    },
    {
      "epoch": 3.5584,
      "grad_norm": 0.40642493963241577,
      "learning_rate": 5.766528e-05,
      "loss": 2.0852,
      "step": 111200
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.34239283204078674,
      "learning_rate": 5.760128e-05,
      "loss": 2.1101,
      "step": 111250
    },
    {
      "epoch": 3.5616,
      "grad_norm": 0.35463836789131165,
      "learning_rate": 5.753728000000001e-05,
      "loss": 2.1344,
      "step": 111300
    },
    {
      "epoch": 3.5632,
      "grad_norm": 0.3446769416332245,
      "learning_rate": 5.747328000000001e-05,
      "loss": 2.1489,
      "step": 111350
    },
    {
      "epoch": 3.5648,
      "grad_norm": 0.35541990399360657,
      "learning_rate": 5.740928e-05,
      "loss": 2.1185,
      "step": 111400
    },
    {
      "epoch": 3.5664,
      "grad_norm": 0.41722381114959717,
      "learning_rate": 5.734528e-05,
      "loss": 2.1306,
      "step": 111450
    },
    {
      "epoch": 3.568,
      "grad_norm": 0.3366469740867615,
      "learning_rate": 5.728128e-05,
      "loss": 2.1508,
      "step": 111500
    },
    {
      "epoch": 3.5696,
      "grad_norm": 0.31762388348579407,
      "learning_rate": 5.7217280000000004e-05,
      "loss": 2.1106,
      "step": 111550
    },
    {
      "epoch": 3.5712,
      "grad_norm": 0.3327247202396393,
      "learning_rate": 5.715328e-05,
      "loss": 2.1133,
      "step": 111600
    },
    {
      "epoch": 3.5728,
      "grad_norm": 0.4734973907470703,
      "learning_rate": 5.708928e-05,
      "loss": 2.0954,
      "step": 111650
    },
    {
      "epoch": 3.5744,
      "grad_norm": 0.37350425124168396,
      "learning_rate": 5.702528e-05,
      "loss": 2.1651,
      "step": 111700
    },
    {
      "epoch": 3.576,
      "grad_norm": 0.41389429569244385,
      "learning_rate": 5.6961280000000005e-05,
      "loss": 2.1142,
      "step": 111750
    },
    {
      "epoch": 3.5776,
      "grad_norm": 0.3399253785610199,
      "learning_rate": 5.689728e-05,
      "loss": 2.1294,
      "step": 111800
    },
    {
      "epoch": 3.5792,
      "grad_norm": 0.4105798304080963,
      "learning_rate": 5.683328e-05,
      "loss": 2.0687,
      "step": 111850
    },
    {
      "epoch": 3.5808,
      "grad_norm": 0.4397813081741333,
      "learning_rate": 5.6769280000000004e-05,
      "loss": 2.0798,
      "step": 111900
    },
    {
      "epoch": 3.5824,
      "grad_norm": 0.33580315113067627,
      "learning_rate": 5.6705280000000006e-05,
      "loss": 2.1149,
      "step": 111950
    },
    {
      "epoch": 3.584,
      "grad_norm": 0.33767953515052795,
      "learning_rate": 5.664128000000001e-05,
      "loss": 2.0474,
      "step": 112000
    },
    {
      "epoch": 3.5856,
      "grad_norm": 0.41852959990501404,
      "learning_rate": 5.6577279999999996e-05,
      "loss": 2.1312,
      "step": 112050
    },
    {
      "epoch": 3.5872,
      "grad_norm": 0.3442693054676056,
      "learning_rate": 5.651328e-05,
      "loss": 2.12,
      "step": 112100
    },
    {
      "epoch": 3.5888,
      "grad_norm": 0.4333036541938782,
      "learning_rate": 5.644928000000001e-05,
      "loss": 2.1286,
      "step": 112150
    },
    {
      "epoch": 3.5904,
      "grad_norm": 0.39882540702819824,
      "learning_rate": 5.638528000000001e-05,
      "loss": 2.1223,
      "step": 112200
    },
    {
      "epoch": 3.592,
      "grad_norm": 0.39743074774742126,
      "learning_rate": 5.632128e-05,
      "loss": 2.1096,
      "step": 112250
    },
    {
      "epoch": 3.5936,
      "grad_norm": 0.39819619059562683,
      "learning_rate": 5.625728e-05,
      "loss": 2.1036,
      "step": 112300
    },
    {
      "epoch": 3.5952,
      "grad_norm": 0.3367372751235962,
      "learning_rate": 5.619328e-05,
      "loss": 2.1068,
      "step": 112350
    },
    {
      "epoch": 3.5968,
      "grad_norm": 0.32548463344573975,
      "learning_rate": 5.6129280000000003e-05,
      "loss": 2.0926,
      "step": 112400
    },
    {
      "epoch": 3.5984,
      "grad_norm": 0.3844586908817291,
      "learning_rate": 5.606528e-05,
      "loss": 2.1149,
      "step": 112450
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.3331650197505951,
      "learning_rate": 5.600128e-05,
      "loss": 2.0735,
      "step": 112500
    },
    {
      "epoch": 3.6016,
      "grad_norm": 0.31195738911628723,
      "learning_rate": 5.593728e-05,
      "loss": 2.1339,
      "step": 112550
    },
    {
      "epoch": 3.6032,
      "grad_norm": 0.43054112792015076,
      "learning_rate": 5.5873280000000005e-05,
      "loss": 2.1428,
      "step": 112600
    },
    {
      "epoch": 3.6048,
      "grad_norm": 0.39701321721076965,
      "learning_rate": 5.5809280000000007e-05,
      "loss": 2.0944,
      "step": 112650
    },
    {
      "epoch": 3.6064,
      "grad_norm": 0.36043086647987366,
      "learning_rate": 5.574528e-05,
      "loss": 2.0524,
      "step": 112700
    },
    {
      "epoch": 3.608,
      "grad_norm": 0.41337016224861145,
      "learning_rate": 5.5681280000000004e-05,
      "loss": 2.0947,
      "step": 112750
    },
    {
      "epoch": 3.6096,
      "grad_norm": 0.39248546957969666,
      "learning_rate": 5.5617280000000006e-05,
      "loss": 2.1332,
      "step": 112800
    },
    {
      "epoch": 3.6112,
      "grad_norm": 0.30985328555107117,
      "learning_rate": 5.555328000000001e-05,
      "loss": 2.1095,
      "step": 112850
    },
    {
      "epoch": 3.6128,
      "grad_norm": 0.4161602854728699,
      "learning_rate": 5.5489279999999996e-05,
      "loss": 2.1078,
      "step": 112900
    },
    {
      "epoch": 3.6144,
      "grad_norm": 0.4117400646209717,
      "learning_rate": 5.5425280000000005e-05,
      "loss": 2.1383,
      "step": 112950
    },
    {
      "epoch": 3.616,
      "grad_norm": 0.3515007793903351,
      "learning_rate": 5.536128000000001e-05,
      "loss": 2.1085,
      "step": 113000
    },
    {
      "epoch": 3.6176,
      "grad_norm": 0.3507385551929474,
      "learning_rate": 5.529728000000001e-05,
      "loss": 2.0883,
      "step": 113050
    },
    {
      "epoch": 3.6192,
      "grad_norm": 0.34603849053382874,
      "learning_rate": 5.523328e-05,
      "loss": 2.1026,
      "step": 113100
    },
    {
      "epoch": 3.6208,
      "grad_norm": 0.37840530276298523,
      "learning_rate": 5.516928e-05,
      "loss": 2.105,
      "step": 113150
    },
    {
      "epoch": 3.6224,
      "grad_norm": 0.371908962726593,
      "learning_rate": 5.510528e-05,
      "loss": 2.1604,
      "step": 113200
    },
    {
      "epoch": 3.624,
      "grad_norm": 0.44290751218795776,
      "learning_rate": 5.504128e-05,
      "loss": 2.2136,
      "step": 113250
    },
    {
      "epoch": 3.6256,
      "grad_norm": 0.42761608958244324,
      "learning_rate": 5.497728e-05,
      "loss": 2.0785,
      "step": 113300
    },
    {
      "epoch": 3.6272,
      "grad_norm": 0.3626213073730469,
      "learning_rate": 5.491328e-05,
      "loss": 2.0979,
      "step": 113350
    },
    {
      "epoch": 3.6288,
      "grad_norm": 0.39704763889312744,
      "learning_rate": 5.484928e-05,
      "loss": 2.0895,
      "step": 113400
    },
    {
      "epoch": 3.6304,
      "grad_norm": 0.32256755232810974,
      "learning_rate": 5.4785280000000004e-05,
      "loss": 2.0862,
      "step": 113450
    },
    {
      "epoch": 3.632,
      "grad_norm": 0.4102669060230255,
      "learning_rate": 5.4721280000000006e-05,
      "loss": 2.0774,
      "step": 113500
    },
    {
      "epoch": 3.6336,
      "grad_norm": 0.340192973613739,
      "learning_rate": 5.465728e-05,
      "loss": 2.0412,
      "step": 113550
    },
    {
      "epoch": 3.6352,
      "grad_norm": 0.4056378901004791,
      "learning_rate": 5.459328e-05,
      "loss": 2.0595,
      "step": 113600
    },
    {
      "epoch": 3.6368,
      "grad_norm": 0.40146127343177795,
      "learning_rate": 5.4529280000000005e-05,
      "loss": 2.0759,
      "step": 113650
    },
    {
      "epoch": 3.6384,
      "grad_norm": 0.38804545998573303,
      "learning_rate": 5.446528000000001e-05,
      "loss": 2.0729,
      "step": 113700
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.3601938486099243,
      "learning_rate": 5.4401279999999996e-05,
      "loss": 2.1328,
      "step": 113750
    },
    {
      "epoch": 3.6416,
      "grad_norm": 0.3704128861427307,
      "learning_rate": 5.4337280000000004e-05,
      "loss": 2.1725,
      "step": 113800
    },
    {
      "epoch": 3.6432,
      "grad_norm": 0.2693498134613037,
      "learning_rate": 5.4273280000000006e-05,
      "loss": 2.0667,
      "step": 113850
    },
    {
      "epoch": 3.6448,
      "grad_norm": 0.346365362405777,
      "learning_rate": 5.420928000000001e-05,
      "loss": 2.0906,
      "step": 113900
    },
    {
      "epoch": 3.6464,
      "grad_norm": 0.3711051046848297,
      "learning_rate": 5.414528e-05,
      "loss": 2.0865,
      "step": 113950
    },
    {
      "epoch": 3.648,
      "grad_norm": 0.36541256308555603,
      "learning_rate": 5.408128e-05,
      "loss": 2.0694,
      "step": 114000
    },
    {
      "epoch": 3.6496,
      "grad_norm": 0.41799187660217285,
      "learning_rate": 5.401728e-05,
      "loss": 2.0903,
      "step": 114050
    },
    {
      "epoch": 3.6512000000000002,
      "grad_norm": 0.35054153203964233,
      "learning_rate": 5.395328000000001e-05,
      "loss": 2.1308,
      "step": 114100
    },
    {
      "epoch": 3.6528,
      "grad_norm": 0.3519872725009918,
      "learning_rate": 5.388928e-05,
      "loss": 2.1183,
      "step": 114150
    },
    {
      "epoch": 3.6544,
      "grad_norm": 0.3428943455219269,
      "learning_rate": 5.382528e-05,
      "loss": 2.0944,
      "step": 114200
    },
    {
      "epoch": 3.656,
      "grad_norm": 0.4292992353439331,
      "learning_rate": 5.376128e-05,
      "loss": 2.1191,
      "step": 114250
    },
    {
      "epoch": 3.6576,
      "grad_norm": 0.37914133071899414,
      "learning_rate": 5.3697280000000004e-05,
      "loss": 2.0918,
      "step": 114300
    },
    {
      "epoch": 3.6592000000000002,
      "grad_norm": 0.42211636900901794,
      "learning_rate": 5.3633280000000006e-05,
      "loss": 2.1327,
      "step": 114350
    },
    {
      "epoch": 3.6608,
      "grad_norm": 0.3549671173095703,
      "learning_rate": 5.356928e-05,
      "loss": 2.1212,
      "step": 114400
    },
    {
      "epoch": 3.6624,
      "grad_norm": 0.3492230772972107,
      "learning_rate": 5.350528e-05,
      "loss": 2.0752,
      "step": 114450
    },
    {
      "epoch": 3.664,
      "grad_norm": 0.39853376150131226,
      "learning_rate": 5.3441280000000005e-05,
      "loss": 2.1391,
      "step": 114500
    },
    {
      "epoch": 3.6656,
      "grad_norm": 0.3380863070487976,
      "learning_rate": 5.337728000000001e-05,
      "loss": 2.0799,
      "step": 114550
    },
    {
      "epoch": 3.6672000000000002,
      "grad_norm": 0.3507564961910248,
      "learning_rate": 5.331328e-05,
      "loss": 2.1674,
      "step": 114600
    },
    {
      "epoch": 3.6688,
      "grad_norm": 0.36269840598106384,
      "learning_rate": 5.3249280000000004e-05,
      "loss": 2.1267,
      "step": 114650
    },
    {
      "epoch": 3.6704,
      "grad_norm": 0.3705903887748718,
      "learning_rate": 5.3185280000000006e-05,
      "loss": 2.0246,
      "step": 114700
    },
    {
      "epoch": 3.672,
      "grad_norm": 0.375698447227478,
      "learning_rate": 5.312128000000001e-05,
      "loss": 2.0895,
      "step": 114750
    },
    {
      "epoch": 3.6736,
      "grad_norm": 0.42069435119628906,
      "learning_rate": 5.3057279999999996e-05,
      "loss": 2.0915,
      "step": 114800
    },
    {
      "epoch": 3.6752000000000002,
      "grad_norm": 0.3997483551502228,
      "learning_rate": 5.299328e-05,
      "loss": 2.1092,
      "step": 114850
    },
    {
      "epoch": 3.6768,
      "grad_norm": 0.3783091604709625,
      "learning_rate": 5.292928e-05,
      "loss": 2.0724,
      "step": 114900
    },
    {
      "epoch": 3.6784,
      "grad_norm": 0.389578253030777,
      "learning_rate": 5.286528000000001e-05,
      "loss": 2.1383,
      "step": 114950
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.36266010999679565,
      "learning_rate": 5.280128e-05,
      "loss": 2.11,
      "step": 115000
    },
    {
      "epoch": 3.6816,
      "grad_norm": 0.36832717061042786,
      "learning_rate": 5.273728e-05,
      "loss": 2.1032,
      "step": 115050
    },
    {
      "epoch": 3.6832000000000003,
      "grad_norm": 0.3679734468460083,
      "learning_rate": 5.267328e-05,
      "loss": 2.1137,
      "step": 115100
    },
    {
      "epoch": 3.6848,
      "grad_norm": 0.3539906442165375,
      "learning_rate": 5.260928e-05,
      "loss": 2.1491,
      "step": 115150
    },
    {
      "epoch": 3.6864,
      "grad_norm": 0.4369131624698639,
      "learning_rate": 5.2545280000000005e-05,
      "loss": 2.1351,
      "step": 115200
    },
    {
      "epoch": 3.6879999999999997,
      "grad_norm": 0.42788150906562805,
      "learning_rate": 5.248128e-05,
      "loss": 2.0971,
      "step": 115250
    },
    {
      "epoch": 3.6896,
      "grad_norm": 0.3812032639980316,
      "learning_rate": 5.241728e-05,
      "loss": 2.0871,
      "step": 115300
    },
    {
      "epoch": 3.6912000000000003,
      "grad_norm": 0.3811023533344269,
      "learning_rate": 5.2353280000000004e-05,
      "loss": 2.1353,
      "step": 115350
    },
    {
      "epoch": 3.6928,
      "grad_norm": 0.39769798517227173,
      "learning_rate": 5.2289280000000006e-05,
      "loss": 2.0841,
      "step": 115400
    },
    {
      "epoch": 3.6944,
      "grad_norm": 0.30725404620170593,
      "learning_rate": 5.222528e-05,
      "loss": 2.1325,
      "step": 115450
    },
    {
      "epoch": 3.6959999999999997,
      "grad_norm": 0.3393498659133911,
      "learning_rate": 5.2161280000000003e-05,
      "loss": 2.1535,
      "step": 115500
    },
    {
      "epoch": 3.6976,
      "grad_norm": 0.4388693571090698,
      "learning_rate": 5.2097280000000005e-05,
      "loss": 2.1256,
      "step": 115550
    },
    {
      "epoch": 3.6992000000000003,
      "grad_norm": 0.459726482629776,
      "learning_rate": 5.203328000000001e-05,
      "loss": 2.0703,
      "step": 115600
    },
    {
      "epoch": 3.7008,
      "grad_norm": 0.4524161219596863,
      "learning_rate": 5.1969279999999996e-05,
      "loss": 2.1301,
      "step": 115650
    },
    {
      "epoch": 3.7024,
      "grad_norm": 0.33958107233047485,
      "learning_rate": 5.190528e-05,
      "loss": 2.0609,
      "step": 115700
    },
    {
      "epoch": 3.7039999999999997,
      "grad_norm": 0.37089672684669495,
      "learning_rate": 5.1841280000000007e-05,
      "loss": 2.0554,
      "step": 115750
    },
    {
      "epoch": 3.7056,
      "grad_norm": 0.34950920939445496,
      "learning_rate": 5.177728000000001e-05,
      "loss": 2.0828,
      "step": 115800
    },
    {
      "epoch": 3.7072000000000003,
      "grad_norm": 0.42483919858932495,
      "learning_rate": 5.171328e-05,
      "loss": 2.0599,
      "step": 115850
    },
    {
      "epoch": 3.7088,
      "grad_norm": 0.3577190339565277,
      "learning_rate": 5.164928e-05,
      "loss": 2.1136,
      "step": 115900
    },
    {
      "epoch": 3.7104,
      "grad_norm": 0.3901163637638092,
      "learning_rate": 5.158528e-05,
      "loss": 2.0985,
      "step": 115950
    },
    {
      "epoch": 3.7119999999999997,
      "grad_norm": 0.38263139128685,
      "learning_rate": 5.152128e-05,
      "loss": 2.0956,
      "step": 116000
    },
    {
      "epoch": 3.7136,
      "grad_norm": 0.34847912192344666,
      "learning_rate": 5.1457280000000005e-05,
      "loss": 2.1272,
      "step": 116050
    },
    {
      "epoch": 3.7152,
      "grad_norm": 0.3943578600883484,
      "learning_rate": 5.139328e-05,
      "loss": 2.107,
      "step": 116100
    },
    {
      "epoch": 3.7168,
      "grad_norm": 0.3579658567905426,
      "learning_rate": 5.132928e-05,
      "loss": 2.0639,
      "step": 116150
    },
    {
      "epoch": 3.7184,
      "grad_norm": 0.46375763416290283,
      "learning_rate": 5.1265280000000004e-05,
      "loss": 2.0474,
      "step": 116200
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.41209858655929565,
      "learning_rate": 5.1201280000000006e-05,
      "loss": 2.1174,
      "step": 116250
    },
    {
      "epoch": 3.7216,
      "grad_norm": 0.37494298815727234,
      "learning_rate": 5.113728e-05,
      "loss": 2.1353,
      "step": 116300
    },
    {
      "epoch": 3.7232,
      "grad_norm": 0.4391652047634125,
      "learning_rate": 5.107328e-05,
      "loss": 2.1335,
      "step": 116350
    },
    {
      "epoch": 3.7248,
      "grad_norm": 0.34335508942604065,
      "learning_rate": 5.1009280000000005e-05,
      "loss": 2.1271,
      "step": 116400
    },
    {
      "epoch": 3.7264,
      "grad_norm": 0.35518816113471985,
      "learning_rate": 5.094528000000001e-05,
      "loss": 2.0916,
      "step": 116450
    },
    {
      "epoch": 3.7279999999999998,
      "grad_norm": 0.3417910635471344,
      "learning_rate": 5.0881279999999995e-05,
      "loss": 2.1288,
      "step": 116500
    },
    {
      "epoch": 3.7296,
      "grad_norm": 0.38319170475006104,
      "learning_rate": 5.081728e-05,
      "loss": 2.1453,
      "step": 116550
    },
    {
      "epoch": 3.7312,
      "grad_norm": 0.40209800004959106,
      "learning_rate": 5.0753280000000006e-05,
      "loss": 2.1383,
      "step": 116600
    },
    {
      "epoch": 3.7328,
      "grad_norm": 0.3408229649066925,
      "learning_rate": 5.068928000000001e-05,
      "loss": 2.1348,
      "step": 116650
    },
    {
      "epoch": 3.7344,
      "grad_norm": 0.4143504202365875,
      "learning_rate": 5.0625279999999997e-05,
      "loss": 2.055,
      "step": 116700
    },
    {
      "epoch": 3.7359999999999998,
      "grad_norm": 0.3976987898349762,
      "learning_rate": 5.056128e-05,
      "loss": 2.0863,
      "step": 116750
    },
    {
      "epoch": 3.7376,
      "grad_norm": 0.37582823634147644,
      "learning_rate": 5.049728e-05,
      "loss": 2.1269,
      "step": 116800
    },
    {
      "epoch": 3.7392,
      "grad_norm": 0.40154704451560974,
      "learning_rate": 5.043328e-05,
      "loss": 2.0907,
      "step": 116850
    },
    {
      "epoch": 3.7408,
      "grad_norm": 0.3501124680042267,
      "learning_rate": 5.0369280000000004e-05,
      "loss": 2.1414,
      "step": 116900
    },
    {
      "epoch": 3.7424,
      "grad_norm": 0.35159674286842346,
      "learning_rate": 5.030528e-05,
      "loss": 2.0727,
      "step": 116950
    },
    {
      "epoch": 3.7439999999999998,
      "grad_norm": 0.3874063193798065,
      "learning_rate": 5.024128e-05,
      "loss": 2.1194,
      "step": 117000
    },
    {
      "epoch": 3.7456,
      "grad_norm": 0.4346069395542145,
      "learning_rate": 5.0177280000000004e-05,
      "loss": 2.1722,
      "step": 117050
    },
    {
      "epoch": 3.7472,
      "grad_norm": 0.3336542248725891,
      "learning_rate": 5.0113280000000005e-05,
      "loss": 2.1391,
      "step": 117100
    },
    {
      "epoch": 3.7488,
      "grad_norm": 0.4120798110961914,
      "learning_rate": 5.004928e-05,
      "loss": 2.1216,
      "step": 117150
    },
    {
      "epoch": 3.7504,
      "grad_norm": 0.32856449484825134,
      "learning_rate": 4.998528e-05,
      "loss": 2.1351,
      "step": 117200
    },
    {
      "epoch": 3.752,
      "grad_norm": 0.36129188537597656,
      "learning_rate": 4.9921280000000005e-05,
      "loss": 2.1063,
      "step": 117250
    },
    {
      "epoch": 3.7536,
      "grad_norm": 0.3984931707382202,
      "learning_rate": 4.985728e-05,
      "loss": 2.127,
      "step": 117300
    },
    {
      "epoch": 3.7552,
      "grad_norm": 0.33244025707244873,
      "learning_rate": 4.979328e-05,
      "loss": 2.031,
      "step": 117350
    },
    {
      "epoch": 3.7568,
      "grad_norm": 0.3511715531349182,
      "learning_rate": 4.972928e-05,
      "loss": 2.0627,
      "step": 117400
    },
    {
      "epoch": 3.7584,
      "grad_norm": 0.3565308451652527,
      "learning_rate": 4.9665280000000006e-05,
      "loss": 2.0686,
      "step": 117450
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.33576294779777527,
      "learning_rate": 4.960128e-05,
      "loss": 2.1149,
      "step": 117500
    },
    {
      "epoch": 3.7616,
      "grad_norm": 0.3377724587917328,
      "learning_rate": 4.953728e-05,
      "loss": 2.087,
      "step": 117550
    },
    {
      "epoch": 3.7632,
      "grad_norm": 0.390329509973526,
      "learning_rate": 4.947328e-05,
      "loss": 2.1167,
      "step": 117600
    },
    {
      "epoch": 3.7648,
      "grad_norm": 0.31279420852661133,
      "learning_rate": 4.940928e-05,
      "loss": 2.0649,
      "step": 117650
    },
    {
      "epoch": 3.7664,
      "grad_norm": 0.33497706055641174,
      "learning_rate": 4.934528e-05,
      "loss": 2.0837,
      "step": 117700
    },
    {
      "epoch": 3.768,
      "grad_norm": 0.3957560062408447,
      "learning_rate": 4.9281280000000004e-05,
      "loss": 2.1456,
      "step": 117750
    },
    {
      "epoch": 3.7696,
      "grad_norm": 0.4199048578739166,
      "learning_rate": 4.9217280000000006e-05,
      "loss": 2.1459,
      "step": 117800
    },
    {
      "epoch": 3.7712,
      "grad_norm": 0.3852127194404602,
      "learning_rate": 4.915328e-05,
      "loss": 2.1122,
      "step": 117850
    },
    {
      "epoch": 3.7728,
      "grad_norm": 0.36549481749534607,
      "learning_rate": 4.908928e-05,
      "loss": 2.0638,
      "step": 117900
    },
    {
      "epoch": 3.7744,
      "grad_norm": 0.3864104151725769,
      "learning_rate": 4.902528e-05,
      "loss": 2.1097,
      "step": 117950
    },
    {
      "epoch": 3.776,
      "grad_norm": 0.3776848316192627,
      "learning_rate": 4.896128000000001e-05,
      "loss": 2.1213,
      "step": 118000
    },
    {
      "epoch": 3.7776,
      "grad_norm": 0.407855749130249,
      "learning_rate": 4.889728e-05,
      "loss": 2.091,
      "step": 118050
    },
    {
      "epoch": 3.7792,
      "grad_norm": 0.3584761619567871,
      "learning_rate": 4.8833280000000004e-05,
      "loss": 2.1379,
      "step": 118100
    },
    {
      "epoch": 3.7808,
      "grad_norm": 0.34961962699890137,
      "learning_rate": 4.876928e-05,
      "loss": 2.0718,
      "step": 118150
    },
    {
      "epoch": 3.7824,
      "grad_norm": 0.34243905544281006,
      "learning_rate": 4.870528e-05,
      "loss": 2.111,
      "step": 118200
    },
    {
      "epoch": 3.784,
      "grad_norm": 0.4413610100746155,
      "learning_rate": 4.864128e-05,
      "loss": 2.0801,
      "step": 118250
    },
    {
      "epoch": 3.7856,
      "grad_norm": 0.3150859475135803,
      "learning_rate": 4.8577280000000005e-05,
      "loss": 2.0991,
      "step": 118300
    },
    {
      "epoch": 3.7872,
      "grad_norm": 0.35000181198120117,
      "learning_rate": 4.851328e-05,
      "loss": 2.0656,
      "step": 118350
    },
    {
      "epoch": 3.7888,
      "grad_norm": 0.3229144215583801,
      "learning_rate": 4.844928e-05,
      "loss": 2.1224,
      "step": 118400
    },
    {
      "epoch": 3.7904,
      "grad_norm": 0.35255691409111023,
      "learning_rate": 4.8385280000000004e-05,
      "loss": 2.1222,
      "step": 118450
    },
    {
      "epoch": 3.792,
      "grad_norm": 0.3683301508426666,
      "learning_rate": 4.832128e-05,
      "loss": 2.1455,
      "step": 118500
    },
    {
      "epoch": 3.7936,
      "grad_norm": 0.34127262234687805,
      "learning_rate": 4.825728e-05,
      "loss": 2.1499,
      "step": 118550
    },
    {
      "epoch": 3.7952,
      "grad_norm": 0.3669538199901581,
      "learning_rate": 4.8193280000000004e-05,
      "loss": 2.0993,
      "step": 118600
    },
    {
      "epoch": 3.7968,
      "grad_norm": 0.39417093992233276,
      "learning_rate": 4.8129280000000006e-05,
      "loss": 2.0847,
      "step": 118650
    },
    {
      "epoch": 3.7984,
      "grad_norm": 0.3524940013885498,
      "learning_rate": 4.806528e-05,
      "loss": 2.1049,
      "step": 118700
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.37771162390708923,
      "learning_rate": 4.800128e-05,
      "loss": 2.1294,
      "step": 118750
    },
    {
      "epoch": 3.8016,
      "grad_norm": 0.35186588764190674,
      "learning_rate": 4.793728e-05,
      "loss": 2.0745,
      "step": 118800
    },
    {
      "epoch": 3.8032,
      "grad_norm": 0.3334243893623352,
      "learning_rate": 4.7873280000000007e-05,
      "loss": 2.1158,
      "step": 118850
    },
    {
      "epoch": 3.8048,
      "grad_norm": 0.3420223891735077,
      "learning_rate": 4.780928e-05,
      "loss": 2.083,
      "step": 118900
    },
    {
      "epoch": 3.8064,
      "grad_norm": 0.362661749124527,
      "learning_rate": 4.7745280000000004e-05,
      "loss": 2.1142,
      "step": 118950
    },
    {
      "epoch": 3.808,
      "grad_norm": 0.3200419843196869,
      "learning_rate": 4.768128e-05,
      "loss": 2.1172,
      "step": 119000
    },
    {
      "epoch": 3.8096,
      "grad_norm": 0.3260290026664734,
      "learning_rate": 4.761728e-05,
      "loss": 2.1242,
      "step": 119050
    },
    {
      "epoch": 3.8112,
      "grad_norm": 0.2846880257129669,
      "learning_rate": 4.755328e-05,
      "loss": 2.1244,
      "step": 119100
    },
    {
      "epoch": 3.8128,
      "grad_norm": 0.38847166299819946,
      "learning_rate": 4.7489280000000005e-05,
      "loss": 2.095,
      "step": 119150
    },
    {
      "epoch": 3.8144,
      "grad_norm": 0.3713676333427429,
      "learning_rate": 4.742528e-05,
      "loss": 2.088,
      "step": 119200
    },
    {
      "epoch": 3.816,
      "grad_norm": 0.39150720834732056,
      "learning_rate": 4.736128e-05,
      "loss": 2.0798,
      "step": 119250
    },
    {
      "epoch": 3.8176,
      "grad_norm": 0.35140058398246765,
      "learning_rate": 4.7297280000000004e-05,
      "loss": 2.1127,
      "step": 119300
    },
    {
      "epoch": 3.8192,
      "grad_norm": 0.3935219645500183,
      "learning_rate": 4.723328e-05,
      "loss": 2.0615,
      "step": 119350
    },
    {
      "epoch": 3.8208,
      "grad_norm": 0.3299645483493805,
      "learning_rate": 4.716928000000001e-05,
      "loss": 2.1185,
      "step": 119400
    },
    {
      "epoch": 3.8224,
      "grad_norm": 0.3684077560901642,
      "learning_rate": 4.710528e-05,
      "loss": 2.1156,
      "step": 119450
    },
    {
      "epoch": 3.824,
      "grad_norm": 0.3413955271244049,
      "learning_rate": 4.7041280000000005e-05,
      "loss": 2.1406,
      "step": 119500
    },
    {
      "epoch": 3.8256,
      "grad_norm": 0.35617727041244507,
      "learning_rate": 4.697728e-05,
      "loss": 2.1051,
      "step": 119550
    },
    {
      "epoch": 3.8272,
      "grad_norm": 0.45101767778396606,
      "learning_rate": 4.691328e-05,
      "loss": 2.1631,
      "step": 119600
    },
    {
      "epoch": 3.8288,
      "grad_norm": 0.39388763904571533,
      "learning_rate": 4.6849280000000004e-05,
      "loss": 2.1416,
      "step": 119650
    },
    {
      "epoch": 3.8304,
      "grad_norm": 0.42800867557525635,
      "learning_rate": 4.6785280000000006e-05,
      "loss": 2.0985,
      "step": 119700
    },
    {
      "epoch": 3.832,
      "grad_norm": 0.3363223075866699,
      "learning_rate": 4.672128e-05,
      "loss": 2.0093,
      "step": 119750
    },
    {
      "epoch": 3.8336,
      "grad_norm": 0.4118826687335968,
      "learning_rate": 4.665728e-05,
      "loss": 2.1119,
      "step": 119800
    },
    {
      "epoch": 3.8352,
      "grad_norm": 0.40243440866470337,
      "learning_rate": 4.659328e-05,
      "loss": 2.1579,
      "step": 119850
    },
    {
      "epoch": 3.8368,
      "grad_norm": 0.42677468061447144,
      "learning_rate": 4.652928e-05,
      "loss": 2.0988,
      "step": 119900
    },
    {
      "epoch": 3.8384,
      "grad_norm": 0.335818886756897,
      "learning_rate": 4.646528e-05,
      "loss": 2.1111,
      "step": 119950
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.34957030415534973,
      "learning_rate": 4.6401280000000004e-05,
      "loss": 2.0888,
      "step": 120000
    },
    {
      "epoch": 3.8416,
      "grad_norm": 0.34521302580833435,
      "learning_rate": 4.633728e-05,
      "loss": 2.08,
      "step": 120050
    },
    {
      "epoch": 3.8432,
      "grad_norm": 0.3290862739086151,
      "learning_rate": 4.627328e-05,
      "loss": 2.1054,
      "step": 120100
    },
    {
      "epoch": 3.8448,
      "grad_norm": 0.3715435862541199,
      "learning_rate": 4.6209280000000004e-05,
      "loss": 2.0796,
      "step": 120150
    },
    {
      "epoch": 3.8464,
      "grad_norm": 0.42685332894325256,
      "learning_rate": 4.614528e-05,
      "loss": 2.0944,
      "step": 120200
    },
    {
      "epoch": 3.848,
      "grad_norm": 0.3296779692173004,
      "learning_rate": 4.608128000000001e-05,
      "loss": 2.0684,
      "step": 120250
    },
    {
      "epoch": 3.8496,
      "grad_norm": 0.45862942934036255,
      "learning_rate": 4.601728e-05,
      "loss": 2.1023,
      "step": 120300
    },
    {
      "epoch": 3.8512,
      "grad_norm": 0.394021213054657,
      "learning_rate": 4.5953280000000005e-05,
      "loss": 2.1275,
      "step": 120350
    },
    {
      "epoch": 3.8528000000000002,
      "grad_norm": 0.4026244580745697,
      "learning_rate": 4.588928e-05,
      "loss": 2.1085,
      "step": 120400
    },
    {
      "epoch": 3.8544,
      "grad_norm": 0.33105844259262085,
      "learning_rate": 4.582528e-05,
      "loss": 2.0722,
      "step": 120450
    },
    {
      "epoch": 3.856,
      "grad_norm": 0.35055890679359436,
      "learning_rate": 4.5761280000000004e-05,
      "loss": 2.0491,
      "step": 120500
    },
    {
      "epoch": 3.8576,
      "grad_norm": 0.36037084460258484,
      "learning_rate": 4.5697280000000006e-05,
      "loss": 2.0954,
      "step": 120550
    },
    {
      "epoch": 3.8592,
      "grad_norm": 0.40442562103271484,
      "learning_rate": 4.563328e-05,
      "loss": 2.0872,
      "step": 120600
    },
    {
      "epoch": 3.8608000000000002,
      "grad_norm": 0.36468929052352905,
      "learning_rate": 4.556928e-05,
      "loss": 2.0881,
      "step": 120650
    },
    {
      "epoch": 3.8624,
      "grad_norm": 0.34677746891975403,
      "learning_rate": 4.550528e-05,
      "loss": 2.1421,
      "step": 120700
    },
    {
      "epoch": 3.864,
      "grad_norm": 0.4176674485206604,
      "learning_rate": 4.544128e-05,
      "loss": 2.112,
      "step": 120750
    },
    {
      "epoch": 3.8656,
      "grad_norm": 0.36421826481819153,
      "learning_rate": 4.537728e-05,
      "loss": 2.0685,
      "step": 120800
    },
    {
      "epoch": 3.8672,
      "grad_norm": 0.3564437925815582,
      "learning_rate": 4.5313280000000004e-05,
      "loss": 2.0135,
      "step": 120850
    },
    {
      "epoch": 3.8688000000000002,
      "grad_norm": 0.4273042380809784,
      "learning_rate": 4.524928e-05,
      "loss": 2.1512,
      "step": 120900
    },
    {
      "epoch": 3.8704,
      "grad_norm": 0.4338489770889282,
      "learning_rate": 4.518528e-05,
      "loss": 2.1178,
      "step": 120950
    },
    {
      "epoch": 3.872,
      "grad_norm": 0.33118176460266113,
      "learning_rate": 4.512128e-05,
      "loss": 2.0566,
      "step": 121000
    },
    {
      "epoch": 3.8736,
      "grad_norm": 0.3447149693965912,
      "learning_rate": 4.505728e-05,
      "loss": 2.1073,
      "step": 121050
    },
    {
      "epoch": 3.8752,
      "grad_norm": 0.3760698735713959,
      "learning_rate": 4.499328000000001e-05,
      "loss": 2.0802,
      "step": 121100
    },
    {
      "epoch": 3.8768000000000002,
      "grad_norm": 0.3481484055519104,
      "learning_rate": 4.492928e-05,
      "loss": 2.1582,
      "step": 121150
    },
    {
      "epoch": 3.8784,
      "grad_norm": 0.3605647683143616,
      "learning_rate": 4.4865280000000004e-05,
      "loss": 2.0658,
      "step": 121200
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.47796007990837097,
      "learning_rate": 4.480128e-05,
      "loss": 2.1077,
      "step": 121250
    },
    {
      "epoch": 3.8816,
      "grad_norm": 0.43975406885147095,
      "learning_rate": 4.473728e-05,
      "loss": 2.0473,
      "step": 121300
    },
    {
      "epoch": 3.8832,
      "grad_norm": 0.44714048504829407,
      "learning_rate": 4.467328e-05,
      "loss": 2.0873,
      "step": 121350
    },
    {
      "epoch": 3.8848000000000003,
      "grad_norm": 0.3203299045562744,
      "learning_rate": 4.4609280000000005e-05,
      "loss": 2.0781,
      "step": 121400
    },
    {
      "epoch": 3.8864,
      "grad_norm": 0.30022382736206055,
      "learning_rate": 4.454528e-05,
      "loss": 2.1495,
      "step": 121450
    },
    {
      "epoch": 3.888,
      "grad_norm": 0.3814852237701416,
      "learning_rate": 4.448128e-05,
      "loss": 2.1926,
      "step": 121500
    },
    {
      "epoch": 3.8895999999999997,
      "grad_norm": 0.40900754928588867,
      "learning_rate": 4.441728e-05,
      "loss": 2.1326,
      "step": 121550
    },
    {
      "epoch": 3.8912,
      "grad_norm": 0.36569416522979736,
      "learning_rate": 4.435328e-05,
      "loss": 2.1126,
      "step": 121600
    },
    {
      "epoch": 3.8928000000000003,
      "grad_norm": 0.4245396554470062,
      "learning_rate": 4.428928e-05,
      "loss": 2.1078,
      "step": 121650
    },
    {
      "epoch": 3.8944,
      "grad_norm": 0.3716447353363037,
      "learning_rate": 4.4225280000000004e-05,
      "loss": 2.146,
      "step": 121700
    },
    {
      "epoch": 3.896,
      "grad_norm": 0.3552591800689697,
      "learning_rate": 4.4161280000000006e-05,
      "loss": 2.1649,
      "step": 121750
    },
    {
      "epoch": 3.8975999999999997,
      "grad_norm": 0.3426215350627899,
      "learning_rate": 4.409728e-05,
      "loss": 2.1,
      "step": 121800
    },
    {
      "epoch": 3.8992,
      "grad_norm": 0.35599127411842346,
      "learning_rate": 4.403328e-05,
      "loss": 2.0939,
      "step": 121850
    },
    {
      "epoch": 3.9008000000000003,
      "grad_norm": 0.3167233467102051,
      "learning_rate": 4.3969280000000005e-05,
      "loss": 2.0922,
      "step": 121900
    },
    {
      "epoch": 3.9024,
      "grad_norm": 0.413310170173645,
      "learning_rate": 4.390528000000001e-05,
      "loss": 2.1096,
      "step": 121950
    },
    {
      "epoch": 3.904,
      "grad_norm": 0.36287006735801697,
      "learning_rate": 4.384128e-05,
      "loss": 2.1448,
      "step": 122000
    },
    {
      "epoch": 3.9055999999999997,
      "grad_norm": 0.38138410449028015,
      "learning_rate": 4.3777280000000004e-05,
      "loss": 2.0887,
      "step": 122050
    },
    {
      "epoch": 3.9072,
      "grad_norm": 0.34263426065444946,
      "learning_rate": 4.371328e-05,
      "loss": 2.149,
      "step": 122100
    },
    {
      "epoch": 3.9088000000000003,
      "grad_norm": 0.3294200897216797,
      "learning_rate": 4.364928e-05,
      "loss": 2.1149,
      "step": 122150
    },
    {
      "epoch": 3.9104,
      "grad_norm": 0.4073432385921478,
      "learning_rate": 4.358528e-05,
      "loss": 2.1121,
      "step": 122200
    },
    {
      "epoch": 3.912,
      "grad_norm": 0.39014968276023865,
      "learning_rate": 4.3521280000000005e-05,
      "loss": 2.141,
      "step": 122250
    },
    {
      "epoch": 3.9135999999999997,
      "grad_norm": 0.3610614240169525,
      "learning_rate": 4.345728e-05,
      "loss": 2.1753,
      "step": 122300
    },
    {
      "epoch": 3.9152,
      "grad_norm": 0.4132649004459381,
      "learning_rate": 4.339328e-05,
      "loss": 2.1231,
      "step": 122350
    },
    {
      "epoch": 3.9168,
      "grad_norm": 0.409161776304245,
      "learning_rate": 4.332928e-05,
      "loss": 2.1082,
      "step": 122400
    },
    {
      "epoch": 3.9184,
      "grad_norm": 0.3811430335044861,
      "learning_rate": 4.326528e-05,
      "loss": 2.1052,
      "step": 122450
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.40804651379585266,
      "learning_rate": 4.320128e-05,
      "loss": 2.0456,
      "step": 122500
    },
    {
      "epoch": 3.9215999999999998,
      "grad_norm": 0.37834811210632324,
      "learning_rate": 4.313728e-05,
      "loss": 2.1159,
      "step": 122550
    },
    {
      "epoch": 3.9232,
      "grad_norm": 0.31524592638015747,
      "learning_rate": 4.3073280000000005e-05,
      "loss": 2.1229,
      "step": 122600
    },
    {
      "epoch": 3.9248,
      "grad_norm": 0.36391910910606384,
      "learning_rate": 4.300928e-05,
      "loss": 2.0483,
      "step": 122650
    },
    {
      "epoch": 3.9264,
      "grad_norm": 0.3523925244808197,
      "learning_rate": 4.294528e-05,
      "loss": 2.1424,
      "step": 122700
    },
    {
      "epoch": 3.928,
      "grad_norm": 0.4256875813007355,
      "learning_rate": 4.2881280000000004e-05,
      "loss": 2.0671,
      "step": 122750
    },
    {
      "epoch": 3.9295999999999998,
      "grad_norm": 0.39397498965263367,
      "learning_rate": 4.2817280000000006e-05,
      "loss": 2.1626,
      "step": 122800
    },
    {
      "epoch": 3.9312,
      "grad_norm": 0.41131144762039185,
      "learning_rate": 4.275328e-05,
      "loss": 2.1116,
      "step": 122850
    },
    {
      "epoch": 3.9328,
      "grad_norm": 0.37971067428588867,
      "learning_rate": 4.268928e-05,
      "loss": 2.1251,
      "step": 122900
    },
    {
      "epoch": 3.9344,
      "grad_norm": 0.3884021043777466,
      "learning_rate": 4.262528e-05,
      "loss": 2.1362,
      "step": 122950
    },
    {
      "epoch": 3.936,
      "grad_norm": 0.37046247720718384,
      "learning_rate": 4.256128e-05,
      "loss": 2.1305,
      "step": 123000
    },
    {
      "epoch": 3.9375999999999998,
      "grad_norm": 0.3755524158477783,
      "learning_rate": 4.249728e-05,
      "loss": 2.1046,
      "step": 123050
    },
    {
      "epoch": 3.9392,
      "grad_norm": 0.374954491853714,
      "learning_rate": 4.2433280000000004e-05,
      "loss": 2.1163,
      "step": 123100
    },
    {
      "epoch": 3.9408,
      "grad_norm": 0.3997407853603363,
      "learning_rate": 4.236928e-05,
      "loss": 2.0969,
      "step": 123150
    },
    {
      "epoch": 3.9424,
      "grad_norm": 0.3431844115257263,
      "learning_rate": 4.230528e-05,
      "loss": 2.106,
      "step": 123200
    },
    {
      "epoch": 3.944,
      "grad_norm": 0.4068765342235565,
      "learning_rate": 4.224128e-05,
      "loss": 2.0106,
      "step": 123250
    },
    {
      "epoch": 3.9455999999999998,
      "grad_norm": 0.42029130458831787,
      "learning_rate": 4.2177280000000006e-05,
      "loss": 2.1259,
      "step": 123300
    },
    {
      "epoch": 3.9472,
      "grad_norm": 0.3378908634185791,
      "learning_rate": 4.211328e-05,
      "loss": 2.1067,
      "step": 123350
    },
    {
      "epoch": 3.9488,
      "grad_norm": 0.33919379115104675,
      "learning_rate": 4.204928e-05,
      "loss": 2.1289,
      "step": 123400
    },
    {
      "epoch": 3.9504,
      "grad_norm": 0.38457927107810974,
      "learning_rate": 4.1985280000000005e-05,
      "loss": 2.1323,
      "step": 123450
    },
    {
      "epoch": 3.952,
      "grad_norm": 0.36435723304748535,
      "learning_rate": 4.192128e-05,
      "loss": 2.058,
      "step": 123500
    },
    {
      "epoch": 3.9536,
      "grad_norm": 0.3995495140552521,
      "learning_rate": 4.185728e-05,
      "loss": 2.0537,
      "step": 123550
    },
    {
      "epoch": 3.9552,
      "grad_norm": 0.39069804549217224,
      "learning_rate": 4.1793280000000004e-05,
      "loss": 2.0907,
      "step": 123600
    },
    {
      "epoch": 3.9568,
      "grad_norm": 0.35275253653526306,
      "learning_rate": 4.1729280000000006e-05,
      "loss": 2.0962,
      "step": 123650
    },
    {
      "epoch": 3.9584,
      "grad_norm": 0.3724420368671417,
      "learning_rate": 4.166528e-05,
      "loss": 2.078,
      "step": 123700
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.4036894142627716,
      "learning_rate": 4.160128e-05,
      "loss": 2.125,
      "step": 123750
    },
    {
      "epoch": 3.9616,
      "grad_norm": 0.34292542934417725,
      "learning_rate": 4.153728e-05,
      "loss": 2.148,
      "step": 123800
    },
    {
      "epoch": 3.9632,
      "grad_norm": 0.33470574021339417,
      "learning_rate": 4.147328e-05,
      "loss": 2.1123,
      "step": 123850
    },
    {
      "epoch": 3.9648,
      "grad_norm": 0.40916338562965393,
      "learning_rate": 4.140928e-05,
      "loss": 2.1347,
      "step": 123900
    },
    {
      "epoch": 3.9664,
      "grad_norm": 0.42538559436798096,
      "learning_rate": 4.1345280000000004e-05,
      "loss": 2.0745,
      "step": 123950
    },
    {
      "epoch": 3.968,
      "grad_norm": 0.3913196921348572,
      "learning_rate": 4.128128e-05,
      "loss": 2.1153,
      "step": 124000
    },
    {
      "epoch": 3.9696,
      "grad_norm": 0.39006173610687256,
      "learning_rate": 4.121728e-05,
      "loss": 2.1687,
      "step": 124050
    },
    {
      "epoch": 3.9712,
      "grad_norm": 0.3851538300514221,
      "learning_rate": 4.1153279999999996e-05,
      "loss": 2.1045,
      "step": 124100
    },
    {
      "epoch": 3.9728,
      "grad_norm": 0.3360162675380707,
      "learning_rate": 4.1089280000000005e-05,
      "loss": 2.0675,
      "step": 124150
    },
    {
      "epoch": 3.9744,
      "grad_norm": 0.36238616704940796,
      "learning_rate": 4.102528e-05,
      "loss": 2.1028,
      "step": 124200
    },
    {
      "epoch": 3.976,
      "grad_norm": 0.4176686406135559,
      "learning_rate": 4.096128e-05,
      "loss": 2.0942,
      "step": 124250
    },
    {
      "epoch": 3.9776,
      "grad_norm": 0.3524235785007477,
      "learning_rate": 4.0897280000000004e-05,
      "loss": 2.1056,
      "step": 124300
    },
    {
      "epoch": 3.9792,
      "grad_norm": 0.39678460359573364,
      "learning_rate": 4.083328e-05,
      "loss": 2.1287,
      "step": 124350
    },
    {
      "epoch": 3.9808,
      "grad_norm": 0.3176577389240265,
      "learning_rate": 4.076928e-05,
      "loss": 2.0685,
      "step": 124400
    },
    {
      "epoch": 3.9824,
      "grad_norm": 0.3631635904312134,
      "learning_rate": 4.0705280000000003e-05,
      "loss": 2.1024,
      "step": 124450
    },
    {
      "epoch": 3.984,
      "grad_norm": 0.437716007232666,
      "learning_rate": 4.0641280000000005e-05,
      "loss": 2.117,
      "step": 124500
    },
    {
      "epoch": 3.9856,
      "grad_norm": 0.3665523827075958,
      "learning_rate": 4.057728e-05,
      "loss": 2.1635,
      "step": 124550
    },
    {
      "epoch": 3.9872,
      "grad_norm": 0.32446354627609253,
      "learning_rate": 4.051328e-05,
      "loss": 2.0976,
      "step": 124600
    },
    {
      "epoch": 3.9888,
      "grad_norm": 0.4068751335144043,
      "learning_rate": 4.044928e-05,
      "loss": 2.0987,
      "step": 124650
    },
    {
      "epoch": 3.9904,
      "grad_norm": 0.39754319190979004,
      "learning_rate": 4.0385280000000006e-05,
      "loss": 2.1533,
      "step": 124700
    },
    {
      "epoch": 3.992,
      "grad_norm": 0.34355899691581726,
      "learning_rate": 4.032128e-05,
      "loss": 2.1214,
      "step": 124750
    },
    {
      "epoch": 3.9936,
      "grad_norm": 0.3393750488758087,
      "learning_rate": 4.0257280000000004e-05,
      "loss": 2.0683,
      "step": 124800
    },
    {
      "epoch": 3.9952,
      "grad_norm": 0.4775655269622803,
      "learning_rate": 4.019328e-05,
      "loss": 2.1298,
      "step": 124850
    },
    {
      "epoch": 3.9968,
      "grad_norm": 0.4181312620639801,
      "learning_rate": 4.012928e-05,
      "loss": 2.0804,
      "step": 124900
    },
    {
      "epoch": 3.9984,
      "grad_norm": 0.3666530251502991,
      "learning_rate": 4.006528e-05,
      "loss": 2.1353,
      "step": 124950
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3513745665550232,
      "learning_rate": 4.0001280000000005e-05,
      "loss": 2.1375,
      "step": 125000
    },
    {
      "epoch": 4.0016,
      "grad_norm": 0.3797484338283539,
      "learning_rate": 3.993728e-05,
      "loss": 2.1036,
      "step": 125050
    },
    {
      "epoch": 4.0032,
      "grad_norm": 0.3941069543361664,
      "learning_rate": 3.987328e-05,
      "loss": 2.0989,
      "step": 125100
    },
    {
      "epoch": 4.0048,
      "grad_norm": 0.32521355152130127,
      "learning_rate": 3.9809280000000004e-05,
      "loss": 2.1011,
      "step": 125150
    },
    {
      "epoch": 4.0064,
      "grad_norm": 0.3605230450630188,
      "learning_rate": 3.974528e-05,
      "loss": 2.1146,
      "step": 125200
    },
    {
      "epoch": 4.008,
      "grad_norm": 0.33727961778640747,
      "learning_rate": 3.968128e-05,
      "loss": 2.1061,
      "step": 125250
    },
    {
      "epoch": 4.0096,
      "grad_norm": 0.35795071721076965,
      "learning_rate": 3.961728e-05,
      "loss": 2.0427,
      "step": 125300
    },
    {
      "epoch": 4.0112,
      "grad_norm": 0.4740176498889923,
      "learning_rate": 3.9553280000000005e-05,
      "loss": 2.1441,
      "step": 125350
    },
    {
      "epoch": 4.0128,
      "grad_norm": 0.3414247930049896,
      "learning_rate": 3.948928e-05,
      "loss": 2.1269,
      "step": 125400
    },
    {
      "epoch": 4.0144,
      "grad_norm": 0.4152988791465759,
      "learning_rate": 3.942528e-05,
      "loss": 2.0922,
      "step": 125450
    },
    {
      "epoch": 4.016,
      "grad_norm": 0.37102052569389343,
      "learning_rate": 3.936128e-05,
      "loss": 2.1224,
      "step": 125500
    },
    {
      "epoch": 4.0176,
      "grad_norm": 0.4412829279899597,
      "learning_rate": 3.9297280000000006e-05,
      "loss": 2.1091,
      "step": 125550
    },
    {
      "epoch": 4.0192,
      "grad_norm": 0.3410639762878418,
      "learning_rate": 3.923328e-05,
      "loss": 2.0629,
      "step": 125600
    },
    {
      "epoch": 4.0208,
      "grad_norm": 0.37270742654800415,
      "learning_rate": 3.916928e-05,
      "loss": 2.1276,
      "step": 125650
    },
    {
      "epoch": 4.0224,
      "grad_norm": 0.3942762017250061,
      "learning_rate": 3.910528e-05,
      "loss": 2.0348,
      "step": 125700
    },
    {
      "epoch": 4.024,
      "grad_norm": 0.41579321026802063,
      "learning_rate": 3.904128e-05,
      "loss": 2.0328,
      "step": 125750
    },
    {
      "epoch": 4.0256,
      "grad_norm": 0.3869241774082184,
      "learning_rate": 3.897728e-05,
      "loss": 2.1454,
      "step": 125800
    },
    {
      "epoch": 4.0272,
      "grad_norm": 0.3463455140590668,
      "learning_rate": 3.8913280000000004e-05,
      "loss": 2.0946,
      "step": 125850
    },
    {
      "epoch": 4.0288,
      "grad_norm": 0.38342994451522827,
      "learning_rate": 3.8849280000000006e-05,
      "loss": 2.0113,
      "step": 125900
    },
    {
      "epoch": 4.0304,
      "grad_norm": 0.41059616208076477,
      "learning_rate": 3.878528e-05,
      "loss": 2.0725,
      "step": 125950
    },
    {
      "epoch": 4.032,
      "grad_norm": 0.43635234236717224,
      "learning_rate": 3.8721280000000003e-05,
      "loss": 2.0917,
      "step": 126000
    },
    {
      "epoch": 4.0336,
      "grad_norm": 0.34325358271598816,
      "learning_rate": 3.865728e-05,
      "loss": 2.089,
      "step": 126050
    },
    {
      "epoch": 4.0352,
      "grad_norm": 0.3784380853176117,
      "learning_rate": 3.859328e-05,
      "loss": 2.086,
      "step": 126100
    },
    {
      "epoch": 4.0368,
      "grad_norm": 0.3742009103298187,
      "learning_rate": 3.852928e-05,
      "loss": 2.1213,
      "step": 126150
    },
    {
      "epoch": 4.0384,
      "grad_norm": 0.37011682987213135,
      "learning_rate": 3.8465280000000005e-05,
      "loss": 2.0829,
      "step": 126200
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.3564310073852539,
      "learning_rate": 3.840128e-05,
      "loss": 2.1559,
      "step": 126250
    },
    {
      "epoch": 4.0416,
      "grad_norm": 0.35270369052886963,
      "learning_rate": 3.833728e-05,
      "loss": 2.0868,
      "step": 126300
    },
    {
      "epoch": 4.0432,
      "grad_norm": 0.3328641951084137,
      "learning_rate": 3.827328e-05,
      "loss": 2.07,
      "step": 126350
    },
    {
      "epoch": 4.0448,
      "grad_norm": 0.3233639895915985,
      "learning_rate": 3.8209280000000006e-05,
      "loss": 2.1243,
      "step": 126400
    },
    {
      "epoch": 4.0464,
      "grad_norm": 0.42825791239738464,
      "learning_rate": 3.814528e-05,
      "loss": 2.1259,
      "step": 126450
    },
    {
      "epoch": 4.048,
      "grad_norm": 0.3624231815338135,
      "learning_rate": 3.808128e-05,
      "loss": 2.1103,
      "step": 126500
    },
    {
      "epoch": 4.0496,
      "grad_norm": 0.41130530834198,
      "learning_rate": 3.801728e-05,
      "loss": 2.0864,
      "step": 126550
    },
    {
      "epoch": 4.0512,
      "grad_norm": 0.3603678047657013,
      "learning_rate": 3.795328e-05,
      "loss": 2.0865,
      "step": 126600
    },
    {
      "epoch": 4.0528,
      "grad_norm": 0.32995352149009705,
      "learning_rate": 3.788928e-05,
      "loss": 2.0954,
      "step": 126650
    },
    {
      "epoch": 4.0544,
      "grad_norm": 0.4932243227958679,
      "learning_rate": 3.7825280000000004e-05,
      "loss": 2.1128,
      "step": 126700
    },
    {
      "epoch": 4.056,
      "grad_norm": 0.34232214093208313,
      "learning_rate": 3.7761280000000006e-05,
      "loss": 2.0906,
      "step": 126750
    },
    {
      "epoch": 4.0576,
      "grad_norm": 0.36454954743385315,
      "learning_rate": 3.769728e-05,
      "loss": 2.0538,
      "step": 126800
    },
    {
      "epoch": 4.0592,
      "grad_norm": 0.4797191619873047,
      "learning_rate": 3.763328e-05,
      "loss": 2.1672,
      "step": 126850
    },
    {
      "epoch": 4.0608,
      "grad_norm": 0.40761202573776245,
      "learning_rate": 3.756928e-05,
      "loss": 2.1171,
      "step": 126900
    },
    {
      "epoch": 4.0624,
      "grad_norm": 0.42086657881736755,
      "learning_rate": 3.750528000000001e-05,
      "loss": 2.1326,
      "step": 126950
    },
    {
      "epoch": 4.064,
      "grad_norm": 0.36401528120040894,
      "learning_rate": 3.744128e-05,
      "loss": 2.1348,
      "step": 127000
    },
    {
      "epoch": 4.0656,
      "grad_norm": 0.40559524297714233,
      "learning_rate": 3.7377280000000004e-05,
      "loss": 2.1124,
      "step": 127050
    },
    {
      "epoch": 4.0672,
      "grad_norm": 0.3807092308998108,
      "learning_rate": 3.731328e-05,
      "loss": 2.0412,
      "step": 127100
    },
    {
      "epoch": 4.0688,
      "grad_norm": 0.39110174775123596,
      "learning_rate": 3.724928e-05,
      "loss": 2.0952,
      "step": 127150
    },
    {
      "epoch": 4.0704,
      "grad_norm": 0.3977724015712738,
      "learning_rate": 3.718528e-05,
      "loss": 2.0217,
      "step": 127200
    },
    {
      "epoch": 4.072,
      "grad_norm": 0.35298022627830505,
      "learning_rate": 3.7121280000000005e-05,
      "loss": 2.1123,
      "step": 127250
    },
    {
      "epoch": 4.0736,
      "grad_norm": 0.35207676887512207,
      "learning_rate": 3.705728e-05,
      "loss": 2.0384,
      "step": 127300
    },
    {
      "epoch": 4.0752,
      "grad_norm": 0.3379555940628052,
      "learning_rate": 3.699328e-05,
      "loss": 2.1084,
      "step": 127350
    },
    {
      "epoch": 4.0768,
      "grad_norm": 0.4017028510570526,
      "learning_rate": 3.692928e-05,
      "loss": 2.12,
      "step": 127400
    },
    {
      "epoch": 4.0784,
      "grad_norm": 0.32807713747024536,
      "learning_rate": 3.686528e-05,
      "loss": 2.0436,
      "step": 127450
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.4087972939014435,
      "learning_rate": 3.680128e-05,
      "loss": 2.1276,
      "step": 127500
    },
    {
      "epoch": 4.0816,
      "grad_norm": 0.34056317806243896,
      "learning_rate": 3.6737280000000003e-05,
      "loss": 2.1018,
      "step": 127550
    },
    {
      "epoch": 4.0832,
      "grad_norm": 0.37540799379348755,
      "learning_rate": 3.6673280000000005e-05,
      "loss": 2.0885,
      "step": 127600
    },
    {
      "epoch": 4.0848,
      "grad_norm": 0.40964025259017944,
      "learning_rate": 3.660928e-05,
      "loss": 2.0808,
      "step": 127650
    },
    {
      "epoch": 4.0864,
      "grad_norm": 0.35516294836997986,
      "learning_rate": 3.654528e-05,
      "loss": 2.0926,
      "step": 127700
    },
    {
      "epoch": 4.088,
      "grad_norm": 0.34493935108184814,
      "learning_rate": 3.648128e-05,
      "loss": 2.1473,
      "step": 127750
    },
    {
      "epoch": 4.0896,
      "grad_norm": 0.3615589439868927,
      "learning_rate": 3.6417280000000007e-05,
      "loss": 2.0994,
      "step": 127800
    },
    {
      "epoch": 4.0912,
      "grad_norm": 0.3377697765827179,
      "learning_rate": 3.635328e-05,
      "loss": 2.1115,
      "step": 127850
    },
    {
      "epoch": 4.0928,
      "grad_norm": 0.37304580211639404,
      "learning_rate": 3.6289280000000004e-05,
      "loss": 2.0988,
      "step": 127900
    },
    {
      "epoch": 4.0944,
      "grad_norm": 0.3627803325653076,
      "learning_rate": 3.622528e-05,
      "loss": 2.0526,
      "step": 127950
    },
    {
      "epoch": 4.096,
      "grad_norm": 0.4004039168357849,
      "learning_rate": 3.616128e-05,
      "loss": 2.1504,
      "step": 128000
    },
    {
      "epoch": 4.0976,
      "grad_norm": 0.3786354959011078,
      "learning_rate": 3.609728e-05,
      "loss": 2.1515,
      "step": 128050
    },
    {
      "epoch": 4.0992,
      "grad_norm": 0.37185537815093994,
      "learning_rate": 3.6033280000000005e-05,
      "loss": 2.1214,
      "step": 128100
    },
    {
      "epoch": 4.1008,
      "grad_norm": 0.3311251997947693,
      "learning_rate": 3.596928e-05,
      "loss": 2.1165,
      "step": 128150
    },
    {
      "epoch": 4.1024,
      "grad_norm": 0.33572059869766235,
      "learning_rate": 3.590528e-05,
      "loss": 2.0932,
      "step": 128200
    },
    {
      "epoch": 4.104,
      "grad_norm": 0.4114832878112793,
      "learning_rate": 3.584128e-05,
      "loss": 2.051,
      "step": 128250
    },
    {
      "epoch": 4.1056,
      "grad_norm": 0.32762694358825684,
      "learning_rate": 3.577728e-05,
      "loss": 2.1163,
      "step": 128300
    },
    {
      "epoch": 4.1072,
      "grad_norm": 0.43160757422447205,
      "learning_rate": 3.571328e-05,
      "loss": 2.0942,
      "step": 128350
    },
    {
      "epoch": 4.1088,
      "grad_norm": 0.4424211382865906,
      "learning_rate": 3.564928e-05,
      "loss": 2.0763,
      "step": 128400
    },
    {
      "epoch": 4.1104,
      "grad_norm": 0.3366330862045288,
      "learning_rate": 3.5585280000000005e-05,
      "loss": 2.1133,
      "step": 128450
    },
    {
      "epoch": 4.112,
      "grad_norm": 0.36401641368865967,
      "learning_rate": 3.552128e-05,
      "loss": 2.0885,
      "step": 128500
    },
    {
      "epoch": 4.1136,
      "grad_norm": 0.3087520897388458,
      "learning_rate": 3.545728e-05,
      "loss": 2.0982,
      "step": 128550
    },
    {
      "epoch": 4.1152,
      "grad_norm": 0.3540191054344177,
      "learning_rate": 3.5393280000000004e-05,
      "loss": 2.0781,
      "step": 128600
    },
    {
      "epoch": 4.1168,
      "grad_norm": 0.3962857723236084,
      "learning_rate": 3.5329280000000006e-05,
      "loss": 2.1122,
      "step": 128650
    },
    {
      "epoch": 4.1184,
      "grad_norm": 0.36639708280563354,
      "learning_rate": 3.526528e-05,
      "loss": 2.081,
      "step": 128700
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.3688650131225586,
      "learning_rate": 3.520128e-05,
      "loss": 2.1464,
      "step": 128750
    },
    {
      "epoch": 4.1216,
      "grad_norm": 0.31396135687828064,
      "learning_rate": 3.513728e-05,
      "loss": 2.0809,
      "step": 128800
    },
    {
      "epoch": 4.1232,
      "grad_norm": 0.3705427944660187,
      "learning_rate": 3.507328e-05,
      "loss": 2.1344,
      "step": 128850
    },
    {
      "epoch": 4.1248,
      "grad_norm": 0.4118066132068634,
      "learning_rate": 3.500928e-05,
      "loss": 2.07,
      "step": 128900
    },
    {
      "epoch": 4.1264,
      "grad_norm": 0.4301087558269501,
      "learning_rate": 3.4945280000000004e-05,
      "loss": 2.0495,
      "step": 128950
    },
    {
      "epoch": 4.128,
      "grad_norm": 0.33978042006492615,
      "learning_rate": 3.488128e-05,
      "loss": 2.0731,
      "step": 129000
    },
    {
      "epoch": 4.1296,
      "grad_norm": 0.4399387538433075,
      "learning_rate": 3.481728e-05,
      "loss": 2.16,
      "step": 129050
    },
    {
      "epoch": 4.1312,
      "grad_norm": 0.3581962585449219,
      "learning_rate": 3.475328e-05,
      "loss": 2.1013,
      "step": 129100
    },
    {
      "epoch": 4.1328,
      "grad_norm": 0.38839206099510193,
      "learning_rate": 3.468928e-05,
      "loss": 2.0889,
      "step": 129150
    },
    {
      "epoch": 4.1344,
      "grad_norm": 0.3736785054206848,
      "learning_rate": 3.462528000000001e-05,
      "loss": 2.0876,
      "step": 129200
    },
    {
      "epoch": 4.136,
      "grad_norm": 0.34324926137924194,
      "learning_rate": 3.456128e-05,
      "loss": 2.0121,
      "step": 129250
    },
    {
      "epoch": 4.1376,
      "grad_norm": 0.37784847617149353,
      "learning_rate": 3.4497280000000005e-05,
      "loss": 2.1011,
      "step": 129300
    },
    {
      "epoch": 4.1392,
      "grad_norm": 0.4412723481655121,
      "learning_rate": 3.443328e-05,
      "loss": 2.1654,
      "step": 129350
    },
    {
      "epoch": 4.1408,
      "grad_norm": 0.42012372612953186,
      "learning_rate": 3.436928e-05,
      "loss": 2.1379,
      "step": 129400
    },
    {
      "epoch": 4.1424,
      "grad_norm": 0.39786940813064575,
      "learning_rate": 3.4305280000000004e-05,
      "loss": 2.1094,
      "step": 129450
    },
    {
      "epoch": 4.144,
      "grad_norm": 0.3834756910800934,
      "learning_rate": 3.4241280000000006e-05,
      "loss": 2.1542,
      "step": 129500
    },
    {
      "epoch": 4.1456,
      "grad_norm": 0.40937498211860657,
      "learning_rate": 3.417728e-05,
      "loss": 2.0856,
      "step": 129550
    },
    {
      "epoch": 4.1472,
      "grad_norm": 0.39082011580467224,
      "learning_rate": 3.411328e-05,
      "loss": 2.0578,
      "step": 129600
    },
    {
      "epoch": 4.1488,
      "grad_norm": 0.4391021132469177,
      "learning_rate": 3.404928e-05,
      "loss": 2.1739,
      "step": 129650
    },
    {
      "epoch": 4.1504,
      "grad_norm": 0.38806548714637756,
      "learning_rate": 3.398528e-05,
      "loss": 2.0619,
      "step": 129700
    },
    {
      "epoch": 4.152,
      "grad_norm": 0.39419764280319214,
      "learning_rate": 3.392128e-05,
      "loss": 2.0608,
      "step": 129750
    },
    {
      "epoch": 4.1536,
      "grad_norm": 0.39132222533226013,
      "learning_rate": 3.3857280000000004e-05,
      "loss": 2.0684,
      "step": 129800
    },
    {
      "epoch": 4.1552,
      "grad_norm": 0.36796924471855164,
      "learning_rate": 3.379328e-05,
      "loss": 2.1216,
      "step": 129850
    },
    {
      "epoch": 4.1568,
      "grad_norm": 0.3614649772644043,
      "learning_rate": 3.372928e-05,
      "loss": 2.0377,
      "step": 129900
    },
    {
      "epoch": 4.1584,
      "grad_norm": 0.39338576793670654,
      "learning_rate": 3.3665279999999996e-05,
      "loss": 2.031,
      "step": 129950
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.3664598762989044,
      "learning_rate": 3.3601280000000005e-05,
      "loss": 2.0738,
      "step": 130000
    },
    {
      "epoch": 4.1616,
      "grad_norm": 0.37781473994255066,
      "learning_rate": 3.353728000000001e-05,
      "loss": 2.0464,
      "step": 130050
    },
    {
      "epoch": 4.1632,
      "grad_norm": 0.41336172819137573,
      "learning_rate": 3.347328e-05,
      "loss": 2.0944,
      "step": 130100
    },
    {
      "epoch": 4.1648,
      "grad_norm": 0.33121997117996216,
      "learning_rate": 3.3409280000000004e-05,
      "loss": 2.1205,
      "step": 130150
    },
    {
      "epoch": 4.1664,
      "grad_norm": 0.32381200790405273,
      "learning_rate": 3.334528e-05,
      "loss": 2.0904,
      "step": 130200
    },
    {
      "epoch": 4.168,
      "grad_norm": 0.36397841572761536,
      "learning_rate": 3.328128e-05,
      "loss": 2.0473,
      "step": 130250
    },
    {
      "epoch": 4.1696,
      "grad_norm": 0.3512641489505768,
      "learning_rate": 3.321728e-05,
      "loss": 2.1319,
      "step": 130300
    },
    {
      "epoch": 4.1712,
      "grad_norm": 0.3929009437561035,
      "learning_rate": 3.3153280000000005e-05,
      "loss": 2.0785,
      "step": 130350
    },
    {
      "epoch": 4.1728,
      "grad_norm": 0.35898473858833313,
      "learning_rate": 3.308928e-05,
      "loss": 2.1124,
      "step": 130400
    },
    {
      "epoch": 4.1744,
      "grad_norm": 0.4102723002433777,
      "learning_rate": 3.302528e-05,
      "loss": 2.0759,
      "step": 130450
    },
    {
      "epoch": 4.176,
      "grad_norm": 0.35254836082458496,
      "learning_rate": 3.296128e-05,
      "loss": 2.1131,
      "step": 130500
    },
    {
      "epoch": 4.1776,
      "grad_norm": 0.3837352693080902,
      "learning_rate": 3.289728e-05,
      "loss": 2.0848,
      "step": 130550
    },
    {
      "epoch": 4.1792,
      "grad_norm": 0.41116806864738464,
      "learning_rate": 3.283328e-05,
      "loss": 2.0912,
      "step": 130600
    },
    {
      "epoch": 4.1808,
      "grad_norm": 0.39762958884239197,
      "learning_rate": 3.2769280000000003e-05,
      "loss": 2.1184,
      "step": 130650
    },
    {
      "epoch": 4.1824,
      "grad_norm": 0.39087462425231934,
      "learning_rate": 3.270528e-05,
      "loss": 2.0356,
      "step": 130700
    },
    {
      "epoch": 4.184,
      "grad_norm": 0.5482416749000549,
      "learning_rate": 3.264128e-05,
      "loss": 2.1012,
      "step": 130750
    },
    {
      "epoch": 4.1856,
      "grad_norm": 0.45261630415916443,
      "learning_rate": 3.2577279999999996e-05,
      "loss": 2.1379,
      "step": 130800
    },
    {
      "epoch": 4.1872,
      "grad_norm": 0.31843024492263794,
      "learning_rate": 3.2513280000000005e-05,
      "loss": 2.1465,
      "step": 130850
    },
    {
      "epoch": 4.1888,
      "grad_norm": 0.3372776210308075,
      "learning_rate": 3.2449280000000007e-05,
      "loss": 2.1019,
      "step": 130900
    },
    {
      "epoch": 4.1904,
      "grad_norm": 0.3690265715122223,
      "learning_rate": 3.238528e-05,
      "loss": 2.072,
      "step": 130950
    },
    {
      "epoch": 4.192,
      "grad_norm": 0.4035485088825226,
      "learning_rate": 3.2321280000000004e-05,
      "loss": 2.1011,
      "step": 131000
    },
    {
      "epoch": 4.1936,
      "grad_norm": 0.363081157207489,
      "learning_rate": 3.225728e-05,
      "loss": 2.0934,
      "step": 131050
    },
    {
      "epoch": 4.1952,
      "grad_norm": 0.4359787106513977,
      "learning_rate": 3.219328e-05,
      "loss": 2.1684,
      "step": 131100
    },
    {
      "epoch": 4.1968,
      "grad_norm": 0.3994208872318268,
      "learning_rate": 3.212928e-05,
      "loss": 2.0542,
      "step": 131150
    },
    {
      "epoch": 4.1984,
      "grad_norm": 0.3409535884857178,
      "learning_rate": 3.2065280000000005e-05,
      "loss": 2.0447,
      "step": 131200
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.36362868547439575,
      "learning_rate": 3.200128e-05,
      "loss": 2.1069,
      "step": 131250
    },
    {
      "epoch": 4.2016,
      "grad_norm": 0.3460848331451416,
      "learning_rate": 3.193728e-05,
      "loss": 2.1298,
      "step": 131300
    },
    {
      "epoch": 4.2032,
      "grad_norm": 0.3433930277824402,
      "learning_rate": 3.187328e-05,
      "loss": 2.0898,
      "step": 131350
    },
    {
      "epoch": 4.2048,
      "grad_norm": 0.4060680866241455,
      "learning_rate": 3.180928e-05,
      "loss": 2.1033,
      "step": 131400
    },
    {
      "epoch": 4.2064,
      "grad_norm": 0.39679422974586487,
      "learning_rate": 3.174528e-05,
      "loss": 2.1283,
      "step": 131450
    },
    {
      "epoch": 4.208,
      "grad_norm": 0.3476475775241852,
      "learning_rate": 3.168128e-05,
      "loss": 2.0722,
      "step": 131500
    },
    {
      "epoch": 4.2096,
      "grad_norm": 0.3815290033817291,
      "learning_rate": 3.161728e-05,
      "loss": 2.1097,
      "step": 131550
    },
    {
      "epoch": 4.2112,
      "grad_norm": 0.3835894465446472,
      "learning_rate": 3.155328e-05,
      "loss": 2.1135,
      "step": 131600
    },
    {
      "epoch": 4.2128,
      "grad_norm": 0.3638584017753601,
      "learning_rate": 3.1489279999999995e-05,
      "loss": 2.0639,
      "step": 131650
    },
    {
      "epoch": 4.2144,
      "grad_norm": 0.47937634587287903,
      "learning_rate": 3.1425280000000004e-05,
      "loss": 2.1204,
      "step": 131700
    },
    {
      "epoch": 4.216,
      "grad_norm": 0.3636530637741089,
      "learning_rate": 3.1361280000000006e-05,
      "loss": 2.0926,
      "step": 131750
    },
    {
      "epoch": 4.2176,
      "grad_norm": 0.36682334542274475,
      "learning_rate": 3.129728e-05,
      "loss": 2.0835,
      "step": 131800
    },
    {
      "epoch": 4.2192,
      "grad_norm": 0.3223874270915985,
      "learning_rate": 3.123328e-05,
      "loss": 2.0793,
      "step": 131850
    },
    {
      "epoch": 4.2208,
      "grad_norm": 0.39933037757873535,
      "learning_rate": 3.116928e-05,
      "loss": 2.0981,
      "step": 131900
    },
    {
      "epoch": 4.2224,
      "grad_norm": 0.43108996748924255,
      "learning_rate": 3.110528e-05,
      "loss": 2.0577,
      "step": 131950
    },
    {
      "epoch": 4.224,
      "grad_norm": 0.3849378526210785,
      "learning_rate": 3.104128e-05,
      "loss": 2.1279,
      "step": 132000
    },
    {
      "epoch": 4.2256,
      "grad_norm": 0.36593741178512573,
      "learning_rate": 3.0977280000000004e-05,
      "loss": 2.0811,
      "step": 132050
    },
    {
      "epoch": 4.2272,
      "grad_norm": 0.4092837870121002,
      "learning_rate": 3.091328e-05,
      "loss": 2.0932,
      "step": 132100
    },
    {
      "epoch": 4.2288,
      "grad_norm": 0.3487499952316284,
      "learning_rate": 3.084928e-05,
      "loss": 2.0773,
      "step": 132150
    },
    {
      "epoch": 4.2304,
      "grad_norm": 0.40599846839904785,
      "learning_rate": 3.078528e-05,
      "loss": 2.0916,
      "step": 132200
    },
    {
      "epoch": 4.232,
      "grad_norm": 0.43898165225982666,
      "learning_rate": 3.0721280000000005e-05,
      "loss": 2.1231,
      "step": 132250
    },
    {
      "epoch": 4.2336,
      "grad_norm": 0.40548205375671387,
      "learning_rate": 3.065728e-05,
      "loss": 2.1195,
      "step": 132300
    },
    {
      "epoch": 4.2352,
      "grad_norm": 0.3647225499153137,
      "learning_rate": 3.059328e-05,
      "loss": 2.1117,
      "step": 132350
    },
    {
      "epoch": 4.2368,
      "grad_norm": 0.3483661711215973,
      "learning_rate": 3.052928e-05,
      "loss": 2.0481,
      "step": 132400
    },
    {
      "epoch": 4.2384,
      "grad_norm": 0.34610217809677124,
      "learning_rate": 3.0465280000000003e-05,
      "loss": 2.0331,
      "step": 132450
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.3918801546096802,
      "learning_rate": 3.0401280000000005e-05,
      "loss": 2.1219,
      "step": 132500
    },
    {
      "epoch": 4.2416,
      "grad_norm": 0.3959169387817383,
      "learning_rate": 3.033728e-05,
      "loss": 2.0498,
      "step": 132550
    },
    {
      "epoch": 4.2432,
      "grad_norm": 0.41327252984046936,
      "learning_rate": 3.0273280000000002e-05,
      "loss": 2.1235,
      "step": 132600
    },
    {
      "epoch": 4.2448,
      "grad_norm": 0.372805655002594,
      "learning_rate": 3.020928e-05,
      "loss": 2.0767,
      "step": 132650
    },
    {
      "epoch": 4.2464,
      "grad_norm": 0.3629625737667084,
      "learning_rate": 3.0145280000000003e-05,
      "loss": 2.0888,
      "step": 132700
    },
    {
      "epoch": 4.248,
      "grad_norm": 0.3941238820552826,
      "learning_rate": 3.008128e-05,
      "loss": 2.1383,
      "step": 132750
    },
    {
      "epoch": 4.2496,
      "grad_norm": 0.37663519382476807,
      "learning_rate": 3.0017280000000003e-05,
      "loss": 2.0145,
      "step": 132800
    },
    {
      "epoch": 4.2512,
      "grad_norm": 0.38937073945999146,
      "learning_rate": 2.995328e-05,
      "loss": 2.1016,
      "step": 132850
    },
    {
      "epoch": 4.2528,
      "grad_norm": 0.3928777873516083,
      "learning_rate": 2.9889280000000004e-05,
      "loss": 2.1283,
      "step": 132900
    },
    {
      "epoch": 4.2544,
      "grad_norm": 0.42805591225624084,
      "learning_rate": 2.982528e-05,
      "loss": 2.1326,
      "step": 132950
    },
    {
      "epoch": 4.256,
      "grad_norm": 0.39873141050338745,
      "learning_rate": 2.976128e-05,
      "loss": 2.073,
      "step": 133000
    },
    {
      "epoch": 4.2576,
      "grad_norm": 0.342356413602829,
      "learning_rate": 2.969728e-05,
      "loss": 2.0588,
      "step": 133050
    },
    {
      "epoch": 4.2592,
      "grad_norm": 0.33927881717681885,
      "learning_rate": 2.963328e-05,
      "loss": 2.0944,
      "step": 133100
    },
    {
      "epoch": 4.2608,
      "grad_norm": 0.33893176913261414,
      "learning_rate": 2.956928e-05,
      "loss": 2.1044,
      "step": 133150
    },
    {
      "epoch": 4.2624,
      "grad_norm": 0.388339638710022,
      "learning_rate": 2.9505280000000002e-05,
      "loss": 2.1007,
      "step": 133200
    },
    {
      "epoch": 4.264,
      "grad_norm": 0.47814813256263733,
      "learning_rate": 2.9441279999999997e-05,
      "loss": 2.1092,
      "step": 133250
    },
    {
      "epoch": 4.2656,
      "grad_norm": 0.4073133170604706,
      "learning_rate": 2.9377280000000003e-05,
      "loss": 2.1064,
      "step": 133300
    },
    {
      "epoch": 4.2672,
      "grad_norm": 0.33114469051361084,
      "learning_rate": 2.9313280000000005e-05,
      "loss": 2.1208,
      "step": 133350
    },
    {
      "epoch": 4.2688,
      "grad_norm": 0.37765371799468994,
      "learning_rate": 2.924928e-05,
      "loss": 2.0312,
      "step": 133400
    },
    {
      "epoch": 4.2704,
      "grad_norm": 0.3537796139717102,
      "learning_rate": 2.9185280000000005e-05,
      "loss": 2.111,
      "step": 133450
    },
    {
      "epoch": 4.272,
      "grad_norm": 0.3755190074443817,
      "learning_rate": 2.912128e-05,
      "loss": 2.1398,
      "step": 133500
    },
    {
      "epoch": 4.2736,
      "grad_norm": 0.3879975974559784,
      "learning_rate": 2.9057280000000002e-05,
      "loss": 2.1209,
      "step": 133550
    },
    {
      "epoch": 4.2752,
      "grad_norm": 0.3664942979812622,
      "learning_rate": 2.899328e-05,
      "loss": 2.1656,
      "step": 133600
    },
    {
      "epoch": 4.2768,
      "grad_norm": 0.39460593461990356,
      "learning_rate": 2.8929280000000003e-05,
      "loss": 2.0806,
      "step": 133650
    },
    {
      "epoch": 4.2783999999999995,
      "grad_norm": 0.5037698149681091,
      "learning_rate": 2.886528e-05,
      "loss": 2.1487,
      "step": 133700
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.3373240828514099,
      "learning_rate": 2.8801280000000004e-05,
      "loss": 2.1153,
      "step": 133750
    },
    {
      "epoch": 4.2816,
      "grad_norm": 0.39340105652809143,
      "learning_rate": 2.873728e-05,
      "loss": 2.0824,
      "step": 133800
    },
    {
      "epoch": 4.2832,
      "grad_norm": 0.3907405436038971,
      "learning_rate": 2.867328e-05,
      "loss": 2.0862,
      "step": 133850
    },
    {
      "epoch": 4.2848,
      "grad_norm": 0.32346558570861816,
      "learning_rate": 2.860928e-05,
      "loss": 2.1062,
      "step": 133900
    },
    {
      "epoch": 4.2864,
      "grad_norm": 0.34425118565559387,
      "learning_rate": 2.854528e-05,
      "loss": 2.1608,
      "step": 133950
    },
    {
      "epoch": 4.288,
      "grad_norm": 0.35514265298843384,
      "learning_rate": 2.848128e-05,
      "loss": 2.1118,
      "step": 134000
    },
    {
      "epoch": 4.2896,
      "grad_norm": 0.3775647282600403,
      "learning_rate": 2.8417280000000002e-05,
      "loss": 2.1041,
      "step": 134050
    },
    {
      "epoch": 4.2912,
      "grad_norm": 0.36146071553230286,
      "learning_rate": 2.835328e-05,
      "loss": 2.0337,
      "step": 134100
    },
    {
      "epoch": 4.2928,
      "grad_norm": 0.4102574288845062,
      "learning_rate": 2.8289280000000002e-05,
      "loss": 2.1164,
      "step": 134150
    },
    {
      "epoch": 4.2943999999999996,
      "grad_norm": 0.37727388739585876,
      "learning_rate": 2.8225280000000004e-05,
      "loss": 2.1221,
      "step": 134200
    },
    {
      "epoch": 4.296,
      "grad_norm": 0.4101206958293915,
      "learning_rate": 2.816128e-05,
      "loss": 2.0881,
      "step": 134250
    },
    {
      "epoch": 4.2976,
      "grad_norm": 0.3726644217967987,
      "learning_rate": 2.8097280000000005e-05,
      "loss": 2.1071,
      "step": 134300
    },
    {
      "epoch": 4.2992,
      "grad_norm": 0.36305737495422363,
      "learning_rate": 2.803328e-05,
      "loss": 2.0914,
      "step": 134350
    },
    {
      "epoch": 4.3008,
      "grad_norm": 0.3992850184440613,
      "learning_rate": 2.7969280000000002e-05,
      "loss": 2.0629,
      "step": 134400
    },
    {
      "epoch": 4.3024000000000004,
      "grad_norm": 0.4080921411514282,
      "learning_rate": 2.790528e-05,
      "loss": 2.0909,
      "step": 134450
    },
    {
      "epoch": 4.304,
      "grad_norm": 0.36621716618537903,
      "learning_rate": 2.7841280000000003e-05,
      "loss": 2.1486,
      "step": 134500
    },
    {
      "epoch": 4.3056,
      "grad_norm": 0.3928946256637573,
      "learning_rate": 2.777728e-05,
      "loss": 2.141,
      "step": 134550
    },
    {
      "epoch": 4.3072,
      "grad_norm": 0.39754369854927063,
      "learning_rate": 2.7713280000000003e-05,
      "loss": 2.1142,
      "step": 134600
    },
    {
      "epoch": 4.3088,
      "grad_norm": 0.37020397186279297,
      "learning_rate": 2.7649279999999998e-05,
      "loss": 2.0533,
      "step": 134650
    },
    {
      "epoch": 4.3104,
      "grad_norm": 0.3769780099391937,
      "learning_rate": 2.7585280000000004e-05,
      "loss": 2.1399,
      "step": 134700
    },
    {
      "epoch": 4.312,
      "grad_norm": 0.37399765849113464,
      "learning_rate": 2.752128e-05,
      "loss": 2.099,
      "step": 134750
    },
    {
      "epoch": 4.3136,
      "grad_norm": 0.39552241563796997,
      "learning_rate": 2.745728e-05,
      "loss": 2.0571,
      "step": 134800
    },
    {
      "epoch": 4.3152,
      "grad_norm": 0.32387271523475647,
      "learning_rate": 2.739328e-05,
      "loss": 2.1223,
      "step": 134850
    },
    {
      "epoch": 4.3168,
      "grad_norm": 0.4159812033176422,
      "learning_rate": 2.732928e-05,
      "loss": 2.1265,
      "step": 134900
    },
    {
      "epoch": 4.3184000000000005,
      "grad_norm": 0.3888240456581116,
      "learning_rate": 2.726528e-05,
      "loss": 2.1215,
      "step": 134950
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.33820515871047974,
      "learning_rate": 2.7201280000000002e-05,
      "loss": 2.0625,
      "step": 135000
    },
    {
      "epoch": 4.3216,
      "grad_norm": 0.3826308846473694,
      "learning_rate": 2.7137280000000004e-05,
      "loss": 2.0788,
      "step": 135050
    },
    {
      "epoch": 4.3232,
      "grad_norm": 0.36888378858566284,
      "learning_rate": 2.7073280000000002e-05,
      "loss": 2.0039,
      "step": 135100
    },
    {
      "epoch": 4.3248,
      "grad_norm": 0.3668529987335205,
      "learning_rate": 2.7009280000000004e-05,
      "loss": 2.1018,
      "step": 135150
    },
    {
      "epoch": 4.3264,
      "grad_norm": 0.41115859150886536,
      "learning_rate": 2.694528e-05,
      "loss": 2.0439,
      "step": 135200
    },
    {
      "epoch": 4.328,
      "grad_norm": 0.34390074014663696,
      "learning_rate": 2.688128e-05,
      "loss": 2.0709,
      "step": 135250
    },
    {
      "epoch": 4.3296,
      "grad_norm": 0.461785227060318,
      "learning_rate": 2.681728e-05,
      "loss": 2.0634,
      "step": 135300
    },
    {
      "epoch": 4.3312,
      "grad_norm": 0.423942893743515,
      "learning_rate": 2.6753280000000002e-05,
      "loss": 2.1254,
      "step": 135350
    },
    {
      "epoch": 4.3328,
      "grad_norm": 0.47674810886383057,
      "learning_rate": 2.668928e-05,
      "loss": 2.0957,
      "step": 135400
    },
    {
      "epoch": 4.3344,
      "grad_norm": 0.38722363114356995,
      "learning_rate": 2.6625280000000003e-05,
      "loss": 2.0777,
      "step": 135450
    },
    {
      "epoch": 4.336,
      "grad_norm": 0.3894144296646118,
      "learning_rate": 2.6561279999999998e-05,
      "loss": 2.0893,
      "step": 135500
    },
    {
      "epoch": 4.3376,
      "grad_norm": 0.42877885699272156,
      "learning_rate": 2.6497280000000003e-05,
      "loss": 2.1755,
      "step": 135550
    },
    {
      "epoch": 4.3392,
      "grad_norm": 0.3620620667934418,
      "learning_rate": 2.643328e-05,
      "loss": 2.067,
      "step": 135600
    },
    {
      "epoch": 4.3408,
      "grad_norm": 0.4183170199394226,
      "learning_rate": 2.636928e-05,
      "loss": 2.126,
      "step": 135650
    },
    {
      "epoch": 4.3424,
      "grad_norm": 0.3529358506202698,
      "learning_rate": 2.630528e-05,
      "loss": 2.0623,
      "step": 135700
    },
    {
      "epoch": 4.344,
      "grad_norm": 0.3949272334575653,
      "learning_rate": 2.624128e-05,
      "loss": 2.0916,
      "step": 135750
    },
    {
      "epoch": 4.3456,
      "grad_norm": 0.46547219157218933,
      "learning_rate": 2.6177280000000003e-05,
      "loss": 2.1041,
      "step": 135800
    },
    {
      "epoch": 4.3472,
      "grad_norm": 0.37861865758895874,
      "learning_rate": 2.611328e-05,
      "loss": 2.0612,
      "step": 135850
    },
    {
      "epoch": 4.3488,
      "grad_norm": 0.4429985582828522,
      "learning_rate": 2.6049280000000003e-05,
      "loss": 2.0605,
      "step": 135900
    },
    {
      "epoch": 4.3504,
      "grad_norm": 0.38566285371780396,
      "learning_rate": 2.5985280000000002e-05,
      "loss": 2.1027,
      "step": 135950
    },
    {
      "epoch": 4.352,
      "grad_norm": 0.3546348810195923,
      "learning_rate": 2.5921280000000004e-05,
      "loss": 2.0848,
      "step": 136000
    },
    {
      "epoch": 4.3536,
      "grad_norm": 0.3609105050563812,
      "learning_rate": 2.585728e-05,
      "loss": 2.1216,
      "step": 136050
    },
    {
      "epoch": 4.3552,
      "grad_norm": 0.33747348189353943,
      "learning_rate": 2.5793280000000005e-05,
      "loss": 2.0759,
      "step": 136100
    },
    {
      "epoch": 4.3568,
      "grad_norm": 0.44450244307518005,
      "learning_rate": 2.572928e-05,
      "loss": 2.0874,
      "step": 136150
    },
    {
      "epoch": 4.3584,
      "grad_norm": 0.40465661883354187,
      "learning_rate": 2.5665280000000002e-05,
      "loss": 2.1038,
      "step": 136200
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.41287603974342346,
      "learning_rate": 2.560128e-05,
      "loss": 2.0847,
      "step": 136250
    },
    {
      "epoch": 4.3616,
      "grad_norm": 0.3867560029029846,
      "learning_rate": 2.5537280000000002e-05,
      "loss": 2.0688,
      "step": 136300
    },
    {
      "epoch": 4.3632,
      "grad_norm": 0.4087866246700287,
      "learning_rate": 2.547328e-05,
      "loss": 2.0884,
      "step": 136350
    },
    {
      "epoch": 4.3648,
      "grad_norm": 0.4549921751022339,
      "learning_rate": 2.5409280000000003e-05,
      "loss": 2.1159,
      "step": 136400
    },
    {
      "epoch": 4.3664,
      "grad_norm": 0.523513913154602,
      "learning_rate": 2.5345279999999998e-05,
      "loss": 2.1009,
      "step": 136450
    },
    {
      "epoch": 4.368,
      "grad_norm": 0.3996484577655792,
      "learning_rate": 2.528128e-05,
      "loss": 2.075,
      "step": 136500
    },
    {
      "epoch": 4.3696,
      "grad_norm": 0.3082025945186615,
      "learning_rate": 2.521728e-05,
      "loss": 2.0276,
      "step": 136550
    },
    {
      "epoch": 4.3712,
      "grad_norm": 0.3516307473182678,
      "learning_rate": 2.515328e-05,
      "loss": 2.1333,
      "step": 136600
    },
    {
      "epoch": 4.3728,
      "grad_norm": 0.40676313638687134,
      "learning_rate": 2.5089280000000002e-05,
      "loss": 2.1039,
      "step": 136650
    },
    {
      "epoch": 4.3744,
      "grad_norm": 0.43843919038772583,
      "learning_rate": 2.502528e-05,
      "loss": 2.0509,
      "step": 136700
    },
    {
      "epoch": 4.376,
      "grad_norm": 0.3915567398071289,
      "learning_rate": 2.496128e-05,
      "loss": 2.0662,
      "step": 136750
    },
    {
      "epoch": 4.3776,
      "grad_norm": 0.3863021433353424,
      "learning_rate": 2.489728e-05,
      "loss": 2.087,
      "step": 136800
    },
    {
      "epoch": 4.3792,
      "grad_norm": 0.42941102385520935,
      "learning_rate": 2.483328e-05,
      "loss": 2.0314,
      "step": 136850
    },
    {
      "epoch": 4.3808,
      "grad_norm": 0.3445943295955658,
      "learning_rate": 2.476928e-05,
      "loss": 2.0872,
      "step": 136900
    },
    {
      "epoch": 4.3824,
      "grad_norm": 0.4453015625476837,
      "learning_rate": 2.470528e-05,
      "loss": 2.1109,
      "step": 136950
    },
    {
      "epoch": 4.384,
      "grad_norm": 0.37581294775009155,
      "learning_rate": 2.464128e-05,
      "loss": 2.0878,
      "step": 137000
    },
    {
      "epoch": 4.3856,
      "grad_norm": 0.3575437664985657,
      "learning_rate": 2.457728e-05,
      "loss": 2.0555,
      "step": 137050
    },
    {
      "epoch": 4.3872,
      "grad_norm": 0.39593812823295593,
      "learning_rate": 2.4513280000000003e-05,
      "loss": 2.0785,
      "step": 137100
    },
    {
      "epoch": 4.3888,
      "grad_norm": 0.38204845786094666,
      "learning_rate": 2.4449280000000002e-05,
      "loss": 2.0687,
      "step": 137150
    },
    {
      "epoch": 4.3904,
      "grad_norm": 0.3757748603820801,
      "learning_rate": 2.438528e-05,
      "loss": 2.1518,
      "step": 137200
    },
    {
      "epoch": 4.392,
      "grad_norm": 0.3552485704421997,
      "learning_rate": 2.4321280000000002e-05,
      "loss": 2.0734,
      "step": 137250
    },
    {
      "epoch": 4.3936,
      "grad_norm": 0.4546829164028168,
      "learning_rate": 2.425728e-05,
      "loss": 2.1399,
      "step": 137300
    },
    {
      "epoch": 4.3952,
      "grad_norm": 0.3726300299167633,
      "learning_rate": 2.4193280000000003e-05,
      "loss": 2.1326,
      "step": 137350
    },
    {
      "epoch": 4.3968,
      "grad_norm": 0.36810213327407837,
      "learning_rate": 2.412928e-05,
      "loss": 2.0788,
      "step": 137400
    },
    {
      "epoch": 4.3984,
      "grad_norm": 0.447274386882782,
      "learning_rate": 2.406528e-05,
      "loss": 2.1136,
      "step": 137450
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.44040176272392273,
      "learning_rate": 2.4001280000000002e-05,
      "loss": 2.0952,
      "step": 137500
    },
    {
      "epoch": 4.4016,
      "grad_norm": 0.3450717031955719,
      "learning_rate": 2.393728e-05,
      "loss": 2.1249,
      "step": 137550
    },
    {
      "epoch": 4.4032,
      "grad_norm": 0.37630796432495117,
      "learning_rate": 2.387328e-05,
      "loss": 2.132,
      "step": 137600
    },
    {
      "epoch": 4.4048,
      "grad_norm": 0.42234665155410767,
      "learning_rate": 2.380928e-05,
      "loss": 2.1205,
      "step": 137650
    },
    {
      "epoch": 4.4064,
      "grad_norm": 0.3864864706993103,
      "learning_rate": 2.374528e-05,
      "loss": 2.1103,
      "step": 137700
    },
    {
      "epoch": 4.408,
      "grad_norm": 0.38850125670433044,
      "learning_rate": 2.3681280000000002e-05,
      "loss": 2.0677,
      "step": 137750
    },
    {
      "epoch": 4.4096,
      "grad_norm": 0.37215712666511536,
      "learning_rate": 2.361728e-05,
      "loss": 2.1251,
      "step": 137800
    },
    {
      "epoch": 4.4112,
      "grad_norm": 0.449459433555603,
      "learning_rate": 2.355328e-05,
      "loss": 2.1076,
      "step": 137850
    },
    {
      "epoch": 4.4128,
      "grad_norm": 0.40376242995262146,
      "learning_rate": 2.348928e-05,
      "loss": 2.0816,
      "step": 137900
    },
    {
      "epoch": 4.4144,
      "grad_norm": 0.3600336015224457,
      "learning_rate": 2.3425280000000003e-05,
      "loss": 2.0933,
      "step": 137950
    },
    {
      "epoch": 4.416,
      "grad_norm": 0.3844045400619507,
      "learning_rate": 2.336128e-05,
      "loss": 2.0657,
      "step": 138000
    },
    {
      "epoch": 4.4176,
      "grad_norm": 0.38930290937423706,
      "learning_rate": 2.3297280000000003e-05,
      "loss": 2.1783,
      "step": 138050
    },
    {
      "epoch": 4.4192,
      "grad_norm": 0.35383284091949463,
      "learning_rate": 2.3233280000000002e-05,
      "loss": 2.1519,
      "step": 138100
    },
    {
      "epoch": 4.4208,
      "grad_norm": 0.38111215829849243,
      "learning_rate": 2.316928e-05,
      "loss": 2.0797,
      "step": 138150
    },
    {
      "epoch": 4.4224,
      "grad_norm": 0.2975751757621765,
      "learning_rate": 2.3105280000000003e-05,
      "loss": 2.1376,
      "step": 138200
    },
    {
      "epoch": 4.424,
      "grad_norm": 0.3863421380519867,
      "learning_rate": 2.304128e-05,
      "loss": 2.0676,
      "step": 138250
    },
    {
      "epoch": 4.4256,
      "grad_norm": 0.37053847312927246,
      "learning_rate": 2.297728e-05,
      "loss": 2.1022,
      "step": 138300
    },
    {
      "epoch": 4.4272,
      "grad_norm": 0.3281143009662628,
      "learning_rate": 2.291328e-05,
      "loss": 2.1289,
      "step": 138350
    },
    {
      "epoch": 4.4288,
      "grad_norm": 0.4142560064792633,
      "learning_rate": 2.284928e-05,
      "loss": 2.0824,
      "step": 138400
    },
    {
      "epoch": 4.4304,
      "grad_norm": 0.35729649662971497,
      "learning_rate": 2.2785280000000002e-05,
      "loss": 2.0603,
      "step": 138450
    },
    {
      "epoch": 4.432,
      "grad_norm": 0.356612890958786,
      "learning_rate": 2.272128e-05,
      "loss": 2.1077,
      "step": 138500
    },
    {
      "epoch": 4.4336,
      "grad_norm": 0.35548606514930725,
      "learning_rate": 2.265728e-05,
      "loss": 2.1058,
      "step": 138550
    },
    {
      "epoch": 4.4352,
      "grad_norm": 0.3898485004901886,
      "learning_rate": 2.259328e-05,
      "loss": 2.0972,
      "step": 138600
    },
    {
      "epoch": 4.4368,
      "grad_norm": 0.5096248388290405,
      "learning_rate": 2.252928e-05,
      "loss": 2.133,
      "step": 138650
    },
    {
      "epoch": 4.4384,
      "grad_norm": 0.3714653551578522,
      "learning_rate": 2.2465280000000002e-05,
      "loss": 2.0899,
      "step": 138700
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.43318691849708557,
      "learning_rate": 2.2401280000000004e-05,
      "loss": 2.0815,
      "step": 138750
    },
    {
      "epoch": 4.4416,
      "grad_norm": 0.39978259801864624,
      "learning_rate": 2.2337280000000002e-05,
      "loss": 2.1246,
      "step": 138800
    },
    {
      "epoch": 4.4432,
      "grad_norm": 0.34415164589881897,
      "learning_rate": 2.227328e-05,
      "loss": 2.0623,
      "step": 138850
    },
    {
      "epoch": 4.4448,
      "grad_norm": 0.41731831431388855,
      "learning_rate": 2.2209280000000003e-05,
      "loss": 2.0616,
      "step": 138900
    },
    {
      "epoch": 4.4464,
      "grad_norm": 0.38406965136528015,
      "learning_rate": 2.214528e-05,
      "loss": 2.1005,
      "step": 138950
    },
    {
      "epoch": 4.448,
      "grad_norm": 0.4315001368522644,
      "learning_rate": 2.208128e-05,
      "loss": 2.0694,
      "step": 139000
    },
    {
      "epoch": 4.4496,
      "grad_norm": 0.3945596218109131,
      "learning_rate": 2.2017280000000002e-05,
      "loss": 2.0566,
      "step": 139050
    },
    {
      "epoch": 4.4512,
      "grad_norm": 0.38671913743019104,
      "learning_rate": 2.195328e-05,
      "loss": 2.0785,
      "step": 139100
    },
    {
      "epoch": 4.4528,
      "grad_norm": 0.42435988783836365,
      "learning_rate": 2.188928e-05,
      "loss": 2.1095,
      "step": 139150
    },
    {
      "epoch": 4.4544,
      "grad_norm": 0.36526891589164734,
      "learning_rate": 2.182528e-05,
      "loss": 2.0872,
      "step": 139200
    },
    {
      "epoch": 4.456,
      "grad_norm": 0.5049155354499817,
      "learning_rate": 2.176128e-05,
      "loss": 2.0341,
      "step": 139250
    },
    {
      "epoch": 4.4576,
      "grad_norm": 0.3538753092288971,
      "learning_rate": 2.1697280000000002e-05,
      "loss": 2.1176,
      "step": 139300
    },
    {
      "epoch": 4.4592,
      "grad_norm": 0.5143476128578186,
      "learning_rate": 2.163328e-05,
      "loss": 2.0435,
      "step": 139350
    },
    {
      "epoch": 4.4608,
      "grad_norm": 0.3704947233200073,
      "learning_rate": 2.156928e-05,
      "loss": 2.0684,
      "step": 139400
    },
    {
      "epoch": 4.4624,
      "grad_norm": 0.34636208415031433,
      "learning_rate": 2.150528e-05,
      "loss": 2.0782,
      "step": 139450
    },
    {
      "epoch": 4.464,
      "grad_norm": 0.38162726163864136,
      "learning_rate": 2.144128e-05,
      "loss": 2.0659,
      "step": 139500
    },
    {
      "epoch": 4.4656,
      "grad_norm": 0.40968725085258484,
      "learning_rate": 2.137728e-05,
      "loss": 2.0696,
      "step": 139550
    },
    {
      "epoch": 4.4672,
      "grad_norm": 0.37967726588249207,
      "learning_rate": 2.1313280000000003e-05,
      "loss": 2.0854,
      "step": 139600
    },
    {
      "epoch": 4.4688,
      "grad_norm": 0.4577089250087738,
      "learning_rate": 2.1249280000000002e-05,
      "loss": 2.097,
      "step": 139650
    },
    {
      "epoch": 4.4704,
      "grad_norm": 0.3473486602306366,
      "learning_rate": 2.118528e-05,
      "loss": 2.1092,
      "step": 139700
    },
    {
      "epoch": 4.4719999999999995,
      "grad_norm": 0.41858169436454773,
      "learning_rate": 2.1121280000000003e-05,
      "loss": 2.1164,
      "step": 139750
    },
    {
      "epoch": 4.4736,
      "grad_norm": 0.41168907284736633,
      "learning_rate": 2.105728e-05,
      "loss": 2.0849,
      "step": 139800
    },
    {
      "epoch": 4.4752,
      "grad_norm": 0.4213279187679291,
      "learning_rate": 2.099328e-05,
      "loss": 2.1326,
      "step": 139850
    },
    {
      "epoch": 4.4768,
      "grad_norm": 0.37191763520240784,
      "learning_rate": 2.092928e-05,
      "loss": 2.0894,
      "step": 139900
    },
    {
      "epoch": 4.4784,
      "grad_norm": 0.43290024995803833,
      "learning_rate": 2.086528e-05,
      "loss": 2.1111,
      "step": 139950
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.37597811222076416,
      "learning_rate": 2.0801280000000002e-05,
      "loss": 2.1089,
      "step": 140000
    },
    {
      "epoch": 4.4816,
      "grad_norm": 0.368875652551651,
      "learning_rate": 2.073728e-05,
      "loss": 2.1693,
      "step": 140050
    },
    {
      "epoch": 4.4832,
      "grad_norm": 0.38287606835365295,
      "learning_rate": 2.067328e-05,
      "loss": 2.13,
      "step": 140100
    },
    {
      "epoch": 4.4848,
      "grad_norm": 0.3062952756881714,
      "learning_rate": 2.060928e-05,
      "loss": 2.1356,
      "step": 140150
    },
    {
      "epoch": 4.4864,
      "grad_norm": 0.3426189422607422,
      "learning_rate": 2.054528e-05,
      "loss": 2.1889,
      "step": 140200
    },
    {
      "epoch": 4.4879999999999995,
      "grad_norm": 0.428275465965271,
      "learning_rate": 2.048128e-05,
      "loss": 2.0433,
      "step": 140250
    },
    {
      "epoch": 4.4896,
      "grad_norm": 0.47383639216423035,
      "learning_rate": 2.041728e-05,
      "loss": 2.0617,
      "step": 140300
    },
    {
      "epoch": 4.4912,
      "grad_norm": 0.32406526803970337,
      "learning_rate": 2.0353280000000002e-05,
      "loss": 2.018,
      "step": 140350
    },
    {
      "epoch": 4.4928,
      "grad_norm": 0.3892606496810913,
      "learning_rate": 2.028928e-05,
      "loss": 2.0808,
      "step": 140400
    },
    {
      "epoch": 4.4944,
      "grad_norm": 0.39778968691825867,
      "learning_rate": 2.0225280000000003e-05,
      "loss": 2.1335,
      "step": 140450
    },
    {
      "epoch": 4.496,
      "grad_norm": 0.38651618361473083,
      "learning_rate": 2.016128e-05,
      "loss": 2.0986,
      "step": 140500
    },
    {
      "epoch": 4.4976,
      "grad_norm": 0.40096208453178406,
      "learning_rate": 2.009728e-05,
      "loss": 2.0979,
      "step": 140550
    },
    {
      "epoch": 4.4992,
      "grad_norm": 0.3678864538669586,
      "learning_rate": 2.0033280000000002e-05,
      "loss": 2.1535,
      "step": 140600
    },
    {
      "epoch": 4.5008,
      "grad_norm": 0.3584246039390564,
      "learning_rate": 1.996928e-05,
      "loss": 2.0826,
      "step": 140650
    },
    {
      "epoch": 4.5024,
      "grad_norm": 0.4739370346069336,
      "learning_rate": 1.9905280000000003e-05,
      "loss": 2.1274,
      "step": 140700
    },
    {
      "epoch": 4.504,
      "grad_norm": 0.349147766828537,
      "learning_rate": 1.984128e-05,
      "loss": 2.1464,
      "step": 140750
    },
    {
      "epoch": 4.5056,
      "grad_norm": 0.40738505125045776,
      "learning_rate": 1.977728e-05,
      "loss": 2.0504,
      "step": 140800
    },
    {
      "epoch": 4.5072,
      "grad_norm": 0.37093955278396606,
      "learning_rate": 1.9713280000000002e-05,
      "loss": 2.1546,
      "step": 140850
    },
    {
      "epoch": 4.5088,
      "grad_norm": 0.3515453636646271,
      "learning_rate": 1.964928e-05,
      "loss": 2.0593,
      "step": 140900
    },
    {
      "epoch": 4.5104,
      "grad_norm": 0.3586220443248749,
      "learning_rate": 1.958528e-05,
      "loss": 2.078,
      "step": 140950
    },
    {
      "epoch": 4.5120000000000005,
      "grad_norm": 0.47185805439949036,
      "learning_rate": 1.952128e-05,
      "loss": 2.0921,
      "step": 141000
    },
    {
      "epoch": 4.5136,
      "grad_norm": 0.331046462059021,
      "learning_rate": 1.945728e-05,
      "loss": 2.0931,
      "step": 141050
    },
    {
      "epoch": 4.5152,
      "grad_norm": 0.3248782753944397,
      "learning_rate": 1.939328e-05,
      "loss": 2.1606,
      "step": 141100
    },
    {
      "epoch": 4.5168,
      "grad_norm": 0.43501541018486023,
      "learning_rate": 1.932928e-05,
      "loss": 2.1042,
      "step": 141150
    },
    {
      "epoch": 4.5184,
      "grad_norm": 0.397054523229599,
      "learning_rate": 1.9265280000000002e-05,
      "loss": 2.097,
      "step": 141200
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.40422388911247253,
      "learning_rate": 1.920128e-05,
      "loss": 2.0948,
      "step": 141250
    },
    {
      "epoch": 4.5216,
      "grad_norm": 0.3851156532764435,
      "learning_rate": 1.9137280000000003e-05,
      "loss": 2.1144,
      "step": 141300
    },
    {
      "epoch": 4.5232,
      "grad_norm": 0.3980642557144165,
      "learning_rate": 1.907328e-05,
      "loss": 2.1197,
      "step": 141350
    },
    {
      "epoch": 4.5248,
      "grad_norm": 0.3812979757785797,
      "learning_rate": 1.9009280000000003e-05,
      "loss": 2.1297,
      "step": 141400
    },
    {
      "epoch": 4.5264,
      "grad_norm": 0.4471363127231598,
      "learning_rate": 1.894528e-05,
      "loss": 2.0937,
      "step": 141450
    },
    {
      "epoch": 4.5280000000000005,
      "grad_norm": 0.4013664126396179,
      "learning_rate": 1.888128e-05,
      "loss": 2.0716,
      "step": 141500
    },
    {
      "epoch": 4.5296,
      "grad_norm": 0.47169843316078186,
      "learning_rate": 1.8817280000000002e-05,
      "loss": 2.0994,
      "step": 141550
    },
    {
      "epoch": 4.5312,
      "grad_norm": 0.40088364481925964,
      "learning_rate": 1.875328e-05,
      "loss": 2.065,
      "step": 141600
    },
    {
      "epoch": 4.5328,
      "grad_norm": 0.47110575437545776,
      "learning_rate": 1.868928e-05,
      "loss": 2.0961,
      "step": 141650
    },
    {
      "epoch": 4.5344,
      "grad_norm": 0.4278927743434906,
      "learning_rate": 1.862528e-05,
      "loss": 2.1438,
      "step": 141700
    },
    {
      "epoch": 4.536,
      "grad_norm": 0.3481352925300598,
      "learning_rate": 1.856128e-05,
      "loss": 2.0421,
      "step": 141750
    },
    {
      "epoch": 4.5376,
      "grad_norm": 0.41517603397369385,
      "learning_rate": 1.849728e-05,
      "loss": 2.1204,
      "step": 141800
    },
    {
      "epoch": 4.5392,
      "grad_norm": 0.4492076337337494,
      "learning_rate": 1.843328e-05,
      "loss": 2.148,
      "step": 141850
    },
    {
      "epoch": 4.5408,
      "grad_norm": 0.4186698794364929,
      "learning_rate": 1.836928e-05,
      "loss": 2.1121,
      "step": 141900
    },
    {
      "epoch": 4.5424,
      "grad_norm": 0.3793834447860718,
      "learning_rate": 1.830528e-05,
      "loss": 2.1363,
      "step": 141950
    },
    {
      "epoch": 4.5440000000000005,
      "grad_norm": 0.4201696217060089,
      "learning_rate": 1.8241280000000003e-05,
      "loss": 2.0549,
      "step": 142000
    },
    {
      "epoch": 4.5456,
      "grad_norm": 0.3973486125469208,
      "learning_rate": 1.817728e-05,
      "loss": 2.1056,
      "step": 142050
    },
    {
      "epoch": 4.5472,
      "grad_norm": 0.38273313641548157,
      "learning_rate": 1.8113280000000004e-05,
      "loss": 2.1338,
      "step": 142100
    },
    {
      "epoch": 4.5488,
      "grad_norm": 0.39506226778030396,
      "learning_rate": 1.8049280000000002e-05,
      "loss": 2.1999,
      "step": 142150
    },
    {
      "epoch": 4.5504,
      "grad_norm": 0.3329034745693207,
      "learning_rate": 1.798528e-05,
      "loss": 2.0723,
      "step": 142200
    },
    {
      "epoch": 4.552,
      "grad_norm": 0.3507506847381592,
      "learning_rate": 1.7921280000000003e-05,
      "loss": 2.1402,
      "step": 142250
    },
    {
      "epoch": 4.5536,
      "grad_norm": 0.3901292681694031,
      "learning_rate": 1.785728e-05,
      "loss": 2.0734,
      "step": 142300
    },
    {
      "epoch": 4.5552,
      "grad_norm": 0.3368918299674988,
      "learning_rate": 1.779328e-05,
      "loss": 2.0884,
      "step": 142350
    },
    {
      "epoch": 4.5568,
      "grad_norm": 0.3152792751789093,
      "learning_rate": 1.7729280000000002e-05,
      "loss": 2.0666,
      "step": 142400
    },
    {
      "epoch": 4.5584,
      "grad_norm": 0.36654630303382874,
      "learning_rate": 1.766528e-05,
      "loss": 2.0849,
      "step": 142450
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.4646720588207245,
      "learning_rate": 1.760128e-05,
      "loss": 2.1285,
      "step": 142500
    },
    {
      "epoch": 4.5616,
      "grad_norm": 0.44681689143180847,
      "learning_rate": 1.753728e-05,
      "loss": 2.1341,
      "step": 142550
    },
    {
      "epoch": 4.5632,
      "grad_norm": 0.3877657651901245,
      "learning_rate": 1.747328e-05,
      "loss": 2.0683,
      "step": 142600
    },
    {
      "epoch": 4.5648,
      "grad_norm": 0.36458468437194824,
      "learning_rate": 1.740928e-05,
      "loss": 2.0944,
      "step": 142650
    },
    {
      "epoch": 4.5664,
      "grad_norm": 0.38100099563598633,
      "learning_rate": 1.734528e-05,
      "loss": 2.1399,
      "step": 142700
    },
    {
      "epoch": 4.568,
      "grad_norm": 0.3749547302722931,
      "learning_rate": 1.728128e-05,
      "loss": 2.1262,
      "step": 142750
    },
    {
      "epoch": 4.5696,
      "grad_norm": 0.3512268662452698,
      "learning_rate": 1.721728e-05,
      "loss": 2.0943,
      "step": 142800
    },
    {
      "epoch": 4.5712,
      "grad_norm": 0.38129037618637085,
      "learning_rate": 1.7153280000000003e-05,
      "loss": 2.0613,
      "step": 142850
    },
    {
      "epoch": 4.5728,
      "grad_norm": 0.3757883906364441,
      "learning_rate": 1.708928e-05,
      "loss": 2.1478,
      "step": 142900
    },
    {
      "epoch": 4.5744,
      "grad_norm": 0.3928784132003784,
      "learning_rate": 1.7025280000000003e-05,
      "loss": 2.0836,
      "step": 142950
    },
    {
      "epoch": 4.576,
      "grad_norm": 0.3476702868938446,
      "learning_rate": 1.6961280000000002e-05,
      "loss": 2.1313,
      "step": 143000
    },
    {
      "epoch": 4.5776,
      "grad_norm": 0.48175400495529175,
      "learning_rate": 1.689728e-05,
      "loss": 2.1015,
      "step": 143050
    },
    {
      "epoch": 4.5792,
      "grad_norm": 0.441127210855484,
      "learning_rate": 1.6833280000000002e-05,
      "loss": 2.0936,
      "step": 143100
    },
    {
      "epoch": 4.5808,
      "grad_norm": 0.35223811864852905,
      "learning_rate": 1.676928e-05,
      "loss": 2.0998,
      "step": 143150
    },
    {
      "epoch": 4.5824,
      "grad_norm": 0.42391160130500793,
      "learning_rate": 1.670528e-05,
      "loss": 2.1547,
      "step": 143200
    },
    {
      "epoch": 4.584,
      "grad_norm": 0.42601504921913147,
      "learning_rate": 1.664128e-05,
      "loss": 2.0902,
      "step": 143250
    },
    {
      "epoch": 4.5856,
      "grad_norm": 0.4251570701599121,
      "learning_rate": 1.657728e-05,
      "loss": 2.151,
      "step": 143300
    },
    {
      "epoch": 4.5872,
      "grad_norm": 0.41063007712364197,
      "learning_rate": 1.6513280000000002e-05,
      "loss": 2.1217,
      "step": 143350
    },
    {
      "epoch": 4.5888,
      "grad_norm": 0.42758283019065857,
      "learning_rate": 1.644928e-05,
      "loss": 2.0813,
      "step": 143400
    },
    {
      "epoch": 4.5904,
      "grad_norm": 0.41927242279052734,
      "learning_rate": 1.638528e-05,
      "loss": 2.1606,
      "step": 143450
    },
    {
      "epoch": 4.592,
      "grad_norm": 0.4166978895664215,
      "learning_rate": 1.632128e-05,
      "loss": 2.0938,
      "step": 143500
    },
    {
      "epoch": 4.5936,
      "grad_norm": 0.36949726939201355,
      "learning_rate": 1.625728e-05,
      "loss": 2.0662,
      "step": 143550
    },
    {
      "epoch": 4.5952,
      "grad_norm": 0.3857767581939697,
      "learning_rate": 1.6193279999999998e-05,
      "loss": 2.1381,
      "step": 143600
    },
    {
      "epoch": 4.5968,
      "grad_norm": 0.3745400011539459,
      "learning_rate": 1.612928e-05,
      "loss": 2.1604,
      "step": 143650
    },
    {
      "epoch": 4.5984,
      "grad_norm": 0.41545093059539795,
      "learning_rate": 1.6065280000000002e-05,
      "loss": 2.1483,
      "step": 143700
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.43818575143814087,
      "learning_rate": 1.600128e-05,
      "loss": 2.0828,
      "step": 143750
    },
    {
      "epoch": 4.6016,
      "grad_norm": 0.4216627776622772,
      "learning_rate": 1.5937280000000003e-05,
      "loss": 2.0898,
      "step": 143800
    },
    {
      "epoch": 4.6032,
      "grad_norm": 0.4411667287349701,
      "learning_rate": 1.587328e-05,
      "loss": 2.0534,
      "step": 143850
    },
    {
      "epoch": 4.6048,
      "grad_norm": 0.3720080852508545,
      "learning_rate": 1.580928e-05,
      "loss": 2.1485,
      "step": 143900
    },
    {
      "epoch": 4.6064,
      "grad_norm": 0.33844390511512756,
      "learning_rate": 1.5745280000000002e-05,
      "loss": 2.0523,
      "step": 143950
    },
    {
      "epoch": 4.608,
      "grad_norm": 0.5618656277656555,
      "learning_rate": 1.568128e-05,
      "loss": 2.122,
      "step": 144000
    },
    {
      "epoch": 4.6096,
      "grad_norm": 0.4260300397872925,
      "learning_rate": 1.5617280000000002e-05,
      "loss": 2.0634,
      "step": 144050
    },
    {
      "epoch": 4.6112,
      "grad_norm": 0.35536617040634155,
      "learning_rate": 1.555328e-05,
      "loss": 2.1201,
      "step": 144100
    },
    {
      "epoch": 4.6128,
      "grad_norm": 0.40015122294425964,
      "learning_rate": 1.548928e-05,
      "loss": 2.1156,
      "step": 144150
    },
    {
      "epoch": 4.6144,
      "grad_norm": 0.41442689299583435,
      "learning_rate": 1.542528e-05,
      "loss": 2.0978,
      "step": 144200
    },
    {
      "epoch": 4.616,
      "grad_norm": 0.4732098877429962,
      "learning_rate": 1.536128e-05,
      "loss": 2.0919,
      "step": 144250
    },
    {
      "epoch": 4.6176,
      "grad_norm": 0.37093424797058105,
      "learning_rate": 1.529728e-05,
      "loss": 2.0551,
      "step": 144300
    },
    {
      "epoch": 4.6192,
      "grad_norm": 0.4453614056110382,
      "learning_rate": 1.5233279999999999e-05,
      "loss": 2.1233,
      "step": 144350
    },
    {
      "epoch": 4.6208,
      "grad_norm": 0.3722034990787506,
      "learning_rate": 1.516928e-05,
      "loss": 2.0555,
      "step": 144400
    },
    {
      "epoch": 4.6224,
      "grad_norm": 0.38089922070503235,
      "learning_rate": 1.510528e-05,
      "loss": 2.0985,
      "step": 144450
    },
    {
      "epoch": 4.624,
      "grad_norm": 0.40341758728027344,
      "learning_rate": 1.5041280000000001e-05,
      "loss": 2.089,
      "step": 144500
    },
    {
      "epoch": 4.6256,
      "grad_norm": 0.3665343225002289,
      "learning_rate": 1.4977280000000002e-05,
      "loss": 2.0595,
      "step": 144550
    },
    {
      "epoch": 4.6272,
      "grad_norm": 0.3406001925468445,
      "learning_rate": 1.4913280000000002e-05,
      "loss": 2.0662,
      "step": 144600
    },
    {
      "epoch": 4.6288,
      "grad_norm": 0.4363648295402527,
      "learning_rate": 1.4849280000000002e-05,
      "loss": 2.0514,
      "step": 144650
    },
    {
      "epoch": 4.6304,
      "grad_norm": 0.405178964138031,
      "learning_rate": 1.4785280000000001e-05,
      "loss": 2.0899,
      "step": 144700
    },
    {
      "epoch": 4.632,
      "grad_norm": 0.45085588097572327,
      "learning_rate": 1.4721280000000001e-05,
      "loss": 2.0822,
      "step": 144750
    },
    {
      "epoch": 4.6336,
      "grad_norm": 0.4321271777153015,
      "learning_rate": 1.4657280000000001e-05,
      "loss": 2.0716,
      "step": 144800
    },
    {
      "epoch": 4.6352,
      "grad_norm": 0.41919344663619995,
      "learning_rate": 1.4593280000000002e-05,
      "loss": 2.1251,
      "step": 144850
    },
    {
      "epoch": 4.6368,
      "grad_norm": 0.46663698554039,
      "learning_rate": 1.452928e-05,
      "loss": 2.0766,
      "step": 144900
    },
    {
      "epoch": 4.6384,
      "grad_norm": 0.38639527559280396,
      "learning_rate": 1.446528e-05,
      "loss": 2.0814,
      "step": 144950
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.43779879808425903,
      "learning_rate": 1.440128e-05,
      "loss": 2.0975,
      "step": 145000
    },
    {
      "epoch": 4.6416,
      "grad_norm": 0.38830551505088806,
      "learning_rate": 1.433728e-05,
      "loss": 2.0573,
      "step": 145050
    },
    {
      "epoch": 4.6432,
      "grad_norm": 0.4222729504108429,
      "learning_rate": 1.427328e-05,
      "loss": 2.0364,
      "step": 145100
    },
    {
      "epoch": 4.6448,
      "grad_norm": 0.42840370535850525,
      "learning_rate": 1.420928e-05,
      "loss": 2.0286,
      "step": 145150
    },
    {
      "epoch": 4.6464,
      "grad_norm": 0.36509159207344055,
      "learning_rate": 1.414528e-05,
      "loss": 2.0608,
      "step": 145200
    },
    {
      "epoch": 4.648,
      "grad_norm": 0.37382134795188904,
      "learning_rate": 1.4081279999999999e-05,
      "loss": 2.0988,
      "step": 145250
    },
    {
      "epoch": 4.6495999999999995,
      "grad_norm": 0.35710409283638,
      "learning_rate": 1.4017279999999999e-05,
      "loss": 1.9983,
      "step": 145300
    },
    {
      "epoch": 4.6512,
      "grad_norm": 0.36348605155944824,
      "learning_rate": 1.3953280000000003e-05,
      "loss": 2.0712,
      "step": 145350
    },
    {
      "epoch": 4.6528,
      "grad_norm": 0.36264458298683167,
      "learning_rate": 1.3889280000000001e-05,
      "loss": 2.1632,
      "step": 145400
    },
    {
      "epoch": 4.6544,
      "grad_norm": 0.3788720667362213,
      "learning_rate": 1.3825280000000002e-05,
      "loss": 2.0987,
      "step": 145450
    },
    {
      "epoch": 4.656,
      "grad_norm": 0.4738155007362366,
      "learning_rate": 1.3761280000000002e-05,
      "loss": 2.1276,
      "step": 145500
    },
    {
      "epoch": 4.6576,
      "grad_norm": 0.36580801010131836,
      "learning_rate": 1.369728e-05,
      "loss": 2.1306,
      "step": 145550
    },
    {
      "epoch": 4.6592,
      "grad_norm": 0.44941189885139465,
      "learning_rate": 1.363328e-05,
      "loss": 2.1596,
      "step": 145600
    },
    {
      "epoch": 4.6608,
      "grad_norm": 0.4645044505596161,
      "learning_rate": 1.3569280000000001e-05,
      "loss": 2.1159,
      "step": 145650
    },
    {
      "epoch": 4.6624,
      "grad_norm": 0.3690727949142456,
      "learning_rate": 1.3505280000000001e-05,
      "loss": 2.0573,
      "step": 145700
    },
    {
      "epoch": 4.664,
      "grad_norm": 0.38843825459480286,
      "learning_rate": 1.344128e-05,
      "loss": 2.0701,
      "step": 145750
    },
    {
      "epoch": 4.6655999999999995,
      "grad_norm": 0.43812093138694763,
      "learning_rate": 1.337728e-05,
      "loss": 2.0743,
      "step": 145800
    },
    {
      "epoch": 4.6672,
      "grad_norm": 0.3561091423034668,
      "learning_rate": 1.331328e-05,
      "loss": 2.1204,
      "step": 145850
    },
    {
      "epoch": 4.6688,
      "grad_norm": 0.3624546527862549,
      "learning_rate": 1.324928e-05,
      "loss": 2.1434,
      "step": 145900
    },
    {
      "epoch": 4.6704,
      "grad_norm": 0.44377610087394714,
      "learning_rate": 1.318528e-05,
      "loss": 2.1125,
      "step": 145950
    },
    {
      "epoch": 4.672,
      "grad_norm": 0.3560066223144531,
      "learning_rate": 1.312128e-05,
      "loss": 2.1093,
      "step": 146000
    },
    {
      "epoch": 4.6736,
      "grad_norm": 0.45149675011634827,
      "learning_rate": 1.305728e-05,
      "loss": 2.1204,
      "step": 146050
    },
    {
      "epoch": 4.6752,
      "grad_norm": 0.4164106547832489,
      "learning_rate": 1.299328e-05,
      "loss": 2.1155,
      "step": 146100
    },
    {
      "epoch": 4.6768,
      "grad_norm": 0.34488847851753235,
      "learning_rate": 1.2929280000000002e-05,
      "loss": 2.075,
      "step": 146150
    },
    {
      "epoch": 4.6784,
      "grad_norm": 0.3901734948158264,
      "learning_rate": 1.2865280000000002e-05,
      "loss": 2.1508,
      "step": 146200
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.4042891263961792,
      "learning_rate": 1.2801280000000001e-05,
      "loss": 2.0938,
      "step": 146250
    },
    {
      "epoch": 4.6815999999999995,
      "grad_norm": 0.4704357087612152,
      "learning_rate": 1.2737280000000001e-05,
      "loss": 2.0577,
      "step": 146300
    },
    {
      "epoch": 4.6832,
      "grad_norm": 0.35403189063072205,
      "learning_rate": 1.2673280000000001e-05,
      "loss": 2.1901,
      "step": 146350
    },
    {
      "epoch": 4.6848,
      "grad_norm": 0.33005407452583313,
      "learning_rate": 1.2609280000000002e-05,
      "loss": 2.0387,
      "step": 146400
    },
    {
      "epoch": 4.6864,
      "grad_norm": 0.37553948163986206,
      "learning_rate": 1.254528e-05,
      "loss": 2.0672,
      "step": 146450
    },
    {
      "epoch": 4.688,
      "grad_norm": 0.38640883564949036,
      "learning_rate": 1.248128e-05,
      "loss": 2.0861,
      "step": 146500
    },
    {
      "epoch": 4.6896,
      "grad_norm": 0.3773367404937744,
      "learning_rate": 1.241728e-05,
      "loss": 2.0965,
      "step": 146550
    },
    {
      "epoch": 4.6912,
      "grad_norm": 0.44749903678894043,
      "learning_rate": 1.2353280000000001e-05,
      "loss": 2.0727,
      "step": 146600
    },
    {
      "epoch": 4.6928,
      "grad_norm": 0.38052067160606384,
      "learning_rate": 1.228928e-05,
      "loss": 2.0937,
      "step": 146650
    },
    {
      "epoch": 4.6944,
      "grad_norm": 0.4049280285835266,
      "learning_rate": 1.222528e-05,
      "loss": 2.1531,
      "step": 146700
    },
    {
      "epoch": 4.696,
      "grad_norm": 0.38367336988449097,
      "learning_rate": 1.216128e-05,
      "loss": 2.104,
      "step": 146750
    },
    {
      "epoch": 4.6975999999999996,
      "grad_norm": 0.3785130977630615,
      "learning_rate": 1.209728e-05,
      "loss": 2.0689,
      "step": 146800
    },
    {
      "epoch": 4.6992,
      "grad_norm": 0.36603251099586487,
      "learning_rate": 1.203328e-05,
      "loss": 2.0562,
      "step": 146850
    },
    {
      "epoch": 4.7008,
      "grad_norm": 0.3850797414779663,
      "learning_rate": 1.1969280000000001e-05,
      "loss": 2.1419,
      "step": 146900
    },
    {
      "epoch": 4.7024,
      "grad_norm": 0.38179996609687805,
      "learning_rate": 1.1905280000000001e-05,
      "loss": 2.1155,
      "step": 146950
    },
    {
      "epoch": 4.704,
      "grad_norm": 0.3679095208644867,
      "learning_rate": 1.184128e-05,
      "loss": 2.1471,
      "step": 147000
    },
    {
      "epoch": 4.7056000000000004,
      "grad_norm": 0.4014839231967926,
      "learning_rate": 1.177728e-05,
      "loss": 2.1325,
      "step": 147050
    },
    {
      "epoch": 4.7072,
      "grad_norm": 0.3462850749492645,
      "learning_rate": 1.171328e-05,
      "loss": 2.0934,
      "step": 147100
    },
    {
      "epoch": 4.7088,
      "grad_norm": 0.30832016468048096,
      "learning_rate": 1.164928e-05,
      "loss": 2.1233,
      "step": 147150
    },
    {
      "epoch": 4.7104,
      "grad_norm": 0.40360790491104126,
      "learning_rate": 1.1585280000000001e-05,
      "loss": 2.1176,
      "step": 147200
    },
    {
      "epoch": 4.712,
      "grad_norm": 0.4323970675468445,
      "learning_rate": 1.1521280000000001e-05,
      "loss": 2.1303,
      "step": 147250
    },
    {
      "epoch": 4.7136,
      "grad_norm": 0.3422973155975342,
      "learning_rate": 1.1457280000000002e-05,
      "loss": 2.1304,
      "step": 147300
    },
    {
      "epoch": 4.7152,
      "grad_norm": 0.35230880975723267,
      "learning_rate": 1.139328e-05,
      "loss": 2.1156,
      "step": 147350
    },
    {
      "epoch": 4.7168,
      "grad_norm": 0.457324355840683,
      "learning_rate": 1.132928e-05,
      "loss": 2.1375,
      "step": 147400
    },
    {
      "epoch": 4.7184,
      "grad_norm": 0.396441251039505,
      "learning_rate": 1.126528e-05,
      "loss": 2.1321,
      "step": 147450
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.31695449352264404,
      "learning_rate": 1.1201280000000001e-05,
      "loss": 2.1038,
      "step": 147500
    },
    {
      "epoch": 4.7216000000000005,
      "grad_norm": 0.3803451657295227,
      "learning_rate": 1.113728e-05,
      "loss": 2.0429,
      "step": 147550
    },
    {
      "epoch": 4.7232,
      "grad_norm": 0.4083847105503082,
      "learning_rate": 1.1073280000000001e-05,
      "loss": 2.1317,
      "step": 147600
    },
    {
      "epoch": 4.7248,
      "grad_norm": 0.35175177454948425,
      "learning_rate": 1.1009280000000002e-05,
      "loss": 2.1199,
      "step": 147650
    },
    {
      "epoch": 4.7264,
      "grad_norm": 0.30015480518341064,
      "learning_rate": 1.094528e-05,
      "loss": 2.1046,
      "step": 147700
    },
    {
      "epoch": 4.728,
      "grad_norm": 0.40580061078071594,
      "learning_rate": 1.088128e-05,
      "loss": 2.1756,
      "step": 147750
    },
    {
      "epoch": 4.7296,
      "grad_norm": 0.4131401479244232,
      "learning_rate": 1.0817280000000001e-05,
      "loss": 2.0546,
      "step": 147800
    },
    {
      "epoch": 4.7312,
      "grad_norm": 0.4422508180141449,
      "learning_rate": 1.075328e-05,
      "loss": 2.0469,
      "step": 147850
    },
    {
      "epoch": 4.7328,
      "grad_norm": 0.31588274240493774,
      "learning_rate": 1.068928e-05,
      "loss": 2.0509,
      "step": 147900
    },
    {
      "epoch": 4.7344,
      "grad_norm": 0.4420822560787201,
      "learning_rate": 1.062528e-05,
      "loss": 2.0794,
      "step": 147950
    },
    {
      "epoch": 4.736,
      "grad_norm": 0.4055553376674652,
      "learning_rate": 1.0561280000000002e-05,
      "loss": 2.1225,
      "step": 148000
    },
    {
      "epoch": 4.7376000000000005,
      "grad_norm": 0.3552461564540863,
      "learning_rate": 1.049728e-05,
      "loss": 2.0888,
      "step": 148050
    },
    {
      "epoch": 4.7392,
      "grad_norm": 0.41532400250434875,
      "learning_rate": 1.043328e-05,
      "loss": 2.1095,
      "step": 148100
    },
    {
      "epoch": 4.7408,
      "grad_norm": 0.4151565134525299,
      "learning_rate": 1.0369280000000001e-05,
      "loss": 2.1143,
      "step": 148150
    },
    {
      "epoch": 4.7424,
      "grad_norm": 0.38302385807037354,
      "learning_rate": 1.030528e-05,
      "loss": 2.1182,
      "step": 148200
    },
    {
      "epoch": 4.744,
      "grad_norm": 0.3962429165840149,
      "learning_rate": 1.024128e-05,
      "loss": 2.1112,
      "step": 148250
    },
    {
      "epoch": 4.7456,
      "grad_norm": 0.35285964608192444,
      "learning_rate": 1.017728e-05,
      "loss": 2.0775,
      "step": 148300
    },
    {
      "epoch": 4.7472,
      "grad_norm": 0.3379986882209778,
      "learning_rate": 1.011328e-05,
      "loss": 2.079,
      "step": 148350
    },
    {
      "epoch": 4.7488,
      "grad_norm": 0.36027294397354126,
      "learning_rate": 1.0049279999999999e-05,
      "loss": 2.0865,
      "step": 148400
    },
    {
      "epoch": 4.7504,
      "grad_norm": 0.3677651882171631,
      "learning_rate": 9.985280000000001e-06,
      "loss": 2.0463,
      "step": 148450
    },
    {
      "epoch": 4.752,
      "grad_norm": 0.41088220477104187,
      "learning_rate": 9.921280000000001e-06,
      "loss": 2.0395,
      "step": 148500
    },
    {
      "epoch": 4.7536000000000005,
      "grad_norm": 0.363387793302536,
      "learning_rate": 9.85728e-06,
      "loss": 1.9878,
      "step": 148550
    },
    {
      "epoch": 4.7552,
      "grad_norm": 0.3768831789493561,
      "learning_rate": 9.79328e-06,
      "loss": 2.0641,
      "step": 148600
    },
    {
      "epoch": 4.7568,
      "grad_norm": 0.3600611388683319,
      "learning_rate": 9.72928e-06,
      "loss": 2.0832,
      "step": 148650
    },
    {
      "epoch": 4.7584,
      "grad_norm": 0.3505742847919464,
      "learning_rate": 9.66528e-06,
      "loss": 2.1126,
      "step": 148700
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.37529265880584717,
      "learning_rate": 9.60128e-06,
      "loss": 2.0592,
      "step": 148750
    },
    {
      "epoch": 4.7616,
      "grad_norm": 0.4324481189250946,
      "learning_rate": 9.53728e-06,
      "loss": 2.0841,
      "step": 148800
    },
    {
      "epoch": 4.7632,
      "grad_norm": 0.3282737731933594,
      "learning_rate": 9.473280000000002e-06,
      "loss": 2.121,
      "step": 148850
    },
    {
      "epoch": 4.7648,
      "grad_norm": 0.3481026291847229,
      "learning_rate": 9.40928e-06,
      "loss": 2.0684,
      "step": 148900
    },
    {
      "epoch": 4.7664,
      "grad_norm": 0.402372807264328,
      "learning_rate": 9.34528e-06,
      "loss": 2.1251,
      "step": 148950
    },
    {
      "epoch": 4.768,
      "grad_norm": 0.4331321120262146,
      "learning_rate": 9.28128e-06,
      "loss": 2.1823,
      "step": 149000
    },
    {
      "epoch": 4.7696,
      "grad_norm": 0.4620818495750427,
      "learning_rate": 9.217280000000001e-06,
      "loss": 2.0954,
      "step": 149050
    },
    {
      "epoch": 4.7712,
      "grad_norm": 0.3459679186344147,
      "learning_rate": 9.15328e-06,
      "loss": 2.0749,
      "step": 149100
    },
    {
      "epoch": 4.7728,
      "grad_norm": 0.4139379858970642,
      "learning_rate": 9.08928e-06,
      "loss": 2.0562,
      "step": 149150
    },
    {
      "epoch": 4.7744,
      "grad_norm": 0.35193198919296265,
      "learning_rate": 9.02528e-06,
      "loss": 2.1175,
      "step": 149200
    },
    {
      "epoch": 4.776,
      "grad_norm": 0.40928834676742554,
      "learning_rate": 8.96128e-06,
      "loss": 2.1108,
      "step": 149250
    },
    {
      "epoch": 4.7776,
      "grad_norm": 0.42774277925491333,
      "learning_rate": 8.89728e-06,
      "loss": 2.068,
      "step": 149300
    },
    {
      "epoch": 4.7792,
      "grad_norm": 0.40413883328437805,
      "learning_rate": 8.833280000000001e-06,
      "loss": 2.0812,
      "step": 149350
    },
    {
      "epoch": 4.7808,
      "grad_norm": 0.3496951460838318,
      "learning_rate": 8.769280000000001e-06,
      "loss": 2.1508,
      "step": 149400
    },
    {
      "epoch": 4.7824,
      "grad_norm": 0.3792170286178589,
      "learning_rate": 8.70528e-06,
      "loss": 2.1011,
      "step": 149450
    },
    {
      "epoch": 4.784,
      "grad_norm": 0.39866191148757935,
      "learning_rate": 8.64128e-06,
      "loss": 2.1017,
      "step": 149500
    },
    {
      "epoch": 4.7856,
      "grad_norm": 0.33785441517829895,
      "learning_rate": 8.57728e-06,
      "loss": 2.1036,
      "step": 149550
    },
    {
      "epoch": 4.7872,
      "grad_norm": 0.5544142723083496,
      "learning_rate": 8.51328e-06,
      "loss": 2.1345,
      "step": 149600
    },
    {
      "epoch": 4.7888,
      "grad_norm": 0.3708856403827667,
      "learning_rate": 8.449280000000001e-06,
      "loss": 2.1204,
      "step": 149650
    },
    {
      "epoch": 4.7904,
      "grad_norm": 0.3529861271381378,
      "learning_rate": 8.385280000000001e-06,
      "loss": 2.1614,
      "step": 149700
    },
    {
      "epoch": 4.792,
      "grad_norm": 0.4255402684211731,
      "learning_rate": 8.321280000000001e-06,
      "loss": 2.1295,
      "step": 149750
    },
    {
      "epoch": 4.7936,
      "grad_norm": 0.43110936880111694,
      "learning_rate": 8.25728e-06,
      "loss": 2.1299,
      "step": 149800
    },
    {
      "epoch": 4.7952,
      "grad_norm": 0.40892645716667175,
      "learning_rate": 8.19328e-06,
      "loss": 2.1591,
      "step": 149850
    },
    {
      "epoch": 4.7968,
      "grad_norm": 0.4319004416465759,
      "learning_rate": 8.12928e-06,
      "loss": 2.0584,
      "step": 149900
    },
    {
      "epoch": 4.7984,
      "grad_norm": 0.41361725330352783,
      "learning_rate": 8.06528e-06,
      "loss": 2.043,
      "step": 149950
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.4249056577682495,
      "learning_rate": 8.00128e-06,
      "loss": 2.0782,
      "step": 150000
    },
    {
      "epoch": 4.8016,
      "grad_norm": 0.38486340641975403,
      "learning_rate": 7.93728e-06,
      "loss": 2.1545,
      "step": 150050
    },
    {
      "epoch": 4.8032,
      "grad_norm": 0.3704335689544678,
      "learning_rate": 7.873280000000002e-06,
      "loss": 2.13,
      "step": 150100
    },
    {
      "epoch": 4.8048,
      "grad_norm": 0.36561140418052673,
      "learning_rate": 7.80928e-06,
      "loss": 2.0353,
      "step": 150150
    },
    {
      "epoch": 4.8064,
      "grad_norm": 0.3780946135520935,
      "learning_rate": 7.74528e-06,
      "loss": 2.0518,
      "step": 150200
    },
    {
      "epoch": 4.808,
      "grad_norm": 0.5965492129325867,
      "learning_rate": 7.68128e-06,
      "loss": 2.122,
      "step": 150250
    },
    {
      "epoch": 4.8096,
      "grad_norm": 0.3835826516151428,
      "learning_rate": 7.61728e-06,
      "loss": 2.0872,
      "step": 150300
    },
    {
      "epoch": 4.8112,
      "grad_norm": 0.41792502999305725,
      "learning_rate": 7.5532800000000005e-06,
      "loss": 2.1456,
      "step": 150350
    },
    {
      "epoch": 4.8128,
      "grad_norm": 0.3187670409679413,
      "learning_rate": 7.48928e-06,
      "loss": 2.0831,
      "step": 150400
    },
    {
      "epoch": 4.8144,
      "grad_norm": 0.39852985739707947,
      "learning_rate": 7.425279999999999e-06,
      "loss": 2.0185,
      "step": 150450
    },
    {
      "epoch": 4.816,
      "grad_norm": 0.44602471590042114,
      "learning_rate": 7.361280000000001e-06,
      "loss": 2.1248,
      "step": 150500
    },
    {
      "epoch": 4.8176,
      "grad_norm": 0.4806636571884155,
      "learning_rate": 7.297280000000001e-06,
      "loss": 2.1088,
      "step": 150550
    },
    {
      "epoch": 4.8192,
      "grad_norm": 0.3981964886188507,
      "learning_rate": 7.233280000000001e-06,
      "loss": 2.1004,
      "step": 150600
    },
    {
      "epoch": 4.8208,
      "grad_norm": 0.4315413236618042,
      "learning_rate": 7.16928e-06,
      "loss": 2.0983,
      "step": 150650
    },
    {
      "epoch": 4.8224,
      "grad_norm": 0.4002537429332733,
      "learning_rate": 7.105280000000001e-06,
      "loss": 2.1401,
      "step": 150700
    },
    {
      "epoch": 4.824,
      "grad_norm": 0.3261917233467102,
      "learning_rate": 7.04128e-06,
      "loss": 2.0863,
      "step": 150750
    },
    {
      "epoch": 4.8256,
      "grad_norm": 0.35806262493133545,
      "learning_rate": 6.9772799999999995e-06,
      "loss": 2.0332,
      "step": 150800
    },
    {
      "epoch": 4.8272,
      "grad_norm": 0.39401569962501526,
      "learning_rate": 6.91328e-06,
      "loss": 2.1363,
      "step": 150850
    },
    {
      "epoch": 4.8288,
      "grad_norm": 0.4109637141227722,
      "learning_rate": 6.849280000000001e-06,
      "loss": 2.1284,
      "step": 150900
    },
    {
      "epoch": 4.8304,
      "grad_norm": 0.2979106307029724,
      "learning_rate": 6.785280000000001e-06,
      "loss": 2.1044,
      "step": 150950
    },
    {
      "epoch": 4.832,
      "grad_norm": 0.42304229736328125,
      "learning_rate": 6.721280000000001e-06,
      "loss": 2.0974,
      "step": 151000
    },
    {
      "epoch": 4.8336,
      "grad_norm": 0.3545896112918854,
      "learning_rate": 6.65728e-06,
      "loss": 2.1304,
      "step": 151050
    },
    {
      "epoch": 4.8352,
      "grad_norm": 0.4481304883956909,
      "learning_rate": 6.59328e-06,
      "loss": 2.1362,
      "step": 151100
    },
    {
      "epoch": 4.8368,
      "grad_norm": 0.4482831358909607,
      "learning_rate": 6.52928e-06,
      "loss": 2.1401,
      "step": 151150
    },
    {
      "epoch": 4.8384,
      "grad_norm": 0.32828786969184875,
      "learning_rate": 6.46528e-06,
      "loss": 2.1363,
      "step": 151200
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.39981332421302795,
      "learning_rate": 6.4012799999999995e-06,
      "loss": 2.1604,
      "step": 151250
    },
    {
      "epoch": 4.8416,
      "grad_norm": 0.35030755400657654,
      "learning_rate": 6.337280000000001e-06,
      "loss": 2.0952,
      "step": 151300
    },
    {
      "epoch": 4.8431999999999995,
      "grad_norm": 0.36819401383399963,
      "learning_rate": 6.273280000000001e-06,
      "loss": 2.1253,
      "step": 151350
    },
    {
      "epoch": 4.8448,
      "grad_norm": 0.45781129598617554,
      "learning_rate": 6.20928e-06,
      "loss": 2.1407,
      "step": 151400
    },
    {
      "epoch": 4.8464,
      "grad_norm": 0.37531915307044983,
      "learning_rate": 6.1452800000000006e-06,
      "loss": 2.0859,
      "step": 151450
    },
    {
      "epoch": 4.848,
      "grad_norm": 0.32774031162261963,
      "learning_rate": 6.08128e-06,
      "loss": 2.0949,
      "step": 151500
    },
    {
      "epoch": 4.8496,
      "grad_norm": 0.47542014718055725,
      "learning_rate": 6.01728e-06,
      "loss": 2.0981,
      "step": 151550
    },
    {
      "epoch": 4.8512,
      "grad_norm": 0.34763461351394653,
      "learning_rate": 5.95328e-06,
      "loss": 2.0855,
      "step": 151600
    },
    {
      "epoch": 4.8528,
      "grad_norm": 0.3907085955142975,
      "learning_rate": 5.889280000000001e-06,
      "loss": 2.0766,
      "step": 151650
    },
    {
      "epoch": 4.8544,
      "grad_norm": 0.36141103506088257,
      "learning_rate": 5.82528e-06,
      "loss": 2.1036,
      "step": 151700
    },
    {
      "epoch": 4.856,
      "grad_norm": 0.34946903586387634,
      "learning_rate": 5.7612800000000005e-06,
      "loss": 2.1352,
      "step": 151750
    },
    {
      "epoch": 4.8576,
      "grad_norm": 0.3541211485862732,
      "learning_rate": 5.69728e-06,
      "loss": 2.1072,
      "step": 151800
    },
    {
      "epoch": 4.8591999999999995,
      "grad_norm": 0.3845944404602051,
      "learning_rate": 5.63328e-06,
      "loss": 2.071,
      "step": 151850
    },
    {
      "epoch": 4.8608,
      "grad_norm": 0.3625536859035492,
      "learning_rate": 5.5692800000000005e-06,
      "loss": 2.1114,
      "step": 151900
    },
    {
      "epoch": 4.8624,
      "grad_norm": 0.40100499987602234,
      "learning_rate": 5.50528e-06,
      "loss": 2.0841,
      "step": 151950
    },
    {
      "epoch": 4.864,
      "grad_norm": 0.37837865948677063,
      "learning_rate": 5.44128e-06,
      "loss": 2.0908,
      "step": 152000
    },
    {
      "epoch": 4.8656,
      "grad_norm": 0.40913981199264526,
      "learning_rate": 5.3772800000000005e-06,
      "loss": 2.1028,
      "step": 152050
    },
    {
      "epoch": 4.8672,
      "grad_norm": 0.34337693452835083,
      "learning_rate": 5.313280000000001e-06,
      "loss": 2.1442,
      "step": 152100
    },
    {
      "epoch": 4.8688,
      "grad_norm": 0.35939523577690125,
      "learning_rate": 5.24928e-06,
      "loss": 2.1375,
      "step": 152150
    },
    {
      "epoch": 4.8704,
      "grad_norm": 0.40779611468315125,
      "learning_rate": 5.18528e-06,
      "loss": 2.06,
      "step": 152200
    },
    {
      "epoch": 4.872,
      "grad_norm": 0.41588225960731506,
      "learning_rate": 5.121280000000001e-06,
      "loss": 2.0687,
      "step": 152250
    },
    {
      "epoch": 4.8736,
      "grad_norm": 0.38181403279304504,
      "learning_rate": 5.05728e-06,
      "loss": 2.1272,
      "step": 152300
    },
    {
      "epoch": 4.8751999999999995,
      "grad_norm": 0.3708854615688324,
      "learning_rate": 4.99328e-06,
      "loss": 2.1014,
      "step": 152350
    },
    {
      "epoch": 4.8768,
      "grad_norm": 0.3879396915435791,
      "learning_rate": 4.92928e-06,
      "loss": 2.058,
      "step": 152400
    },
    {
      "epoch": 4.8784,
      "grad_norm": 0.40008312463760376,
      "learning_rate": 4.86528e-06,
      "loss": 2.0473,
      "step": 152450
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.3999009132385254,
      "learning_rate": 4.80128e-06,
      "loss": 2.1001,
      "step": 152500
    },
    {
      "epoch": 4.8816,
      "grad_norm": 0.39616769552230835,
      "learning_rate": 4.73728e-06,
      "loss": 2.0853,
      "step": 152550
    },
    {
      "epoch": 4.8832,
      "grad_norm": 0.41858306527137756,
      "learning_rate": 4.67328e-06,
      "loss": 2.0887,
      "step": 152600
    },
    {
      "epoch": 4.8848,
      "grad_norm": 0.3859216272830963,
      "learning_rate": 4.60928e-06,
      "loss": 2.0453,
      "step": 152650
    },
    {
      "epoch": 4.8864,
      "grad_norm": 0.37039512395858765,
      "learning_rate": 4.545280000000001e-06,
      "loss": 2.0658,
      "step": 152700
    },
    {
      "epoch": 4.888,
      "grad_norm": 0.3788066804409027,
      "learning_rate": 4.48128e-06,
      "loss": 2.0932,
      "step": 152750
    },
    {
      "epoch": 4.8896,
      "grad_norm": 0.4340724050998688,
      "learning_rate": 4.41728e-06,
      "loss": 2.1221,
      "step": 152800
    },
    {
      "epoch": 4.8911999999999995,
      "grad_norm": 0.38540196418762207,
      "learning_rate": 4.353280000000001e-06,
      "loss": 2.0665,
      "step": 152850
    },
    {
      "epoch": 4.8928,
      "grad_norm": 0.35491859912872314,
      "learning_rate": 4.28928e-06,
      "loss": 2.0977,
      "step": 152900
    },
    {
      "epoch": 4.8944,
      "grad_norm": 0.36223283410072327,
      "learning_rate": 4.22528e-06,
      "loss": 2.1338,
      "step": 152950
    },
    {
      "epoch": 4.896,
      "grad_norm": 0.4182359576225281,
      "learning_rate": 4.16128e-06,
      "loss": 2.1111,
      "step": 153000
    },
    {
      "epoch": 4.8976,
      "grad_norm": 0.3900017738342285,
      "learning_rate": 4.09728e-06,
      "loss": 2.1328,
      "step": 153050
    },
    {
      "epoch": 4.8992,
      "grad_norm": 0.34887704253196716,
      "learning_rate": 4.03328e-06,
      "loss": 2.1186,
      "step": 153100
    },
    {
      "epoch": 4.9008,
      "grad_norm": 0.4416937530040741,
      "learning_rate": 3.9692800000000006e-06,
      "loss": 2.104,
      "step": 153150
    },
    {
      "epoch": 4.9024,
      "grad_norm": 0.47174695134162903,
      "learning_rate": 3.90528e-06,
      "loss": 2.1092,
      "step": 153200
    },
    {
      "epoch": 4.904,
      "grad_norm": 0.35334110260009766,
      "learning_rate": 3.84128e-06,
      "loss": 2.1102,
      "step": 153250
    },
    {
      "epoch": 4.9056,
      "grad_norm": 0.3086842894554138,
      "learning_rate": 3.7772800000000005e-06,
      "loss": 2.1277,
      "step": 153300
    },
    {
      "epoch": 4.9072,
      "grad_norm": 0.3458985984325409,
      "learning_rate": 3.7132800000000004e-06,
      "loss": 2.0786,
      "step": 153350
    },
    {
      "epoch": 4.9088,
      "grad_norm": 0.37190812826156616,
      "learning_rate": 3.6492800000000002e-06,
      "loss": 2.1295,
      "step": 153400
    },
    {
      "epoch": 4.9104,
      "grad_norm": 0.3443310260772705,
      "learning_rate": 3.58528e-06,
      "loss": 2.1296,
      "step": 153450
    },
    {
      "epoch": 4.912,
      "grad_norm": 0.42881670594215393,
      "learning_rate": 3.5212800000000004e-06,
      "loss": 2.1472,
      "step": 153500
    },
    {
      "epoch": 4.9136,
      "grad_norm": 0.39329224824905396,
      "learning_rate": 3.45728e-06,
      "loss": 2.0653,
      "step": 153550
    },
    {
      "epoch": 4.9152000000000005,
      "grad_norm": 0.2880496382713318,
      "learning_rate": 3.39328e-06,
      "loss": 2.0672,
      "step": 153600
    },
    {
      "epoch": 4.9168,
      "grad_norm": 0.3824521601200104,
      "learning_rate": 3.32928e-06,
      "loss": 2.1219,
      "step": 153650
    },
    {
      "epoch": 4.9184,
      "grad_norm": 0.39917877316474915,
      "learning_rate": 3.2652800000000006e-06,
      "loss": 2.1146,
      "step": 153700
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.3308224081993103,
      "learning_rate": 3.2012800000000005e-06,
      "loss": 2.0363,
      "step": 153750
    },
    {
      "epoch": 4.9216,
      "grad_norm": 0.38401177525520325,
      "learning_rate": 3.13728e-06,
      "loss": 2.094,
      "step": 153800
    },
    {
      "epoch": 4.9232,
      "grad_norm": 0.4073036313056946,
      "learning_rate": 3.07328e-06,
      "loss": 2.0835,
      "step": 153850
    },
    {
      "epoch": 4.9248,
      "grad_norm": 0.3253495395183563,
      "learning_rate": 3.00928e-06,
      "loss": 2.1056,
      "step": 153900
    },
    {
      "epoch": 4.9264,
      "grad_norm": 0.5225905179977417,
      "learning_rate": 2.9452800000000003e-06,
      "loss": 2.0785,
      "step": 153950
    },
    {
      "epoch": 4.928,
      "grad_norm": 0.38625484704971313,
      "learning_rate": 2.88128e-06,
      "loss": 2.0886,
      "step": 154000
    },
    {
      "epoch": 4.9296,
      "grad_norm": 0.34764379262924194,
      "learning_rate": 2.8172800000000004e-06,
      "loss": 2.0333,
      "step": 154050
    },
    {
      "epoch": 4.9312000000000005,
      "grad_norm": 0.4454754889011383,
      "learning_rate": 2.7532800000000003e-06,
      "loss": 2.1342,
      "step": 154100
    },
    {
      "epoch": 4.9328,
      "grad_norm": 0.4295828938484192,
      "learning_rate": 2.68928e-06,
      "loss": 2.1043,
      "step": 154150
    },
    {
      "epoch": 4.9344,
      "grad_norm": 0.37469980120658875,
      "learning_rate": 2.62528e-06,
      "loss": 2.1328,
      "step": 154200
    },
    {
      "epoch": 4.936,
      "grad_norm": 0.3682090938091278,
      "learning_rate": 2.5612800000000002e-06,
      "loss": 2.1073,
      "step": 154250
    },
    {
      "epoch": 4.9376,
      "grad_norm": 0.32291263341903687,
      "learning_rate": 2.49728e-06,
      "loss": 2.0785,
      "step": 154300
    },
    {
      "epoch": 4.9392,
      "grad_norm": 0.3846701383590698,
      "learning_rate": 2.4332800000000004e-06,
      "loss": 2.1255,
      "step": 154350
    },
    {
      "epoch": 4.9408,
      "grad_norm": 0.3419444262981415,
      "learning_rate": 2.36928e-06,
      "loss": 2.148,
      "step": 154400
    },
    {
      "epoch": 4.9424,
      "grad_norm": 0.40151065587997437,
      "learning_rate": 2.30528e-06,
      "loss": 2.0893,
      "step": 154450
    },
    {
      "epoch": 4.944,
      "grad_norm": 0.3703435957431793,
      "learning_rate": 2.24128e-06,
      "loss": 2.0955,
      "step": 154500
    },
    {
      "epoch": 4.9456,
      "grad_norm": 0.4024084210395813,
      "learning_rate": 2.1772799999999998e-06,
      "loss": 2.1747,
      "step": 154550
    },
    {
      "epoch": 4.9472000000000005,
      "grad_norm": 0.33994385600090027,
      "learning_rate": 2.11328e-06,
      "loss": 2.0958,
      "step": 154600
    },
    {
      "epoch": 4.9488,
      "grad_norm": 0.34946098923683167,
      "learning_rate": 2.04928e-06,
      "loss": 2.1019,
      "step": 154650
    },
    {
      "epoch": 4.9504,
      "grad_norm": 0.36884453892707825,
      "learning_rate": 1.98528e-06,
      "loss": 2.082,
      "step": 154700
    },
    {
      "epoch": 4.952,
      "grad_norm": 0.3497551381587982,
      "learning_rate": 1.92128e-06,
      "loss": 2.1563,
      "step": 154750
    },
    {
      "epoch": 4.9536,
      "grad_norm": 0.42835238575935364,
      "learning_rate": 1.85728e-06,
      "loss": 2.0859,
      "step": 154800
    },
    {
      "epoch": 4.9552,
      "grad_norm": 0.389151930809021,
      "learning_rate": 1.79328e-06,
      "loss": 2.1223,
      "step": 154850
    },
    {
      "epoch": 4.9568,
      "grad_norm": 0.38098692893981934,
      "learning_rate": 1.7292800000000002e-06,
      "loss": 2.1371,
      "step": 154900
    },
    {
      "epoch": 4.9584,
      "grad_norm": 0.417880117893219,
      "learning_rate": 1.66528e-06,
      "loss": 2.0851,
      "step": 154950
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.3397437632083893,
      "learning_rate": 1.6012800000000001e-06,
      "loss": 2.093,
      "step": 155000
    }
  ],
  "logging_steps": 50,
  "max_steps": 156250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3019691921206477e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
