{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 5000,
  "global_step": 7815,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032,
      "grad_norm": 0.35668501257896423,
      "learning_rate": 0.00019874600127959053,
      "loss": 3.1848,
      "step": 50
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.3549189567565918,
      "learning_rate": 0.00019746641074856047,
      "loss": 2.7662,
      "step": 100
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.27428126335144043,
      "learning_rate": 0.00019618682021753042,
      "loss": 2.6762,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.263206422328949,
      "learning_rate": 0.00019490722968650034,
      "loss": 2.6631,
      "step": 200
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.28215962648391724,
      "learning_rate": 0.00019362763915547026,
      "loss": 2.5901,
      "step": 250
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.26663994789123535,
      "learning_rate": 0.00019234804862444018,
      "loss": 2.5477,
      "step": 300
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.2794972062110901,
      "learning_rate": 0.00019106845809341012,
      "loss": 2.6551,
      "step": 350
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.24798883497714996,
      "learning_rate": 0.00018978886756238007,
      "loss": 2.6611,
      "step": 400
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.28708958625793457,
      "learning_rate": 0.00018850927703134996,
      "loss": 2.6831,
      "step": 450
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.2918524146080017,
      "learning_rate": 0.0001872296865003199,
      "loss": 2.6252,
      "step": 500
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.2882082760334015,
      "learning_rate": 0.00018595009596928983,
      "loss": 2.6045,
      "step": 550
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.3082842230796814,
      "learning_rate": 0.00018467050543825977,
      "loss": 2.6783,
      "step": 600
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.2607249915599823,
      "learning_rate": 0.0001833909149072297,
      "loss": 2.644,
      "step": 650
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.3043314516544342,
      "learning_rate": 0.0001821113243761996,
      "loss": 2.6469,
      "step": 700
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.25553321838378906,
      "learning_rate": 0.00018083173384516956,
      "loss": 2.602,
      "step": 750
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.2428867220878601,
      "learning_rate": 0.00017955214331413948,
      "loss": 2.5376,
      "step": 800
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.24554917216300964,
      "learning_rate": 0.00017827255278310942,
      "loss": 2.7524,
      "step": 850
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.25183913111686707,
      "learning_rate": 0.00017699296225207934,
      "loss": 2.6179,
      "step": 900
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.28103023767471313,
      "learning_rate": 0.00017571337172104926,
      "loss": 2.6733,
      "step": 950
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.24141891300678253,
      "learning_rate": 0.0001744337811900192,
      "loss": 2.6574,
      "step": 1000
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.28103259205818176,
      "learning_rate": 0.00017315419065898913,
      "loss": 2.6446,
      "step": 1050
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.3028023838996887,
      "learning_rate": 0.00017187460012795907,
      "loss": 2.6266,
      "step": 1100
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.3137257397174835,
      "learning_rate": 0.000170595009596929,
      "loss": 2.6462,
      "step": 1150
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.2546202838420868,
      "learning_rate": 0.0001693154190658989,
      "loss": 2.6094,
      "step": 1200
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.30142396688461304,
      "learning_rate": 0.00016803582853486886,
      "loss": 2.6849,
      "step": 1250
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.27920612692832947,
      "learning_rate": 0.00016675623800383878,
      "loss": 2.5919,
      "step": 1300
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.29160168766975403,
      "learning_rate": 0.0001654766474728087,
      "loss": 2.628,
      "step": 1350
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.2567727267742157,
      "learning_rate": 0.00016419705694177864,
      "loss": 2.5876,
      "step": 1400
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.2682228982448578,
      "learning_rate": 0.00016291746641074856,
      "loss": 2.6016,
      "step": 1450
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.26444530487060547,
      "learning_rate": 0.0001616378758797185,
      "loss": 2.6074,
      "step": 1500
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.2533867359161377,
      "learning_rate": 0.00016035828534868843,
      "loss": 2.6041,
      "step": 1550
    },
    {
      "epoch": 1.02368,
      "grad_norm": 0.3106793761253357,
      "learning_rate": 0.00015907869481765835,
      "loss": 2.6678,
      "step": 1600
    },
    {
      "epoch": 1.05568,
      "grad_norm": 0.22588109970092773,
      "learning_rate": 0.0001577991042866283,
      "loss": 2.5367,
      "step": 1650
    },
    {
      "epoch": 1.08768,
      "grad_norm": 0.2854110300540924,
      "learning_rate": 0.00015651951375559821,
      "loss": 2.6585,
      "step": 1700
    },
    {
      "epoch": 1.11968,
      "grad_norm": 0.29044175148010254,
      "learning_rate": 0.00015523992322456816,
      "loss": 2.6091,
      "step": 1750
    },
    {
      "epoch": 1.15168,
      "grad_norm": 0.27527502179145813,
      "learning_rate": 0.00015396033269353808,
      "loss": 2.5587,
      "step": 1800
    },
    {
      "epoch": 1.18368,
      "grad_norm": 0.2907460033893585,
      "learning_rate": 0.000152680742162508,
      "loss": 2.6028,
      "step": 1850
    },
    {
      "epoch": 1.21568,
      "grad_norm": 0.2883146107196808,
      "learning_rate": 0.00015140115163147795,
      "loss": 2.5878,
      "step": 1900
    },
    {
      "epoch": 1.24768,
      "grad_norm": 0.3098805546760559,
      "learning_rate": 0.00015012156110044786,
      "loss": 2.5245,
      "step": 1950
    },
    {
      "epoch": 1.27968,
      "grad_norm": 0.33807411789894104,
      "learning_rate": 0.0001488419705694178,
      "loss": 2.6666,
      "step": 2000
    },
    {
      "epoch": 1.31168,
      "grad_norm": 0.2849603593349457,
      "learning_rate": 0.0001475623800383877,
      "loss": 2.6067,
      "step": 2050
    },
    {
      "epoch": 1.34368,
      "grad_norm": 0.30755287408828735,
      "learning_rate": 0.00014628278950735765,
      "loss": 2.5879,
      "step": 2100
    },
    {
      "epoch": 1.37568,
      "grad_norm": 0.3176899552345276,
      "learning_rate": 0.0001450031989763276,
      "loss": 2.6176,
      "step": 2150
    },
    {
      "epoch": 1.40768,
      "grad_norm": 0.2884513735771179,
      "learning_rate": 0.00014372360844529752,
      "loss": 2.6377,
      "step": 2200
    },
    {
      "epoch": 1.43968,
      "grad_norm": 0.325858473777771,
      "learning_rate": 0.00014244401791426743,
      "loss": 2.6461,
      "step": 2250
    },
    {
      "epoch": 1.47168,
      "grad_norm": 0.28780874609947205,
      "learning_rate": 0.00014116442738323735,
      "loss": 2.6195,
      "step": 2300
    },
    {
      "epoch": 1.5036800000000001,
      "grad_norm": 0.3386910855770111,
      "learning_rate": 0.0001398848368522073,
      "loss": 2.6141,
      "step": 2350
    },
    {
      "epoch": 1.5356800000000002,
      "grad_norm": 0.28699493408203125,
      "learning_rate": 0.00013860524632117725,
      "loss": 2.6407,
      "step": 2400
    },
    {
      "epoch": 1.56768,
      "grad_norm": 0.27602019906044006,
      "learning_rate": 0.00013732565579014717,
      "loss": 2.6317,
      "step": 2450
    },
    {
      "epoch": 1.59968,
      "grad_norm": 0.28952959179878235,
      "learning_rate": 0.00013604606525911708,
      "loss": 2.6405,
      "step": 2500
    },
    {
      "epoch": 1.63168,
      "grad_norm": 0.29700198769569397,
      "learning_rate": 0.000134766474728087,
      "loss": 2.5987,
      "step": 2550
    },
    {
      "epoch": 1.66368,
      "grad_norm": 0.3076232075691223,
      "learning_rate": 0.00013348688419705695,
      "loss": 2.5748,
      "step": 2600
    },
    {
      "epoch": 1.6956799999999999,
      "grad_norm": 0.28849223256111145,
      "learning_rate": 0.0001322072936660269,
      "loss": 2.583,
      "step": 2650
    },
    {
      "epoch": 1.7276799999999999,
      "grad_norm": 0.33262860774993896,
      "learning_rate": 0.00013092770313499682,
      "loss": 2.5889,
      "step": 2700
    },
    {
      "epoch": 1.75968,
      "grad_norm": 0.3187907636165619,
      "learning_rate": 0.00012964811260396674,
      "loss": 2.5962,
      "step": 2750
    },
    {
      "epoch": 1.79168,
      "grad_norm": 0.2838424742221832,
      "learning_rate": 0.00012836852207293665,
      "loss": 2.6102,
      "step": 2800
    },
    {
      "epoch": 1.82368,
      "grad_norm": 0.36958083510398865,
      "learning_rate": 0.0001270889315419066,
      "loss": 2.6377,
      "step": 2850
    },
    {
      "epoch": 1.85568,
      "grad_norm": 0.2975652813911438,
      "learning_rate": 0.00012580934101087655,
      "loss": 2.5736,
      "step": 2900
    },
    {
      "epoch": 1.88768,
      "grad_norm": 0.32866090536117554,
      "learning_rate": 0.00012452975047984644,
      "loss": 2.5221,
      "step": 2950
    },
    {
      "epoch": 1.91968,
      "grad_norm": 0.29578107595443726,
      "learning_rate": 0.00012325015994881639,
      "loss": 2.6257,
      "step": 3000
    },
    {
      "epoch": 1.95168,
      "grad_norm": 0.28861215710639954,
      "learning_rate": 0.0001219705694177863,
      "loss": 2.631,
      "step": 3050
    },
    {
      "epoch": 1.98368,
      "grad_norm": 0.3408018946647644,
      "learning_rate": 0.00012069097888675625,
      "loss": 2.5803,
      "step": 3100
    },
    {
      "epoch": 2.01536,
      "grad_norm": 0.3225470185279846,
      "learning_rate": 0.00011941138835572618,
      "loss": 2.6215,
      "step": 3150
    },
    {
      "epoch": 2.04736,
      "grad_norm": 0.31445491313934326,
      "learning_rate": 0.0001181317978246961,
      "loss": 2.6401,
      "step": 3200
    },
    {
      "epoch": 2.07936,
      "grad_norm": 0.3112960457801819,
      "learning_rate": 0.00011685220729366604,
      "loss": 2.557,
      "step": 3250
    },
    {
      "epoch": 2.11136,
      "grad_norm": 0.3048502802848816,
      "learning_rate": 0.00011557261676263596,
      "loss": 2.5772,
      "step": 3300
    },
    {
      "epoch": 2.14336,
      "grad_norm": 0.3003123104572296,
      "learning_rate": 0.00011429302623160589,
      "loss": 2.6197,
      "step": 3350
    },
    {
      "epoch": 2.17536,
      "grad_norm": 0.3328644633293152,
      "learning_rate": 0.00011301343570057583,
      "loss": 2.6389,
      "step": 3400
    },
    {
      "epoch": 2.20736,
      "grad_norm": 0.31102100014686584,
      "learning_rate": 0.00011173384516954575,
      "loss": 2.5014,
      "step": 3450
    },
    {
      "epoch": 2.23936,
      "grad_norm": 0.3493320047855377,
      "learning_rate": 0.00011045425463851569,
      "loss": 2.6668,
      "step": 3500
    },
    {
      "epoch": 2.27136,
      "grad_norm": 0.30911099910736084,
      "learning_rate": 0.0001091746641074856,
      "loss": 2.5721,
      "step": 3550
    },
    {
      "epoch": 2.30336,
      "grad_norm": 0.35525408387184143,
      "learning_rate": 0.00010789507357645554,
      "loss": 2.6091,
      "step": 3600
    },
    {
      "epoch": 2.33536,
      "grad_norm": 0.3399748206138611,
      "learning_rate": 0.00010661548304542549,
      "loss": 2.6079,
      "step": 3650
    },
    {
      "epoch": 2.36736,
      "grad_norm": 0.3503837287425995,
      "learning_rate": 0.00010533589251439539,
      "loss": 2.5564,
      "step": 3700
    },
    {
      "epoch": 2.39936,
      "grad_norm": 0.343363493680954,
      "learning_rate": 0.00010405630198336534,
      "loss": 2.6168,
      "step": 3750
    },
    {
      "epoch": 2.43136,
      "grad_norm": 0.3255160450935364,
      "learning_rate": 0.00010277671145233526,
      "loss": 2.6225,
      "step": 3800
    },
    {
      "epoch": 2.4633599999999998,
      "grad_norm": 0.3170522153377533,
      "learning_rate": 0.00010149712092130519,
      "loss": 2.6009,
      "step": 3850
    },
    {
      "epoch": 2.49536,
      "grad_norm": 0.3473260700702667,
      "learning_rate": 0.00010021753039027512,
      "loss": 2.5726,
      "step": 3900
    },
    {
      "epoch": 2.52736,
      "grad_norm": 0.34657156467437744,
      "learning_rate": 9.893793985924504e-05,
      "loss": 2.6658,
      "step": 3950
    },
    {
      "epoch": 2.55936,
      "grad_norm": 0.38504019379615784,
      "learning_rate": 9.765834932821497e-05,
      "loss": 2.511,
      "step": 4000
    },
    {
      "epoch": 2.59136,
      "grad_norm": 0.328885555267334,
      "learning_rate": 9.637875879718491e-05,
      "loss": 2.5921,
      "step": 4050
    },
    {
      "epoch": 2.62336,
      "grad_norm": 0.33791792392730713,
      "learning_rate": 9.509916826615484e-05,
      "loss": 2.6224,
      "step": 4100
    },
    {
      "epoch": 2.65536,
      "grad_norm": 0.31086769700050354,
      "learning_rate": 9.381957773512476e-05,
      "loss": 2.5507,
      "step": 4150
    },
    {
      "epoch": 2.68736,
      "grad_norm": 0.34834909439086914,
      "learning_rate": 9.253998720409469e-05,
      "loss": 2.6313,
      "step": 4200
    },
    {
      "epoch": 2.71936,
      "grad_norm": 0.3154197931289673,
      "learning_rate": 9.126039667306462e-05,
      "loss": 2.5457,
      "step": 4250
    },
    {
      "epoch": 2.75136,
      "grad_norm": 0.33065924048423767,
      "learning_rate": 8.998080614203456e-05,
      "loss": 2.5564,
      "step": 4300
    },
    {
      "epoch": 2.78336,
      "grad_norm": 0.32020285725593567,
      "learning_rate": 8.870121561100449e-05,
      "loss": 2.5023,
      "step": 4350
    },
    {
      "epoch": 2.81536,
      "grad_norm": 0.34003323316574097,
      "learning_rate": 8.742162507997441e-05,
      "loss": 2.6033,
      "step": 4400
    },
    {
      "epoch": 2.84736,
      "grad_norm": 0.3129398822784424,
      "learning_rate": 8.614203454894434e-05,
      "loss": 2.5927,
      "step": 4450
    },
    {
      "epoch": 2.87936,
      "grad_norm": 0.3378976285457611,
      "learning_rate": 8.486244401791426e-05,
      "loss": 2.5282,
      "step": 4500
    },
    {
      "epoch": 2.91136,
      "grad_norm": 0.32288292050361633,
      "learning_rate": 8.358285348688421e-05,
      "loss": 2.612,
      "step": 4550
    },
    {
      "epoch": 2.94336,
      "grad_norm": 0.3496977984905243,
      "learning_rate": 8.230326295585413e-05,
      "loss": 2.6079,
      "step": 4600
    },
    {
      "epoch": 2.9753600000000002,
      "grad_norm": 0.373251736164093,
      "learning_rate": 8.102367242482406e-05,
      "loss": 2.605,
      "step": 4650
    },
    {
      "epoch": 3.00704,
      "grad_norm": 0.31679025292396545,
      "learning_rate": 7.974408189379399e-05,
      "loss": 2.6011,
      "step": 4700
    },
    {
      "epoch": 3.03904,
      "grad_norm": 0.33722445368766785,
      "learning_rate": 7.846449136276391e-05,
      "loss": 2.5319,
      "step": 4750
    },
    {
      "epoch": 3.07104,
      "grad_norm": 0.33931076526641846,
      "learning_rate": 7.718490083173386e-05,
      "loss": 2.5839,
      "step": 4800
    },
    {
      "epoch": 3.10304,
      "grad_norm": 0.3887338936328888,
      "learning_rate": 7.590531030070378e-05,
      "loss": 2.5694,
      "step": 4850
    },
    {
      "epoch": 3.13504,
      "grad_norm": 0.3471428453922272,
      "learning_rate": 7.462571976967371e-05,
      "loss": 2.681,
      "step": 4900
    },
    {
      "epoch": 3.16704,
      "grad_norm": 0.360943078994751,
      "learning_rate": 7.334612923864363e-05,
      "loss": 2.6227,
      "step": 4950
    },
    {
      "epoch": 3.19904,
      "grad_norm": 0.3151426315307617,
      "learning_rate": 7.206653870761356e-05,
      "loss": 2.5642,
      "step": 5000
    },
    {
      "epoch": 3.23104,
      "grad_norm": 0.3291967809200287,
      "learning_rate": 7.07869481765835e-05,
      "loss": 2.643,
      "step": 5050
    },
    {
      "epoch": 3.26304,
      "grad_norm": 0.3447413146495819,
      "learning_rate": 6.950735764555343e-05,
      "loss": 2.5584,
      "step": 5100
    },
    {
      "epoch": 3.29504,
      "grad_norm": 0.31838518381118774,
      "learning_rate": 6.822776711452336e-05,
      "loss": 2.563,
      "step": 5150
    },
    {
      "epoch": 3.32704,
      "grad_norm": 0.3458521366119385,
      "learning_rate": 6.694817658349328e-05,
      "loss": 2.6005,
      "step": 5200
    },
    {
      "epoch": 3.3590400000000002,
      "grad_norm": 0.35317450761795044,
      "learning_rate": 6.566858605246321e-05,
      "loss": 2.5717,
      "step": 5250
    },
    {
      "epoch": 3.39104,
      "grad_norm": 0.3266039192676544,
      "learning_rate": 6.438899552143315e-05,
      "loss": 2.5648,
      "step": 5300
    },
    {
      "epoch": 3.42304,
      "grad_norm": 0.33925408124923706,
      "learning_rate": 6.310940499040308e-05,
      "loss": 2.5992,
      "step": 5350
    },
    {
      "epoch": 3.45504,
      "grad_norm": 0.3549526035785675,
      "learning_rate": 6.1829814459373e-05,
      "loss": 2.6572,
      "step": 5400
    },
    {
      "epoch": 3.48704,
      "grad_norm": 0.3444928824901581,
      "learning_rate": 6.055022392834293e-05,
      "loss": 2.6068,
      "step": 5450
    },
    {
      "epoch": 3.51904,
      "grad_norm": 0.3664470314979553,
      "learning_rate": 5.927063339731286e-05,
      "loss": 2.632,
      "step": 5500
    },
    {
      "epoch": 3.55104,
      "grad_norm": 0.34468182921409607,
      "learning_rate": 5.79910428662828e-05,
      "loss": 2.5499,
      "step": 5550
    },
    {
      "epoch": 3.58304,
      "grad_norm": 0.3784453868865967,
      "learning_rate": 5.671145233525272e-05,
      "loss": 2.5728,
      "step": 5600
    },
    {
      "epoch": 3.61504,
      "grad_norm": 0.4001767635345459,
      "learning_rate": 5.543186180422265e-05,
      "loss": 2.5715,
      "step": 5650
    },
    {
      "epoch": 3.64704,
      "grad_norm": 0.36878761649131775,
      "learning_rate": 5.415227127319258e-05,
      "loss": 2.5327,
      "step": 5700
    },
    {
      "epoch": 3.67904,
      "grad_norm": 0.4012157618999481,
      "learning_rate": 5.287268074216251e-05,
      "loss": 2.519,
      "step": 5750
    },
    {
      "epoch": 3.71104,
      "grad_norm": 0.40937340259552,
      "learning_rate": 5.159309021113245e-05,
      "loss": 2.6547,
      "step": 5800
    },
    {
      "epoch": 3.74304,
      "grad_norm": 0.48301881551742554,
      "learning_rate": 5.031349968010237e-05,
      "loss": 2.5739,
      "step": 5850
    },
    {
      "epoch": 3.7750399999999997,
      "grad_norm": 0.3569161891937256,
      "learning_rate": 4.90339091490723e-05,
      "loss": 2.5691,
      "step": 5900
    },
    {
      "epoch": 3.8070399999999998,
      "grad_norm": 0.4054175019264221,
      "learning_rate": 4.7754318618042225e-05,
      "loss": 2.5877,
      "step": 5950
    },
    {
      "epoch": 3.83904,
      "grad_norm": 0.39974719285964966,
      "learning_rate": 4.647472808701216e-05,
      "loss": 2.5767,
      "step": 6000
    },
    {
      "epoch": 3.87104,
      "grad_norm": 0.3875028192996979,
      "learning_rate": 4.5195137555982084e-05,
      "loss": 2.5634,
      "step": 6050
    },
    {
      "epoch": 3.90304,
      "grad_norm": 0.3908146619796753,
      "learning_rate": 4.391554702495202e-05,
      "loss": 2.5502,
      "step": 6100
    },
    {
      "epoch": 3.93504,
      "grad_norm": 0.39985620975494385,
      "learning_rate": 4.263595649392195e-05,
      "loss": 2.5582,
      "step": 6150
    },
    {
      "epoch": 3.96704,
      "grad_norm": 0.3019852638244629,
      "learning_rate": 4.1356365962891876e-05,
      "loss": 2.5568,
      "step": 6200
    },
    {
      "epoch": 3.99904,
      "grad_norm": 0.3681924343109131,
      "learning_rate": 4.007677543186181e-05,
      "loss": 2.5945,
      "step": 6250
    },
    {
      "epoch": 4.03072,
      "grad_norm": 0.3611981272697449,
      "learning_rate": 3.8797184900831735e-05,
      "loss": 2.6191,
      "step": 6300
    },
    {
      "epoch": 4.06272,
      "grad_norm": 0.351640522480011,
      "learning_rate": 3.751759436980167e-05,
      "loss": 2.54,
      "step": 6350
    },
    {
      "epoch": 4.09472,
      "grad_norm": 0.3843957185745239,
      "learning_rate": 3.6238003838771594e-05,
      "loss": 2.6069,
      "step": 6400
    },
    {
      "epoch": 4.12672,
      "grad_norm": 0.36108171939849854,
      "learning_rate": 3.495841330774152e-05,
      "loss": 2.5708,
      "step": 6450
    },
    {
      "epoch": 4.15872,
      "grad_norm": 0.3683532178401947,
      "learning_rate": 3.367882277671145e-05,
      "loss": 2.5961,
      "step": 6500
    },
    {
      "epoch": 4.19072,
      "grad_norm": 0.42676979303359985,
      "learning_rate": 3.2399232245681385e-05,
      "loss": 2.6071,
      "step": 6550
    },
    {
      "epoch": 4.22272,
      "grad_norm": 0.39907586574554443,
      "learning_rate": 3.111964171465132e-05,
      "loss": 2.5365,
      "step": 6600
    },
    {
      "epoch": 4.25472,
      "grad_norm": 0.38776907324790955,
      "learning_rate": 2.9840051183621244e-05,
      "loss": 2.6017,
      "step": 6650
    },
    {
      "epoch": 4.28672,
      "grad_norm": 0.3539324998855591,
      "learning_rate": 2.856046065259117e-05,
      "loss": 2.5707,
      "step": 6700
    },
    {
      "epoch": 4.31872,
      "grad_norm": 0.44461002945899963,
      "learning_rate": 2.7280870121561103e-05,
      "loss": 2.5848,
      "step": 6750
    },
    {
      "epoch": 4.35072,
      "grad_norm": 0.3505827486515045,
      "learning_rate": 2.600127959053103e-05,
      "loss": 2.5711,
      "step": 6800
    },
    {
      "epoch": 4.38272,
      "grad_norm": 0.39615893363952637,
      "learning_rate": 2.4721689059500962e-05,
      "loss": 2.6035,
      "step": 6850
    },
    {
      "epoch": 4.41472,
      "grad_norm": 0.3916971981525421,
      "learning_rate": 2.344209852847089e-05,
      "loss": 2.5156,
      "step": 6900
    },
    {
      "epoch": 4.44672,
      "grad_norm": 0.415968656539917,
      "learning_rate": 2.216250799744082e-05,
      "loss": 2.528,
      "step": 6950
    },
    {
      "epoch": 4.47872,
      "grad_norm": 0.39397677779197693,
      "learning_rate": 2.088291746641075e-05,
      "loss": 2.5568,
      "step": 7000
    },
    {
      "epoch": 4.51072,
      "grad_norm": 0.4189649820327759,
      "learning_rate": 1.960332693538068e-05,
      "loss": 2.5755,
      "step": 7050
    },
    {
      "epoch": 4.54272,
      "grad_norm": 0.372189998626709,
      "learning_rate": 1.832373640435061e-05,
      "loss": 2.5508,
      "step": 7100
    },
    {
      "epoch": 4.57472,
      "grad_norm": 0.36491522192955017,
      "learning_rate": 1.7044145873320538e-05,
      "loss": 2.5961,
      "step": 7150
    },
    {
      "epoch": 4.60672,
      "grad_norm": 0.38061457872390747,
      "learning_rate": 1.5764555342290468e-05,
      "loss": 2.5099,
      "step": 7200
    },
    {
      "epoch": 4.63872,
      "grad_norm": 0.37777358293533325,
      "learning_rate": 1.4484964811260399e-05,
      "loss": 2.5231,
      "step": 7250
    },
    {
      "epoch": 4.67072,
      "grad_norm": 0.4283186197280884,
      "learning_rate": 1.3205374280230327e-05,
      "loss": 2.5419,
      "step": 7300
    },
    {
      "epoch": 4.70272,
      "grad_norm": 0.35392796993255615,
      "learning_rate": 1.1925783749200256e-05,
      "loss": 2.5849,
      "step": 7350
    },
    {
      "epoch": 4.73472,
      "grad_norm": 0.3976552486419678,
      "learning_rate": 1.0646193218170185e-05,
      "loss": 2.6034,
      "step": 7400
    },
    {
      "epoch": 4.76672,
      "grad_norm": 0.4572399854660034,
      "learning_rate": 9.366602687140115e-06,
      "loss": 2.5745,
      "step": 7450
    },
    {
      "epoch": 4.79872,
      "grad_norm": 0.3824979364871979,
      "learning_rate": 8.087012156110044e-06,
      "loss": 2.6428,
      "step": 7500
    },
    {
      "epoch": 4.83072,
      "grad_norm": 0.3874027729034424,
      "learning_rate": 6.807421625079975e-06,
      "loss": 2.5447,
      "step": 7550
    },
    {
      "epoch": 4.86272,
      "grad_norm": 0.3693925738334656,
      "learning_rate": 5.527831094049904e-06,
      "loss": 2.5739,
      "step": 7600
    },
    {
      "epoch": 4.8947199999999995,
      "grad_norm": 0.3880341947078705,
      "learning_rate": 4.248240563019834e-06,
      "loss": 2.583,
      "step": 7650
    },
    {
      "epoch": 4.9267199999999995,
      "grad_norm": 0.45642325282096863,
      "learning_rate": 2.9686500319897637e-06,
      "loss": 2.5906,
      "step": 7700
    },
    {
      "epoch": 4.95872,
      "grad_norm": 0.3518381714820862,
      "learning_rate": 1.6890595009596929e-06,
      "loss": 2.5544,
      "step": 7750
    },
    {
      "epoch": 4.99072,
      "grad_norm": 0.4056564271450043,
      "learning_rate": 4.0946896992962257e-07,
      "loss": 2.5399,
      "step": 7800
    }
  ],
  "logging_steps": 50,
  "max_steps": 7815,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5875428337827840.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
