nohup: ignoring input
/home/mwei/NMT_projects/MAenv/lib/python3.13/site-packages/peft/tuners/lora/bnb.py:93: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.
  warnings.warn(
--- 1. Loading base model and LoRA adapter ---
Loading LoRA adapter from: ./am-25k-finetune/checkpoint-7815
--- Merging LoRA adapter into the base model ---
--- 2. Loading source test file: ./test_data/flores200_en.txt ---
--- 3. Generating translations ---
  0%|          | 0/64 [00:00<?, ?it/s]/home/mwei/NMT_projects/MAenv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
  2%|▏         | 1/64 [00:05<05:38,  5.38s/it]  3%|▎         | 2/64 [00:10<05:06,  4.94s/it]  5%|▍         | 3/64 [00:13<04:12,  4.13s/it]  6%|▋         | 4/64 [00:17<04:08,  4.14s/it]  8%|▊         | 5/64 [00:21<04:12,  4.29s/it]  9%|▉         | 6/64 [00:25<03:47,  3.92s/it] 11%|█         | 7/64 [00:29<03:47,  4.00s/it] 12%|█▎        | 8/64 [00:32<03:36,  3.87s/it] 14%|█▍        | 9/64 [00:36<03:24,  3.71s/it] 16%|█▌        | 10/64 [00:42<04:11,  4.66s/it] 17%|█▋        | 11/64 [00:48<04:20,  4.91s/it] 19%|█▉        | 12/64 [00:52<03:56,  4.56s/it] 20%|██        | 13/64 [00:59<04:28,  5.26s/it] 22%|██▏       | 14/64 [01:01<03:44,  4.50s/it] 23%|██▎       | 15/64 [01:05<03:30,  4.30s/it] 25%|██▌       | 16/64 [01:10<03:31,  4.41s/it] 27%|██▋       | 17/64 [01:14<03:25,  4.38s/it] 28%|██▊       | 18/64 [01:17<03:01,  3.94s/it] 30%|██▉       | 19/64 [01:21<02:51,  3.80s/it] 31%|███▏      | 20/64 [01:24<02:41,  3.66s/it] 33%|███▎      | 21/64 [01:31<03:17,  4.59s/it] 34%|███▍      | 22/64 [01:36<03:24,  4.86s/it] 36%|███▌      | 23/64 [01:43<03:42,  5.43s/it] 38%|███▊      | 24/64 [01:50<03:55,  5.88s/it] 39%|███▉      | 25/64 [01:53<03:19,  5.11s/it] 41%|████      | 26/64 [01:57<02:56,  4.63s/it] 42%|████▏     | 27/64 [02:03<03:15,  5.28s/it] 44%|████▍     | 28/64 [02:07<02:51,  4.75s/it] 45%|████▌     | 29/64 [02:10<02:27,  4.22s/it] 47%|████▋     | 30/64 [02:17<02:50,  5.02s/it] 48%|████▊     | 31/64 [02:21<02:37,  4.77s/it] 50%|█████     | 32/64 [02:25<02:21,  4.41s/it] 52%|█████▏    | 33/64 [02:27<02:00,  3.90s/it] 53%|█████▎    | 34/64 [02:31<01:57,  3.90s/it] 55%|█████▍    | 35/64 [02:37<02:12,  4.56s/it] 56%|█████▋    | 36/64 [02:44<02:27,  5.26s/it] 58%|█████▊    | 37/64 [02:47<02:01,  4.50s/it] 59%|█████▉    | 38/64 [02:50<01:45,  4.07s/it] 61%|██████    | 39/64 [02:53<01:32,  3.69s/it] 62%|██████▎   | 40/64 [03:00<01:50,  4.62s/it] 64%|██████▍   | 41/64 [03:04<01:41,  4.43s/it] 66%|██████▌   | 42/64 [03:06<01:24,  3.82s/it] 67%|██████▋   | 43/64 [03:09<01:17,  3.71s/it] 69%|██████▉   | 44/64 [03:14<01:16,  3.83s/it] 70%|███████   | 45/64 [03:17<01:11,  3.78s/it] 72%|███████▏  | 46/64 [03:21<01:05,  3.64s/it] 73%|███████▎  | 47/64 [03:24<01:02,  3.70s/it] 75%|███████▌  | 48/64 [03:28<00:57,  3.57s/it] 77%|███████▋  | 49/64 [03:34<01:07,  4.52s/it] 78%|███████▊  | 50/64 [03:37<00:56,  4.02s/it] 80%|███████▉  | 51/64 [03:40<00:49,  3.80s/it] 81%|████████▏ | 52/64 [03:44<00:43,  3.66s/it] 83%|████████▎ | 53/64 [03:48<00:42,  3.85s/it] 84%|████████▍ | 54/64 [03:52<00:37,  3.78s/it] 86%|████████▌ | 55/64 [03:55<00:32,  3.62s/it] 88%|████████▊ | 56/64 [04:02<00:36,  4.56s/it] 89%|████████▉ | 57/64 [04:05<00:29,  4.17s/it] 91%|█████████ | 58/64 [04:08<00:22,  3.70s/it] 92%|█████████▏| 59/64 [04:11<00:18,  3.61s/it] 94%|█████████▍| 60/64 [04:16<00:16,  4.03s/it] 95%|█████████▌| 61/64 [04:19<00:11,  3.83s/it] 97%|█████████▋| 62/64 [04:26<00:09,  4.70s/it] 98%|█████████▊| 63/64 [04:30<00:04,  4.48s/it]100%|██████████| 64/64 [04:32<00:00,  3.77s/it]100%|██████████| 64/64 [04:32<00:00,  4.26s/it]

--- 4. Calculating metrics ---
BLEU Score: 10.43
chrF++ Score: 35.56

--- 5. Machine Translation (MT) predictions successfully saved to: ./inflection/amharic_large_MT.txt ---

COMET not installed. Skipping. Install with: pip install unbabel-comet
